# é—®å·ç”Ÿæˆé€»è¾‘ä¸ä¿®æ”¹å†å²å®Œæ•´æ¢³ç†

> **æ–‡æ¡£ç›®çš„**ï¼šç³»ç»ŸåŒ–æ¢³ç†é—®å·ç”Ÿæˆçš„å®Œæ•´é€»è¾‘é“¾è·¯ã€æ¶æ„æ¼”è¿›å†å²ã€å·²çŸ¥é—®é¢˜ä¸ä¿®å¤è®°å½•
> 
> **ç»´æŠ¤åŸåˆ™**ï¼šæ¯æ¬¡ä¿®æ”¹é—®å·ç›¸å…³ä»£ç åï¼Œå¿…é¡»æ›´æ–°æœ¬æ–‡æ¡£å¯¹åº”ç« èŠ‚
>
> **æœ€åæ›´æ–°**ï¼š2025-12-12

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¶æ„](#1-ç³»ç»Ÿæ¶æ„)
2. [æ ¸å¿ƒæµç¨‹](#2-æ ¸å¿ƒæµç¨‹)
3. [å…³é”®æ¨¡å—](#3-å…³é”®æ¨¡å—)
4. [æ•°æ®æµè½¬](#4-æ•°æ®æµè½¬)
5. [å·²çŸ¥é—®é¢˜ä¸ä¿®å¤](#5-å·²çŸ¥é—®é¢˜ä¸ä¿®å¤)
6. [ä¿®æ”¹å†å²æ—¶é—´çº¿](#6-ä¿®æ”¹å†å²æ—¶é—´çº¿)
7. [æµ‹è¯•ç”¨ä¾‹](#7-æµ‹è¯•ç”¨ä¾‹)
8. [ç»´æŠ¤æŒ‡å—](#8-ç»´æŠ¤æŒ‡å—)

---

## 1. ç³»ç»Ÿæ¶æ„

### 1.1 æ•´ä½“æ¶æ„å›¾

```
ç”¨æˆ·è¾“å…¥
  â†“
éœ€æ±‚åˆ†æå¸ˆ (requirements_analyst.py)
  â†“ structured_data (20+å­—æ®µ)
  â†“
æ ¡å‡†é—®å·èŠ‚ç‚¹ (calibration_questionnaire.py)
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é—®å·ç”Ÿæˆç­–ç•¥é€‰æ‹©                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. LLMé©±åŠ¨ç”Ÿæˆ (llm_generator.py)    â”‚ â† v7.5æ–°å¢ï¼Œä¼˜å…ˆçº§æœ€é«˜
â”‚    â”œâ”€ æç¤ºè¯åŠ è½½                     â”‚
â”‚    â”œâ”€ åˆ†ææ‘˜è¦æ„å»º                   â”‚
â”‚    â””â”€ LLMè°ƒç”¨ + éªŒè¯                 â”‚
â”‚                                      â”‚
â”‚ 2. å›é€€æ–¹æ¡ˆ (generators.py)          â”‚ â† LLMå¤±è´¥æ—¶å…œåº•
â”‚    â”œâ”€ å…³é”®è¯æå– (context.py)       â”‚
â”‚    â”œâ”€ è§„åˆ™ç”Ÿæˆ                       â”‚
â”‚    â””â”€ æ¨¡æ¿å¡«å……                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
é—®å·è°ƒæ•´å™¨ (adjusters.py)
  â”œâ”€ é¢˜å‹é¡ºåºä¿®æ­£
  â”œâ”€ æ•°é‡åŠ¨æ€è°ƒæ•´
  â””â”€ å†²çª/ç†å¿µé—®é¢˜æ³¨å…¥
  â†“
é—®å·å±•ç¤º (å‰ç«¯)
  â†“
ç”¨æˆ·å›ç­”
  â†“
æ„å›¾è§£æ (intent_parser.py)
  â”œâ”€ skip: è·³è¿‡é—®å·
  â”œâ”€ add: è¡¥å……éœ€æ±‚
  â””â”€ default: æ­£å¸¸å›ç­”
  â†“
äºŒæ¬¡éœ€æ±‚åˆ†æ (å¦‚æœè¡¥å……éœ€æ±‚)
```

### 1.2 æ¶æ„æ¼”è¿›å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | æ¶æ„å˜åŒ– | åŠ¨æœº |
|------|------|---------|------|
| v1.0 | 2024-11 | çº¯è§„åˆ™ç”Ÿæˆå™¨ | åˆå§‹ç‰ˆæœ¬ |
| v2.0 | 2024-12 | å¼•å…¥å…³é”®è¯æå– | æå‡é’ˆå¯¹æ€§ |
| v7.2 | 2025-12-10 | æ¨¡å—åŒ–é‡æ„ | å‡å°‘46.2%ä»£ç  |
| v7.5 | 2025-12-11 | LLMé©±åŠ¨ç”Ÿæˆ | è§£å†³æ³›åŒ–é—®é¢˜ |
| v7.6 | 2025-12-11 | å­—æ®µæ‰©å±• | æå‡é—®é¢˜ç›¸å…³æ€§ |
| v7.9 | 2025-12-12 | ç±»å‹å…¼å®¹ä¿®å¤ | ä¿®å¤TypeError |

---

## 2. æ ¸å¿ƒæµç¨‹

### 2.1 å®Œæ•´æ‰§è¡Œæµç¨‹

```python
# 1. å…¥å£ï¼šcalibration_questionnaire.py execute()
def execute(state: ProjectAnalysisState) -> Command:
    # 2. æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    if state.get("calibration_processed"):
        return Command(goto="requirements_confirmation")
    
    # 3. è·å–éœ€æ±‚åˆ†æç»“æœ
    requirements_result = state.get("requirements_result", {})
    structured_data = requirements_result.get("structured_data", {})
    
    # 4. å°è¯•LLMç”Ÿæˆï¼ˆv7.5+ï¼‰
    try:
        questionnaire, source = LLMQuestionGenerator.generate(
            user_input=state.get("user_input", ""),
            structured_data=structured_data,
            llm_model=self.llm_model
        )
        
        if source == "llm_generated":
            logger.info("âœ… LLMç”ŸæˆæˆåŠŸ")
        else:
            logger.warning("âš ï¸ LLMè¿”å›å›é€€æ–¹æ¡ˆ")
            # ä½¿ç”¨å›é€€æ–¹æ¡ˆ
    except Exception as e:
        logger.error(f"âŒ LLMç”Ÿæˆå¤±è´¥: {e}")
        # 5. å›é€€åˆ°è§„åˆ™ç”Ÿæˆ
        questionnaire = FallbackQuestionGenerator.generate(
            user_input=state.get("user_input", ""),
            structured_data=structured_data
        )
    
    # 6. åŠ¨æ€è°ƒæ•´å™¨
    questionnaire = QuestionnaireAdjuster.adjust(
        questionnaire, 
        structured_data
    )
    
    # 7. è§¦å‘ä¸­æ–­ï¼Œç­‰å¾…ç”¨æˆ·å›ç­”
    user_response = interrupt(questionnaire_payload)
    
    # 8. æ„å›¾è§£æ
    intent = IntentParser.parse(user_response)
    
    # 9. æ ¹æ®æ„å›¾è·¯ç”±
    if intent == "skip":
        return Command(goto="requirements_confirmation")
    elif intent == "add":
        return Command(goto="requirements_analyst")  # äºŒæ¬¡åˆ†æ
    else:
        return Command(goto="requirements_confirmation")
```

### 2.2 å…³é”®å†³ç­–ç‚¹

| å†³ç­–ç‚¹ | æ¡ä»¶ | è¾“å‡º |
|-------|------|------|
| æ˜¯å¦ç”Ÿæˆé—®å· | `calibration_processed=False` | ç”Ÿæˆ |
| ä½¿ç”¨LLMè¿˜æ˜¯è§„åˆ™ | LLMå¯ç”¨ä¸”æœªè¶…æ—¶ | ä¼˜å…ˆLLM |
| æ˜¯å¦æ³¨å…¥ç†å¿µé—®é¢˜ | æ£€æµ‹åˆ°design_challengeçŸ›ç›¾ | æ³¨å…¥ |
| æ˜¯å¦æ³¨å…¥å†²çªé—®é¢˜ | æ£€æµ‹åˆ°budget/timelineçº¦æŸ | æ³¨å…¥ |
| æ˜¯å¦äºŒæ¬¡åˆ†æ | ç”¨æˆ·è¡¥å……éœ€æ±‚ï¼ˆintent=addï¼‰ | è§¦å‘ |

---

## 3. å…³é”®æ¨¡å—

### 3.1 LLMQuestionGenerator (v7.5+)

**æ–‡ä»¶**ï¼š`intelligent_project_analyzer/interaction/questionnaire/llm_generator.py`

**èŒè´£**ï¼šä½¿ç”¨LLMåŸºäºç”¨æˆ·è¾“å…¥å’Œéœ€æ±‚åˆ†æç”Ÿæˆé«˜åº¦å®šåˆ¶åŒ–çš„é—®å·

**æ ¸å¿ƒæ–¹æ³•**ï¼š

#### `generate()` - ä¸»å…¥å£
```python
@classmethod
def generate(
    cls,
    user_input: str,
    structured_data: Dict[str, Any],
    llm_model: Optional[Any] = None,
    timeout: int = 30
) -> Tuple[List[Dict[str, Any]], str]:
    """
    è¿”å›ï¼š(é—®é¢˜åˆ—è¡¨, æ¥æºæ ‡å¿—)
    æ¥æºæ ‡å¿—ï¼š
    - "llm_generated": LLMæˆåŠŸç”Ÿæˆ
    - "fallback": LLMå¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ
    """
```

#### `_build_analysis_summary()` - æ•°æ®æå–
```python
@classmethod
def _build_analysis_summary(cls, structured_data: Dict[str, Any]) -> str:
    """
    ä»éœ€æ±‚åˆ†æç»“æœä¸­æå–å…³é”®ä¿¡æ¯ï¼Œæ„å»ºLLMæç¤ºè¯ä¸Šä¸‹æ–‡
    
    v7.6æ‰©å±•å­—æ®µï¼š
    - project_overview (é¡¹ç›®æ¦‚è§ˆ)
    - core_objectives (æ ¸å¿ƒç›®æ ‡)
    - narrative_characters (äººç‰©å™äº‹)
    - physical_contexts (ç‰©ç†ç¯å¢ƒ)
    - constraints_opportunities (çº¦æŸä¸æœºé‡)
    - critical_questions_for_experts (ä¸“å®¶å…³é”®é—®é¢˜)
    
    v7.9ç±»å‹å…¼å®¹ä¿®å¤ï¼š
    - æ˜¾å¼å¤„ç† list/dict/str ä¸‰ç§ç±»å‹
    - é¿å… TypeError: sequence item 0: expected str instance, dict found
    """
```

**æç¤ºè¯é…ç½®**ï¼š
- æ–‡ä»¶ï¼š`config/prompts/questionnaire_generator.yaml`
- å…³é”®è¦æ±‚ï¼š
  - ç”Ÿæˆ7-10ä¸ªé—®é¢˜
  - å¼•ç”¨ç”¨æˆ·åŸè¯å…³é”®è¯
  - ç¦æ­¢æ³›åŒ–æ¨¡æ¿é—®é¢˜
  - å¿…é¡»åŒ…å«å®é™…æ¡ˆä¾‹çº¦æŸ

**ç›¸å…³æ€§éªŒè¯**ï¼š
```python
@classmethod
def _check_question_relevance(
    cls,
    questions: List[Dict[str, Any]],
    user_input: str,
    threshold: float = 0.5
) -> Tuple[float, List[str]]:
    """
    éªŒè¯ç”Ÿæˆçš„é—®é¢˜æ˜¯å¦ä¸ç”¨æˆ·è¾“å…¥ç›¸å…³
    
    ç­–ç•¥ï¼šæ£€æŸ¥é—®é¢˜ä¸­æ˜¯å¦åŒ…å«ç”¨æˆ·è¾“å…¥çš„å…³é”®è¯
    é˜ˆå€¼ï¼šè‡³å°‘50%çš„é—®é¢˜éœ€è¦åŒ…å«ç”¨æˆ·å…³é”®è¯
    """
```

### 3.2 FallbackQuestionGenerator (å…œåº•æ–¹æ¡ˆ)

**æ–‡ä»¶**ï¼š`intelligent_project_analyzer/interaction/questionnaire/generators.py`

**èŒè´£**ï¼šè§„åˆ™é©±åŠ¨çš„é—®å·ç”Ÿæˆï¼Œä½œä¸ºLLMå¤±è´¥æ—¶çš„å…œåº•æ–¹æ¡ˆ

**æ ¸å¿ƒé€»è¾‘**ï¼š
1. å…³é”®è¯æå–ï¼ˆKeywordExtractorï¼‰
2. æ ¸å¿ƒæ¦‚å¿µ/çŸ›ç›¾è¯†åˆ«
3. é¡¹ç›®ç±»å‹åˆ¤æ–­
4. æ¨¡æ¿å¡«å…… + åŠ¨æ€é€‰é¡¹ç”Ÿæˆ

**ä¼˜åŠ¿**ï¼šå¯é ã€å¿«é€Ÿã€å¯é¢„æµ‹
**åŠ£åŠ¿**ï¼šé’ˆå¯¹æ€§ä¸å¦‚LLMã€æ˜“ç”Ÿæˆé€šç”¨é—®é¢˜

### 3.3 KeywordExtractor (å…³é”®è¯æå–)

**æ–‡ä»¶**ï¼š`intelligent_project_analyzer/interaction/questionnaire/context.py`

**èŒè´£**ï¼šä»éœ€æ±‚åˆ†æç»“æœä¸­æå–å…³é”®è¯å’Œæ ¸å¿ƒæ¦‚å¿µ

**æå–ç­–ç•¥**ï¼š
```python
# 1. é¢†åŸŸè¯†åˆ«
domain = detect_domain(structured_data)  # ä½å®…/å•†ä¸š/æ–‡åŒ–ç­‰

# 2. æ ¸å¿ƒæ¦‚å¿µæå–ï¼ˆæ­£åˆ™+é™åˆ¶é•¿åº¦ï¼Œé¿å…ç¾éš¾æ€§å›æº¯ï¼‰
CONCEPT_PATTERNS = [
    r'"([^""]{2,15})"',  # ä¸­æ–‡å¼•å·
    r'"([^"]{2,15})"',   # è‹±æ–‡å¼•å·
    r'ã€Œ([^ã€]{2,15})ã€', # æ—¥å¼å¼•å·
    r'ã€([^ã€‘]{2,15})ã€‘'  # æ–¹æ‹¬å·
]

# 3. æ–‡æœ¬é•¿åº¦é™åˆ¶ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
safe_text = text[:500]  # v7.4.2: 2000â†’500ï¼Œé¿å…æ­£åˆ™è¶…æ—¶

# 4. åŒ¹é…æ¬¡æ•°é™åˆ¶
matches = re.findall(pattern, safe_text[:500])
concepts.extend(matches[:5])  # æ¯ä¸ªæ¨¡å¼æœ€å¤š5ä¸ª
```

**å†å²é—®é¢˜**ï¼š
- v7.4.2ä¹‹å‰ï¼šå¤æ‚æ­£åˆ™å¯¼è‡´ç¾éš¾æ€§å›æº¯ï¼ˆCPU 100%ï¼Œè¶…æ—¶60s+ï¼‰
- v7.4.2ä¿®å¤ï¼šç®€åŒ–æ­£åˆ™ã€é™åˆ¶é•¿åº¦ã€é™åˆ¶åŒ¹é…æ¬¡æ•°

### 3.4 QuestionnaireAdjuster (åŠ¨æ€è°ƒæ•´å™¨)

**æ–‡ä»¶**ï¼š`intelligent_project_analyzer/interaction/questionnaire/adjusters.py`

**èŒè´£**ï¼š
1. é¢˜å‹é¡ºåºä¿®æ­£ï¼ˆå•é€‰â†’å¤šé€‰â†’å¼€æ”¾ï¼‰
2. æ•°é‡åŠ¨æ€è°ƒæ•´ï¼ˆ8-10ä¸ªä¸ºæœ€ä½³ï¼‰
3. ç†å¿µ/å†²çªé—®é¢˜æ³¨å…¥

**è°ƒæ•´ç­–ç•¥**ï¼š
```python
# 1. æ•°é‡åˆ¤æ–­
if len(questions) < 8:
    # è½»åº¦æ‰©å±•ï¼ˆä¿ç•™å…¨éƒ¨ï¼Œä¸è£å‰ªï¼‰
elif 8 <= len(questions) <= 10:
    # è½»åº¦è£å‰ªï¼ˆä¿ç•™80%ç†å¿µé—®é¢˜ï¼‰
elif len(questions) > 10:
    # é‡åº¦è£å‰ªï¼ˆä¿ç•™60%ç†å¿µé—®é¢˜ï¼‰

# 2. ç†å¿µé—®é¢˜æ³¨å…¥
if design_challengeåŒ…å«çŸ›ç›¾:
    ç”Ÿæˆç†å¿µé€‰æ‹©é—®é¢˜ï¼ˆä»çŸ›ç›¾æå–A vs Bï¼‰
    ç”Ÿæˆå¼€æ”¾æ¢ç´¢é—®é¢˜ï¼ˆåŸºäºcritical_questionsï¼‰

# 3. å†²çªé—®é¢˜æ³¨å…¥
if æ£€æµ‹åˆ°budget/timelineçº¦æŸ:
    ç”Ÿæˆèµ„æºåˆ†é…é—®é¢˜
    æ³¨å…¥åˆ°é—®å·ç¬¬2é¢˜ä½ç½®
```

---

## 4. æ•°æ®æµè½¬

### 4.1 å…³é”®æ•°æ®ç»“æ„

#### è¾“å…¥ï¼šstructured_data (éœ€æ±‚åˆ†æç»“æœ)

```python
{
    # æ ¸å¿ƒå­—æ®µï¼ˆv7.6æ‰©å±•ï¼‰
    "project_overview": "é¡¹ç›®æ•´ä½“æè¿°",
    "project_task": "å…·ä½“ä»»åŠ¡åˆ—è¡¨" | ["ä»»åŠ¡1", "ä»»åŠ¡2"],
    "core_objectives": ["ç›®æ ‡1", "ç›®æ ‡2"],
    "project_type": "personal_residential" | "commercial_enterprise" | ...,
    
    # å™äº‹ä¸åœºæ™¯
    "narrative_characters": "äººç‰©å™äº‹" | ["è§’è‰²1", "è§’è‰²2"],
    "character_narrative": "ï¼ˆåˆ«åï¼Œå…¼å®¹æ—§ç‰ˆï¼‰",
    "physical_contexts": "ç‰©ç†ç¯å¢ƒ" | ["ç¯å¢ƒ1", "ç¯å¢ƒ2"],
    
    # æŒ‘æˆ˜ä¸çº¦æŸ
    "design_challenge": "æ ¸å¿ƒè®¾è®¡æŒ‘æˆ˜ï¼ˆå¯èƒ½åŒ…å«çŸ›ç›¾ï¼šA vs Bï¼‰",
    "core_tension": "æ ¸å¿ƒå¼ åŠ›",
    "resource_constraints": "èµ„æºçº¦æŸ",
    "constraints_opportunities": {
        "constraints": "çº¦æŸæè¿°",
        "opportunities": "æœºé‡æè¿°"
    } | "å­—ç¬¦ä¸²å½¢å¼",
    
    # ä¸“å®¶äº¤æ¥
    "expert_handoff": {
        "design_challenge_spectrum": {
            "æç«¯A": {"æ ‡ç­¾": "..."},
            "æç«¯B": {"æ ‡ç­¾": "..."}
        },
        "required_roles": ["V2_è®¾è®¡æ€»ç›‘", "V4_è®¾è®¡ç ”ç©¶å‘˜"],
        "critical_questions_for_experts": {
            "è§’è‰²1": ["é—®é¢˜1", "é—®é¢˜2"] | {"key": "value"} | "å­—ç¬¦ä¸²",
            "è§’è‰²2": ...
        }
    }
}
```

#### è¾“å‡ºï¼šquestionnaire (é—®å·æ•°æ®)

```json
{
    "introduction": "é—®å·å¼•å¯¼è¯­",
    "questions": [
        {
            "id": "core_tension_priority",
            "question": "å½“'A'ä¸'B'äº§ç”Ÿå†²çªæ—¶ï¼Œæ‚¨æ›´å€¾å‘äºï¼Ÿ(å•é€‰)",
            "type": "single_choice",
            "options": ["é€‰é¡¹1", "é€‰é¡¹2", "é€‰é¡¹3"],
            "context": "è¿™æ˜¯æœ¬é¡¹ç›®æœ€æ ¸å¿ƒçš„æˆ˜ç•¥é€‰æ‹©...",
            "source": "v1_strategic_insight",  // å¯é€‰ï¼šæ ‡è®°é—®é¢˜æ¥æº
            "dimension": "philosophy"  // å¯é€‰ï¼šæ ‡è®°é—®é¢˜ç»´åº¦
        }
    ],
    "note": "åŸºäºæ‚¨çš„éœ€æ±‚æ·±åº¦åˆ†æç»“æœç”Ÿæˆçš„å®šåˆ¶é—®å·"
}
```

### 4.2 å­—æ®µæ˜ å°„è¡¨

| éœ€æ±‚åˆ†æå­—æ®µ | é—®å·ç”Ÿæˆç”¨é€” | æå–ä¼˜å…ˆçº§ |
|------------|------------|-----------|
| project_overview | æç¤ºè¯ä¸Šä¸‹æ–‡ | é«˜ |
| design_challenge | ç†å¿µå†²çªé—®é¢˜ | é«˜ |
| core_objectives | æç¤ºè¯ä¸Šä¸‹æ–‡ | ä¸­ |
| resource_constraints | å†²çªé—®é¢˜ç”Ÿæˆ | é«˜ |
| narrative_characters | æç¤ºè¯ä¸Šä¸‹æ–‡ | ä¸­ |
| physical_contexts | æç¤ºè¯ä¸Šä¸‹æ–‡ | ä¸­ |
| critical_questions | å¼€æ”¾æ¢ç´¢é—®é¢˜ | ä¸­ |

---

## 5. å·²çŸ¥é—®é¢˜ä¸ä¿®å¤

### 5.1 é—®é¢˜è¿½è¸ªè¡¨

| é—®é¢˜ID | æ—¥æœŸ | ç—‡çŠ¶ | æ ¹å›  | ä¿®å¤ç‰ˆæœ¬ | çŠ¶æ€ |
|-------|------|------|------|---------|------|
| Q-001 | 2025-12-10 | é—®å·åªæœ‰4ä¸ªé—®é¢˜ | æç¤ºè¯çº¦æŸä¸è¶³ | v7.5 | âœ…å·²ä¿®å¤ |
| Q-002 | 2025-12-10 | é—®é¢˜æ³›åŒ–ï¼Œæ— é’ˆå¯¹æ€§ | æœªå¼•ç”¨ç”¨æˆ·åŸè¯ | v7.5 | âœ…å·²ä¿®å¤ |
| Q-003 | 2025-12-11 | æ­£åˆ™è¶…æ—¶ï¼ŒCPU 100% | ç¾éš¾æ€§å›æº¯ | v7.4.2 | âœ…å·²ä¿®å¤ |
| Q-004 | 2025-12-11 | é—®é¢˜ç›¸å…³æ€§ä½ | å­—æ®µæå–ä¸å®Œæ•´ | v7.6 | âœ…å·²ä¿®å¤ |
| Q-005 | 2025-12-12 | TypeError: expected str, dict found | critical_questionsç±»å‹æœªå¤„ç† | v7.9 | âœ…å·²ä¿®å¤ |

### 5.2 è¯¦ç»†ä¿®å¤è®°å½•

#### Q-001ï¼šé—®å·åªæœ‰4ä¸ªé—®é¢˜ (v7.5ä¿®å¤)

**ç—‡çŠ¶**ï¼š
- é…ç½®è¦æ±‚7-10ä¸ªé—®é¢˜ï¼Œå®é™…åªç”Ÿæˆ4ä¸ª
- ç”¨æˆ·è®¤ä¸ºé—®é¢˜ä¸å¤Ÿæ·±å…¥

**æ ¹å› **ï¼š
1. æç¤ºè¯ç¼ºä¹å¼ºåˆ¶çº¦æŸ
2. LLMå®¹æ˜“ç”Ÿæˆç®€åŒ–ç‰ˆæœ¬
3. æ— ç›¸å…³æ€§éªŒè¯æœºåˆ¶

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```yaml
# questionnaire_generator.yaml
system_prompt: |
  ğŸš¨ å¼ºåˆ¶è¦æ±‚ï¼š
  - å¿…é¡»ç”Ÿæˆ **7-10ä¸ªé—®é¢˜**
  - æ¯ä¸ªé—®é¢˜å¿…é¡»å¼•ç”¨ç”¨æˆ·åŸè¯ä¸­çš„å…³é”®è¯/æ•°å­—
  - ç¦æ­¢ç”Ÿæˆæ³›åŒ–æ¨¡æ¿é—®é¢˜ï¼ˆå¦‚"æ‚¨å–œæ¬¢ä»€ä¹ˆé£æ ¼ï¼Ÿ"ï¼‰
  
  ç¤ºä¾‹ï¼š
  âœ… æ­£ç¡®ï¼š"æ‚¨æåˆ°'ä¸‰ä»£åŒå ‚'ï¼Œå½“è€äººçš„å®‰é™éœ€æ±‚ä¸å­©å­çš„æ´»åŠ¨ç©ºé—´å†²çªæ—¶..."
  âŒ é”™è¯¯ï¼š"æ‚¨å¸Œæœ›ä½å®…ä¸­æœ‰å“ªäº›åŠŸèƒ½åŒºåŸŸï¼Ÿ"
```

**æ•ˆæœ**ï¼š
- é—®é¢˜æ•°é‡ç¨³å®šåœ¨7-10ä¸ª
- é—®é¢˜é’ˆå¯¹æ€§æ˜¾è‘—æå‡

#### Q-002ï¼šé—®é¢˜æ³›åŒ–ï¼Œæ— é’ˆå¯¹æ€§ (v7.5ä¿®å¤)

**ç—‡çŠ¶**ï¼š
- ä¸åŒç”¨æˆ·è¾“å…¥ç”Ÿæˆå‡ ä¹ç›¸åŒçš„é—®é¢˜
- é—®é¢˜åƒé€šç”¨æ¨¡æ¿æ‹¼å‡‘

**æ ¹å› **ï¼š
1. æç¤ºè¯æœªæ˜ç¡®è¦æ±‚å¼•ç”¨ç”¨æˆ·åŸè¯
2. æ— ç›¸å…³æ€§éªŒè¯
3. å›é€€æ–¹æ¡ˆè´¨é‡ä¸é«˜

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# llm_generator.py
# 1. å¢åŠ ç›¸å…³æ€§éªŒè¯
relevance_score, low_relevance_questions = cls._check_question_relevance(
    validated_questions, user_input
)
if relevance_score < 0.5:
    logger.warning(f"âš ï¸ é—®é¢˜ç›¸å…³æ€§ä½: {low_relevance_questions}")

# 2. æç¤ºè¯å¼ºåˆ¶è¦æ±‚
"""
æ¯ä¸ªé—®é¢˜å¿…é¡»åŒ…å«ï¼š
- ç”¨æˆ·åŸè¯ä¸­çš„å…³é”®è¯ï¼ˆåŠ å¼•å·ï¼‰
- ç”¨æˆ·æåˆ°çš„å…·ä½“æ•°å­—/çº¦æŸ
- é’ˆå¯¹ç”¨æˆ·åœºæ™¯çš„å…·ä½“å†²çª
"""
```

**æ•ˆæœ**ï¼š
- é—®é¢˜ä¸ç”¨æˆ·è¾“å…¥é«˜åº¦ç›¸å…³
- 90%ä»¥ä¸Šé—®é¢˜åŒ…å«ç”¨æˆ·å…³é”®è¯

#### Q-003ï¼šæ­£åˆ™è¶…æ—¶ï¼ŒCPU 100% (v7.4.2ä¿®å¤)

**ç—‡çŠ¶**ï¼š
- å·¥ä½œæµå¡åœ¨ `KeywordExtractor.extract()` è¶…è¿‡60ç§’
- CPU 100% å ç”¨
- åç«¯æ— å“åº”

**æ ¹å› **ï¼š
```python
# é—®é¢˜æ­£åˆ™ï¼ˆç¾éš¾æ€§å›æº¯ï¼‰
r'(?:è¦æ±‚|éœ€è¦|å¸Œæœ›)[^ï¼Œã€‚]{0,10}([^ï¼Œã€‚,.\s""]{2,15})(?:çš„|å±æ€§|åŠŸèƒ½)'
# åµŒå¥—é‡è¯ [^ï¼Œã€‚]{0,10} å¯¼è‡´æŒ‡æ•°çº§å›æº¯
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# context.py
# 1. ç®€åŒ–æ­£åˆ™æ¨¡å¼
CONCEPT_PATTERNS = [
    r'"([^""]{2,15})"',  # é™åˆ¶é•¿åº¦
    r'"([^"]{2,15})"',
    r'ã€Œ([^ã€]{2,15})ã€',
    r'ã€([^ã€‘]{2,15})ã€‘'
]

# 2. ä¸¥æ ¼é™åˆ¶æ–‡æœ¬é•¿åº¦
safe_text = text[:500]  # 2000â†’500

# 3. é™åˆ¶åŒ¹é…æ¬¡æ•°
matches = re.findall(pattern, safe_text[:500])
concepts.extend(matches[:5])  # æ¯ä¸ªæ¨¡å¼æœ€å¤š5ä¸ª
```

**æ•ˆæœ**ï¼š
- æ‰§è¡Œæ—¶é—´ä» >60s é™è‡³ <0.1s
- æ€§èƒ½æå‡ **600å€ä»¥ä¸Š**

#### Q-004ï¼šé—®é¢˜ç›¸å…³æ€§ä½ (v7.6ä¿®å¤)

**ç—‡çŠ¶**ï¼š
- LLMç”Ÿæˆçš„é—®é¢˜ç¼ºä¹æ·±åº¦
- æœªèƒ½æŒ–æ˜ç”¨æˆ·çœŸå®éœ€æ±‚

**æ ¹å› **ï¼š
- `_build_analysis_summary` åªæå–äº†éƒ¨åˆ†å­—æ®µ
- å…³é”®ä¿¡æ¯ï¼ˆå¦‚ project_overview, core_objectivesï¼‰æœªæ³¨å…¥æç¤ºè¯

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# llm_generator.py _build_analysis_summary()
# v7.6: æ‰©å±•å­—æ®µæå–
project_overview = structured_data.get("project_overview", "")
core_objectives = structured_data.get("core_objectives", [])
narrative_characters = structured_data.get("narrative_characters", "") or \
                      structured_data.get("character_narrative", "")
physical_contexts = structured_data.get("physical_contexts", "")
constraints_opportunities = structured_data.get("constraints_opportunities", "")

# åˆ«åå…¼å®¹
project_task = structured_data.get("project_task", "") or \
               structured_data.get("project_tasks", "")
```

**æ•ˆæœ**ï¼š
- LLMè·å¾—æ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡
- ç”Ÿæˆé—®é¢˜æ›´è´´è¿‘ç”¨æˆ·éœ€æ±‚

#### Q-005ï¼šTypeError: expected str, dict found (v7.9ä¿®å¤)

**ç—‡çŠ¶**ï¼š
```
2025-12-12 08:34:33.551 | ERROR | ... LLMç”Ÿæˆå¤±è´¥: 
TypeError: sequence item 0: expected str instance, dict found
```
- ç”¨æˆ·æäº¤é—®å·ç­”æ¡ˆåï¼ŒäºŒæ¬¡éœ€æ±‚åˆ†æè§¦å‘
- LLMé—®å·ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°Fallbackæ–¹æ¡ˆ

**æ ¹å› **ï¼š
```python
# llm_generator.py ç¬¬227-235è¡Œï¼ˆä¿®å¤å‰ï¼‰
critical_questions = expert_handoff.get("critical_questions_for_experts", {})
if critical_questions:
    cq_list = []
    for role, questions in list(critical_questions.items())[:3]:
        if questions:
            # âŒ å‡è®¾questionsè¦ä¹ˆæ˜¯listè¦ä¹ˆæ˜¯str
            q_text = questions[0] if isinstance(questions, list) else questions
            # å¦‚æœquestionsæ˜¯dictï¼Œquestions[0]ä¼šå°è¯•è·å–é”®è€Œéç´¢å¼•
            cq_list.append(f"- {role}: {q_text[:50]}...")
    if cq_list:
        # âŒ å¦‚æœcq_listä¸­æœ‰dictï¼Œjoin()ä¼šå¤±è´¥
        handoff_summary.append(f"å…³é”®é—®é¢˜:\n" + "\n".join(cq_list))
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼š
```python
# v7.9: å¢å¼ºç±»å‹åˆ¤æ–­
for role, questions in list(critical_questions.items())[:3]:
    if questions:
        # âœ… æ˜¾å¼å¤„ç† list/dict/str ä¸‰ç§æƒ…å†µ
        if isinstance(questions, list):
            q_text = questions[0] if questions else ""
        elif isinstance(questions, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–ç¬¬ä¸€ä¸ªå€¼
            q_text = next(iter(questions.values())) if questions else ""
        else:
            q_text = str(questions)
        
        # âœ… ç¡®ä¿q_textæ˜¯å­—ç¬¦ä¸²åå†åˆ‡ç‰‡
        if isinstance(q_text, str) and q_text:
            cq_list.append(f"- {role}: {q_text[:50]}...")
```

**æ•ˆæœ**ï¼š
- æˆåŠŸå¤„ç† dict ç±»å‹çš„ critical_questions
- äºŒæ¬¡éœ€æ±‚åˆ†æä¸å†å› ç±»å‹é—®é¢˜ä¸­æ–­

---

## 6. ä¿®æ”¹å†å²æ—¶é—´çº¿

### v7.0 (2025-12-06)
- åˆå§‹é—®å·ç”Ÿæˆæœºåˆ¶
- åŸºäºè§„åˆ™çš„ç®€å•æ¨¡æ¿

### v7.2 (2025-12-10)
- **æ¨¡å—åŒ–é‡æ„**
- ä»£ç å‡å°‘ 46.2%ï¼ˆ1508è¡Œ â†’ 811è¡Œï¼‰
- æå– 7 ä¸ªç‹¬ç«‹ç»„ä»¶
- æµ‹è¯•è¦†ç›–ç‡ 0% â†’ 80%+

### v7.4.2 (2025-12-11)
- **æ€§èƒ½ä¼˜åŒ–ï¼šä¿®å¤æ­£åˆ™ç¾éš¾æ€§å›æº¯**
- ç®€åŒ–æ­£åˆ™æ¨¡å¼
- é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼ˆ2000â†’500ï¼‰
- é™åˆ¶åŒ¹é…æ¬¡æ•°
- æ€§èƒ½æå‡ 600å€ä»¥ä¸Š

### v7.4.3 (2025-12-11)
- **ä¿®å¤å˜é‡ä½œç”¨åŸŸé”™è¯¯**
- `user_input` æå‰å®šä¹‰
- é¿å… NameError

### v7.5 (2025-12-11)
- **LLMé©±åŠ¨é—®å·ç”Ÿæˆ**
- æ–°å¢ LLMQuestionGenerator
- æç¤ºè¯å¼ºåˆ¶çº¦æŸï¼ˆ7-10ä¸ªé—®é¢˜ï¼‰
- ç›¸å…³æ€§éªŒè¯æœºåˆ¶
- å›é€€æ–¹æ¡ˆä¼˜åŒ–

### v7.6 (2025-12-11)
- **å­—æ®µæå–æ‰©å±•**
- æ–°å¢ project_overview, core_objectives ç­‰
- åˆ«åå…¼å®¹ï¼ˆproject_task/project_tasksï¼‰
- æå‡é—®é¢˜é’ˆå¯¹æ€§

### v7.9 (2025-12-12)
- **ç±»å‹å…¼å®¹æ€§ä¿®å¤**
- å¤„ç† critical_questions å­—å…¸ç±»å‹
- é¿å… TypeError: expected str, dict found
- å¢å¼ºç±»å‹åˆ¤æ–­ï¼ˆlist/dict/strï¼‰

---

## 7. æµ‹è¯•ç”¨ä¾‹

### 7.1 å•å…ƒæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**ï¼š`tests/test_questionnaire_generation.py`

```python
def test_llm_generation_success():
    """æµ‹è¯•LLMæˆåŠŸç”Ÿæˆé—®å·"""
    questions, source = LLMQuestionGenerator.generate(
        user_input="ä¸‰ä»£åŒå ‚150ã¡ä½å®…è®¾è®¡",
        structured_data=mock_structured_data
    )
    assert source == "llm_generated"
    assert 7 <= len(questions) <= 10
    assert any("ä¸‰ä»£åŒå ‚" in q["question"] for q in questions)

def test_llm_generation_fallback():
    """æµ‹è¯•LLMå¤±è´¥æ—¶å›é€€"""
    with patch('llm_model.invoke', side_effect=Exception("LLM error")):
        questions, source = LLMQuestionGenerator.generate(...)
        assert source == "fallback"
        assert len(questions) >= 7

def test_critical_questions_dict_type():
    """æµ‹è¯•critical_questionså­—å…¸ç±»å‹å¤„ç†"""
    structured_data = {
        "expert_handoff": {
            "critical_questions_for_experts": {
                "V4_è®¾è®¡ç ”ç©¶å‘˜": {"key1": "é—®é¢˜1", "key2": "é—®é¢˜2"},
                "V2_è®¾è®¡æ€»ç›‘": ["é—®é¢˜3", "é—®é¢˜4"]
            }
        }
    }
    summary = LLMQuestionGenerator._build_analysis_summary(structured_data)
    assert "é—®é¢˜1" in summary or "é—®é¢˜3" in summary
    # ä¸åº”æŠ›å‡º TypeError
```

### 7.2 é›†æˆæµ‹è¯•

```python
def test_full_questionnaire_flow():
    """æµ‹è¯•å®Œæ•´é—®å·æµç¨‹"""
    # 1. éœ€æ±‚åˆ†æ
    requirements_result = RequirementsAnalyst.execute(state)
    
    # 2. é—®å·ç”Ÿæˆ
    questionnaire = calibration_questionnaire.execute(state)
    
    # 3. éªŒè¯é—®å·è´¨é‡
    assert 7 <= len(questionnaire["questions"]) <= 10
    assert questionnaire["questions"][0]["type"] == "single_choice"
    assert questionnaire["questions"][-1]["type"] == "open_ended"
    
    # 4. ç”¨æˆ·å›ç­”
    state["user_response"] = mock_answers
    
    # 5. æ„å›¾è§£æ
    intent = IntentParser.parse(state["user_response"])
    assert intent in ["skip", "add", "default"]
```

### 7.3 å›å½’æµ‹è¯•åœºæ™¯

| åœºæ™¯ | è¾“å…¥ | é¢„æœŸè¾“å‡º |
|------|------|---------|
| ä¸ªäººä½å®… | "ä¸‰ä»£åŒå ‚150ã¡" | 7-10ä¸ªé—®é¢˜ï¼ŒåŒ…å«"ä¸‰ä»£åŒå ‚"å…³é”®è¯ |
| å•†ä¸šç©ºé—´ | "å’–å•¡é¦†50ã¡é¢„ç®—20ä¸‡" | 7-10ä¸ªé—®é¢˜ï¼ŒåŒ…å«"å’–å•¡é¦†"ã€"20ä¸‡" |
| æ–‡åŒ–é¡¹ç›® | "ç¤¾åŒºå›¾ä¹¦é¦†200ã¡" | 7-10ä¸ªé—®é¢˜ï¼ŒåŒ…å«"ç¤¾åŒº"ã€"å›¾ä¹¦é¦†" |
| LLMå¤±è´¥ | ä»»æ„è¾“å…¥ + LLMå¼‚å¸¸ | å›é€€åˆ°Fallbackï¼Œ7+ä¸ªé—®é¢˜ |
| å­—å…¸ç±»å‹ | critical_questions=dict | ä¸æŠ›å‡ºTypeError |

---

## 8. ç»´æŠ¤æŒ‡å—

### 8.1 ä¿®æ”¹å‰æ£€æŸ¥æ¸…å•

**ä¿®æ”¹é—®å·ç›¸å…³ä»£ç å‰ï¼Œå¿…é¡»ï¼š**
- [ ] é˜…è¯» `.github/DEVELOPMENT_RULES.md` ç¬¬10-11ç« 
- [ ] æ£€æŸ¥ `_build_analysis_summary` æ˜¯å¦è¦†ç›–æ‰€æœ‰å…³é”®å­—æ®µ
- [ ] æ£€æŸ¥æç¤ºè¯æ˜¯å¦åŒ…å«ç¦æ­¢/å¿…é¡»è§„åˆ™
- [ ] éªŒè¯ç”Ÿæˆçš„é—®é¢˜æ˜¯å¦å¼•ç”¨ç”¨æˆ·åŸè¯å…³é”®è¯

**æ¶‰åŠå­—æ®µæå–æ—¶ï¼š**
- [ ] åˆ—å‡ºç›®æ ‡æ•°æ®æºçš„æ‰€æœ‰å¯ç”¨å­—æ®µ
- [ ] ç¡®ä¿æå–å‡½æ•°è¦†ç›–å…¨éƒ¨å…³é”®å­—æ®µ
- [ ] æ·»åŠ å­—æ®µåˆ«åå…¼å®¹ï¼ˆå¦‚ project_task/project_tasksï¼‰
- [ ] å¤„ç†å­—æ®µç±»å‹å·®å¼‚ï¼ˆå­—ç¬¦ä¸²/åˆ—è¡¨/å­—å…¸ï¼‰
- [ ] ç©ºå€¼æ—¶è¿”å›å¼•å¯¼æ€§æç¤ºè€Œé"æš‚æ— "

**æ¶‰åŠç±»å‹å¤„ç†æ—¶ï¼š**
- [ ] æ˜¾å¼å¤„ç† `list`/`dict`/`str` ä¸‰ç§ç±»å‹
- [ ] ä½¿ç”¨ `"\n".join()` å‰ï¼Œç¡®ä¿åˆ—è¡¨ä¸­æ‰€æœ‰å…ƒç´ éƒ½æ˜¯å­—ç¬¦ä¸²
- [ ] å­—ç¬¦ä¸²åˆ‡ç‰‡å‰ï¼Œå¿…é¡»å…ˆè¿›è¡Œç±»å‹æ£€æŸ¥
- [ ] æ·»åŠ æ—¥å¿—è®°å½•ï¼Œä¾¿äºè¿½è¸ªæ•°æ®æ ¼å¼é—®é¢˜

### 8.2 ä¿®æ”¹åéªŒè¯æ¸…å•

**ä¿®æ”¹åå¿…é¡»ï¼š**
- [ ] è¿è¡Œå•å…ƒæµ‹è¯•ï¼š`python -B tests/test_questionnaire_generation.py`
- [ ] è¿è¡Œé›†æˆæµ‹è¯•ï¼šéªŒè¯å®Œæ•´æµç¨‹
- [ ] æµ‹è¯•LLMå¤±è´¥åœºæ™¯ï¼šç¡®ä¿å›é€€æ–¹æ¡ˆæ­£å¸¸
- [ ] æµ‹è¯•ä¸åŒé¡¹ç›®ç±»å‹ï¼šä¸ªäºº/å•†ä¸š/æ–‡åŒ–ç­‰
- [ ] éªŒè¯é—®é¢˜æ•°é‡ï¼š7-10ä¸ª
- [ ] éªŒè¯é—®é¢˜é’ˆå¯¹æ€§ï¼šæ˜¯å¦å¼•ç”¨ç”¨æˆ·å…³é”®è¯
- [ ] éªŒè¯é¢˜å‹é¡ºåºï¼šå•é€‰â†’å¤šé€‰â†’å¼€æ”¾

**æ–‡æ¡£æ›´æ–°ï¼š**
- [ ] æ›´æ–° `.github/DEVELOPMENT_RULES.md` çš„ã€Œå†å²é—®é¢˜è¿½è¸ªã€
- [ ] æ›´æ–°æœ¬æ–‡æ¡£å¯¹åº”ç« èŠ‚
- [ ] å¦‚æœæ˜¯é‡å¤§ä¿®æ”¹ï¼Œåˆ›å»ºç‹¬ç«‹çš„ä¿®å¤æ–‡æ¡£

### 8.3 å¸¸è§é™·é˜±

| é™·é˜± | ç—‡çŠ¶ | é¢„é˜²æªæ–½ |
|------|------|---------|
| å­—æ®µæå–ä¸å®Œæ•´ | é—®å·å˜æˆæ³›åŒ–æ¨¡æ¿ | ä½¿ç”¨å­—æ®µæ˜ å°„è¡¨æ£€æŸ¥ |
| æç¤ºè¯ç¼ºä¹çº¦æŸ | LLMç”Ÿæˆé€šç”¨é—®é¢˜ | æ·»åŠ ç¦æ­¢/å¿…é¡»ç¤ºä¾‹ |
| æœªéªŒè¯ç›¸å…³æ€§ | é—®é¢˜ä¸ç”¨æˆ·è¾“å…¥è„±èŠ‚ | è°ƒç”¨ _check_question_relevance |
| æ­£åˆ™è¿‡äºå¤æ‚ | æ€§èƒ½é—®é¢˜/è¶…æ—¶ | ç®€åŒ–æ¨¡å¼ã€é™åˆ¶é•¿åº¦ |
| ç±»å‹å‡è®¾é”™è¯¯ | TypeErrorå¼‚å¸¸ | æ˜¾å¼åˆ¤æ–­æ‰€æœ‰å¯èƒ½ç±»å‹ |

### 8.4 è°ƒè¯•æŠ€å·§

**æ—¥å¿—çº§åˆ«æ§åˆ¶**ï¼š
```python
# ä¸´æ—¶å¼€å¯è¯¦ç»†æ—¥å¿—
logger.level = "DEBUG"

# å…³é”®ç‚¹æ·»åŠ è°ƒè¯•æ—¥å¿—
logger.debug(f"ğŸ” [TRACE] structured_data keys: {structured_data.keys()}")
logger.debug(f"ğŸ” [TRACE] questions type: {type(questions)}")
```

**é—®é¢˜å®šä½**ï¼š
```bash
# æœç´¢é—®å·ç”Ÿæˆç›¸å…³æ—¥å¿—
grep "LLMQuestionGenerator" logs/*.log

# æœç´¢é”™è¯¯
grep "TypeError\|AttributeError\|KeyError" logs/*.log

# æŸ¥çœ‹å®Œæ•´å †æ ˆ
python -B -m pytest tests/test_questionnaire_generation.py -v --tb=long
```

**å¸¸è§é”™è¯¯é€ŸæŸ¥**ï¼š
- `TypeError: expected str, dict found` â†’ æ£€æŸ¥ critical_questions ç±»å‹å¤„ç†
- `AttributeError: 'NoneType' object` â†’ æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
- `KeyError: 'xxx'` â†’ æ£€æŸ¥å­—æ®µåæ‹¼å†™/åˆ«å
- `æ­£åˆ™è¶…æ—¶` â†’ æ£€æŸ¥æ–‡æœ¬é•¿åº¦é™åˆ¶

---

## é™„å½•

### A. å…³é”®æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | èŒè´£ | ä»£ç è¡Œæ•° |
|------|------|---------|
| `llm_generator.py` | LLMé©±åŠ¨ç”Ÿæˆ | ~700 |
| `generators.py` | å›é€€æ–¹æ¡ˆ | ~500 |
| `context.py` | å…³é”®è¯æå– | ~300 |
| `adjusters.py` | åŠ¨æ€è°ƒæ•´ | ~200 |
| `parsers.py` | æ„å›¾è§£æ | ~150 |
| `calibration_questionnaire.py` | èŠ‚ç‚¹é€»è¾‘ | ~800 |
| `questionnaire_generator.yaml` | LLMæç¤ºè¯ | ~200 |

### B. ä¾èµ–å…³ç³»å›¾

```
calibration_questionnaire.py (å…¥å£)
  â”œâ”€ llm_generator.py (ä¼˜å…ˆ)
  â”‚   â”œâ”€ prompt_manager.py (æç¤ºè¯åŠ è½½)
  â”‚   â””â”€ llm_factory.py (LLMå®ä¾‹)
  â”‚
  â”œâ”€ generators.py (å›é€€)
  â”‚   â”œâ”€ context.py (å…³é”®è¯æå–)
  â”‚   â””â”€ parsers.py (æ„å›¾è§£æ)
  â”‚
  â””â”€ adjusters.py (åå¤„ç†)
```

### C. ç‰ˆæœ¬å…¼å®¹æ€§

| ç‰ˆæœ¬ | Python | LangChain | Pydantic | å…¼å®¹æ€§ |
|------|--------|-----------|----------|--------|
| v7.9 | 3.10+ | 0.2+ | v2 | âœ… å®Œå…¨å…¼å®¹ |
| v7.6 | 3.10+ | 0.2+ | v2 | âœ… å‘åå…¼å®¹ |
| v7.5 | 3.10+ | 0.2+ | v2 | âš ï¸ éœ€æ‰‹åŠ¨è¿ç§» |

---

**æ–‡æ¡£ç»´æŠ¤è€…**ï¼šAI Assistant & Design Beyond Team  
**æœ€åæ›´æ–°**ï¼š2025-12-12  
**ç‰ˆæœ¬**ï¼šv1.0
