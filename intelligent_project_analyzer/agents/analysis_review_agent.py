"""
åˆ†æå®¡æ ¸æ™ºèƒ½ä½“ (LangGraph StateGraph)

ğŸ”¥ v7.16: å°† AnalysisReviewNode å‡çº§ä¸ºçœŸæ­£çš„ LangGraph Agent

æ ¸å¿ƒåŠŸèƒ½:
1. çº¢è“å¯¹æŠ— (Red-Blue Debate)
2. ç”²æ–¹å†³ç­– (Client Review)
3. ç”Ÿæˆæœ€ç»ˆè£å®š (Final Ruling)
4. æ”¹è¿›å»ºè®®è¾“å‡º (Improvement Suggestions)

èŠ‚ç‚¹æµè½¬:
    red_blue_debate â†’ client_review â†’ generate_ruling â†’ END
"""

from typing import TypedDict, Dict, Any, List, Optional, Literal
from loguru import logger
from datetime import datetime
import time

from langgraph.graph import StateGraph, START, END
from langgraph.types import Command

from ..utils.shared_agent_utils import PerformanceMonitor
from ..review.review_agents import (
    RedTeamReviewer,
    BlueTeamReviewer,
    ClientReviewer
)


# ============================================================================
# çŠ¶æ€å®šä¹‰
# ============================================================================

class AnalysisReviewState(TypedDict):
    """åˆ†æå®¡æ ¸æ™ºèƒ½ä½“çŠ¶æ€"""
    
    # è¾“å…¥
    agent_results: Dict[str, Any]  # æ‰€æœ‰ä¸“å®¶çš„åˆ†æç»“æœ
    requirements: Dict[str, Any]   # é¡¹ç›®éœ€æ±‚
    review_iteration_round: int    # å½“å‰å®¡æ ¸è½®æ¬¡
    
    # ä¸­é—´çŠ¶æ€
    red_review: Dict[str, Any]     # çº¢é˜Ÿå®¡æ ¸ç»“æœ
    blue_review: Dict[str, Any]    # è“é˜Ÿå®¡æ ¸ç»“æœ
    red_blue_debate: Dict[str, Any]  # çº¢è“å¯¹æŠ—ç»“æœ
    client_review: Dict[str, Any]  # ç”²æ–¹å®¡æ ¸ç»“æœ
    
    # è¾“å‡º
    final_ruling: str              # æœ€ç»ˆè£å®šæ–‡æ¡£
    improvement_suggestions: List[Dict[str, Any]]  # æ”¹è¿›å»ºè®®åˆ—è¡¨
    must_fix_count: int            # must_fixé—®é¢˜æ•°é‡
    analysis_approved: bool        # å®¡æ ¸æ˜¯å¦é€šè¿‡
    agents_to_improve: List[str]   # éœ€è¦æ•´æ”¹çš„ä¸“å®¶ID
    
    # å¤„ç†æ—¥å¿—
    processing_log: List[str]


# ============================================================================
# èŠ‚ç‚¹å‡½æ•°
# ============================================================================

def red_blue_debate_node(state: AnalysisReviewState) -> Dict[str, Any]:
    """
    çº¢è“å¯¹æŠ—èŠ‚ç‚¹ - å‘ç°é—®é¢˜å¹¶è¾©æŠ¤
    
    çº¢é˜Ÿï¼šæ‰¹åˆ¤æ€§å®¡æŸ¥ï¼Œæ‰¾é—®é¢˜
    è“é˜Ÿï¼šé˜²å¾¡æ€§è¾©æŠ¤ï¼Œè¿‡æ»¤è¯¯åˆ¤
    """
    logger.info("âš”ï¸ æ‰§è¡Œçº¢è“å¯¹æŠ—èŠ‚ç‚¹")
    
    agent_results = state.get("agent_results", {})
    requirements = state.get("requirements", {})
    
    # å‡†å¤‡å®¡æ ¸å†…å®¹
    review_content = _prepare_review_content(agent_results, requirements)
    
    # è·å– LLM æ¨¡å‹ï¼ˆä»é…ç½®æˆ–é»˜è®¤ï¼‰
    llm_model = state.get("_llm_model")
    
    if not llm_model:
        logger.warning("âš ï¸ æœªæä¾› LLM æ¨¡å‹ï¼Œä½¿ç”¨ç©ºç»“æœ")
        return {
            "red_review": {"issues": [], "overall_assessment": "æœªæ‰§è¡Œ"},
            "blue_review": {"defenses": [], "overall_assessment": "æœªæ‰§è¡Œ"},
            "red_blue_debate": {"issues": [], "validated_issues": []},
            "processing_log": ["âš ï¸ çº¢è“å¯¹æŠ—è·³è¿‡ï¼šæœªæä¾›LLMæ¨¡å‹"]
        }
    
    # æ‰§è¡Œçº¢é˜Ÿå®¡æ ¸
    logger.info("ğŸ”´ çº¢é˜Ÿå®¡æ ¸ï¼šæ‰¹åˆ¤æ€§åˆ†æ...")
    red_team = RedTeamReviewer(llm_model)
    red_review = red_team.review(review_content)
    
    # æ‰§è¡Œè“é˜Ÿå®¡æ ¸ï¼ˆåŸºäºçº¢é˜Ÿç»“æœï¼‰
    logger.info("ğŸ”µ è“é˜Ÿå®¡æ ¸ï¼šé˜²å¾¡æ€§è¾©æŠ¤...")
    blue_team = BlueTeamReviewer(llm_model)
    blue_review = blue_team.review(review_content, red_review)
    
    # åˆæˆçº¢è“å¯¹æŠ—ç»“æœ
    red_issues = red_review.get("issues", [])
    blue_defenses = blue_review.get("defenses", [])
    
    # è®¡ç®—éªŒè¯åçš„é—®é¢˜ï¼ˆè¢«è“é˜Ÿè®¤å¯çš„é—®é¢˜ï¼‰
    validated_issues = []
    for issue in red_issues:
        issue_id = issue.get("id", "")
        # æŸ¥æ‰¾è“é˜Ÿæ˜¯å¦è®¤å¯è¿™ä¸ªé—®é¢˜
        defense = next(
            (d for d in blue_defenses if d.get("issue_id") == issue_id),
            None
        )
        if defense and defense.get("acknowledged", False):
            validated_issues.append({
                **issue,
                "blue_defense": defense.get("defense", ""),
                "final_severity": defense.get("adjusted_severity", issue.get("severity", "medium"))
            })
    
    red_blue_debate = {
        "red_review": red_review,
        "blue_review": blue_review,
        "issues": red_issues,
        "validated_issues": validated_issues,
        "total_issues": len(red_issues),
        "validated_count": len(validated_issues)
    }
    
    log_entry = f"âš”ï¸ çº¢è“å¯¹æŠ—å®Œæˆï¼šçº¢é˜Ÿå‘ç°{len(red_issues)}ä¸ªé—®é¢˜ï¼Œè“é˜ŸéªŒè¯{len(validated_issues)}ä¸ª"
    logger.info(log_entry)
    
    return {
        "red_review": red_review,
        "blue_review": blue_review,
        "red_blue_debate": red_blue_debate,
        "processing_log": [log_entry]
    }


def client_review_node(state: AnalysisReviewState) -> Dict[str, Any]:
    """
    ç”²æ–¹å†³ç­–èŠ‚ç‚¹ - åŸºäºçº¢è“å¯¹æŠ—ç»“æœåšæœ€ç»ˆå†³ç­–
    """
    logger.info("ğŸ‘” æ‰§è¡Œç”²æ–¹å†³ç­–èŠ‚ç‚¹")
    
    agent_results = state.get("agent_results", {})
    requirements = state.get("requirements", {})
    red_blue_debate = state.get("red_blue_debate", {})
    
    # å‡†å¤‡å®¡æ ¸å†…å®¹
    review_content = _prepare_review_content(agent_results, requirements)
    
    # è·å– LLM æ¨¡å‹
    llm_model = state.get("_llm_model")
    
    if not llm_model:
        logger.warning("âš ï¸ æœªæä¾› LLM æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤å†³ç­–")
        return {
            "client_review": {
                "final_decision": "approve",
                "confidence": 0.5,
                "reasoning": "æœªæ‰§è¡ŒLLMå®¡æ ¸ï¼Œé»˜è®¤é€šè¿‡"
            },
            "processing_log": ["âš ï¸ ç”²æ–¹å†³ç­–è·³è¿‡ï¼šæœªæä¾›LLMæ¨¡å‹"]
        }
    
    # æ‰§è¡Œç”²æ–¹å®¡æ ¸
    client_reviewer = ClientReviewer(llm_model)
    client_review = client_reviewer.review(
        review_content,
        red_blue_debate
    )
    
    final_decision = client_review.get("final_decision", "approve")
    log_entry = f"ğŸ‘” ç”²æ–¹å†³ç­–å®Œæˆï¼š{final_decision}"
    logger.info(log_entry)
    
    return {
        "client_review": client_review,
        "processing_log": [log_entry]
    }


def generate_ruling_node(state: AnalysisReviewState) -> Dict[str, Any]:
    """
    ç”Ÿæˆæœ€ç»ˆè£å®šèŠ‚ç‚¹ - æ±‡æ€»å®¡æ ¸ç»“æœï¼Œç”Ÿæˆæ”¹è¿›å»ºè®®
    """
    logger.info("ğŸ“‹ ç”Ÿæˆæœ€ç»ˆè£å®š")
    
    red_blue_debate = state.get("red_blue_debate", {})
    client_review = state.get("client_review", {})
    review_iteration_round = state.get("review_iteration_round", 0)
    
    # æå–éªŒè¯åçš„é—®é¢˜
    validated_issues = red_blue_debate.get("validated_issues", [])
    
    # ç”Ÿæˆæ”¹è¿›å»ºè®®
    improvement_suggestions = []
    for issue in validated_issues:
        suggestion = {
            "issue_id": issue.get("id", ""),
            "agent_id": issue.get("agent_id", issue.get("responsible_agent", "")),
            "description": issue.get("description", ""),
            "suggestion": issue.get("recommendation", ""),
            "priority": issue.get("final_severity", "medium"),
            "category": issue.get("category", "quality")
        }
        
        # æ ‡è®° must_fix
        if issue.get("final_severity") in ["critical", "high"]:
            suggestion["priority"] = "must_fix"
        
        improvement_suggestions.append(suggestion)
    
    # ç»Ÿè®¡ must_fix æ•°é‡
    must_fix_count = len([s for s in improvement_suggestions if s.get("priority") == "must_fix"])
    
    # æå–éœ€è¦æ•´æ”¹çš„ä¸“å®¶
    agents_to_improve = list(set(
        s.get("agent_id", "") for s in improvement_suggestions 
        if s.get("priority") == "must_fix" and s.get("agent_id")
    ))
    
    # åˆ¤æ–­å®¡æ ¸æ˜¯å¦é€šè¿‡
    final_decision = client_review.get("final_decision", "approve")
    analysis_approved = (
        final_decision == "approve" or
        (must_fix_count == 0) or
        (review_iteration_round >= 1)  # å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
    )
    
    # ç”Ÿæˆè£å®šæ–‡æ¡£
    final_ruling = _generate_ruling_document(
        red_blue_debate,
        client_review,
        improvement_suggestions,
        analysis_approved
    )
    
    log_entry = f"ğŸ“‹ è£å®šç”Ÿæˆå®Œæˆï¼š{must_fix_count}ä¸ªmust_fixé—®é¢˜ï¼Œ{'é€šè¿‡' if analysis_approved else 'éœ€æ•´æ”¹'}"
    logger.info(log_entry)
    
    return {
        "final_ruling": final_ruling,
        "improvement_suggestions": improvement_suggestions,
        "must_fix_count": must_fix_count,
        "analysis_approved": analysis_approved,
        "agents_to_improve": agents_to_improve,
        "processing_log": [log_entry]
    }


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def _prepare_review_content(agent_results: Dict[str, Any], requirements: Dict[str, Any]) -> Dict[str, Any]:
    """å‡†å¤‡å®¡æ ¸å†…å®¹"""
    return {
        "agent_results": agent_results,
        "requirements": requirements,
        "timestamp": datetime.now().isoformat()
    }


def _generate_ruling_document(
    red_blue_debate: Dict[str, Any],
    client_review: Dict[str, Any],
    improvement_suggestions: List[Dict[str, Any]],
    analysis_approved: bool
) -> str:
    """ç”Ÿæˆæœ€ç»ˆè£å®šæ–‡æ¡£"""
    
    must_fix = [s for s in improvement_suggestions if s.get("priority") == "must_fix"]
    should_fix = [s for s in improvement_suggestions if s.get("priority") != "must_fix"]
    
    ruling = f"""
# åˆ†æå®¡æ ¸è£å®šæ–‡æ¡£

## å®¡æ ¸ç»“è®º
- **çŠ¶æ€**: {'âœ… å®¡æ ¸é€šè¿‡' if analysis_approved else 'âš ï¸ éœ€è¦æ•´æ”¹'}
- **ç”²æ–¹å†³ç­–**: {client_review.get('final_decision', 'N/A')}
- **çº¢è“å¯¹æŠ—é—®é¢˜æ•°**: {red_blue_debate.get('total_issues', 0)}
- **éªŒè¯åé—®é¢˜æ•°**: {red_blue_debate.get('validated_count', 0)}

## Must-Fix é—®é¢˜ ({len(must_fix)}é¡¹)
"""
    
    for i, issue in enumerate(must_fix, 1):
        ruling += f"""
### {i}. {issue.get('description', 'æœªçŸ¥é—®é¢˜')}
- **è´£ä»»ä¸“å®¶**: {issue.get('agent_id', 'æœªçŸ¥')}
- **å»ºè®®**: {issue.get('suggestion', 'æ— ')}
"""
    
    ruling += f"""
## Should-Fix å»ºè®® ({len(should_fix)}é¡¹)
"""
    
    for i, issue in enumerate(should_fix, 1):
        ruling += f"- {issue.get('description', 'æœªçŸ¥')}\n"
    
    return ruling


# ============================================================================
# çŠ¶æ€å›¾æ„å»º
# ============================================================================

def build_analysis_review_graph() -> StateGraph:
    """
    æ„å»ºåˆ†æå®¡æ ¸çŠ¶æ€å›¾
    
    æµç¨‹:
        START â†’ red_blue_debate â†’ client_review â†’ generate_ruling â†’ END
    """
    workflow = StateGraph(AnalysisReviewState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("red_blue_debate", red_blue_debate_node)
    workflow.add_node("client_review", client_review_node)
    workflow.add_node("generate_ruling", generate_ruling_node)
    
    # æ·»åŠ è¾¹
    workflow.add_edge(START, "red_blue_debate")
    workflow.add_edge("red_blue_debate", "client_review")
    workflow.add_edge("client_review", "generate_ruling")
    workflow.add_edge("generate_ruling", END)
    
    return workflow


# ============================================================================
# Agent å°è£…ç±»
# ============================================================================

class AnalysisReviewAgent:
    """
    åˆ†æå®¡æ ¸æ™ºèƒ½ä½“ - LangGraph å°è£…
    
    ä½¿ç”¨æ–¹å¼:
        agent = AnalysisReviewAgent(llm_model)
        result = agent.execute(agent_results, requirements)
    """
    
    def __init__(self, llm_model, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–åˆ†æå®¡æ ¸æ™ºèƒ½ä½“
        
        Args:
            llm_model: LLMæ¨¡å‹å®ä¾‹
            config: é…ç½®å‚æ•°
        """
        self.llm_model = llm_model
        self.config = config or {}
        
        # æ„å»ºå¹¶ç¼–è¯‘çŠ¶æ€å›¾
        self._graph = build_analysis_review_graph().compile()
        
        logger.info("ğŸš€ AnalysisReviewAgent (LangGraph) å·²åˆå§‹åŒ–")
    
    def execute(
        self,
        agent_results: Dict[str, Any],
        requirements: Dict[str, Any],
        review_iteration_round: int = 0
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œåˆ†æå®¡æ ¸
        
        Args:
            agent_results: æ‰€æœ‰ä¸“å®¶çš„åˆ†æç»“æœ
            requirements: é¡¹ç›®éœ€æ±‚
            review_iteration_round: å½“å‰å®¡æ ¸è½®æ¬¡
            
        Returns:
            å®¡æ ¸ç»“æœå­—å…¸
        """
        logger.info(f"ğŸ¯ AnalysisReviewAgent å¼€å§‹å®¡æ ¸ (è½®æ¬¡ {review_iteration_round})")
        start_time = time.time()
        
        # å‡†å¤‡åˆå§‹çŠ¶æ€
        initial_state = {
            "agent_results": agent_results,
            "requirements": requirements,
            "review_iteration_round": review_iteration_round,
            "_llm_model": self.llm_model,  # ä¼ é€’LLMæ¨¡å‹
            
            # åˆå§‹åŒ–ä¸­é—´çŠ¶æ€
            "red_review": {},
            "blue_review": {},
            "red_blue_debate": {},
            "client_review": {},
            
            # åˆå§‹åŒ–è¾“å‡º
            "final_ruling": "",
            "improvement_suggestions": [],
            "must_fix_count": 0,
            "analysis_approved": False,
            "agents_to_improve": [],
            "processing_log": []
        }
        
        # æ‰§è¡ŒçŠ¶æ€å›¾
        try:
            final_state = self._graph.invoke(initial_state)
            
            # æå–ç»“æœ
            result = {
                "final_ruling": final_state.get("final_ruling", ""),
                "improvement_suggestions": final_state.get("improvement_suggestions", []),
                "must_fix_count": final_state.get("must_fix_count", 0),
                "analysis_approved": final_state.get("analysis_approved", False),
                "agents_to_improve": final_state.get("agents_to_improve", []),
                "red_blue_debate": final_state.get("red_blue_debate", {}),
                "client_review": final_state.get("client_review", {}),
                "processing_log": final_state.get("processing_log", [])
            }
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            PerformanceMonitor.record("AnalysisReviewAgent", time.time() - start_time, "v7.16")
            
            logger.info(f"âœ… AnalysisReviewAgent å®Œæˆ: {result['must_fix_count']} must_fix, approved={result['analysis_approved']}")
            return result
            
        except Exception as e:
            # è®°å½•å¤±è´¥æ—¶çš„æ€§èƒ½æŒ‡æ ‡
            PerformanceMonitor.record("AnalysisReviewAgent", time.time() - start_time, "v7.16-error")
            
            logger.error(f"âŒ AnalysisReviewAgent æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
            return {
                "final_ruling": "å®¡æ ¸æ‰§è¡Œå¤±è´¥",
                "improvement_suggestions": [],
                "must_fix_count": 0,
                "analysis_approved": True,  # å¤±è´¥æ—¶é»˜è®¤é€šè¿‡ï¼Œé¿å…é˜»å¡æµç¨‹
                "agents_to_improve": [],
                "red_blue_debate": {},
                "client_review": {},
                "processing_log": [f"âŒ æ‰§è¡Œå¤±è´¥: {e}"],
                "error": str(e)
            }
    
    async def execute_async(
        self,
        agent_results: Dict[str, Any],
        requirements: Dict[str, Any],
        review_iteration_round: int = 0
    ) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œåˆ†æå®¡æ ¸"""
        # å½“å‰å®ç°ä¸åŒæ­¥ç‰ˆæœ¬ç›¸åŒï¼Œåç»­å¯ä¼˜åŒ–ä¸ºçœŸæ­£å¼‚æ­¥
        return self.execute(agent_results, requirements, review_iteration_round)


# ============================================================================
# å‘åå…¼å®¹å±‚
# ============================================================================

class AnalysisReviewNodeCompat:
    """
    å‘åå…¼å®¹åŸ AnalysisReviewNode æ¥å£
    
    ç”¨äºå¹³æ»‘è¿ç§»ï¼Œä¸ä¿®æ”¹ main_workflow.py çš„è°ƒç”¨æ–¹å¼
    """
    
    _agent: Optional[AnalysisReviewAgent] = None
    _llm_model = None
    
    @classmethod
    def initialize(cls, llm_model, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–å…¼å®¹å±‚"""
        if cls._agent is None or cls._llm_model != llm_model:
            cls._llm_model = llm_model
            cls._agent = AnalysisReviewAgent(llm_model, config)
    
    @classmethod
    def execute(
        cls,
        state: Dict[str, Any],
        store=None,
        llm_model=None,
        config: Optional[Dict[str, Any]] = None
    ) -> Command:
        """
        å…¼å®¹åŸ AnalysisReviewNode.execute() æ¥å£
        
        è¿”å› Command å¯¹è±¡ä»¥å…¼å®¹ main_workflow.py
        """
        from ..core.state import AnalysisStage
        
        # åˆå§‹åŒ–
        if llm_model:
            cls.initialize(llm_model, config)
        
        if cls._agent is None:
            logger.error("AnalysisReviewAgent æœªåˆå§‹åŒ–")
            return Command(
                update={"analysis_approved": True},
                goto="detect_challenges"
            )
        
        # æå–å‚æ•°
        agent_results = state.get("agent_results", {})
        requirements = state.get("structured_requirements", {})
        review_iteration_round = state.get("review_iteration_round", 0)
        
        # æ‰§è¡Œå®¡æ ¸
        result = cls._agent.execute(
            agent_results,
            requirements,
            review_iteration_round
        )
        
        # æ„å»ºçŠ¶æ€æ›´æ–°
        updated_state = {
            "current_stage": AnalysisStage.ANALYSIS_REVIEW.value,
            "review_result": result,
            "final_ruling": result.get("final_ruling", ""),
            "improvement_suggestions": result.get("improvement_suggestions", []),
            "analysis_approved": result.get("analysis_approved", True),
            "last_review_decision": result.get("client_review", {}).get("final_decision", "approve")
        }
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡åš
        must_fix_count = result.get("must_fix_count", 0)
        agents_to_improve = result.get("agents_to_improve", [])
        
        if must_fix_count > 0 and review_iteration_round < 1 and agents_to_improve:
            logger.warning(f"ğŸ”„ å‘ç°{must_fix_count}ä¸ªmust_fixé—®é¢˜ï¼Œè§¦å‘ä¸“å®¶æ•´æ”¹")
            
            # æ„å»ºåé¦ˆ
            agent_feedback = {}
            for agent_id in agents_to_improve:
                agent_issues = [
                    imp for imp in result.get("improvement_suggestions", [])
                    if imp.get("agent_id") == agent_id and imp.get("priority") == "must_fix"
                ]
                agent_feedback[agent_id] = {
                    "must_fix_issues": agent_issues,
                    "iteration_round": review_iteration_round + 1
                }
            
            updated_state["specific_agents_to_run"] = agents_to_improve
            updated_state["agent_feedback"] = agent_feedback
            updated_state["review_iteration_round"] = review_iteration_round + 1
            updated_state["skip_role_review"] = True
            updated_state["skip_task_review"] = True
            updated_state["is_rerun"] = True
            
            return Command(update=updated_state, goto="batch_executor")
        
        # æ­£å¸¸æµç¨‹ï¼šç»§ç»­åˆ°æŒ‘æˆ˜æ£€æµ‹
        return Command(update=updated_state, goto="detect_challenges")
