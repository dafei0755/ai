"""
åŸºç¡€æ™ºèƒ½ä½“æ¡†æ¶

å®šä¹‰å¯æ‰©å±•çš„æ™ºèƒ½ä½“åŸºç±»å’Œé€šç”¨åŠŸèƒ½
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any
import asyncio
from datetime import datetime

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from langgraph.store.base import BaseStore
from loguru import logger

from ..core.state import ProjectAnalysisState, AgentType
from ..core.types import AnalysisResult, SystemError, ErrorType


class NullLLM:
    """å ä½LLMï¼Œå½“æœªé…ç½®çœŸå®æ¨¡å‹æ—¶æä¾›å‹å¥½æç¤ºã€‚"""

    def __init__(self, owner: str):
        self.owner = owner

    def _raise(self, method: str) -> None:
        raise RuntimeError(
            f"{self.owner} éœ€è¦é…ç½® llm_model æ‰èƒ½è°ƒç”¨ {method}ã€‚"
            " è¯·åœ¨è¿è¡Œå®Œæ•´å·¥ä½œæµå‰æä¾›æœ‰æ•ˆçš„ LLM å®ä¾‹ã€‚"
        )

    def invoke(self, *args, **kwargs):
        self._raise("invoke")

    def with_structured_output(self, *args, **kwargs):
        self._raise("with_structured_output")

    def __repr__(self) -> str:  # pragma: no cover - è°ƒè¯•è¾…åŠ©
        return f"NullLLM(owner={self.owner!r})"


class BaseAgent(ABC):
    """æ™ºèƒ½ä½“åŸºç±»"""
    
    def __init__(
        self,
        agent_type: AgentType,
        name: str,
        description: str,
        llm_model: Optional[Any] = None,
        tools: Optional[List[Any]] = None,
        config: Optional[Dict[str, Any]] = None
    ):
        self.agent_type = agent_type
        self.name = name
        self.description = description
        self.llm_model = llm_model
        self.tools = tools or []
        self.config = config or {}
        
        # æ€§èƒ½ç›‘æ§
        self.execution_count = 0
        self.total_execution_time = 0.0
        self.last_execution_time = None
        
        logger.info(f"Initialized agent: {self.name} ({self.agent_type.value})")
    
    @abstractmethod
    def execute(
        self,
        state: ProjectAnalysisState,
        config: RunnableConfig,
        store: Optional[BaseStore] = None
    ) -> AnalysisResult:
        """æ‰§è¡Œæ™ºèƒ½ä½“ä»»åŠ¡"""
        pass
    
    @abstractmethod
    def validate_input(self, state: ProjectAnalysisState) -> bool:
        """éªŒè¯è¾“å…¥æ˜¯å¦æœ‰æ•ˆ"""
        pass
    
    def get_dependencies(self) -> List[AgentType]:
        """è·å–ä¾èµ–çš„æ™ºèƒ½ä½“ï¼ˆé»˜è®¤æ— ä¾èµ–ï¼‰"""
        return []
    
    def get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return f"""ä½ æ˜¯{self.name}ï¼Œä¸“é—¨è´Ÿè´£{self.description}ã€‚
        
è¯·æ ¹æ®æä¾›çš„é¡¹ç›®éœ€æ±‚è¿›è¡Œä¸“ä¸šåˆ†æï¼Œå¹¶æä¾›è¯¦ç»†ã€å¯æ“ä½œçš„å»ºè®®ã€‚

åˆ†æè¦æ±‚ï¼š
1. æ·±å…¥ç†è§£é¡¹ç›®éœ€æ±‚å’ŒèƒŒæ™¯
2. æä¾›ä¸“ä¸šã€å‡†ç¡®çš„åˆ†æç»“æœ
3. ç»™å‡ºå…·ä½“ã€å¯æ‰§è¡Œçš„å»ºè®®
4. è€ƒè™‘å®é™…å¯è¡Œæ€§å’Œæˆæœ¬æ•ˆç›Š
5. ç»“æ„åŒ–è¾“å‡ºï¼Œä¾¿äºåç»­å¤„ç†

è¯·ç¡®ä¿åˆ†æç»“æœçš„ä¸“ä¸šæ€§å’Œå®ç”¨æ€§ã€‚"""
    
    def prepare_context(self, state: ProjectAnalysisState) -> str:
        """å‡†å¤‡ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_parts = []
        
        # ç”¨æˆ·éœ€æ±‚
        if state.get("user_input"):
            context_parts.append(f"ç”¨æˆ·åŸå§‹éœ€æ±‚ï¼š\n{state['user_input']}")
        
        # ç»“æ„åŒ–éœ€æ±‚
        if state.get("structured_requirements"):
            context_parts.append(f"ç»“æ„åŒ–éœ€æ±‚ï¼š\n{state['structured_requirements']}")
        
        # æˆ˜ç•¥åˆ†æ
        if state.get("strategic_analysis"):
            context_parts.append(f"æˆ˜ç•¥åˆ†æï¼š\n{state['strategic_analysis']}")
        
        # å…¶ä»–æ™ºèƒ½ä½“çš„ç»“æœï¼ˆå¦‚æœæœ‰ä¾èµ–ï¼‰
        dependencies = self.get_dependencies()
        for dep in dependencies:
            result_key = f"{dep.value.lower()}_result"
            if state.get(result_key):
                context_parts.append(f"{dep.value}åˆ†æç»“æœï¼š\n{state[result_key]}")
        
        return "\n\n".join(context_parts)
    
    def get_review_feedback_for_agent(self, state: ProjectAnalysisState) -> Optional[Dict[str, Any]]:
        """
        ğŸ†• è·å–é’ˆå¯¹å½“å‰ä¸“å®¶çš„å®¡æ ¸åé¦ˆ
        
        Args:
            state: é¡¹ç›®çŠ¶æ€
            
        Returns:
            é’ˆå¯¹å½“å‰ä¸“å®¶çš„åé¦ˆï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        review_feedback = state.get("review_feedback")
        if not review_feedback:
            return None
        
        feedback_by_agent = review_feedback.get("feedback_by_agent", {})
        agent_feedback = feedback_by_agent.get(self.agent_type.value)
        
        return agent_feedback
    
    def build_retry_prompt_suffix(self, review_feedback: Dict[str, Any], retry_round: int) -> str:
        """
        ğŸ†• æ„å»ºé‡è¯•æ—¶çš„promptåç¼€
        
        Args:
            review_feedback: å®¡æ ¸åé¦ˆ
            retry_round: é‡è¯•è½®æ¬¡
            
        Returns:
            è¿½åŠ çš„promptå†…å®¹
        """
        if not review_feedback:
            return ""
        
        issues = review_feedback.get("issues", [])
        suggestions = review_feedback.get("suggestions", [])
        current_conf = review_feedback.get("current_confidence", 0)
        target_conf = review_feedback.get("target_confidence", 0.8)
        
        suffix = f"""

==========================================
âš ï¸ è¿™æ˜¯ç¬¬ {retry_round} æ¬¡åˆ†æ
==========================================

ğŸ“‹ ä¸Šä¸€è½®åˆ†æå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
"""
        for i, issue in enumerate(issues, 1):
            suffix += f"\n{i}. {issue}"
        
        suffix += f"""

ğŸ’¡ æ”¹è¿›å»ºè®®ï¼š
"""
        for i, suggestion in enumerate(suggestions, 1):
            suffix += f"\n{i}. {suggestion}"
        
        suffix += f"""

ğŸ“Š è´¨é‡ç›®æ ‡ï¼š
- å½“å‰ç½®ä¿¡åº¦: {current_conf:.0%}
- ç›®æ ‡ç½®ä¿¡åº¦: {target_conf:.0%}
- éœ€è¦æå‡: {(target_conf - current_conf):.0%}

ğŸ¯ æœ¬æ¬¡åˆ†æè¦æ±‚ï¼š
1. **é‡ç‚¹é’ˆå¯¹ä¸Šè¿°é—®é¢˜é€ä¸€è§£å†³**
2. **è¡¥å……ç¼ºå¤±çš„åˆ†æå†…å®¹å’Œæ•°æ®æ”¯æŒ**
3. **æä¾›æ›´è¯¦ç»†ã€æ›´ä¸“ä¸šçš„åˆ†æ**
4. **ç¡®ä¿åˆ†æè´¨é‡æ˜¾è‘—æå‡**

è¯·æ ¹æ®ä»¥ä¸Šåé¦ˆè¿›è¡Œæ·±åº¦æ”¹è¿›ï¼Œæä¾›æ›´é«˜è´¨é‡çš„åˆ†æç»“æœã€‚
"""
        
        return suffix
    
    def create_analysis_result(
        self,
        content: str,
        structured_data: Optional[Dict[str, Any]] = None,
        confidence: float = 1.0,
        sources: Optional[List[str]] = None
    ) -> AnalysisResult:
        """åˆ›å»ºåˆ†æç»“æœ"""
        result = AnalysisResult(
            agent_type=self.agent_type,
            content=content,
            structured_data=structured_data,
            confidence=confidence,
            sources=sources,
            metadata={
                "agent_name": self.name,
                "execution_time": self.last_execution_time,
                "timestamp": datetime.now().isoformat()
            }
        )
        result.timestamp = datetime.now().isoformat()
        return result
    
    def handle_error(self, error: Exception, context: str = "") -> Exception:
        """
        å¤„ç†é”™è¯¯

        è®°å½•é”™è¯¯ä¿¡æ¯å¹¶è¿”å›ä¸€ä¸ªå¯ä»¥è¢« raise çš„å¼‚å¸¸å¯¹è±¡
        """
        error_message = f"{self.name} execution failed: {str(error)}"
        if context:
            error_message += f" Context: {context}"

        logger.error(error_message)

        # åˆ›å»º SystemError dataclass ç”¨äºè®°å½•ï¼ˆä½†ä¸ç”¨äº raiseï¼‰
        system_error = SystemError(
            error_type=ErrorType.AGENT_ERROR,
            message=error_message,
            details={
                "agent_type": self.agent_type.value,
                "agent_name": self.name,
                "exception_type": type(error).__name__,
                "context": context
            },
            agent_type=self.agent_type,
            recoverable=True
        )

        # è¿”å›åŸå§‹å¼‚å¸¸ï¼ˆå¯ä»¥è¢« raiseï¼‰
        # å¦‚æœéœ€è¦ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„ RuntimeError åŒ…è£…åŸå§‹å¼‚å¸¸
        if isinstance(error, Exception):
            return error
        else:
            return RuntimeError(error_message)
    
    def _track_execution_time(self, start_time: float, end_time: float):
        """è·Ÿè¸ªæ‰§è¡Œæ—¶é—´"""
        execution_time = end_time - start_time
        self.execution_count += 1
        self.total_execution_time += execution_time
        self.last_execution_time = execution_time
        
        logger.info(
            f"{self.name} execution completed in {execution_time:.2f}s "
            f"(avg: {self.total_execution_time/self.execution_count:.2f}s)"
        )
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return {
            "agent_name": self.name,
            "agent_type": self.agent_type.value,
            "execution_count": self.execution_count,
            "total_execution_time": self.total_execution_time,
            "average_execution_time": (
                self.total_execution_time / self.execution_count 
                if self.execution_count > 0 else 0
            ),
            "last_execution_time": self.last_execution_time
        }


class LLMAgent(BaseAgent):
    """åŸºäºLLMçš„æ™ºèƒ½ä½“åŸºç±»"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        if not self.llm_model:
            # ä½¿ç”¨å ä½LLMï¼Œå…è®¸åœ¨æµ‹è¯•ä¸­æ„é€ æ— æ¨¡å‹çš„ä»£ç†
            self.llm_model = NullLLM(self.name)
            self.config.setdefault("llm_placeholder", True)
    
    def invoke_llm(
        self,
        messages: List[BaseMessage],
        **kwargs
    ) -> AIMessage:
        """
        è°ƒç”¨LLMï¼Œå¸¦å‚æ•°éªŒè¯ã€é‡è¯•æœºåˆ¶å’Œè¯¦ç»†é”™è¯¯æ—¥å¿—

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            **kwargs: é¢å¤–çš„LLMå‚æ•°

        Returns:
            AIMessage: LLMå“åº”

        Raises:
            Exception: LLMè°ƒç”¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        import json
        import time

        try:
            # åˆå¹¶é…ç½® - åªæå–invoke()æ–¹æ³•æ”¯æŒçš„å‚æ•°
            # ä¸è¦ä¼ é€’api_key, base_urlç­‰åˆå§‹åŒ–å‚æ•°
            llm_config = self.config.get("llm", {})
            llm_kwargs = {
                "max_tokens": llm_config.get("max_tokens", 4000),
                "temperature": llm_config.get("temperature", 0.7),
                **kwargs  # å…è®¸è°ƒç”¨è€…è¦†ç›–
            }

            # âœ… å‚æ•°éªŒè¯: ç¡®ä¿ max_tokens >= 16 (GPT-4.1 è¦æ±‚)
            max_tokens = llm_kwargs.get("max_tokens", 4000)
            if max_tokens < 16:
                logger.warning(
                    f"[{self.name}] max_tokens ({max_tokens}) å°äº GPT-4.1 æœ€å°å€¼ 16, "
                    f"è‡ªåŠ¨è°ƒæ•´ä¸º 100"
                )
                llm_kwargs["max_tokens"] = 100

            # âœ… é‡è¯•æœºåˆ¶: æœ€å¤šé‡è¯• 3 æ¬¡
            max_retries = 3
            last_error = None

            for attempt in range(max_retries):
                try:
                    # è°ƒç”¨LLM
                    logger.debug(f"[{self.name}] LLM è°ƒç”¨ (å°è¯• {attempt + 1}/{max_retries})")
                    response = self.llm_model.invoke(messages, **llm_kwargs)

                    if not isinstance(response, AIMessage):
                        response = AIMessage(content=str(response))

                    logger.debug(f"[{self.name}] LLM è°ƒç”¨æˆåŠŸ")
                    return response

                except json.JSONDecodeError as e:
                    # âœ… è¯¦ç»†é”™è¯¯æ—¥å¿—: JSON è§£æé”™è¯¯
                    last_error = e
                    logger.error(f"[{self.name}] JSON è§£æé”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                    logger.error(f"[{self.name}] OpenRouter å¯èƒ½è¿”å›äº† HTML é”™è¯¯é¡µé¢è€Œé JSON")
                    logger.error(f"[{self.name}] å¸¸è§åŸå› :")
                    logger.error(f"[{self.name}]   1. max_tokens å‚æ•°å°äº 16 (GPT-4.1 è¦æ±‚)")
                    logger.error(f"[{self.name}]   2. å…¶ä»–å‚æ•°ä¸ç¬¦åˆæ¨¡å‹è¦æ±‚")
                    logger.error(f"[{self.name}]   3. æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨æˆ–é€Ÿç‡é™åˆ¶")

                    if attempt < max_retries - 1:
                        wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿: 1s, 2s, 4s
                        logger.info(f"[{self.name}] ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                    else:
                        logger.error(f"[{self.name}] å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒ")
                        raise

                except Exception as e:
                    # âœ… è¯¦ç»†é”™è¯¯æ—¥å¿—: å…¶ä»–é”™è¯¯
                    last_error = e
                    logger.error(f"[{self.name}] LLM è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {type(e).__name__}: {e}")

                    if attempt < max_retries - 1:
                        wait_time = 2 ** attempt
                        logger.info(f"[{self.name}] ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                    else:
                        logger.error(f"[{self.name}] å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒ")
                        raise

            # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªé”™è¯¯
            if last_error:
                raise last_error

        except Exception as e:
            logger.error(f"[{self.name}] LLM invocation failed: {str(e)}")
            raise
    
    def prepare_messages(
        self,
        state: ProjectAnalysisState,
        additional_context: Optional[Dict[str, Any]] = None
    ) -> List[BaseMessage]:
        """
        å‡†å¤‡LLMæ¶ˆæ¯

        Args:
            state: é¡¹ç›®åˆ†æçŠ¶æ€
            additional_context: å¯é€‰çš„é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯(å¦‚å·¥å…·ç»“æœ)

        Returns:
            æ¶ˆæ¯åˆ—è¡¨
        """
        messages = []

        # ç³»ç»Ÿæç¤º
        system_prompt = self.get_system_prompt()
        messages.append(HumanMessage(content=f"System: {system_prompt}"))

        # ä¸Šä¸‹æ–‡ä¿¡æ¯
        context = self.prepare_context(state)
        if context:
            messages.append(HumanMessage(content=f"Context: {context}"))

        # é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯(å¦‚å·¥å…·ç»“æœ)
        if additional_context:
            context_str = self._format_additional_context(additional_context)
            if context_str:
                messages.append(HumanMessage(content=f"Additional Context: {context_str}"))

        # å…·ä½“ä»»åŠ¡
        task_description = self.get_task_description(state)
        messages.append(HumanMessage(content=f"Task: {task_description}"))

        return messages

    def _format_additional_context(self, context: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯

        Args:
            context: é¢å¤–ä¸Šä¸‹æ–‡å­—å…¸

        Returns:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if not context:
            return ""

        formatted_parts = []
        for key, value in context.items():
            if isinstance(value, (list, dict)):
                import json
                value_str = json.dumps(value, ensure_ascii=False, indent=2)
            else:
                value_str = str(value)
            formatted_parts.append(f"{key}:\n{value_str}")

        return "\n\n".join(formatted_parts)
    
    @abstractmethod
    def get_task_description(self, state: ProjectAnalysisState) -> str:
        """è·å–å…·ä½“ä»»åŠ¡æè¿°"""
        pass


class ToolAgent(BaseAgent):
    """åŸºäºå·¥å…·çš„æ™ºèƒ½ä½“åŸºç±»"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # ä¸åœ¨è¿™é‡Œæ£€æŸ¥å·¥å…·ï¼Œå› ä¸ºå­ç±»å¯èƒ½åœ¨super().__init__()ä¹‹åæ‰åˆå§‹åŒ–å·¥å…·
        # å·¥å…·æ£€æŸ¥åº”è¯¥åœ¨å­ç±»çš„__init__å®Œæˆåè¿›è¡Œ
    
    def execute_tool(self, tool_name: str, **kwargs) -> Any:
        """æ‰§è¡Œå·¥å…·"""
        tool = self.get_tool(tool_name)
        if not tool:
            raise ValueError(f"Tool {tool_name} not found in {self.name}")
        
        try:
            return tool.invoke(**kwargs)
        except Exception as e:
            logger.error(f"Tool {tool_name} execution failed: {str(e)}")
            raise
    
    def get_tool(self, tool_name: str) -> Optional[Any]:
        """è·å–å·¥å…·"""
        for tool in self.tools:
            if hasattr(tool, 'name') and tool.name == tool_name:
                return tool
            elif hasattr(tool, '__name__') and tool.__name__ == tool_name:
                return tool
        return None
    
    def get_available_tools(self) -> List[str]:
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        tool_names = []
        for tool in self.tools:
            if hasattr(tool, 'name'):
                tool_names.append(tool.name)
            elif hasattr(tool, '__name__'):
                tool_names.append(tool.__name__)
        return tool_names


class HybridAgent(LLMAgent, ToolAgent):
    """æ··åˆæ™ºèƒ½ä½“ï¼ˆåŒæ—¶ä½¿ç”¨LLMå’Œå·¥å…·ï¼‰"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # éªŒè¯LLMå·²é…ç½®
        if not self.llm_model:
            raise ValueError(f"LLM model is required for hybrid agent {self.name}")

        # ä¸åœ¨è¿™é‡Œæ£€æŸ¥å·¥å…·ï¼Œå› ä¸ºå­ç±»å¯èƒ½åœ¨super().__init__()ä¹‹åæ‰åˆå§‹åŒ–å·¥å…·
        # å·¥å…·æ£€æŸ¥åº”è¯¥åœ¨å­ç±»çš„__init__å®Œæˆåè¿›è¡Œ


class AgentFactory:
    """æ™ºèƒ½ä½“å·¥å‚"""
    
    _agent_classes = {}
    
    @classmethod
    def register_agent(cls, agent_type: AgentType, agent_class: type):
        """æ³¨å†Œæ™ºèƒ½ä½“ç±»"""
        cls._agent_classes[agent_type] = agent_class
    
    @classmethod
    def create_agent(
        cls,
        agent_type: AgentType,
        llm_model: Optional[Any] = None,
        tools: Optional[List[Any]] = None,
        config: Optional[Dict[str, Any]] = None
    ) -> BaseAgent:
        """åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹"""
        if agent_type not in cls._agent_classes:
            raise ValueError(f"Unknown agent type: {agent_type}")
        
        agent_class = cls._agent_classes[agent_type]

        # æ£€æŸ¥æ„é€ å‡½æ•°å‚æ•°
        import inspect
        sig = inspect.signature(agent_class.__init__)
        params = list(sig.parameters.keys())

        # æ„å»ºå‚æ•°å­—å…¸
        kwargs = {}
        if 'llm_model' in params:
            kwargs['llm_model'] = llm_model
        if 'tools' in params:
            kwargs['tools'] = tools
        if 'config' in params:
            kwargs['config'] = config
        if 'agent_config' in params:
            kwargs['agent_config'] = config

        return agent_class(**kwargs)
    
    @classmethod
    def get_registered_agents(cls) -> List[AgentType]:
        """è·å–å·²æ³¨å†Œçš„æ™ºèƒ½ä½“ç±»å‹"""
        return list(cls._agent_classes.keys())
