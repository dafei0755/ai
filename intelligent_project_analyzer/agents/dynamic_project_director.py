"""
åŠ¨æ€é¡¹ç›®æ€»ç›‘æ™ºèƒ½ä½“ - Dynamic Project Director Agent

åŸºäºè§’è‰²é…ç½®ç³»ç»Ÿçš„é¡¹ç›®æ€»ç›‘,è´Ÿè´£åˆ†æéœ€æ±‚å¹¶é€‰æ‹©åˆé€‚çš„ä¸“ä¸šè§’è‰²ã€‚
Project Director based on role configuration system.
"""

import json
import re
from datetime import datetime
from typing import Any, Dict, List, Optional, Union

from langchain_core.exceptions import OutputParserException
from langchain_core.messages import HumanMessage, SystemMessage
from loguru import logger
from pydantic import BaseModel, Field, ValidationError, model_validator, validator

from intelligent_project_analyzer.core.prompt_manager import PromptManager
from intelligent_project_analyzer.core.role_manager import RoleManager
from intelligent_project_analyzer.core.task_oriented_models import (
    DeliverableFormat,
    DeliverableSpec,
    Priority,
    RoleWithTaskInstruction,
    TaskInstruction,
    TaskInstructionSet,
    generate_task_instruction_template,
    validate_task_instruction_completeness,
)


def format_for_log(obj: Any) -> str:
    """
    æ ¼å¼åŒ–å¯¹è±¡ç”¨äºæ—¥å¿—è¾“å‡ºï¼Œé¿å… Unicode è½¬ä¹‰

    Args:
        obj: è¦æ ¼å¼åŒ–çš„å¯¹è±¡

    Returns:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼Œä¸­æ–‡ä¸ä¼šè¢«è½¬ä¹‰
    """
    if isinstance(obj, (dict, list)):
        return json.dumps(obj, ensure_ascii=False, indent=2)
    elif isinstance(obj, BaseException):
        # å¯¹äºå¼‚å¸¸å¯¹è±¡ï¼Œæå–å¯è¯»çš„é”™è¯¯ä¿¡æ¯
        return json.dumps(str(obj), ensure_ascii=False)
    else:
        return str(obj)


class TaskDetail(BaseModel):
    """ä»»åŠ¡è¯¦æƒ…"""

    tasks: List[str] = Field(description="å…·ä½“ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åº”è¯¥è¯¦ç»†ã€å¯æ‰§è¡Œ", min_length=1)
    focus_areas: List[str] = Field(default_factory=list, description="é‡ç‚¹å…³æ³¨é¢†åŸŸ")
    expected_output: str = Field(default="", description="æœŸæœ›è¾“å‡ºæè¿°")
    dependencies: List[str] = Field(default_factory=list, description="ä¾èµ–çš„å…¶ä»–è§’è‰²ID")


class RoleObject(BaseModel):
    """è§’è‰²å¯¹è±¡ - åŒ…å«è§’è‰²çš„å®Œæ•´ä¿¡æ¯ï¼ˆæ›´æ–°ä¸ºä»»åŠ¡å¯¼å‘ï¼‰"""

    role_id: str = Field(description="è§’è‰²ID (å¦‚ '2-1')")
    role_name: str = Field(description="è§’è‰²åŸºç¡€åç§° (å¦‚ 'å±…ä½ç©ºé—´è®¾è®¡æ€»ç›‘')")
    dynamic_role_name: str = Field(description="åŠ¨æ€è§’è‰²åç§° - åæ˜ æœ¬æ¬¡ä»»åŠ¡ä¸­çš„å…·ä½“èŒè´£ (å¦‚ 'ä¸‰ä»£åŒå ‚å±…ä½ç©ºé—´ä¸ç”Ÿæ´»æ¨¡å¼æ€»è®¾è®¡å¸ˆ')")

    # ğŸ†• ä½¿ç”¨æ–°çš„TaskInstructionæ›¿ä»£åˆ†æ•£çš„å­—æ®µ
    task_instruction: TaskInstruction = Field(description="ç»Ÿä¸€çš„ä»»åŠ¡æ‰§è¡ŒæŒ‡ä»¤ï¼ˆåˆå¹¶äº†tasksã€expected_outputã€focus_areasï¼‰")

    dependencies: List[str] = Field(default_factory=list, description="è¿™ä¸ªåŠ¨æ€è§’è‰²çš„å¯åŠ¨ä¾èµ–")
    execution_priority: int = Field(default=1, description="æ‰§è¡Œä¼˜å…ˆçº§ï¼ˆ1æœ€é«˜ï¼‰")

    # ğŸ”„ ä¿æŒå…¼å®¹æ€§çš„å±æ€§ï¼ˆè‡ªåŠ¨ä»task_instructionç”Ÿæˆï¼‰
    @property
    def tasks(self) -> List[str]:
        """å‘åå…¼å®¹ï¼šä»task_instructionç”Ÿæˆä»»åŠ¡åˆ—è¡¨"""
        return [d.description for d in self.task_instruction.deliverables]

    @property
    def expected_output(self) -> str:
        """å‘åå…¼å®¹ï¼šä»task_instructionç”Ÿæˆé¢„æœŸè¾“å‡º"""
        return self.task_instruction.objective

    @property
    def focus_areas(self) -> List[str]:
        """å‘åå…¼å®¹ï¼šä»task_instructionç”Ÿæˆå…³æ³¨é¢†åŸŸ"""
        return [d.name for d in self.task_instruction.deliverables]


class RoleSelection(BaseModel):
    """è§’è‰²é€‰æ‹©ç»“æœ"""

    selected_roles: List[RoleObject] = Field(description="é€‰ä¸­çš„è§’è‰²å¯¹è±¡åˆ—è¡¨ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«å®Œæ•´çš„è§’è‰²ä¿¡æ¯å’Œä»»åŠ¡åˆ†é…", min_length=3, max_length=8)
    reasoning: str = Field(description="é€‰æ‹©è¿™äº›è§’è‰²çš„è¯¦ç»†ç†ç”±,è§£é‡Šä¸ºä»€ä¹ˆè¿™äº›è§’è‰²æœ€é€‚åˆå®Œæˆä»»åŠ¡", min_length=50)

    # âœ… ä¿ç•™ task_distribution å­—æ®µä»¥å…¼å®¹æ—§ä»£ç ï¼Œä½†è‡ªåŠ¨ä» selected_roles ç”Ÿæˆ
    @property
    def task_distribution(self) -> Dict[str, Union[TaskDetail, str]]:
        """ä» selected_roles è‡ªåŠ¨ç”Ÿæˆ task_distribution ä»¥å…¼å®¹æ—§ä»£ç """
        distribution = {}
        for role in self.selected_roles:
            # æ„é€ å®Œæ•´çš„è§’è‰²ID (å¦‚ "V2_è®¾è®¡æ€»ç›‘_2-1")
            full_id = self._construct_full_role_id(role.role_id)
            distribution[full_id] = TaskDetail(
                tasks=role.tasks,
                focus_areas=role.focus_areas,
                expected_output=role.expected_output,
                dependencies=role.dependencies,
            )
        return distribution

    def _construct_full_role_id(self, role_id: str) -> str:
        """
        æ ¹æ® role_id æ„é€ å®Œæ•´çš„è§’è‰²ID

        æ³¨æ„: ä½¿ç”¨é…ç½®æ–‡ä»¶çš„å®é™…é”®åï¼ˆä¸»è§’è‰²åç§°/é™æ€ï¼‰ï¼Œè€ŒéLLMç”Ÿæˆçš„åŠ¨æ€åç§°
        - V3: "å™äº‹ä¸ä½“éªŒä¸“å®¶" (é…ç½®æ–‡ä»¶) vs "äººç‰©åŠå™äº‹ä¸“å®¶" (LLMç”Ÿæˆ)
        - V5: "åœºæ™¯ä¸è¡Œä¸šä¸“å®¶" (é…ç½®æ–‡ä»¶) vs "åœºæ™¯ä¸ç”¨æˆ·ç”Ÿæ€ä¸“å®¶" (LLMç”Ÿæˆ)
        """
        # å¦‚æœå·²ç»æ˜¯å®Œæ•´æ ¼å¼ (å¦‚ "V2_è®¾è®¡æ€»ç›‘_2-1")ï¼Œç›´æ¥è¿”å›
        if role_id.count("_") >= 2:
            return role_id

        # å¦‚æœåªæ˜¯çŸ­ID (å¦‚ "2-1")ï¼Œéœ€è¦æ¨æ–­å‰ç¼€
        # æ ¹æ®ç¬¬ä¸€ä¸ªæ•°å­—æ¨æ–­å‰ç¼€
        if role_id.startswith("2-"):
            return f"V2_è®¾è®¡æ€»ç›‘_{role_id}"
        elif role_id.startswith("3-"):
            return f"V3_å™äº‹ä¸ä½“éªŒä¸“å®¶_{role_id}"  # âœ… é…ç½®æ–‡ä»¶é”®å
        elif role_id.startswith("4-"):
            return f"V4_è®¾è®¡ç ”ç©¶å‘˜_{role_id}"
        elif role_id.startswith("5-"):
            return f"V5_åœºæ™¯ä¸è¡Œä¸šä¸“å®¶_{role_id}"  # âœ… é…ç½®æ–‡ä»¶é”®å
        elif role_id.startswith("6-"):
            return f"V6_ä¸“ä¸šæ€»å·¥ç¨‹å¸ˆ_{role_id}"
        else:
            # æœªçŸ¥æ ¼å¼ï¼Œç›´æ¥è¿”å›
            return role_id

    @model_validator(mode="after")
    def validate_v4_presence(self) -> "RoleSelection":
        """
        éªŒè¯V4è§’è‰²å­˜åœ¨æ€§ï¼ˆä½¿ç”¨ Pydantic v2 çš„ model_validatorï¼‰

        V4_è®¾è®¡ç ”ç©¶å‘˜æ˜¯å…¶ä»–è§’è‰²çš„åŸºç¡€ä¾èµ–ï¼Œå¿…é¡»å§‹ç»ˆåŒ…å«åœ¨selected_rolesä¸­ã€‚

        Raises:
            ValueError: å¦‚æœselected_rolesä¸­æ²¡æœ‰V4è§’è‰²
        """
        # ä» RoleObject ä¸­æå– role_id
        role_ids = [role.role_id for role in self.selected_roles]
        has_v4 = any(rid.startswith("4-") or rid.startswith("V4_") for rid in role_ids)

        if not has_v4:
            raise ValueError(
                "âŒ V4_è®¾è®¡ç ”ç©¶å‘˜æ˜¯å¿…é€‰è§’è‰²ï¼Œä½†åœ¨selected_rolesä¸­æœªæ‰¾åˆ°ã€‚\n"
                "V4æ˜¯å…¶ä»–è§’è‰²ï¼ˆV2ã€V3ã€V5ï¼‰çš„ä¾èµ–åŸºç¡€ï¼Œå¿…é¡»åŒ…å«ã€‚\n"
                f"å½“å‰role_ids: {role_ids}\n"
                "è¯·é‡æ–°é€‰æ‹©ï¼Œç¡®ä¿åŒ…å«è‡³å°‘ä¸€ä¸ªrole_idä»¥'4-'å¼€å¤´çš„è§’è‰²ã€‚"
            )

        # éªŒè¯é€šè¿‡ï¼Œè®°å½•æ—¥å¿—
        v4_roles = [
            role for role in self.selected_roles if role.role_id.startswith("4-") or role.role_id.startswith("V4_")
        ]
        logger.info(f"âœ… V4è§’è‰²éªŒè¯é€šè¿‡: {[r.role_id for r in v4_roles]}")

        return self

    @model_validator(mode="after")
    def validate_task_distribution_differentiation(self) -> "RoleSelection":
        """
        ğŸ†• éªŒè¯ä»»åŠ¡åˆ†é…å·®å¼‚åŒ–ï¼ˆé˜²æ­¢å¹³å‡åˆ†é…ï¼‰

        ç¡®ä¿æ ¸å¿ƒè§’è‰²æ‰¿æ‹…æ›´å¤šä»»åŠ¡ï¼Œé¿å…æ‰€æœ‰è§’è‰²å¹³å‡åˆ†é…ç›¸åŒæ•°é‡çš„äº¤ä»˜ç‰©ã€‚
        è¿™æ˜¯é’ˆå¯¹ä¸“é¢˜1å‘ç°çš„"ä»»åŠ¡åˆ†é…å¹³å‡åŒ–å€¾å‘"é—®é¢˜çš„ä¿®å¤ã€‚

        è§„åˆ™ï¼š
        - å¦‚æœæ‰€æœ‰è§’è‰²çš„äº¤ä»˜ç‰©æ•°é‡æ ‡å‡†å·® < 0.5ï¼Œè®¤ä¸ºæ˜¯å¹³å‡åˆ†é…
        - è‡³å°‘åº”è¯¥æœ‰1ä¸ªè§’è‰²çš„äº¤ä»˜ç‰©æ•°é‡æ˜¾è‘—é«˜äºå¹³å‡å€¼

        Raises:
            ValueError: å¦‚æœä»»åŠ¡åˆ†é…è¿‡äºå¹³å‡åŒ–
        """
        import statistics

        # ç»Ÿè®¡æ¯ä¸ªè§’è‰²çš„äº¤ä»˜ç‰©æ•°é‡
        deliverable_counts = [len(role.task_instruction.deliverables) for role in self.selected_roles]

        if len(deliverable_counts) < 2:
            # åªæœ‰1ä¸ªè§’è‰²æ—¶ä¸éªŒè¯
            return self

        # è®¡ç®—æ ‡å‡†å·®
        mean_count = statistics.mean(deliverable_counts)
        stdev_count = statistics.stdev(deliverable_counts) if len(deliverable_counts) > 1 else 0

        logger.info(f"ğŸ“Š äº¤ä»˜ç‰©æ•°é‡åˆ†å¸ƒ: {deliverable_counts}, å¹³å‡å€¼: {mean_count:.1f}, æ ‡å‡†å·®: {stdev_count:.2f}")

        # å¦‚æœæ ‡å‡†å·®å¤ªå°ï¼Œè¯´æ˜åˆ†é…è¿‡äºå¹³å‡
        if stdev_count < 0.8:  # é˜ˆå€¼å¯è°ƒæ•´
            logger.warning(
                f"âš ï¸ ä»»åŠ¡åˆ†é…è¿‡äºå¹³å‡åŒ–ï¼æ ‡å‡†å·®: {stdev_count:.2f} < 0.8\n"
                f"   äº¤ä»˜ç‰©æ•°é‡: {deliverable_counts}\n"
                f"   å»ºè®®: æ ¸å¿ƒè§’è‰²åº”æ‰¿æ‹…4-6ä¸ªäº¤ä»˜ç‰©ï¼Œæ”¯æŒè§’è‰²1-2ä¸ª"
            )
            # æ³¨æ„: è¿™é‡Œä½¿ç”¨warningè€Œéraiseï¼Œç»™LLMä¸€äº›å®¹é”™ç©ºé—´
            # å¦‚æœéœ€è¦ä¸¥æ ¼æ§åˆ¶ï¼Œå¯æ”¹ä¸º raise ValueError

        # éªŒè¯æ˜¯å¦æœ‰"æ ¸å¿ƒè§’è‰²"ï¼ˆè‡³å°‘4ä¸ªäº¤ä»˜ç‰©ï¼‰
        max_count = max(deliverable_counts)
        if max_count >= 4:
            core_roles = [role.role_id for role, count in zip(self.selected_roles, deliverable_counts) if count >= 4]
            logger.info(f"âœ… æ£€æµ‹åˆ°æ ¸å¿ƒè§’è‰²: {core_roles} (äº¤ä»˜ç‰©æ•°é‡â‰¥4)")
        else:
            logger.warning(f"âš ï¸ æ‰€æœ‰è§’è‰²çš„äº¤ä»˜ç‰©æ•°é‡éƒ½<4ï¼Œå¯èƒ½ç¼ºå°‘æ ¸å¿ƒè§’è‰²")

        return self

    @model_validator(mode="after")
    def validate_task_deliverable_alignment(self) -> "RoleSelection":
        """
        ğŸ†• éªŒè¯ä»»åŠ¡-äº¤ä»˜ç‰©å¯¹é½ï¼ˆç¡®ä¿ç”¨æˆ·ç¡®è®¤çš„ä»»åŠ¡è¢«è¦†ç›–ï¼‰

        æ£€æŸ¥confirmed_core_tasksä¸­çš„æ¯ä¸ªä»»åŠ¡æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªä¸“å®¶çš„deliverableä¸ä¹‹å¯¹åº”ã€‚
        è¿™æ˜¯é’ˆå¯¹é—®å·ä¸ä»»åŠ¡åˆ†é…å…³ç³»ç ”ç©¶å‘ç°çš„å…³é”®ä¼˜åŒ–ï¼šç”¨æˆ·ç¡®è®¤çš„ä»»åŠ¡å¿…é¡»è¢«æ‰§è¡Œã€‚

        å¯¹é½ç®—æ³•ï¼š
        1. æå–ä»»åŠ¡æ ‡é¢˜çš„å…³é”®è¯ï¼ˆå»é™¤åœç”¨è¯ï¼‰
        2. éå†æ‰€æœ‰è§’è‰²çš„äº¤ä»˜ç‰©ï¼Œæ£€æŸ¥deliverableçš„name/descriptionæ˜¯å¦åŒ…å«ä»»åŠ¡å…³é”®è¯
        3. å¦‚æœä»»åŠ¡çš„å…³é”®è¯åŒ¹é…åº¦ >= 50%ï¼Œè®¤ä¸ºè¯¥ä»»åŠ¡è¢«è¦†ç›–

        æ³¨æ„ï¼šæ­¤éªŒè¯éœ€è¦ä»å¤–éƒ¨contextè·å–confirmed_core_tasksï¼Œæš‚æ—¶è®°å½•è­¦å‘Šè€Œéå¼ºåˆ¶å¤±è´¥
        """
        # å°è¯•ä»model_configçš„contextä¸­è·å–confirmed_core_tasks
        # æ³¨æ„ï¼šç”±äºPydanticæ¨¡å‹çš„é™åˆ¶ï¼Œè¿™é‡Œéœ€è¦ç‰¹æ®Šå¤„ç†
        confirmed_tasks = getattr(self, "_confirmed_tasks", None)

        if not confirmed_tasks:
            # æ²¡æœ‰confirmed_tasksæ•°æ®ï¼Œè·³è¿‡éªŒè¯
            logger.debug("ğŸ“‹ æœªæ£€æµ‹åˆ°confirmed_core_tasksï¼Œè·³è¿‡ä»»åŠ¡-äº¤ä»˜ç‰©å¯¹é½éªŒè¯")
            return self

        logger.info(f"ğŸ“‹ å¼€å§‹éªŒè¯ {len(confirmed_tasks)} ä¸ªç¡®è®¤ä»»åŠ¡çš„å¯¹é½æƒ…å†µ...")

        # æ”¶é›†æ‰€æœ‰äº¤ä»˜ç‰©çš„å…³é”®è¯
        all_deliverables = []
        for role in self.selected_roles:
            for deliverable in role.task_instruction.deliverables:
                all_deliverables.append(
                    {
                        "role_id": role.role_id,
                        "name": deliverable.name,
                        "description": deliverable.description,
                        "text": f"{deliverable.name} {deliverable.description}".lower(),
                    }
                )

        # æ£€æŸ¥æ¯ä¸ªç¡®è®¤ä»»åŠ¡æ˜¯å¦è¢«è¦†ç›–
        uncovered_tasks = []
        for task in confirmed_tasks:
            task_title = task.get("title", "")
            task_desc = task.get("description", "")
            task_keywords = self._extract_keywords(f"{task_title} {task_desc}")

            # æŸ¥æ‰¾åŒ¹é…çš„äº¤ä»˜ç‰©
            matched = False
            best_match_score = 0
            best_match_deliverable = None

            for deliverable in all_deliverables:
                # è®¡ç®—å…³é”®è¯åŒ¹é…åº¦
                match_count = sum(1 for kw in task_keywords if kw in deliverable["text"])
                match_score = match_count / len(task_keywords) if task_keywords else 0

                if match_score > best_match_score:
                    best_match_score = match_score
                    best_match_deliverable = deliverable

                if match_score >= 0.4:  # 40%åŒ¹é…åº¦é˜ˆå€¼
                    matched = True
                    logger.info(
                        f"  âœ… ä»»åŠ¡ '{task_title}' å·²å¯¹é½åˆ° {deliverable['role_id']} "
                        f"çš„äº¤ä»˜ç‰© '{deliverable['name']}' (åŒ¹é…åº¦: {match_score:.0%})"
                    )
                    break

            if not matched:
                uncovered_tasks.append(
                    {
                        "task": task_title,
                        "best_match": best_match_deliverable["name"] if best_match_deliverable else "N/A",
                        "score": best_match_score,
                    }
                )
                logger.warning(
                    f"  âš ï¸ ä»»åŠ¡ '{task_title}' æœªè¢«å……åˆ†è¦†ç›–ï¼"
                    f"æœ€ä½³åŒ¹é…: {best_match_deliverable['name'] if best_match_deliverable else 'N/A'} "
                    f"(åŒ¹é…åº¦ä»…: {best_match_score:.0%})"
                )

        # æ±‡æ€»éªŒè¯ç»“æœ
        if uncovered_tasks:
            logger.warning(
                f"âš ï¸ ä»»åŠ¡-äº¤ä»˜ç‰©å¯¹é½éªŒè¯: {len(uncovered_tasks)}/{len(confirmed_tasks)} ä¸ªä»»åŠ¡æœªè¢«å……åˆ†è¦†ç›–\n"
                f"   æœªè¦†ç›–ä»»åŠ¡: {[t['task'] for t in uncovered_tasks]}\n"
                f"   å»ºè®®: LLMå¯èƒ½éœ€è¦ä¸ºè¿™äº›ä»»åŠ¡åˆ†é…ä¸“é—¨çš„äº¤ä»˜ç‰©"
            )
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨warningè€Œéraiseï¼Œé¿å…é˜»æ–­æµç¨‹
            # åœ¨å®é™…åœºæ™¯ä¸­ï¼Œå¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚å†³å®šæ˜¯å¦å¼ºåˆ¶å¤±è´¥
        else:
            logger.info(f"âœ… ä»»åŠ¡-äº¤ä»˜ç‰©å¯¹é½éªŒè¯é€šè¿‡: æ‰€æœ‰ {len(confirmed_tasks)} ä¸ªç¡®è®¤ä»»åŠ¡å‡å·²è¦†ç›–")

        return self

    def _extract_keywords(self, text: str) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼ˆç®€åŒ–ç‰ˆï¼Œå»é™¤åœç”¨è¯ï¼‰

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        import re

        # ç®€å•çš„åœç”¨è¯åˆ—è¡¨ï¼ˆä¸­æ–‡ï¼‰
        stopwords = {
            "çš„",
            "äº†",
            "å’Œ",
            "æ˜¯",
            "åœ¨",
            "æœ‰",
            "ä¸",
            "å¯¹",
            "ä¸º",
            "ä»¥",
            "åŠ",
            "ç­‰",
            "ä¸­",
            "ä¸ª",
            "å°†",
            "è¦",
            "å¯",
            "èƒ½",
            "å¦‚",
            "æˆ–",
            "ç­‰",
            "äº",
            "ç”±",
            "ä»",
        }

        # åˆ†è¯ï¼ˆç®€å•æŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²ï¼‰
        words = re.findall(r"[\w]+", text.lower())

        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        keywords = [w for w in words if w not in stopwords and len(w) >= 2]

        return keywords


class DynamicProjectDirector:
    """
    åŠ¨æ€é¡¹ç›®æ€»ç›‘ - è´Ÿè´£åˆ†æéœ€æ±‚å¹¶é€‰æ‹©åˆé€‚çš„è§’è‰²

    èŒè´£:
    1. åˆ†æç”¨æˆ·éœ€æ±‚
    2. ä»å¯ç”¨è§’è‰²ä¸­é€‰æ‹©3-8ä¸ªæœ€åˆé€‚çš„è§’è‰²
    3. ä¸ºæ¯ä¸ªè§’è‰²åˆ†é…å…·ä½“ä»»åŠ¡
    4. è§£é‡Šé€‰æ‹©ç†ç”±
    """

    def __init__(self, llm_model, role_manager: RoleManager):
        """
        åˆå§‹åŒ–é¡¹ç›®æ€»ç›‘

        Args:
            llm_model: LLMæ¨¡å‹å®ä¾‹
            role_manager: è§’è‰²ç®¡ç†å™¨å®ä¾‹
        """
        self.llm = llm_model
        self.role_manager = role_manager

        # åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨
        self.prompt_manager = PromptManager()

        # ã€æ–°å¢ã€‘åˆå§‹åŒ–æƒé‡è®¡ç®—å™¨
        from pathlib import Path

        from intelligent_project_analyzer.services.role_weight_calculator import RoleWeightCalculator

        strategy_path = Path(__file__).parent.parent / "config" / "role_selection_strategy.yaml"
        self.weight_calculator = RoleWeightCalculator(str(strategy_path))
        logger.info("âœ… æƒé‡è®¡ç®—å™¨å·²åˆå§‹åŒ–")

    def select_roles_for_task(
        self, requirements: str, confirmed_core_tasks: Optional[List[Dict[str, Any]]] = None, max_retries: int = 3
    ) -> RoleSelection:
        """
        æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„è§’è‰²ï¼ˆå¸¦ project_scope è¿‡æ»¤ï¼‰

        Args:
            requirements: ç”¨æˆ·éœ€æ±‚æè¿°
            confirmed_core_tasks: ç”¨æˆ·ç¡®è®¤çš„æ ¸å¿ƒä»»åŠ¡åˆ—è¡¨ï¼ˆç”¨äºä»»åŠ¡-äº¤ä»˜ç‰©å¯¹é½éªŒè¯ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Note:
            ä¸å†éœ€è¦å¤–éƒ¨ä¼ å…¥task_complexityï¼Œç”±LLMæ ¹æ®éœ€æ±‚è‡ªä¸»åˆ¤æ–­é¡¹ç›®å¤æ‚åº¦å’Œä¸“å®¶ç»„åˆ
        """
        # 1. è§£æ project_scope å­—æ®µï¼ˆæ”¯æŒ JSON æ ¼å¼æˆ– YAML æ ¼å¼è¾“å…¥ï¼‰
        project_scope = None
        # å°è¯•æå– project_scope
        match = re.search(r'"project_scope"\s*:\s*"([^"]+)"', requirements)
        if match:
            project_scope = match.group(1)
        else:
            # å°è¯• YAML æ ¼å¼
            match2 = re.search(r"project_scope\s*:\s*([a-zA-Z_]+)", requirements)
            if match2:
                project_scope = match2.group(1)
        # é»˜è®¤ mixed
        if not project_scope:
            project_scope = "mixed"
        logger.info(f"ğŸ” è§£æåˆ° project_scope: {project_scope}")

        # 2. è®¡ç®—è§’è‰²æƒé‡ï¼ˆğŸ†• ä¼ é€’confirmed_core_tasksä»¥æå‡ç²¾åº¦ï¼‰
        role_weights = self.weight_calculator.calculate_weights(requirements, confirmed_core_tasks=confirmed_core_tasks)
        logger.info(f"ğŸ“Š è§’è‰²æƒé‡è®¡ç®—å®Œæˆ: {role_weights}")

        # 3. è·å–æ‰€æœ‰å¯ç”¨è§’è‰²ï¼Œå¹¶æ ¹æ® applicable_scope è¿‡æ»¤
        available_roles = self.role_manager.get_available_roles()
        filtered_roles = []
        for role in available_roles:
            scope_list = role.get("applicable_scope")
            if scope_list:
                if project_scope in scope_list:
                    filtered_roles.append(role)
            else:
                # æ²¡æœ‰ scope é™åˆ¶çš„è§’è‰²é»˜è®¤ä¿ç•™
                filtered_roles.append(role)

        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰è§’è‰²ï¼Œä½¿ç”¨æ‰€æœ‰è§’è‰²ä½œä¸ºåå¤‡
        if not filtered_roles:
            logger.warning(f"âš ï¸ æ ¹æ® scope '{project_scope}' è¿‡æ»¤åæ²¡æœ‰å¯ç”¨è§’è‰²ï¼Œå°†ä½¿ç”¨æ‰€æœ‰ {len(available_roles)} ä¸ªè§’è‰²")
            filtered_roles = available_roles

        logger.info(f"âœ… æœ€ç»ˆå¯ç”¨è§’è‰²æ•°: {len(filtered_roles)}")

        # 4. æ„å»ºè§’è‰²ä¿¡æ¯å­—ç¬¦ä¸²ï¼ˆåŒ…å«æƒé‡ï¼‰
        roles_info = self._format_roles_info_with_weights(filtered_roles, role_weights)

        # 5. æ„å»ºæç¤ºè¯ï¼ˆè®©LLMè‡ªä¸»åˆ¤æ–­å¤æ‚åº¦ï¼‰
        system_prompt = self._build_system_prompt()
        user_prompt = self._build_user_prompt_with_weights(requirements, roles_info, role_weights)

        # 6. è°ƒç”¨LLMè¿›è¡Œè§’è‰²é€‰æ‹©ï¼ˆå¸¦é‡è¯•ï¼‰
        messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_prompt)]

        llm_with_structure = self.llm.with_structured_output(RoleSelection, method="json_mode")

        last_error = None
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ å°è¯•è§’è‰²é€‰æ‹© (ç¬¬ {attempt + 1}/{max_retries} æ¬¡)")
                raw_response = None
                try:
                    raw_response = llm_with_structure.invoke(messages)
                    logger.debug(f"ğŸ“¥ LLMåŸå§‹å“åº”ç±»å‹: {type(raw_response)}")
                except (ValidationError, OutputParserException) as structured_error:
                    logger.warning(f"âš ï¸ LangChainç»“æ„åŒ–è¾“å‡ºå¤±è´¥ ({type(structured_error).__name__})\n" f"   å°è¯•ä»å¼‚å¸¸ä¸­æ¢å¤åŸå§‹å“åº”...")
                    raw_response = self._extract_raw_response_from_validation_error(structured_error)
                    if raw_response is None:
                        logger.error("âŒ æ— æ³•æå–LLMåŸå§‹å“åº”ï¼Œå°†åœ¨ {max_retries-attempt} æ¬¡åé™çº§")
                        raise structured_error

                response = self._validate_response_with_conversion(raw_response)

                # ğŸ†• å°†confirmed_core_tasksæ³¨å…¥åˆ°responseå¯¹è±¡ä»¥ä¾¿éªŒè¯å™¨ä½¿ç”¨
                if confirmed_core_tasks:
                    response._confirmed_tasks = confirmed_core_tasks

                if not response.task_distribution:
                    error_msg = "âŒ task_distribution ä¸èƒ½ä¸ºç©ºå­—å…¸ï¼å¿…é¡»ä¸ºæ¯ä¸ªé€‰æ‹©çš„è§’è‰²åˆ†é…ä»»åŠ¡ã€‚"
                    logger.error(error_msg)
                    raise ValueError(error_msg)
                task_dist_keys = set(response.task_distribution.keys())
                logger.info(f"ğŸ” [DEBUG] task_distribution keys: {task_dist_keys}")
                if len(task_dist_keys) != len(response.selected_roles):
                    error_msg = f"âŒ task_distribution ({len(task_dist_keys)}ä¸ª) ä¸ selected_roles ({len(response.selected_roles)}ä¸ª) æ•°é‡ä¸ä¸€è‡´"
                    logger.error(error_msg)
                    raise ValueError(error_msg)
                if not isinstance(response.task_distribution, dict):
                    logger.warning(f"âš ï¸ task_distribution is not a dict: {type(response.task_distribution)}")
                    response = self._fix_task_distribution(response)
                logger.info(f"âœ… Role selection successful on attempt {attempt + 1}")
                logger.info(f"ğŸ” [DEBUG] task_distribution ç±»å‹: {type(response.task_distribution)}")
                logger.info(f"ğŸ” [DEBUG] task_distribution åŒ…å« {len(response.task_distribution)} ä¸ªè§’è‰²")
                for role_id, task_data in response.task_distribution.items():
                    logger.info(f"ğŸ” [DEBUG] è§’è‰² {role_id}:")
                    logger.info(f"   - task_data ç±»å‹: {type(task_data)}")
                    if hasattr(task_data, "tasks"):
                        logger.info(f"   - TaskDetail å¯¹è±¡ï¼ŒåŒ…å« {len(task_data.tasks)} ä¸ªä»»åŠ¡")
                        logger.info(f"   - ä»»åŠ¡åˆ—è¡¨å‰2ä¸ª: {format_for_log(task_data.tasks[:2])}")
                    elif isinstance(task_data, dict):
                        logger.info(f"   - å­—å…¸æ ¼å¼ï¼Œkeys: {format_for_log(list(task_data.keys()))}")
                    elif isinstance(task_data, str):
                        logger.info(f"   - å­—ç¬¦ä¸²æ ¼å¼ï¼Œé•¿åº¦: {len(task_data)}")
                        logger.info(f"   - å†…å®¹é¢„è§ˆ: {task_data[:100]}...")
                    else:
                        logger.info(f"   - æœªçŸ¥æ ¼å¼: {type(task_data)}")
                return response
            except (ValidationError, ValueError, OutputParserException) as e:
                last_error = e
                error_type = type(e).__name__
                logger.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: [{error_type}] {format_for_log(e)}")
                if attempt < max_retries - 1:
                    logger.info(f"ğŸ”„ å‡†å¤‡é‡è¯•... (ç¬¬ {attempt + 2}/{max_retries} æ¬¡)")
                    continue
                else:
                    logger.error(
                        f"âŒ æ‰€æœ‰ {max_retries} æ¬¡å°è¯•å‡å¤±è´¥ï¼Œé™çº§åˆ°é»˜è®¤è§’è‰²é€‰æ‹©\n"
                        f"   æœ€åé”™è¯¯: [{error_type}] {str(e)[:500]}\n"
                        f"   ğŸš¨ é™çº§è­¦å‘Š: é»˜è®¤é€‰æ‹©çš„ä»»åŠ¡è´¨é‡å¯èƒ½ä½äºLLMæ™ºèƒ½é€‰æ‹©"
                    )
                    # è®°å½•é™çº§äº‹ä»¶ï¼ˆå¯ç”¨äºç›‘æ§å’Œä¼˜åŒ–ï¼‰
                    self._log_fallback_event(requirements, last_error)
            except Exception as e:
                # ğŸ”¥ æ–°å¢ï¼šæ•è·ç½‘ç»œè¿æ¥é”™è¯¯ï¼ˆå¦‚ SSL/ä»£ç†é—®é¢˜ï¼‰
                last_error = e
                error_type = type(e).__name__
                logger.error(f"âŒ Attempt {attempt + 1} failed with {error_type}: {e}")

                # å¦‚æœæ˜¯ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
                if "Connection" in error_type or "SSL" in str(e):
                    logger.error("ğŸŒ æ£€æµ‹åˆ°ç½‘ç»œè¿æ¥é—®é¢˜:")
                    logger.error(f"   - é”™è¯¯ç±»å‹: {error_type}")
                    logger.error(f"   - é”™è¯¯è¯¦æƒ…: {str(e)[:200]}")
                    logger.error("   - å¯èƒ½åŸå› : SSLè¯ä¹¦éªŒè¯å¤±è´¥ã€ä»£ç†é…ç½®é—®é¢˜ã€ç½‘ç»œä¸ç¨³å®š")
                    logger.error("   - å»ºè®®: æ£€æŸ¥ .env ä¸­çš„ OPENAI_API_BASE/OPENAI_PROXY è®¾ç½®")

                if attempt < max_retries - 1:
                    import time

                    wait_time = 2**attempt  # æŒ‡æ•°é€€é¿: 1s, 2s, 4s
                    logger.info(f"ğŸ”„ ç­‰å¾… {wait_time}ç§’åé‡è¯•... ({attempt + 2}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    logger.error(f"âŒ All {max_retries} attempts failed due to {error_type}")
                    # æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†
                    raise
        # ...existing code...
        """
        æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„è§’è‰²ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        Args:
            requirements: ç”¨æˆ·éœ€æ±‚æè¿°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰

        Returns:
            RoleSelectionå¯¹è±¡,åŒ…å«é€‰ä¸­çš„è§’è‰²å’Œç†ç”±
        """
        # ã€æ–°å¢ã€‘1. è®¡ç®—è§’è‰²æƒé‡
        role_weights = self.weight_calculator.calculate_weights(requirements)
        logger.info(f"ğŸ“Š è§’è‰²æƒé‡è®¡ç®—å®Œæˆ: {role_weights}")

        # è·å–æ‰€æœ‰å¯ç”¨è§’è‰²
        available_roles = self.role_manager.get_available_roles()

        # æ„å»ºè§’è‰²ä¿¡æ¯å­—ç¬¦ä¸²ï¼ˆåŒ…å«æƒé‡ï¼‰
        roles_info = self._format_roles_info_with_weights(available_roles, role_weights)

        # æ„å»ºæç¤ºè¯
        system_prompt = self._build_system_prompt()
        user_prompt = self._build_user_prompt_with_weights(requirements, roles_info, role_weights)

        # è°ƒç”¨LLMè¿›è¡Œè§’è‰²é€‰æ‹©ï¼ˆå¸¦é‡è¯•ï¼‰
        messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_prompt)]

        # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º (ä½¿ç”¨ json_mode æ–¹æ³•ä»¥æ›´å¥½æ”¯æŒå¤æ‚åµŒå¥—ç±»å‹)
        # æ³¨æ„: json_mode æ¯” function_calling æ›´å¥½åœ°æ”¯æŒ Dict[str, Union[TaskDetail, str]] è¿™ç§å¤æ‚ç±»å‹
        llm_with_structure = self.llm.with_structured_output(RoleSelection, method="json_mode")

        # é‡è¯•é€»è¾‘
        last_error = None
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ Attempting role selection (attempt {attempt + 1}/{max_retries})")
                raw_response = llm_with_structure.invoke(messages)

                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šLLM è¿”å›çš„åŸå§‹å“åº”
                logger.info(f"ğŸ” [DEBUG] LLM è¿”å›çš„ raw_response ç±»å‹: {type(raw_response)}")

                # ğŸš¨ æ‰‹åŠ¨éªŒè¯å“åº”ï¼ˆè§¦å‘ Pydantic çš„ @model_validatorï¼‰
                # è¿™æ˜¯å…³é”®æ­¥éª¤ï¼with_structured_output ä¸ä¼šè°ƒç”¨éªŒè¯å™¨ï¼Œéœ€è¦æ‰‹åŠ¨è°ƒç”¨
                try:
                    response = RoleSelection.model_validate(raw_response)
                    logger.info("âœ… Pydantic éªŒè¯é€šè¿‡")
                except Exception as validation_error:
                    logger.error(f"âŒ Pydantic éªŒè¯å¤±è´¥: {format_for_log(validation_error)}")
                    raise validation_error

                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šéªŒè¯åçš„å“åº”
                logger.info(
                    f"ğŸ” [DEBUG] response.selected_roles: {format_for_log([r.dict() for r in response.selected_roles])}"
                )
                logger.info(f"ğŸ” [DEBUG] response.task_distribution ç±»å‹: {type(response.task_distribution)}")

                # ğŸš¨ é¢å¤–çš„æ‰‹åŠ¨éªŒè¯ï¼ˆåŒé‡ä¿é™©ï¼‰
                if not response.task_distribution:
                    error_msg = "âŒ task_distribution ä¸èƒ½ä¸ºç©ºå­—å…¸ï¼å¿…é¡»ä¸ºæ¯ä¸ªé€‰æ‹©çš„è§’è‰²åˆ†é…ä»»åŠ¡ã€‚"
                    logger.error(error_msg)
                    raise ValueError(error_msg)

                # ğŸš¨ æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é€‰æ‹©çš„è§’è‰²éƒ½æœ‰ä»»åŠ¡åˆ†é…
                # âœ… ä¿®å¤ï¼šresponse.task_distribution çš„é”®å·²ç»æ˜¯å®Œæ•´è§’è‰²ID (é€šè¿‡ @property è‡ªåŠ¨ç”Ÿæˆ)
                # ç”±äº task_distribution æ˜¯ä» selected_roles è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œè¿™ä¸ªæ£€æŸ¥å®é™…ä¸Šæ€»æ˜¯é€šè¿‡
                # ä¿ç•™è¿™ä¸ªæ£€æŸ¥ä»…ç”¨äºé˜²å¾¡æ€§ç¼–ç¨‹
                task_dist_keys = set(response.task_distribution.keys())
                logger.info(f"ğŸ” [DEBUG] task_distribution keys: {task_dist_keys}")

                if len(task_dist_keys) != len(response.selected_roles):
                    error_msg = f"âŒ task_distribution ({len(task_dist_keys)}ä¸ª) ä¸ selected_roles ({len(response.selected_roles)}ä¸ª) æ•°é‡ä¸ä¸€è‡´"
                    logger.error(error_msg)
                    raise ValueError(error_msg)

                # éªŒè¯ task_distribution æ˜¯å¦ä¸ºå­—å…¸
                if not isinstance(response.task_distribution, dict):
                    logger.warning(f"âš ï¸ task_distribution is not a dict: {type(response.task_distribution)}")
                    # å°è¯•ä¿®å¤
                    response = self._fix_task_distribution(response)
                    # å°è¯•ä¿®å¤
                    response = self._fix_task_distribution(response)

                logger.info(f"âœ… Role selection successful on attempt {attempt + 1}")

                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡º task_distribution çš„è¯¦ç»†ä¿¡æ¯
                logger.info(f"ğŸ” [DEBUG] task_distribution ç±»å‹: {type(response.task_distribution)}")
                logger.info(f"ğŸ” [DEBUG] task_distribution åŒ…å« {len(response.task_distribution)} ä¸ªè§’è‰²")

                for role_id, task_data in response.task_distribution.items():
                    logger.info(f"ğŸ” [DEBUG] è§’è‰² {role_id}:")
                    logger.info(f"   - task_data ç±»å‹: {type(task_data)}")
                    if hasattr(task_data, "tasks"):
                        logger.info(f"   - TaskDetail å¯¹è±¡ï¼ŒåŒ…å« {len(task_data.tasks)} ä¸ªä»»åŠ¡")
                        logger.info(f"   - ä»»åŠ¡åˆ—è¡¨å‰2ä¸ª: {format_for_log(task_data.tasks[:2])}")
                    elif isinstance(task_data, dict):
                        logger.info(f"   - å­—å…¸æ ¼å¼ï¼Œkeys: {format_for_log(list(task_data.keys()))}")
                    elif isinstance(task_data, str):
                        logger.info(f"   - å­—ç¬¦ä¸²æ ¼å¼ï¼Œé•¿åº¦: {len(task_data)}")
                        logger.info(f"   - å†…å®¹é¢„è§ˆ: {task_data[:100]}...")
                    else:
                        logger.info(f"   - æœªçŸ¥æ ¼å¼: {type(task_data)}")

                return response

            except (ValidationError, ValueError) as e:
                last_error = e
                logger.warning(f"âš ï¸ Attempt {attempt + 1} failed with validation error: {format_for_log(e)}")

                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç»§ç»­é‡è¯•
                if attempt < max_retries - 1:
                    logger.info(f"ğŸ”„ Retrying... ({attempt + 2}/{max_retries})")
                    continue
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿
                    logger.error(f"âŒ All {max_retries} attempts failed, using default template")
                    return self._get_default_role_selection(available_roles)

            except Exception as e:
                last_error = e
                logger.error(f"âŒ Attempt {attempt + 1} failed with unexpected error: {e}")

                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç»§ç»­é‡è¯•
                if attempt < max_retries - 1:
                    logger.info(f"ğŸ”„ Retrying... ({attempt + 2}/{max_retries})")
                    continue
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿
                    logger.error(f"âŒ All {max_retries} attempts failed, using default template")
                    return self._get_default_role_selection(available_roles)

        # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§
        logger.error(f"âŒ Unexpected: reached end of retry loop, using default template")
        return self._get_default_role_selection(available_roles)

    def _fix_task_distribution(self, response: RoleSelection) -> RoleSelection:
        """
        å°è¯•ä¿®å¤ task_distribution å­—æ®µï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®

        Args:
            response: åŸå§‹å“åº”

        Returns:
            ä¿®å¤åçš„ RoleSelection
        """
        logger.info(f"ğŸ”§ [DEBUG] å¼€å§‹ä¿®å¤ task_distribution")
        logger.info(f"ğŸ”§ [DEBUG] åŸå§‹ task_distribution ç±»å‹: {type(response.task_distribution)}")

        # ğŸš¨ æ£€æŸ¥ task_distribution æ˜¯å¦ä¸ºç©º
        if not response.task_distribution:
            logger.error("âŒ task_distribution ä¸ºç©ºå­—å…¸ï¼LLM æ²¡æœ‰ä¸ºä»»ä½•è§’è‰²åˆ†é…ä»»åŠ¡ã€‚")
            logger.error("âŒ è¿™é€šå¸¸æ„å‘³ç€ LLM æ²¡æœ‰ç†è§£ Prompt è¦æ±‚ï¼Œæˆ–è€…ç”Ÿæˆçš„å“åº”è¢«æˆªæ–­ã€‚")
            logger.error("âŒ å°†ä½¿ç”¨é»˜è®¤è§’è‰²é€‰æ‹©å’Œæ¨¡æ¿ä»»åŠ¡ã€‚")

            # è·å–å¯ç”¨è§’è‰²åˆ—è¡¨
            available_roles = self.role_manager.get_available_roles()
            return self._get_default_role_selection(available_roles)

        # ğŸš¨ æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é€‰æ‹©çš„è§’è‰²éƒ½æœ‰ä»»åŠ¡åˆ†é…
        missing_roles = [role for role in response.selected_roles if role not in response.task_distribution]
        if missing_roles:
            logger.error(f"âŒ ä»¥ä¸‹è§’è‰²ç¼ºå°‘ä»»åŠ¡åˆ†é…: {missing_roles}")
            logger.error(f"âŒ selected_roles: {response.selected_roles}")
            logger.error(f"âŒ task_distribution keys: {list(response.task_distribution.keys())}")
            logger.error("âŒ å°†ä½¿ç”¨é»˜è®¤è§’è‰²é€‰æ‹©å’Œæ¨¡æ¿ä»»åŠ¡ã€‚")

            # è·å–å¯ç”¨è§’è‰²åˆ—è¡¨
            available_roles = self.role_manager.get_available_roles()
            return self._get_default_role_selection(available_roles)

        try:
            # æ£€æŸ¥æ¯ä¸ªè§’è‰²çš„ä»»åŠ¡åˆ†é…
            fixed_distribution = {}

            for role_id in response.selected_roles:
                role_task = response.task_distribution.get(role_id)

                logger.info(f"ğŸ”§ [DEBUG] ä¿®å¤è§’è‰² {role_id}:")
                logger.info(f"ğŸ”§ [DEBUG]   - åŸå§‹ç±»å‹: {type(role_task)}")

                # æƒ…å†µ1: å·²ç»æ˜¯ TaskDetail å¯¹è±¡
                if isinstance(role_task, TaskDetail):
                    fixed_distribution[role_id] = role_task
                    continue

                # æƒ…å†µ2: æ˜¯å­—å…¸ï¼Œå°è¯•è½¬æ¢ä¸º TaskDetail
                if isinstance(role_task, dict):
                    try:
                        logger.info(f"ğŸ”§ [DEBUG]   - å­—å…¸ keys: {list(role_task.keys())}")
                        fixed_distribution[role_id] = TaskDetail(**role_task)
                        logger.info(f"âœ… æˆåŠŸå°† {role_id} çš„å­—å…¸è½¬æ¢ä¸º TaskDetail")
                        continue
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ— æ³•å°† {role_id} çš„å­—å…¸è½¬æ¢ä¸º TaskDetail: {e}")

                # æƒ…å†µ3: æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸º TaskDetail
                if isinstance(role_task, str):
                    logger.info(f"ğŸ”§ [DEBUG]   - å­—ç¬¦ä¸²é•¿åº¦: {len(role_task)}")
                    logger.info(f"ğŸ”§ å°† {role_id} çš„å­—ç¬¦ä¸²ä»»åŠ¡è½¬æ¢ä¸º TaskDetail æ ¼å¼")
                    fixed_distribution[role_id] = TaskDetail(
                        tasks=[role_task], focus_areas=[], expected_output="", dependencies=[]
                    )
                    continue

                # æƒ…å†µ4: æ²¡æœ‰ä»»åŠ¡æˆ–æ ¼å¼ä¸å¯¹ï¼Œåˆ›å»ºé»˜è®¤ä»»åŠ¡
                logger.warning(f"âš ï¸ {role_id} æ²¡æœ‰æœ‰æ•ˆä»»åŠ¡ï¼Œåˆ›å»ºé»˜è®¤ä»»åŠ¡")
                fixed_distribution[role_id] = TaskDetail(
                    tasks=["æ‰§è¡Œä¸“ä¸šåˆ†æ"], focus_areas=[], expected_output="", dependencies=[]
                )

            response.task_distribution = fixed_distribution
            logger.info("âœ… æˆåŠŸä¿®å¤ task_distribution æ ¼å¼")
            return response

        except Exception as e:
            logger.error(f"âŒ Failed to fix task_distribution: {e}")
            # åˆ›å»ºé»˜è®¤ TaskDetail å­—å…¸
            response.task_distribution = {
                role_id: TaskDetail(tasks=["æ‰§è¡Œä¸“ä¸šåˆ†æ"], focus_areas=[], expected_output="", dependencies=[])
                for role_id in response.selected_roles
            }
            return response

    def _log_fallback_event(self, requirements: str, error: Exception) -> None:
        """
        ğŸ†• è®°å½•é™çº§äº‹ä»¶ï¼ˆç”¨äºç›‘æ§å’Œä¼˜åŒ–ï¼‰

        å½“LLMé€‰æ‹©å¤±è´¥ï¼Œç³»ç»Ÿé™çº§åˆ°é»˜è®¤é€‰æ‹©æ—¶è°ƒç”¨æ­¤æ–¹æ³•ã€‚
        è®°å½•çš„ä¿¡æ¯å¯ç”¨äºï¼š
        1. ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶å†µ
        2. åˆ†æpromptä¼˜åŒ–æ–¹å‘
        3. è¯†åˆ«å¸¸è§å¤±è´¥æ¨¡å¼

        Args:
            requirements: è§¦å‘é™çº§çš„éœ€æ±‚æ–‡æœ¬
            error: å¯¼è‡´é™çº§çš„æœ€åä¸€ä¸ªé”™è¯¯
        """
        import json
        import time
        from pathlib import Path

        try:
            # å‡†å¤‡æ—¥å¿—ç›®å½•
            log_dir = Path("logs/fallback_events")
            log_dir.mkdir(parents=True, exist_ok=True)

            # æ„å»ºäº‹ä»¶è®°å½•
            event = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "error_type": type(error).__name__,
                "error_message": str(error)[:500],  # é™åˆ¶é•¿åº¦
                "requirements_preview": requirements[:300],  # é¢„è§ˆå‰300å­—ç¬¦
                "requirements_length": len(requirements),
            }

            # è¿½åŠ åˆ°æ—¥å¿—æ–‡ä»¶
            log_file = log_dir / f"fallback_{time.strftime('%Y%m%d')}.jsonl"
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(event, ensure_ascii=False) + "\n")

            logger.info(f"ğŸ“ é™çº§äº‹ä»¶å·²è®°å½•åˆ°: {log_file}")

        except Exception as log_error:
            logger.warning(f"âš ï¸ è®°å½•é™çº§äº‹ä»¶å¤±è´¥: {log_error}")

    def _get_default_role_selection(self, available_roles: List[Dict]) -> RoleSelection:
        """
        è·å–é»˜è®¤çš„è§’è‰²é€‰æ‹©ï¼ˆå½“æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥æ—¶ä½¿ç”¨ï¼‰- v2.0ä»»åŠ¡å¯¼å‘æ¶æ„

        âš ï¸ æ­¤æ–¹æ³•ä»…åœ¨LLMå¤šæ¬¡é‡è¯•å¤±è´¥åä½œä¸ºé™çº§æ–¹æ¡ˆä½¿ç”¨
        ç”Ÿæˆçš„TaskInstructionè¾ƒä¸ºåŸºç¡€ï¼Œå»ºè®®ä¼˜åŒ–LLM promptä»¥å‡å°‘å¯¹æ­¤æ–¹æ³•çš„ä¾èµ–

        Args:
            available_roles: å¯ç”¨è§’è‰²åˆ—è¡¨

        Returns:
            é»˜è®¤çš„ RoleSelectionï¼ˆåŒ…å«å®Œæ•´çš„RoleObjectå’ŒTaskInstructionï¼‰
        """
        logger.info("ğŸ”§ Creating default role selection with task-oriented architecture")

        # å¦‚æœä¼ å…¥çš„ available_roles ä¸ºç©ºï¼Œå°è¯•ä» RoleManager è·å–æ‰€æœ‰è§’è‰²
        if not available_roles:
            logger.warning("âš ï¸ ä¼ å…¥çš„ available_roles ä¸ºç©ºï¼Œå°è¯•è·å–æ‰€æœ‰å¯ç”¨è§’è‰²")
            available_roles = self.role_manager.get_available_roles()

        # é€‰æ‹©æ¯ä¸ªç±»åˆ«çš„ç¬¬ä¸€ä¸ªè§’è‰²ï¼ˆV2, V3, V4, V6ï¼‰
        role_objects = []
        role_categories = ["V2_è®¾è®¡æ€»ç›‘", "V3_å™äº‹ä¸ä½“éªŒä¸“å®¶", "V4_è®¾è®¡ç ”ç©¶å‘˜", "V6_ä¸“ä¸šå‘˜å·¥ç¾¤"]

        selected_base_types = set()

        for role in available_roles:
            base_type = role.get("base_type", "")
            if base_type in role_categories and base_type not in selected_base_types:
                # æ„é€ RoleObject
                role_obj = self._create_default_role_object(role)
                role_objects.append(role_obj)
                selected_base_types.add(base_type)

                if len(role_objects) >= 4:
                    break

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„è§’è‰²ï¼Œä»å‰4ä¸ªå¯ç”¨è§’è‰²ç”Ÿæˆ
        if len(role_objects) < 3:
            logger.warning(f"âš ï¸ åªæ‰¾åˆ°{len(role_objects)}ä¸ªé»˜è®¤è§’è‰²ï¼Œå°è¯•è¡¥å……è‡³3ä¸ª")
            for role in available_roles[:4]:
                if len(role_objects) >= 4:
                    break
                base_type = role.get("base_type", "")
                if base_type not in selected_base_types:
                    role_obj = self._create_default_role_object(role)
                    role_objects.append(role_obj)
                    selected_base_types.add(base_type)

        logger.info(f"âœ… Created default selection with {len(role_objects)} roles")

        return RoleSelection(
            selected_roles=role_objects,
            reasoning=(
                "ç”±äºLLMå“åº”æ ¼å¼é”™è¯¯æˆ–ç¼ºå°‘å¿…éœ€å­—æ®µï¼Œç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨é»˜è®¤è§’è‰²é€‰æ‹©ç­–ç•¥ã€‚"
                "å·²é€‰æ‹©æ ¸å¿ƒè§’è‰²ï¼ˆè®¾è®¡æ€»ç›‘ã€å™äº‹ä¸“å®¶ã€è®¾è®¡ç ”ç©¶å‘˜ç­‰ï¼‰ä»¥ç¡®ä¿é¡¹ç›®åˆ†æçš„å®Œæ•´æ€§å’Œä¸“ä¸šæ€§ã€‚"
                "è¿™äº›è§’è‰²å°†ååŒå·¥ä½œï¼Œä»å¤šä¸ªç»´åº¦å¯¹é¡¹ç›®è¿›è¡Œæ·±å…¥åˆ†æã€‚"
                "âš ï¸ æ³¨æ„ï¼šç”±äºä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼Œä»»åŠ¡æŒ‡ä»¤è¾ƒä¸ºåŸºç¡€ï¼Œå»ºè®®äººå·¥å®¡æ ¸å¹¶ä¼˜åŒ–ã€‚"
            ),
        )

    def _create_default_role_object(self, role_config: Dict) -> RoleObject:
        """
        ä»è§’è‰²é…ç½®åˆ›å»ºé»˜è®¤çš„RoleObjectï¼ˆåŒ…å«TaskInstructionï¼‰

        Args:
            role_config: è§’è‰²é…ç½®å­—å…¸ï¼ˆæ¥è‡ªrole_managerï¼‰

        Returns:
            åŒ…å«å®Œæ•´TaskInstructionçš„RoleObject
        """
        role_id = role_config.get("role_id", "unknown")
        # ğŸ”¥ v7.22: å…¼å®¹ä¸¤ç§å­—æ®µå - role_manager ä½¿ç”¨ "name"ï¼ŒLLM è¾“å‡ºä½¿ç”¨ "role_name"
        role_name = role_config.get("role_name") or role_config.get("name", "æœªçŸ¥è§’è‰²")
        base_type = role_config.get("base_type", "")

        # Map base_type to role_type for template generation
        role_type_map = {"V2_è®¾è®¡æ€»ç›‘": "V2_design_director", "V3_å™äº‹ä¸ä½“éªŒä¸“å®¶": "V3_narrative_expert"}
        mapped_role_type = role_type_map.get(base_type, "default")

        # ğŸ†• ç”Ÿæˆé»˜è®¤çš„TaskInstruction
        default_task_instruction = generate_task_instruction_template(mapped_role_type)

        # ğŸ”¥ v7.10: ä¸ºV3å™äº‹ä¸“å®¶æ ‡è®°åˆ›æ„æ¨¡å¼
        if base_type == "V3_å™äº‹ä¸ä½“éªŒä¸“å®¶" or role_id.startswith("3-"):
            default_task_instruction.is_creative_narrative = True
            logger.info(f"ğŸ¨ ä¸ºå™äº‹ä¸“å®¶ {role_name} å¯ç”¨åˆ›æ„å™äº‹æ¨¡å¼")

        # å°è¯•ä»ç­–ç•¥ç®¡ç†å™¨è·å–æ›´è¯¦ç»†çš„ä»»åŠ¡æ¨¡æ¿
        try:
            from intelligent_project_analyzer.core.strategy_manager import StrategyManager

            strategy_manager = StrategyManager()
            template_tasks = strategy_manager.get_task_template(base_type)

            if template_tasks and len(template_tasks) > 0:
                # å°†æ¨¡æ¿ä»»åŠ¡è½¬æ¢ä¸ºdeliverables
                deliverables = []
                for i, task_desc in enumerate(template_tasks[:3]):  # æœ€å¤š3ä¸ª
                    deliverables.append(
                        DeliverableSpec(
                            name=f"{role_name}äº¤ä»˜ç‰©{i+1}",
                            description=task_desc if len(task_desc) > 20 else f"å®Œæˆ{task_desc}ç›¸å…³åˆ†æå’Œæ–¹æ¡ˆ",
                            format=DeliverableFormat.ANALYSIS,
                            priority=Priority.HIGH if i == 0 else Priority.MEDIUM,
                            success_criteria=["åˆ†æå†…å®¹å®Œæ•´å‡†ç¡®", "æä¾›å¯æ‰§è¡Œå»ºè®®"],
                        )
                    )

                if deliverables:
                    default_task_instruction.deliverables = deliverables
                    logger.info(f"âœ… ä¸º {role_name} ç”Ÿæˆäº† {len(deliverables)} ä¸ªäº¤ä»˜ç‰©")
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•ä»ç­–ç•¥ç®¡ç†å™¨è·å–ä»»åŠ¡æ¨¡æ¿: {e}ï¼Œä½¿ç”¨åŸºç¡€æ¨¡æ¿")

        return RoleObject(
            role_id=role_id,
            role_name=role_name,
            dynamic_role_name=f"{role_name}ï¼ˆé»˜è®¤é…ç½®ï¼‰",
            task_instruction=default_task_instruction,
            dependencies=[],
            execution_priority=1,
        )

    def _convert_legacy_format_to_v2(self, raw_response: dict) -> Optional[dict]:
        """
        å°†LLMè¿”å›çš„è€æ ¼å¼(tasks/expected_output)è½¬æ¢ä¸ºv2æ ¼å¼(task_instruction)

        è€æ ¼å¼ç¤ºä¾‹:
        {
          "selected_roles": [{
            "role_id": "2-1",
            "role_name": "è®¾è®¡æ€»ç›‘",
            "dynamic_role_name": "...",
            "tasks": ["ä»»åŠ¡1", "ä»»åŠ¡2"],
            "expected_output": "é¢„æœŸè¾“å‡º",
            "focus_areas": ["é¢†åŸŸ1", "é¢†åŸŸ2"],
            "dependencies": ["3-1"]
          }],
          "reasoning": "..."
        }

        æ–°æ ¼å¼ç¤ºä¾‹:
        {
          "selected_roles": [{
            "role_id": "2-1",
            "role_name": "è®¾è®¡æ€»ç›‘",
            "dynamic_role_name": "...",
            "task_instruction": {
              "objective": "é¢„æœŸè¾“å‡º",
              "deliverables": [{"name": "ä»»åŠ¡1", "description": "ä»»åŠ¡1", ...}],
              "success_criteria": ["å®Œæˆæ‰€æœ‰ä»»åŠ¡", "ç¬¦åˆé¢„æœŸè¾“å‡ºè¦æ±‚"]
            },
            "dependencies": ["3-1"]
          }],
          "reasoning": "..."
        }

        Args:
            raw_response: LLMè¿”å›çš„åŸå§‹å“åº”

        Returns:
            è½¬æ¢åçš„å“åº”å­—å…¸,å¦‚æœè½¬æ¢å¤±è´¥åˆ™è¿”å›None
        """
        try:
            if not isinstance(raw_response, dict) or "selected_roles" not in raw_response:
                logger.error("âŒ åŸå§‹å“åº”æ ¼å¼ä¸æ­£ç¡®,ç¼ºå°‘selected_roles")
                return None

            selected_roles = raw_response.get("selected_roles", [])
            if not selected_roles:
                logger.error("âŒ selected_roles ä¸ºç©º")
                return None

            converted_roles = []
            for role_data in selected_roles:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯v2æ ¼å¼
                if "task_instruction" in role_data:
                    converted_roles.append(role_data)
                    continue

                # è½¬æ¢è€æ ¼å¼åˆ°v2
                logger.info(f"ğŸ”„ è½¬æ¢è§’è‰² {role_data.get('role_id')} ä»è€æ ¼å¼åˆ°v2")

                # æå–è€æ ¼å¼å­—æ®µ
                tasks = role_data.get("tasks", [])
                expected_output = role_data.get("expected_output", "")
                focus_areas = role_data.get("focus_areas", [])

                # æ„é€ TaskInstruction
                deliverables = []
                for i, task in enumerate(tasks[:5]):  # æœ€å¤š5ä¸ª
                    deliverables.append(
                        {
                            "name": focus_areas[i] if i < len(focus_areas) else f"äº¤ä»˜ç‰©{i+1}",
                            "description": task if len(task) > 20 else f"å®Œæˆ{task}ç›¸å…³åˆ†æå’Œæ–¹æ¡ˆ",
                            "format": "analysis",
                            "priority": "high" if i == 0 else "medium",
                            "success_criteria": ["å†…å®¹å®Œæ•´å‡†ç¡®", "æä¾›å¯æ‰§è¡Œå»ºè®®"],
                        }
                    )

                task_instruction = {
                    "objective": expected_output if expected_output else "å®Œæˆè§’è‰²åˆ†é…çš„æ‰€æœ‰ä»»åŠ¡",
                    "deliverables": deliverables,
                    "success_criteria": ["å®Œæˆæ‰€æœ‰æŒ‡å®šä»»åŠ¡", "è¾“å‡ºç¬¦åˆé¢„æœŸæ ¼å¼å’Œè´¨é‡è¦æ±‚"],
                    "constraints": [],
                    "context_requirements": [],
                    # ğŸ”¥ v7.10: ä¸ºV3å™äº‹ä¸“å®¶æ ‡è®°åˆ›æ„æ¨¡å¼
                    "is_creative_narrative": role_data.get("role_id", "").startswith("3-"),
                }

                # æ„é€ v2æ ¼å¼çš„RoleObject
                converted_role = {
                    "role_id": role_data.get("role_id", ""),
                    "role_name": role_data.get("role_name", ""),
                    "dynamic_role_name": role_data.get("dynamic_role_name", ""),
                    "task_instruction": task_instruction,
                    "dependencies": role_data.get("dependencies", []),
                    "execution_priority": role_data.get("execution_priority", 1),
                }

                converted_roles.append(converted_role)
                logger.info(f"âœ… è§’è‰² {converted_role['role_id']} è½¬æ¢æˆåŠŸ")

            # æ„é€ æœ€ç»ˆå“åº”
            converted_response = {
                "selected_roles": converted_roles,
                "reasoning": raw_response.get("reasoning", "è§’è‰²é€‰æ‹©å®Œæˆ"),
            }

            logger.info(f"âœ… æˆåŠŸè½¬æ¢ {len(converted_roles)} ä¸ªè§’è‰²åˆ°v2æ ¼å¼")
            return converted_response

        except Exception as e:
            logger.error(f"âŒ æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            import traceback

            logger.error(traceback.format_exc())
            return None

    def _validate_response_with_conversion(self, raw_response: Any) -> RoleSelection:
        """éªŒè¯LLMå“åº”ï¼Œå¦‚é‡è€æ ¼å¼åˆ™å°è¯•è‡ªåŠ¨è½¬æ¢ã€‚"""
        if isinstance(raw_response, RoleSelection):
            logger.info("âœ… å·²æ”¶åˆ°RoleSelectionå®ä¾‹ï¼Œæ— éœ€å†æ¬¡éªŒè¯")
            return raw_response

        # å­—ç¬¦ä¸²å“åº”éœ€è¦å…ˆè§£ææˆå­—å…¸
        if isinstance(raw_response, str):
            try:
                raw_response = json.loads(raw_response)
            except json.JSONDecodeError as decode_error:
                logger.error(f"âŒ æ— æ³•è§£æLLMå­—ç¬¦ä¸²å“åº”ä¸ºJSON: {decode_error}")
                raise decode_error

        # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šå°è¯•ç›´æ¥éªŒè¯ï¼ˆæœŸæœ›v2æ ¼å¼ï¼‰
        try:
            response = RoleSelection.model_validate(raw_response)
            logger.info("âœ… Pydantic éªŒè¯é€šè¿‡ï¼ˆv2æ ¼å¼ï¼‰")
            return response
        except ValidationError as validation_error:
            # ğŸ†• ç¬¬äºŒæ­¥ï¼šæ£€æµ‹åˆ°éªŒè¯å¤±è´¥ï¼Œå°è¯•ä»è€æ ¼å¼è½¬æ¢
            logger.warning("âš ï¸ Pydantic éªŒè¯å¤±è´¥ï¼Œå°è¯•ä»è€æ ¼å¼è½¬æ¢")
            logger.debug(f"   åŸå§‹é”™è¯¯: {format_for_log(validation_error)}")

            converted_response = self._convert_legacy_format_to_v2(raw_response)
            if converted_response:
                try:
                    response = RoleSelection.model_validate(converted_response)
                    logger.info("âœ… è€æ ¼å¼è½¬æ¢æˆåŠŸï¼ŒéªŒè¯é€šè¿‡")
                    return response
                except ValidationError as convert_error:
                    logger.error(f"âŒ è½¬æ¢åä»ç„¶éªŒè¯å¤±è´¥: {format_for_log(convert_error)}")
                    raise validation_error  # æŠ›å‡ºåŸå§‹é”™è¯¯ï¼Œè§¦å‘é‡è¯•

            logger.error("âŒ æ— æ³•è½¬æ¢è€æ ¼å¼ï¼ˆæ£€æµ‹å¤±è´¥æˆ–æ•°æ®å¼‚å¸¸ï¼‰")
            raise validation_error  # æŠ›å‡ºåŸå§‹é”™è¯¯ï¼Œè§¦å‘é‡è¯•

    def _extract_raw_response_from_validation_error(self, error: Exception) -> Optional[dict]:
        """å°è¯•ä»LangChainæŠ›å‡ºçš„ValidationErroræˆ–OutputParserExceptionå­—ç¬¦ä¸²ä¸­æå–åŸå§‹completionã€‚"""

        # 1. å°è¯•ä» OutputParserException ä¸­æå– llm_output
        if hasattr(error, "llm_output") and error.llm_output:
            if isinstance(error.llm_output, dict):
                return error.llm_output
            if isinstance(error.llm_output, str):
                try:
                    return json.loads(error.llm_output)
                except json.JSONDecodeError:
                    pass

        # 2. å°è¯•ä» error.args ä¸­æå– completion (é’ˆå¯¹ ValidationError)
        if hasattr(error, "args"):
            for arg in error.args:
                if isinstance(arg, dict):
                    completion = arg.get("completion")
                    if completion:
                        if isinstance(completion, dict):
                            return completion
                        if isinstance(completion, str):
                            try:
                                return json.loads(completion)
                            except json.JSONDecodeError:
                                logger.error("âŒ completion å­—æ®µéæœ‰æ•ˆJSONå­—ç¬¦ä¸²")

        # 3. å›é€€åˆ°è§£ææŠ¥é”™æ–‡æœ¬ (Regex)
        error_text = str(error)
        # åŒ¹é… "completion {...}. Got" æ¨¡å¼ (LangChain æ ‡å‡†é”™è¯¯æ ¼å¼)
        match = re.search(r"completion\s+(\{.*\})\.\s+Got", error_text, re.DOTALL)
        if match:
            json_text = match.group(1)
            try:
                return json.loads(json_text)
            except json.JSONDecodeError:
                logger.error("âŒ æ— æ³•ä»ValidationErroræ–‡æœ¬è§£æå‡ºæœ‰æ•ˆJSON")

        # å°è¯•åŒ¹é… OutputParserException çš„å¸¸è§æ ¼å¼ (æ›´å®½æ³›çš„åŒ¹é…)
        # æ¯”å¦‚ "Failed to parse RoleSelection from completion {...}"
        # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½ä¼šåŒ¹é…åˆ°ä¸å®Œæ•´çš„JSONï¼Œæ‰€ä»¥æ”¾åœ¨æœ€åå°è¯•
        match = re.search(r"completion\s+(\{.*\})", error_text, re.DOTALL)
        if match:
            json_text = match.group(1)
            try:
                return json.loads(json_text)
            except json.JSONDecodeError:
                pass

        logger.error("âŒ å¼‚å¸¸ä¸­æœªæ‰¾åˆ°completionç‰‡æ®µ")
        return None

    def _build_system_prompt(self) -> str:
        """
        æ„å»ºç³»ç»Ÿæç¤ºè¯ - ä»å¤–éƒ¨é…ç½®åŠ è½½

        Returns:
            ç³»ç»Ÿæç¤ºè¯

        Note:
            ä¸å†éœ€è¦task_complexityå‚æ•°ï¼ŒLLMä¼šæ ¹æ®éœ€æ±‚è‡ªä¸»åˆ¤æ–­é¡¹ç›®å¤æ‚åº¦
        """
        # ä¼˜å…ˆä½¿ç”¨v2ç‰ˆæœ¬ï¼ˆä»»åŠ¡å¯¼å‘æ¶æ„ï¼‰
        prompt = self.prompt_manager.get_prompt("dynamic_project_director_v2")

        # å¦‚æœv2ä¸å­˜åœ¨ï¼Œå›é€€åˆ°v1
        if not prompt:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°v2ç‰ˆæœ¬æç¤ºè¯ï¼Œå›é€€åˆ°v1ç‰ˆæœ¬")
            prompt = self.prompt_manager.get_prompt("dynamic_project_director")

        # å¦‚æœé…ç½®ä¸å­˜åœ¨ï¼ŒæŠ›å‡ºé”™è¯¯ï¼ˆä¸å†ä½¿ç”¨ç¡¬ç¼–ç  fallbackï¼‰
        if not prompt:
            raise ValueError(
                "âŒ æœªæ‰¾åˆ°æç¤ºè¯é…ç½®: dynamic_project_director æˆ– dynamic_project_director_v2\n"
                "è¯·ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨: config/prompts/dynamic_project_director_v2.yaml\n"
                "ç³»ç»Ÿæ— æ³•ä½¿ç”¨ç¡¬ç¼–ç æç¤ºè¯ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ã€‚"
            )

        return prompt

    def _build_user_prompt(self, requirements: str, roles_info: str) -> str:
        """
        æ„å»ºç”¨æˆ·æç¤ºè¯

        Args:
            requirements: ç”¨æˆ·éœ€æ±‚
            roles_info: æ ¼å¼åŒ–çš„è§’è‰²ä¿¡æ¯

        Returns:
            ç”¨æˆ·æç¤ºè¯å­—ç¬¦ä¸²
        """
        return f"""# é¡¹ç›®éœ€æ±‚

{requirements}

# å¯ç”¨è§’è‰²

{roles_info}

# ä»»åŠ¡

è¯·æ ¹æ®ä¸Šè¿°é¡¹ç›®éœ€æ±‚,ä»å¯ç”¨è§’è‰²ä¸­é€‰æ‹©3-8ä¸ªæœ€åˆé€‚çš„è§’è‰²æ¥å®Œæˆè¿™ä¸ªé¡¹ç›®ã€‚

è¦æ±‚:
1. é€‰æ‹©çš„è§’è‰²å¿…é¡»èƒ½å¤Ÿè¦†ç›–é¡¹ç›®çš„æ‰€æœ‰å…³é”®æ–¹é¢
2. ä¸ºæ¯ä¸ªè§’è‰²åˆ†é…å…·ä½“ã€è¯¦ç»†ã€å¯æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆæ¯ä¸ªä»»åŠ¡æè¿°è‡³å°‘30-50ä¸ªå­—ç¬¦ï¼‰
3. ä»»åŠ¡æè¿°è¦æ˜ç¡®è¯´æ˜è¯¥è§’è‰²éœ€è¦å®Œæˆä»€ä¹ˆã€å¦‚ä½•å®Œæˆã€è¾¾åˆ°ä»€ä¹ˆç›®æ ‡
4. è§£é‡Šä½ çš„é€‰æ‹©ç†ç”±
5. è¯´æ˜è¿™äº›è§’è‰²å¦‚ä½•åä½œå®Œæˆé¡¹ç›®

âš ï¸ é‡è¦æ ¼å¼è¦æ±‚ï¼š
ä½ å¿…é¡»æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š

{{
  "selected_roles": [
    {{
      "role_id": "2-1",
      "role_name": "å±…ä½ç©ºé—´è®¾è®¡æ€»ç›‘",
      "dynamic_role_name": "é’ˆå¯¹æœ¬é¡¹ç›®çš„å…·ä½“ç§°å‘¼ï¼ˆå¦‚ï¼šä¸‰ä»£åŒå ‚å±…ä½ç©ºé—´ä¸ç”Ÿæ´»æ¨¡å¼æ€»è®¾è®¡å¸ˆï¼‰",
      "tasks": ["ä»»åŠ¡1æè¿°ï¼ˆè‡³å°‘30å­—ï¼‰", "ä»»åŠ¡2æè¿°"],
      "focus_areas": ["å…³æ³¨ç‚¹1", "å…³æ³¨ç‚¹2"],
      "expected_output": "é¢„æœŸäº¤ä»˜ç‰©æè¿°",
      "dependencies": ["ä¾èµ–çš„å…¶ä»–è§’è‰²ID"]
    }},
    ...
  ],
  "reasoning": "é€‰æ‹©ç†ç”±ï¼ˆè‡³å°‘50ä¸ªå­—ç¬¦ï¼‰"
}}

ğŸš¨ğŸš¨ğŸš¨ å…³é”®æ³¨æ„äº‹é¡¹ï¼š
1. selected_roles å¿…é¡»æ˜¯å¯¹è±¡æ•°ç»„ï¼Œä¸èƒ½æ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼
2. æ¯ä¸ªè§’è‰²å¯¹è±¡å¿…é¡»åŒ…å« role_id, role_name, dynamic_role_name, tasks ç­‰æ‰€æœ‰å­—æ®µ
3. dynamic_role_name æ˜¯å¿…å¡«é¡¹ï¼Œè¦æ ¹æ®æœ¬é¡¹ç›®éœ€æ±‚åˆ›é€ ä¸€ä¸ªç²¾å‡†åæ˜ è¯¥è§’è‰²èŒè´£çš„åç§°
4. ä¸è¦è¾“å‡º task_distribution å­—æ®µï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆï¼‰

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¿”å›ç»“æœã€‚
"""

    def _format_roles_info(self, roles: List[Dict]) -> str:
        """
        æ ¼å¼åŒ–è§’è‰²ä¿¡æ¯

        Args:
            roles: è§’è‰²åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„è§’è‰²ä¿¡æ¯å­—ç¬¦ä¸²
        """
        lines = []

        # æŒ‰base_typeåˆ†ç»„
        grouped_roles = {}
        for role in roles:
            base_type = role["base_type"]
            if base_type not in grouped_roles:
                grouped_roles[base_type] = []
            grouped_roles[base_type].append(role)

        # æ ¼å¼åŒ–è¾“å‡º
        for base_type, role_list in grouped_roles.items():
            lines.append(f"\n## {base_type}")

            for role in role_list:
                lines.append(f"\n### {role['full_id']}")
                lines.append(f"**åç§°**: {role.get('name', 'N/A')}")
                lines.append(f"**æè¿°**: {role.get('description', 'N/A')}")

                keywords = role.get("keywords", [])
                if keywords:
                    lines.append(f"**å…³é”®è¯**: {', '.join(keywords)}")

                lines.append("")

        return "\n".join(lines)

    def _format_roles_info_with_weights(self, roles: List[Dict], weights: Dict[str, float]) -> str:
        """
        æ ¼å¼åŒ–è§’è‰²ä¿¡æ¯ï¼ˆåŒ…å«æƒé‡ï¼‰

        Args:
            roles: è§’è‰²åˆ—è¡¨
            weights: æƒé‡å­—å…¸ï¼ˆkeyä¸ºè§’è‰²ç±»åˆ«ï¼Œå¦‚ "V4_è®¾è®¡ç ”ç©¶å‘˜"ï¼‰

        Returns:
            æ ¼å¼åŒ–çš„è§’è‰²ä¿¡æ¯å­—ç¬¦ä¸²ï¼ˆæŒ‰æƒé‡æ’åºï¼‰
        """
        lines = []

        # æŒ‰base_typeåˆ†ç»„
        grouped_roles = {}
        for role in roles:
            base_type = role["base_type"]
            if base_type not in grouped_roles:
                grouped_roles[base_type] = []
            grouped_roles[base_type].append(role)

        # æŒ‰æƒé‡æ’åºï¼ˆæƒé‡é«˜çš„åœ¨å‰ï¼‰
        sorted_base_types = sorted(grouped_roles.keys(), key=lambda bt: weights.get(bt, 0.0), reverse=True)

        # æ ¼å¼åŒ–è¾“å‡º
        for base_type in sorted_base_types:
            weight = weights.get(base_type, 0.0)
            lines.append(f"\n## {base_type} ï¼ˆæƒé‡: {weight:.1f}ï¼‰")

            role_list = grouped_roles[base_type]
            for role in role_list:
                lines.append(f"\n### {role['full_id']}")
                lines.append(f"**åç§°**: {role.get('name', 'N/A')}")
                lines.append(f"**æè¿°**: {role.get('description', 'N/A')}")

                keywords = role.get("keywords", [])
                if keywords:
                    lines.append(f"**å…³é”®è¯**: {', '.join(keywords)}")

                lines.append("")

        return "\n".join(lines)

    def _build_user_prompt_with_weights(self, requirements: str, roles_info: str, weights: Dict[str, float]) -> str:
        """
        æ„å»ºç”¨æˆ·æç¤ºè¯ï¼ˆåŒ…å«æƒé‡ä¿¡æ¯ï¼‰

        Args:
            requirements: ç”¨æˆ·éœ€æ±‚
            roles_info: æ ¼å¼åŒ–çš„è§’è‰²ä¿¡æ¯ï¼ˆå·²åŒ…å«æƒé‡ï¼‰
            weights: æƒé‡å­—å…¸

        Returns:
            ç”¨æˆ·æç¤ºè¯å­—ç¬¦ä¸²
        """
        # ç”Ÿæˆæƒé‡è¯´æ˜
        weight_explanation = self._generate_weight_explanation(weights)

        return f"""# é¡¹ç›®éœ€æ±‚

{requirements}

{weight_explanation}

# å¯ç”¨è§’è‰²ï¼ˆå·²æŒ‰æƒé‡æ’åºï¼‰

{roles_info}

# ä»»åŠ¡

è¯·æ ¹æ®ä¸Šè¿°é¡¹ç›®éœ€æ±‚å’Œæƒé‡ä¿¡æ¯,ä»å¯ç”¨è§’è‰²ä¸­é€‰æ‹©3-8ä¸ªæœ€åˆé€‚çš„è§’è‰²æ¥å®Œæˆè¿™ä¸ªé¡¹ç›®ã€‚

ğŸ“Š **ä»»åŠ¡é‡åˆ†é…è¦æ±‚ï¼ˆé‡è¦ï¼‰**ï¼š
- **ç¦æ­¢å¹³å‡åˆ†é…**ï¼šä¸è¦ç»™æ¯ä¸ªè§’è‰²åˆ†é…ç›¸åŒæ•°é‡çš„ä»»åŠ¡ï¼
- **æ ¸å¿ƒè§’è‰²**ï¼ˆæƒé‡â‰¥2.5 æˆ– V2è®¾è®¡æ€»ç›‘ï¼‰ï¼šåˆ†é… **4-6ä¸ªäº¤ä»˜ç‰©**
- **é‡è¦è§’è‰²**ï¼ˆæƒé‡2.0-2.4ï¼‰ï¼šåˆ†é… **2-3ä¸ªäº¤ä»˜ç‰©**
- **æ”¯æŒè§’è‰²**ï¼ˆæƒé‡1.5-1.9ï¼‰ï¼šåˆ†é… **1-2ä¸ªäº¤ä»˜ç‰©**
- **è¾…åŠ©è§’è‰²**ï¼ˆæƒé‡<1.5ï¼‰ï¼šåˆ†é… **1ä¸ªäº¤ä»˜ç‰©**
- **V2è®¾è®¡æ€»ç›‘å¿…é¡»æ˜¯ä»»åŠ¡é‡æœ€å¤šçš„è§’è‰²ï¼ˆ4-6ä¸ªäº¤ä»˜ç‰©ï¼‰**

å…¶ä»–è¦æ±‚:
1. **å‚è€ƒæƒé‡ä¿¡æ¯**ï¼šæƒé‡è¶Šé«˜è¯´æ˜è¯¥è§’è‰²ä¸éœ€æ±‚çš„åŒ¹é…åº¦è¶Šé«˜ï¼Œåº”æ‰¿æ‹…æ›´å¤šä»»åŠ¡
2. é€‰æ‹©çš„è§’è‰²å¿…é¡»èƒ½å¤Ÿè¦†ç›–é¡¹ç›®çš„æ‰€æœ‰å…³é”®æ–¹é¢
3. **å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ª V4_è®¾è®¡ç ”ç©¶å‘˜ è§’è‰²**ï¼Œä½œä¸ºé¡¹ç›®çš„åŸºç¡€ç ”ç©¶æ”¯æ’‘ï¼ˆè¿™æ˜¯å¼ºåˆ¶è¦æ±‚ï¼‰
4. ä¸ºæ¯ä¸ªè§’è‰²çš„task_instruction.deliverablesåˆ†é…å…·ä½“äº¤ä»˜ç‰©ï¼ˆå‚è€ƒä¸Šè¿°æ•°é‡è¦æ±‚ï¼‰
5. ä»»åŠ¡æè¿°è¦æ˜ç¡®è¯´æ˜è¯¥è§’è‰²éœ€è¦å®Œæˆä»€ä¹ˆã€å¦‚ä½•å®Œæˆã€è¾¾åˆ°ä»€ä¹ˆç›®æ ‡
6. è§£é‡Šä½ çš„é€‰æ‹©ç†ç”±ï¼ˆè¦ç»“åˆæƒé‡ä¿¡æ¯è¯´æ˜ä¸ºä½•æŸäº›è§’è‰²æ‰¿æ‹…æ›´å¤šä»»åŠ¡ï¼‰
7. è¯´æ˜è¿™äº›è§’è‰²å¦‚ä½•åä½œå®Œæˆé¡¹ç›®

âš ï¸ é‡è¦æ ¼å¼è¦æ±‚ï¼š
ä½ å¿…é¡»æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š

{{
  "selected_roles": [
    {{
      "role_id": "2-1",
      "role_name": "å±…ä½ç©ºé—´è®¾è®¡æ€»ç›‘",
      "dynamic_role_name": "é’ˆå¯¹æœ¬é¡¹ç›®çš„å…·ä½“ç§°å‘¼ï¼ˆå¦‚ï¼šä¸‰ä»£åŒå ‚å±…ä½ç©ºé—´ä¸ç”Ÿæ´»æ¨¡å¼æ€»è®¾è®¡å¸ˆï¼‰",
      "task_instruction": {{
        "objective": "æ ¸å¿ƒç›®æ ‡æè¿°",
        "deliverables": [
          {{
            "name": "äº¤ä»˜ç‰©åç§°",
            "description": "å…·ä½“è¦æ±‚ï¼ˆ50-150å­—ï¼‰",
            "format": "analysis",
            "priority": "high",
            "success_criteria": ["æ ‡å‡†1", "æ ‡å‡†2"]
          }}
        ],
        "success_criteria": ["æ•´ä½“æˆåŠŸæ ‡å‡†1", "æ ‡å‡†2"],
        "constraints": ["çº¦æŸæ¡ä»¶"],
        "context_requirements": ["ä¸Šä¸‹æ–‡è¦æ±‚"]
      }},
      "dependencies": ["ä¾èµ–çš„å…¶ä»–è§’è‰²ID"],
      "execution_priority": 1
    }},
    ...
  ],
  "reasoning": "é€‰æ‹©ç†ç”±ï¼ˆè‡³å°‘50ä¸ªå­—ç¬¦ï¼Œè¦è¯´æ˜ä¸ºä½•ä¸åŒè§’è‰²æ‰¿æ‹…ä¸åŒæ•°é‡çš„ä»»åŠ¡ï¼‰"
}}

ğŸš¨ğŸš¨ğŸš¨ å…³é”®æ³¨æ„äº‹é¡¹ï¼š
1. selected_roles å¿…é¡»æ˜¯å¯¹è±¡æ•°ç»„ï¼Œä¸èƒ½æ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼
2. æ¯ä¸ªè§’è‰²å¯¹è±¡å¿…é¡»åŒ…å« task_instructionï¼ˆä½¿ç”¨æ–°çš„TaskInstructionç»“æ„ï¼‰
3. dynamic_role_name æ˜¯å¿…å¡«é¡¹ï¼Œè¦æ ¹æ®æœ¬é¡¹ç›®éœ€æ±‚åˆ›é€ ä¸€ä¸ªç²¾å‡†åæ˜ è¯¥è§’è‰²èŒè´£çš„åç§°
4. ä¸è¦è¾“å‡º task_distribution å­—æ®µï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆï¼‰
5. **æ ¸å¿ƒè§’è‰²çš„deliverablesæ•°é‡å¿…é¡»æ˜æ˜¾å¤šäºæ”¯æŒè§’è‰²**

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼å’Œä»»åŠ¡é‡è¦æ±‚è¿”å›ç»“æœã€‚
"""

    def _generate_weight_explanation(self, weights: Dict[str, float]) -> str:
        """
        ç”Ÿæˆæƒé‡è¯´æ˜

        Args:
            weights: æƒé‡å­—å…¸

        Returns:
            æƒé‡è¯´æ˜æ–‡æœ¬
        """
        lines = ["# æƒé‡ä¿¡æ¯ä¸ä»»åŠ¡é‡åˆ†é…æŒ‡å¼•", "", "åŸºäºéœ€æ±‚æ–‡æœ¬ä¸­çš„å…³é”®è¯ï¼Œç³»ç»Ÿè®¡ç®—å‡ºä»¥ä¸‹è§’è‰²æƒé‡ï¼š", ""]

        # æŒ‰æƒé‡æ’åº
        sorted_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)

        for role, weight in sorted_weights:
            if weight > 0.1:  # åªæ˜¾ç¤ºæœ‰æ„ä¹‰çš„æƒé‡
                # æ ¹æ®æƒé‡æ¨èä»»åŠ¡é‡
                if weight >= 2.5:
                    task_recommendation = "â†’ å»ºè®®åˆ†é… **4-6ä¸ªäº¤ä»˜ç‰©**ï¼ˆæ ¸å¿ƒè§’è‰²ï¼‰"
                elif weight >= 2.0:
                    task_recommendation = "â†’ å»ºè®®åˆ†é… **2-3ä¸ªäº¤ä»˜ç‰©**ï¼ˆé‡è¦è§’è‰²ï¼‰"
                elif weight >= 1.5:
                    task_recommendation = "â†’ å»ºè®®åˆ†é… **1-2ä¸ªäº¤ä»˜ç‰©**ï¼ˆæ”¯æŒè§’è‰²ï¼‰"
                else:
                    task_recommendation = "â†’ å»ºè®®åˆ†é… **1ä¸ªäº¤ä»˜ç‰©**ï¼ˆè¾…åŠ©è§’è‰²ï¼‰"

                lines.append(f"- **{role}**: {weight:.1f} {task_recommendation}")

        lines.extend(
            [
                "",
                "**æƒé‡è¯´æ˜ä¸ä»»åŠ¡é‡å¯¹åº”å…³ç³»**ï¼š",
                "- æƒé‡ â‰¥2.5ï¼šå¼ºçƒˆæ¨èï¼Œä¸éœ€æ±‚é«˜åº¦åŒ¹é… â†’ **åˆ†é…4-6ä¸ªäº¤ä»˜ç‰©**",
                "- æƒé‡ 2.0-2.4ï¼šé€‚åº¦æ¨èï¼Œæœ‰ä¸€å®šåŒ¹é…åº¦ â†’ **åˆ†é…2-3ä¸ªäº¤ä»˜ç‰©**",
                "- æƒé‡ 1.5-1.9ï¼šåŸºç¡€è§’è‰²æˆ–ä¸­ç­‰åŒ¹é… â†’ **åˆ†é…1-2ä¸ªäº¤ä»˜ç‰©**",
                "- æƒé‡ <1.5ï¼šå¼±åŒ¹é…æˆ–éå¿…éœ€ â†’ **åˆ†é…1ä¸ªäº¤ä»˜ç‰©**",
                "",
                "âš ï¸ **é‡è¦åŸåˆ™**ï¼š",
                "- V2è®¾è®¡æ€»ç›‘æ— è®ºæƒé‡å¤šå°‘ï¼Œéƒ½å¿…é¡»åˆ†é…**4-6ä¸ªäº¤ä»˜ç‰©**ï¼ˆä½œä¸ºæ ¸å¿ƒæ•´åˆè§’è‰²ï¼‰",
                "- ç¦æ­¢å¹³å‡åˆ†é…ï¼šä¸åŒæƒé‡çš„è§’è‰²æ‰¿æ‹…çš„ä»»åŠ¡é‡åº”æœ‰æ˜æ˜¾å·®å¼‚",
                "- æƒé‡ä»…ä¾›å‚è€ƒï¼Œæœ€ç»ˆé€‰æ‹©éœ€è¦ä½ ç»¼åˆåˆ¤æ–­éœ€æ±‚çš„éšå«æ„å›¾",
                "",
            ]
        )

        return "\n".join(lines)

    def explain_selection(self, selection: RoleSelection) -> str:
        """
        ç”Ÿæˆé€‰æ‹©ç»“æœçš„è¯¦ç»†è¯´æ˜

        Args:
            selection: è§’è‰²é€‰æ‹©ç»“æœ

        Returns:
            æ ¼å¼åŒ–çš„è¯´æ˜æ–‡æœ¬
        """
        lines = ["# è§’è‰²é€‰æ‹©ç»“æœ\n", f"## é€‰ä¸­çš„è§’è‰² ({len(selection.selected_roles)}ä¸ª)\n"]

        for role_id in selection.selected_roles:
            try:
                base_type, rid = self.role_manager.parse_full_role_id(role_id)
                role_config = self.role_manager.get_role_config(base_type, rid)

                if role_config:
                    lines.append(f"### {role_id}")
                    lines.append(f"**åç§°**: {role_config.get('name', 'N/A')}")
                    lines.append(f"**ä»»åŠ¡**: {selection.task_distribution.get(role_id, 'N/A')}")
                    lines.append("")
            except Exception as e:
                lines.append(f"### {role_id}")
                lines.append(f"**é”™è¯¯**: æ— æ³•è§£æè§’è‰²ID - {e}")
                lines.append("")

        lines.append("\n## é€‰æ‹©ç†ç”±\n")
        lines.append(selection.reasoning)

        return "\n".join(lines)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import os

    from langchain_openai import ChatOpenAI

    # åˆå§‹åŒ– - ä½¿ç”¨ OpenAI Official API
    llm = ChatOpenAI(
        model="gpt-4.1",
        temperature=0,
        api_key=os.getenv("OPENAI_API_KEY"),
    )
    role_manager = RoleManager()
    director = DynamicProjectDirector(llm, role_manager)

    # æµ‹è¯•éœ€æ±‚
    test_requirements = """
    é¡¹ç›®éœ€æ±‚: è®¾è®¡ä¸€ä¸ªç°ä»£åŒ–çš„åŠå…¬ç©ºé—´

    è¦æ±‚:
    1. é¢ç§¯çº¦1000å¹³æ–¹ç±³
    2. éœ€è¦å®¹çº³50äººåŠå…¬
    3. åŒ…å«ä¼šè®®å®¤ã€ä¼‘æ¯åŒºã€å¼€æ”¾åŠå…¬åŒº
    4. æ³¨é‡è‡ªç„¶é‡‡å…‰å’Œç»¿è‰²ç¯ä¿
    5. ä½“ç°å…¬å¸çš„åˆ›æ–°æ–‡åŒ–
    """

    # é€‰æ‹©è§’è‰²
    print("æ­£åœ¨åˆ†æéœ€æ±‚å¹¶é€‰æ‹©è§’è‰²...")
    selection = director.select_roles_for_task(test_requirements)

    # æ˜¾ç¤ºç»“æœ
    print("\n" + director.explain_selection(selection))


# ============================================================================
# v3.5 Expert Collaboration: Challenge Detection & Feedback Loop
# ============================================================================


class ChallengeDetector:
    """
    v3.5æŒ‘æˆ˜æ£€æµ‹å™¨ - æ£€æµ‹ä¸“å®¶è¾“å‡ºä¸­çš„challenge_flagså¹¶å¤„ç†

    èŒè´£:
    1. æ£€æµ‹ä¸“å®¶è¾“å‡ºä¸­çš„challenge_flags
    2. åˆ†ç±»æŒ‘æˆ˜ç±»å‹ï¼ˆdeeper_insight/uncertainty_clarification/competing_framesï¼‰
    3. å†³ç­–å¤„ç†æ–¹å¼ï¼ˆaccept/revisit/synthesize/escalateï¼‰
    4. è®°å½•æŒ‘æˆ˜æ—¥å¿—
    """

    def __init__(self):
        self.challenge_log = []

    def detect_challenges(self, expert_outputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ£€æµ‹æ‰€æœ‰ä¸“å®¶è¾“å‡ºä¸­çš„æŒ‘æˆ˜æ ‡è®°

        Args:
            expert_outputs: ä¸“å®¶è¾“å‡ºå­—å…¸ï¼Œæ ¼å¼ä¸º {expert_role_id: expert_output}

        Returns:
            æ£€æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å«:
            - has_challenges: bool
            - challenges: List[Dict]
            - challenge_summary: str
        """
        challenges = []

        for expert_role, output in expert_outputs.items():
            # æ£€æŸ¥æ˜¯å¦æœ‰challenge_flagså­—æ®µ
            if isinstance(output, dict) and "challenge_flags" in output:
                challenge_flags = output.get("challenge_flags")

                # ç¡®ä¿challenge_flagsä¸ä¸ºç©º
                if challenge_flags and isinstance(challenge_flags, list):
                    for challenge in challenge_flags:
                        # ğŸ”§ P0ä¿®å¤: æ”¯æŒå­—ç¬¦ä¸²ç±»å‹çš„JSONè§£æ
                        if isinstance(challenge, str):
                            try:
                                import json

                                # å°è¯•è§£æJSON
                                parsed_challenge = json.loads(challenge)
                                if isinstance(parsed_challenge, dict):
                                    challenge = parsed_challenge
                                    logger.debug(f"âœ… æˆåŠŸè§£æå­—ç¬¦ä¸²ç±»å‹çš„challenge: {challenge.get('challenged_item', '')}")
                                else:
                                    # å¦‚æœè§£æç»“æœä¸æ˜¯å­—å…¸ï¼ŒæŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘fallback
                                    raise ValueError("Parsed JSON is not a dict")
                            except (json.JSONDecodeError, AttributeError, ValueError) as e:
                                # Fallback: å°†æ™®é€šå­—ç¬¦ä¸²è§†ä¸ºæŒ‘æˆ˜æè¿°
                                logger.info(f"â„¹ï¸ å°†å­—ç¬¦ä¸²è§†ä¸ºç®€å•æŒ‘æˆ˜æè¿°: {challenge[:50]}...")
                                challenge = {
                                    "challenged_item": "General Issue",
                                    "rationale": challenge,
                                    "reinterpretation": "N/A",
                                    "design_impact": "See rationale",
                                }

                        # æ£€æŸ¥challengeæ˜¯å¦ä¸ºå­—å…¸ç±»å‹
                        if not isinstance(challenge, dict):
                            logger.warning(f"âš ï¸ è·³è¿‡éå­—å…¸ç±»å‹çš„challenge: {type(challenge)}")
                            continue

                        # æ·»åŠ ä¸“å®¶è§’è‰²ä¿¡æ¯
                        challenge_with_role = {
                            "expert_role": expert_role,
                            "challenged_item": challenge.get("challenged_item", ""),
                            "rationale": challenge.get("rationale", ""),
                            "reinterpretation": challenge.get("reinterpretation", ""),
                            "design_impact": challenge.get("design_impact", ""),
                        }
                        challenges.append(challenge_with_role)

                        # è®°å½•åˆ°æ—¥å¿—
                        self.challenge_log.append(
                            {
                                "timestamp": datetime.now().isoformat(),
                                "expert_role": expert_role,
                                "challenge": challenge_with_role,
                            }
                        )

                        logger.warning(f"ğŸ”¥ æ£€æµ‹åˆ°æŒ‘æˆ˜ from {expert_role}: {challenge.get('challenged_item')}")

        # ğŸ”§ ä¿®å¤P1: æ”¹è¿›æŒ‘æˆ˜æ£€æµ‹é€»è¾‘,ç¡®ä¿æ­£ç¡®è¯†åˆ«challenge_flags
        has_challenges = len(challenges) > 0

        result = {
            "has_challenges": has_challenges,
            "challenges": challenges,
            "challenge_summary": self._summarize_challenges(challenges) if has_challenges else "",
        }

        if has_challenges:
            logger.warning(f"ğŸ”¥ [v3.5] å…±æ£€æµ‹åˆ° {len(challenges)} ä¸ªæŒ‘æˆ˜æ ‡è®°,è§¦å‘åé¦ˆå¾ªç¯")
            for i, ch in enumerate(challenges, 1):
                logger.warning(f"   ğŸ”¥ æŒ‘æˆ˜{i}: {ch.get('expert_role')} å¯¹ '{ch.get('challenged_item')}' æå‡ºè´¨ç–‘")
        else:
            logger.info("âœ… [v3.5] æœªæ£€æµ‹åˆ°æŒ‘æˆ˜æ ‡è®°ï¼Œä¸“å®¶æ¥å—éœ€æ±‚åˆ†æå¸ˆçš„æ´å¯Ÿ")

        return result

    def _summarize_challenges(self, challenges: List[Dict]) -> str:
        """ç”ŸæˆæŒ‘æˆ˜æ‘˜è¦"""
        summary_parts = []
        for i, challenge in enumerate(challenges, 1):
            summary_parts.append(
                f"{i}. **{challenge['expert_role']}** æŒ‘æˆ˜äº† '{challenge['challenged_item']}':\n"
                f"   ç†ç”±: {challenge['rationale'][:100]}...\n"
                f"   é‡æ–°è¯ é‡Š: {challenge['reinterpretation'][:100]}..."
            )
        return "\n\n".join(summary_parts)

    def classify_challenge_type(self, challenge: Dict[str, Any]) -> str:
        """
        åˆ†ç±»æŒ‘æˆ˜ç±»å‹

        Returns:
            challenge_type: "deeper_insight" | "uncertainty_clarification" | "competing_frames" | "other"
        """
        challenged_item = challenge.get("challenged_item", "").lower()
        rationale = challenge.get("rationale", "").lower()

        # æ ¹æ®å…³é”®è¯åˆ¤æ–­ç±»å‹
        if "æ›´æ·±" in rationale or "æ·±åˆ»" in rationale or "çœŸæ­£" in rationale:
            return "deeper_insight"
        elif "ä¸ç¡®å®š" in challenged_item or "æ¨¡ç³Š" in challenged_item or "æ ‡è®°" in rationale:
            return "uncertainty_clarification"
        elif "æ¡†æ¶" in challenged_item or "ç†è§£" in challenged_item or "è¯ é‡Š" in rationale:
            return "competing_frames"
        else:
            return "other"

    def decide_handling(self, challenge: Dict[str, Any], challenge_type: str) -> str:
        """
        å†³ç­–æŒ‘æˆ˜å¤„ç†æ–¹å¼

        Args:
            challenge: æŒ‘æˆ˜è¯¦æƒ…
            challenge_type: æŒ‘æˆ˜ç±»å‹

        Returns:
            handling_decision: "accept" | "revisit_ra" | "synthesize" | "escalate"
        """
        # æ ¹æ®æŒ‘æˆ˜ç±»å‹å†³å®šå¤„ç†æ–¹å¼
        if challenge_type == "deeper_insight":
            # ä¸“å®¶å‘ç°äº†æ›´æ·±çš„æ´å¯Ÿ â†’ æ¥å—ä¸“å®¶çš„é‡æ–°è¯ é‡Š
            logger.info(f"ğŸ“Œ å†³ç­–: æ¥å—ä¸“å®¶çš„æ›´æ·±æ´å¯Ÿ")
            return "accept"

        elif challenge_type == "uncertainty_clarification":
            # ä¸“å®¶æ ‡è®°äº†ä¸ç¡®å®šæ€§éœ€è¦æ¾„æ¸… â†’ å›è®¿éœ€æ±‚åˆ†æå¸ˆæˆ–ç”¨æˆ·
            logger.info(f"ğŸ“Œ å†³ç­–: å›è®¿éœ€æ±‚åˆ†æå¸ˆæˆ–ç”¨æˆ·ç¡®è®¤")
            return "revisit_ra"

        elif challenge_type == "competing_frames":
            # å­˜åœ¨ç«äº‰æ€§æ¡†æ¶ â†’ ç»¼åˆå¤šä¸ªæ–¹æ¡ˆ
            logger.info(f"ğŸ“Œ å†³ç­–: ç»¼åˆå¤šä¸ªè¯ é‡Šæ¡†æ¶")
            return "synthesize"

        else:
            # å…¶ä»–æƒ…å†µ â†’ äº¤ç”²æ–¹è£å†³
            logger.info(f"ğŸ“Œ å†³ç­–: äº¤ç”²æ–¹è£å†³")
            return "escalate"

    def handle_challenges(self, detection_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†æ‰€æœ‰æ£€æµ‹åˆ°çš„æŒ‘æˆ˜

        Returns:
            handling_result: {
                "handling_decisions": List[Dict],  # æ¯ä¸ªæŒ‘æˆ˜çš„å¤„ç†å†³ç­–
                "requires_revisit": bool,          # æ˜¯å¦éœ€è¦å›è®¿éœ€æ±‚åˆ†æå¸ˆ
                "requires_synthesis": bool,        # æ˜¯å¦éœ€è¦ç»¼åˆå¤šæ–¹æ¡ˆ
                "escalated_challenges": List[Dict] # éœ€è¦äº¤ç”²æ–¹è£å†³çš„æŒ‘æˆ˜
            }
        """
        if not detection_result["has_challenges"]:
            return {
                "handling_decisions": [],
                "requires_revisit": False,
                "requires_synthesis": False,
                "escalated_challenges": [],
            }

        handling_decisions = []
        requires_revisit = False
        requires_synthesis = False
        escalated_challenges = []

        for challenge in detection_result["challenges"]:
            # åˆ†ç±»
            challenge_type = self.classify_challenge_type(challenge)

            # å†³ç­–
            decision = self.decide_handling(challenge, challenge_type)

            handling_decisions.append({"challenge": challenge, "challenge_type": challenge_type, "decision": decision})

            # æ›´æ–°æ ‡å¿—
            if decision == "revisit_ra":
                requires_revisit = True
            elif decision == "synthesize":
                requires_synthesis = True
            elif decision == "escalate":
                escalated_challenges.append(challenge)

        result = {
            "handling_decisions": handling_decisions,
            "requires_revisit": requires_revisit,
            "requires_synthesis": requires_synthesis,
            "escalated_challenges": escalated_challenges,
        }

        logger.info(f"âœ… æŒ‘æˆ˜å¤„ç†å®Œæˆ: å›è®¿={requires_revisit}, ç»¼åˆ={requires_synthesis}, å‡çº§={len(escalated_challenges)}")

        return result

    def get_challenge_log(self) -> List[Dict]:
        """è·å–å®Œæ•´çš„æŒ‘æˆ˜æ—¥å¿—"""
        return self.challenge_log


def _apply_accepted_reinterpretation(state: Dict[str, Any], challenge: Dict[str, Any]) -> None:
    """
    åº”ç”¨è¢«æ¥å—çš„ä¸“å®¶é‡æ–°è¯ é‡Š - Acceptå†³ç­–çš„é—­ç¯é€»è¾‘

    å°†ä¸“å®¶çš„æ–°æ´å¯Ÿæ›´æ–°åˆ°stateä¸­ï¼Œä½¿å…¶å¯¹åç»­åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆå¯è§

    Args:
        state: å·¥ä½œæµçŠ¶æ€ï¼ˆä¼šè¢«åŸåœ°ä¿®æ”¹ï¼‰
        challenge: åŒ…å«ä¸“å®¶é‡æ–°è¯ é‡Šçš„æŒ‘æˆ˜è¯¦æƒ…
    """
    # ğŸ”§ P0ä¿®å¤: é˜²å¾¡æ€§æ£€æŸ¥
    if not isinstance(challenge, dict):
        logger.error(f"âŒ _apply_accepted_reinterpretation æ”¶åˆ°éå­—å…¸ç±»å‹challenge: {type(challenge)}")
        return

    expert_role = challenge.get("expert_role", "unknown")
    challenged_item = challenge.get("challenged_item", "")
    reinterpretation = challenge.get("reinterpretation", "")
    design_impact = challenge.get("design_impact", "")

    # åˆå§‹åŒ–expert_driven_insightså­—æ®µ
    if "expert_driven_insights" not in state:
        state["expert_driven_insights"] = {}

    # è®°å½•é‡‡çº³çš„æ–°æ´å¯Ÿ
    state["expert_driven_insights"][challenged_item] = {
        "original_interpretation": "éœ€æ±‚åˆ†æå¸ˆçš„åˆå§‹åˆ¤æ–­",
        "expert_reinterpretation": reinterpretation,
        "accepted_from": expert_role,
        "design_impact": design_impact,
        "timestamp": datetime.now().isoformat(),
        "status": "accepted",
    }

    # é€šçŸ¥æœºåˆ¶ï¼šè®°å½•æ´å¯Ÿæ›´æ–°ï¼Œä¾›å…¶ä»–ä¸“å®¶å‚è€ƒ
    if "insight_updates" not in state:
        state["insight_updates"] = []

    state["insight_updates"].append(
        {
            "item": challenged_item,
            "new_interpretation": reinterpretation,
            "source": expert_role,
            "reason": "ä¸“å®¶æå‡ºæ›´æ·±æ´å¯Ÿï¼Œå·²è¢«é¡¹ç›®æ€»ç›‘æ¥å—",
        }
    )

    logger.info(f"âœ… [Accepté—­ç¯] é‡‡çº³{expert_role}å¯¹'{challenged_item}'çš„é‡æ–°è¯ é‡Š")


def _synthesize_competing_frames(state: Dict[str, Any], challenges: List[Dict[str, Any]]) -> None:
    """
    ç»¼åˆå¤šä¸ªç«äº‰æ€§æ¡†æ¶ - Synthesizeå†³ç­–çš„é—­ç¯é€»è¾‘

    å½“å¤šä¸ªä¸“å®¶å¯¹åŒä¸€äº‹é¡¹æå‡ºä¸åŒè¯ é‡Šæ—¶ï¼Œç»¼åˆæˆæ··åˆæ–¹æ¡ˆ

    Args:
        state: å·¥ä½œæµçŠ¶æ€ï¼ˆä¼šè¢«åŸåœ°ä¿®æ”¹ï¼‰
        challenges: éœ€è¦ç»¼åˆçš„æŒ‘æˆ˜åˆ—è¡¨
    """
    if not challenges:
        return

    # æå–æ‰€æœ‰ç«äº‰æ€§æ¡†æ¶
    competing_interpretations = []
    for challenge in challenges:
        competing_interpretations.append(
            {
                "expert": challenge.get("expert_role", "unknown"),
                "challenged_item": challenge.get("challenged_item", ""),
                "interpretation": challenge.get("reinterpretation", ""),
                "rationale": challenge.get("rationale", ""),
                "design_impact": challenge.get("design_impact", ""),
            }
        )

    # åˆ†ç»„ï¼šæŒ‰challenged_itemåˆ†ç»„
    from collections import defaultdict

    grouped = defaultdict(list)
    for interp in competing_interpretations:
        grouped[interp["challenged_item"]].append(interp)

    # ä¸ºæ¯ä¸ªæœ‰ç«äº‰çš„é¡¹ç”Ÿæˆç»¼åˆæ–¹æ¡ˆ
    if "framework_synthesis" not in state:
        state["framework_synthesis"] = {}

    for item, interpretations in grouped.items():
        if len(interpretations) > 1:
            # å¤šä¸ªæ¡†æ¶éœ€è¦ç»¼åˆ
            synthesis_summary = f"æ£€æµ‹åˆ°{len(interpretations)}ä¸ªç«äº‰æ€§æ¡†æ¶:\n"
            for i, interp in enumerate(interpretations, 1):
                synthesis_summary += f"{i}. {interp['expert']}: {interp['interpretation'][:100]}...\n"

            state["framework_synthesis"][item] = {
                "competing_frames": interpretations,
                "synthesis_summary": synthesis_summary,
                "recommendation": "å»ºè®®åœ¨æŠ¥å‘Šä¸­å¹¶åˆ—å±•ç¤ºå¤šä¸ªæ–¹æ¡ˆï¼Œæ ¹æ®å…·ä½“æƒ…å¢ƒé€‰æ‹©",
                "requires_deep_analysis": True,
            }

            logger.info(f"ğŸ”„ [Synthesizeé—­ç¯] ç»¼åˆ{len(interpretations)}ä¸ªå…³äº'{item}'çš„ç«äº‰æ€§æ¡†æ¶")

    # æ ‡è®°éœ€è¦ç»¼åˆ
    state["has_competing_frameworks"] = True
    state["synthesis_required"] = True


def detect_and_handle_challenges_node(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    å·¥ä½œæµèŠ‚ç‚¹ï¼šæŒ‘æˆ˜æ£€æµ‹ä¸å¤„ç† + é—­ç¯æ‰§è¡Œ

    åœ¨æ‰€æœ‰ä¸“å®¶å®Œæˆè¾“å‡ºåè°ƒç”¨ï¼Œæ£€æµ‹challenge_flagså¹¶å†³ç­–å¤„ç†æ–¹å¼

    ğŸ†• v3.5.1 æ–°å¢é—­ç¯æœºåˆ¶:
    - Acceptå†³ç­–: æ›´æ–°expert_driven_insights
    - Synthesizeå†³ç­–: ç»¼åˆç«äº‰æ€§æ¡†æ¶
    - Escalateå†³ç­–: æ ‡è®°éœ€è¦ç”²æ–¹è£å†³

    Args:
        state: å·¥ä½œæµçŠ¶æ€ï¼ŒåŒ…å«æ‰€æœ‰ä¸“å®¶çš„è¾“å‡º

    Returns:
        æ›´æ–°çš„çŠ¶æ€ï¼ŒåŒ…å«æŒ‘æˆ˜æ£€æµ‹å’Œå¤„ç†ç»“æœ
    """
    logger.info("ğŸ” å¼€å§‹æ£€æµ‹ä¸“å®¶æŒ‘æˆ˜...")

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = ChallengeDetector()

    # æ”¶é›†æ‰€æœ‰ä¸“å®¶è¾“å‡º
    expert_outputs = {}

    # ğŸ”§ ä¿®å¤ï¼šä»æ­£ç¡®çš„å­—æ®µè¯»å–ä¸“å®¶è¾“å‡º
    # ä¸“å®¶è¾“å‡ºå­˜å‚¨åœ¨ state["agent_results"] ä¸­
    agent_results = state.get("agent_results", {})

    logger.debug(f"ğŸ” å¼€å§‹æ‰«æ {len(agent_results)} ä¸ªä¸“å®¶è¾“å‡º...")

    for agent_id, agent_data in agent_results.items():
        # agent_data æ˜¯ AgentExecutionResult å¯¹è±¡è½¬æ¢çš„å­—å…¸
        if isinstance(agent_data, dict):
            # æå– structured_data å­—æ®µï¼ˆä¸“å®¶çš„ç»“æ„åŒ–è¾“å‡ºï¼‰
            structured_data = agent_data.get("structured_data", {})
            if structured_data:
                expert_outputs[agent_id] = structured_data
                logger.debug(f"   âœ… æå– {agent_id} çš„è¾“å‡º (åŒ…å« {len(structured_data.keys())} ä¸ªå­—æ®µ)")
            elif agent_data.get("challenge_flags"):
                # å…¼å®¹æ—§æ ¼å¼ï¼šchallenge_flags ç›´æ¥é™„ç€åœ¨ agent_data ä¸Š
                expert_outputs[agent_id] = agent_data
                logger.debug(f"   âœ… ä» {agent_id} æ•è·ç›´è¿çš„ challenge_flags")
            else:
                logger.debug(f"   âš ï¸ {agent_id} çš„ structured_data ä¸ºç©º")

    # ğŸ†• å…¼å®¹æ‰¹æ¬¡èšåˆç»“æœä¸­çš„ challenge_flagsï¼ˆtests ç›´æ¥å†™åœ¨ batch_results ä¸­ï¼‰
    batch_results = state.get("batch_results", {})
    for batch_id, batch_data in batch_results.items():
        if not isinstance(batch_data, dict):
            continue
        for agent_id, agent_payload in batch_data.items():
            if not isinstance(agent_payload, dict):
                continue

            candidate = (
                agent_payload.get("structured_data")
                if isinstance(agent_payload.get("structured_data"), dict)
                else agent_payload
            )
            if isinstance(candidate, dict) and candidate.get("challenge_flags"):
                if agent_id not in expert_outputs:
                    expert_outputs[agent_id] = candidate
                    logger.debug(f"   âœ… ä» batch {batch_id} æ•è· {agent_id} çš„ challenge_flags")

    # æ£€æµ‹æŒ‘æˆ˜
    detection_result = detector.detect_challenges(expert_outputs)

    # å¤„ç†æŒ‘æˆ˜
    handling_result = detector.handle_challenges(detection_result)

    # æ›´æ–°stateï¼ˆåªè¿”å›æ–°å¢/ä¿®æ”¹çš„å­—æ®µï¼Œé¿å…ä¸ä¸Šæ¸¸èŠ‚ç‚¹çš„çŠ¶æ€æ›´æ–°å†²çªï¼‰
    updated_state = {
        "challenge_detection": detection_result,
        "challenge_handling": handling_result,
        "has_active_challenges": detection_result["has_challenges"],
        "requires_feedback_loop": handling_result["requires_revisit"],
    }

    # ğŸ†• æ‰§è¡Œé—­ç¯é€»è¾‘
    handling_decisions = handling_result.get("handling_decisions", [])

    # 1ï¸âƒ£ Accepté—­ç¯: åº”ç”¨è¢«æ¥å—çš„é‡æ–°è¯ é‡Š
    accepted_challenges = [d["challenge"] for d in handling_decisions if d["decision"] == "accept"]
    for challenge in accepted_challenges:
        _apply_accepted_reinterpretation(state, challenge)

    if accepted_challenges:
        updated_state["accepted_reinterpretations_count"] = len(accepted_challenges)
        logger.info(f"âœ… [Accepté—­ç¯] åº”ç”¨äº†{len(accepted_challenges)}ä¸ªä¸“å®¶çš„é‡æ–°è¯ é‡Š")

    # 2ï¸âƒ£ Synthesizeé—­ç¯: ç»¼åˆç«äº‰æ€§æ¡†æ¶
    if handling_result.get("requires_synthesis"):
        synthesis_challenges = [d["challenge"] for d in handling_decisions if d["decision"] == "synthesize"]
        _synthesize_competing_frames(state, synthesis_challenges)
        updated_state["synthesis_required"] = True
        logger.info(f"ğŸ”„ [Synthesizeé—­ç¯] ç»¼åˆäº†{len(synthesis_challenges)}ä¸ªç«äº‰æ€§æ¡†æ¶")

    # 3ï¸âƒ£ Escalateé—­ç¯: æ ‡è®°éœ€è¦ç”²æ–¹è£å†³çš„æŒ‘æˆ˜
    escalated = handling_result.get("escalated_challenges", [])
    if escalated:
        # æ ¼å¼åŒ–ä¸ºå®¡æ ¸ç³»ç»Ÿèƒ½ç†è§£çš„é—®é¢˜æ ¼å¼
        escalated_issues = []
        for challenge in escalated:
            escalated_issues.append(
                {
                    "issue_id": f"CHALLENGE_{challenge.get('expert_role', 'unknown')}_{datetime.now().strftime('%H%M%S')}",
                    "type": "strategic_decision",
                    "severity": "high",
                    "description": f"{challenge.get('expert_role')}æŒ‘æˆ˜äº†'{challenge.get('challenged_item')}'",
                    "expert_rationale": challenge.get("rationale", ""),
                    "reinterpretation": challenge.get("reinterpretation", ""),
                    "design_impact": challenge.get("design_impact", ""),
                    "requires_client_decision": True,
                }
            )

        updated_state["escalated_challenges"] = escalated_issues
        updated_state["requires_client_review"] = True
        logger.warning(f"ğŸš¨ [Escalateé—­ç¯] {len(escalated)}ä¸ªæŒ‘æˆ˜éœ€è¦ç”²æ–¹è£å†³")

    # å¦‚æœéœ€è¦å›è®¿ï¼Œè®°å½•åŸå› 
    if handling_result["requires_revisit"]:
        logger.warning("âš ï¸ æ£€æµ‹åˆ°éœ€è¦å›è®¿éœ€æ±‚åˆ†æå¸ˆçš„æŒ‘æˆ˜")
        updated_state["feedback_loop_reason"] = "Expert challenges require clarification"

    return updated_state
