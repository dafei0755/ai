"""
ğŸ”¥ v7.15: è¿½é—®æ™ºèƒ½ä½“ - åŸºäº LangGraph çš„ç‹¬ç«‹ Agent

åŠŸèƒ½ï¼š
1. æ„å›¾è¯†åˆ«èŠ‚ç‚¹ï¼šclosed/open/creative/general
2. ä¸Šä¸‹æ–‡æ£€ç´¢èŠ‚ç‚¹ï¼šä»æŠ¥å‘Šä¸­æå–ç›¸å…³å†…å®¹
3. å›ç­”ç”ŸæˆèŠ‚ç‚¹ï¼šæ ¹æ®æ„å›¾é€‰æ‹©æç¤ºè¯æ¨¡å¼
4. å»ºè®®ç”ŸæˆèŠ‚ç‚¹ï¼šæ™ºèƒ½æ¨èåç»­é—®é¢˜
5. æ”¯æŒå·¥å…·æ‰©å±•ï¼šé¢„ç•™æœç´¢å·¥å…·æ¥å£ï¼ˆæš‚æœªå¯ç”¨ï¼‰

æ¶æ„ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  classify_intent â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ retrieve_context â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ generate_answer  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ generate_suggest â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
           [END]
"""

from typing import Dict, Any, List, Optional, Literal, TypedDict, Annotated
from datetime import datetime
from loguru import logger
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, SystemMessage
from pydantic import BaseModel, Field
import operator


# ============================================================
# çŠ¶æ€å®šä¹‰
# ============================================================

class FollowupAgentState(TypedDict):
    """è¿½é—® Agent çŠ¶æ€"""
    # è¾“å…¥
    question: str                          # ç”¨æˆ·é—®é¢˜
    report_context: Dict[str, Any]         # æŠ¥å‘Šä¸Šä¸‹æ–‡
    conversation_history: List[Dict]       # å¯¹è¯å†å²
    
    # ä¸­é—´çŠ¶æ€
    intent: str                            # è¯†åˆ«çš„æ„å›¾
    relevant_sections: List[Dict]          # æ£€ç´¢åˆ°çš„ç›¸å…³ç« èŠ‚
    intent_prompt: str                     # æ„å›¾ä¸“å±æç¤ºè¯
    
    # è¾“å‡º
    answer: str                            # ç”Ÿæˆçš„å›ç­”
    references: List[str]                  # å¼•ç”¨çš„ç« èŠ‚
    suggestions: List[str]                 # åç»­é—®é¢˜å»ºè®®
    
    # å…ƒæ•°æ®
    processing_log: Annotated[List[str], operator.add]  # å¤„ç†æ—¥å¿—ï¼ˆç´¯åŠ ï¼‰


# ============================================================
# æ„å›¾åˆ†ç±»å™¨
# ============================================================

# æ„å›¾ä¸“å±æç¤ºè¯
INTENT_PROMPTS = {
    "closed": """ã€é—­ç¯æ¨¡å¼ã€‘ç”¨æˆ·è¯¢é—®çš„æ˜¯æŠ¥å‘Šä¸­çš„å…·ä½“å†…å®¹ï¼Œè¯·ä¸¥æ ¼åŸºäºæŠ¥å‘Šå›ç­”ï¼š
- ç›´æ¥å¼•ç”¨æŠ¥å‘Šä¸­çš„æ•°æ®å’Œç»“è®º
- æŒ‡å‡ºå…·ä½“ç« èŠ‚ä½ç½®
- å¦‚æŠ¥å‘Šæœªæ¶‰åŠï¼Œæ˜ç¡®è¯´æ˜""",
    
    "open_with_context": """ã€æ‰©å±•æ¨¡å¼ã€‘ç”¨æˆ·å¸Œæœ›è·å¾—æ›´å¹¿æ³›çš„è§è§£ï¼Œåœ¨æŠ¥å‘ŠåŸºç¡€ä¸Šæ‰©å±•å›ç­”ï¼š
- é¦–å…ˆå›åº”æŠ¥å‘Šä¸­çš„ç›¸å…³å†…å®¹ã€ğŸ“– æŠ¥å‘Šå†…å®¹ã€‘
- ç„¶åè¡¥å……ä¸“ä¸šçŸ¥è¯†å’Œè¡Œä¸šç»éªŒã€ğŸŒ æ‰©å±•çŸ¥è¯†ã€‘
- å¯ä»¥æä¾›ç±»ä¼¼æ¡ˆä¾‹å‚è€ƒã€ğŸ“š ä¸šç•Œå‚è€ƒã€‘
- ç¡®ä¿ç”¨æˆ·èƒ½åŒºåˆ†å“ªäº›æ˜¯æŠ¥å‘Šç»“è®ºï¼Œå“ªäº›æ˜¯æ‰©å±•å»ºè®®""",
    
    "creative": """ã€åˆ›æ„æ¨¡å¼ã€‘ç”¨æˆ·å¸Œæœ›è¿›è¡Œå¤´è„‘é£æš´æˆ–æ¢ç´¢æ€§è®¨è®ºï¼š
- è‡ªç”±å‘æŒ¥ä¸“ä¸šçŸ¥è¯†å’Œåˆ›æ„æ€ç»´
- æä¾›å¤šç§å¯èƒ½æ€§å’Œæ–¹å‘
- é¼“åŠ±ã€ŒWhat-ifã€å‡è®¾æ€§æ¢è®¨
- ç»“åˆè¡Œä¸šè¶‹åŠ¿å’Œå‰æ²¿ç†å¿µã€ğŸ’¡ åˆ›æ„å»ºè®®ã€‘
- å¯ä»¥è·¨é¢†åŸŸç±»æ¯”å€Ÿé‰´ã€ğŸ”— è·¨ç•Œå¯å‘ã€‘""",
    
    "general": """è¯·ç»¼åˆæŠ¥å‘Šå†…å®¹å’Œä¸“ä¸šçŸ¥è¯†å›ç­”ï¼Œæ³¨æ„æ ‡æ³¨ä¿¡æ¯æ¥æºã€‚"""
}


def classify_intent_node(state: FollowupAgentState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹1: æ„å›¾åˆ†ç±»
    
    åˆ†ç±»ç»´åº¦ï¼š
    - closed: é—­ç¯é—®é¢˜ï¼Œè¯¢é—®æŠ¥å‘Šå…·ä½“å†…å®¹
    - open_with_context: å¼€æ”¾é—®é¢˜ï¼Œå¸Œæœ›æ‰©å±•
    - creative: åˆ›æ„é—®é¢˜ï¼Œå¤´è„‘é£æš´
    - general: é€šç”¨é—®é¢˜
    """
    question = state["question"].lower()
    
    # === é—­ç¯é—®é¢˜å…³é”®è¯ ===
    closed_keywords = [
        "æŠ¥å‘Šä¸­", "æŠ¥å‘Šé‡Œ", "åˆ†æç»“æœ", "ä¸“å®¶è¯´", "å“ªä¸ªä¸“å®¶",
        "ç¬¬å‡ ç« ", "å“ªä¸€ç« ", "å“ªä¸ªéƒ¨åˆ†", "åœ¨å“ªé‡Œæåˆ°",
        "å…·ä½“æ˜¯ä»€ä¹ˆ", "åŸæ–‡æ˜¯", "æ€ä¹ˆè¯´çš„", "ç»“è®ºæ˜¯ä»€ä¹ˆ",
        "æ•°æ®æ˜¯å¤šå°‘", "æ¯”ä¾‹æ˜¯", "å æ¯”", "æ€»ç»“äº†ä»€ä¹ˆ"
    ]
    
    # === å¼€æ”¾æ‰©å±•é—®é¢˜å…³é”®è¯ ===
    open_keywords = [
        "è¿˜æœ‰ä»€ä¹ˆ", "é™¤æ­¤ä¹‹å¤–", "è¡¥å……", "æ‰©å±•", "æ›´å¤š",
        "ç±»ä¼¼æ¡ˆä¾‹", "ç±»ä¼¼çš„", "è¡Œä¸šç»éªŒ", "æœ€ä½³å®è·µ", "ä¸šç•Œ",
        "æœ‰æ²¡æœ‰æ¡ˆä¾‹", "æ¡ˆä¾‹å‚è€ƒ",
        "ä¸ºä»€ä¹ˆ", "æ€ä¹ˆç†è§£", "å¦‚ä½•è§£è¯»", "èƒŒååŸå› ",
        "æœ‰ä»€ä¹ˆå»ºè®®", "ä½ è§‰å¾—", "ä½ è®¤ä¸º"
    ]
    
    # === åˆ›æ„å‘æ•£é—®é¢˜å…³é”®è¯ ===
    creative_keywords = [
        "å¦‚æœ", "å‡è®¾", "å‡å¦‚", "what if", "what-if",
        "ä¸‡ä¸€", "è¦æ˜¯", "è®¾æƒ³",
        "æœ‰æ²¡æœ‰å¯èƒ½", "èƒ½ä¸èƒ½", "å¯ä»¥æ€ä¹ˆ", "è¿˜èƒ½æ€æ ·",
        "çªç ´", "åˆ›æ–°", "é¢ è¦†", "å¤§èƒ†ä¸€ç‚¹", "å¤§èƒ†",
        "æ›´å¤§èƒ†", "æ¿€è¿›", "å‰å«",
        "å…¶ä»–è¡Œä¸š", "è·¨ç•Œ", "å€Ÿé‰´", "ç±»æ¯”", "å‚è€ƒå…¶ä»–"
    ]
    
    # ä¼˜å…ˆçº§ï¼šcreative > open > closed > general
    intent = "general"
    matched_keyword = None
    
    for keyword in creative_keywords:
        if keyword in question:
            intent = "creative"
            matched_keyword = keyword
            break
    
    if intent == "general":
        for keyword in open_keywords:
            if keyword in question:
                intent = "open_with_context"
                matched_keyword = keyword
                break
    
    if intent == "general":
        for keyword in closed_keywords:
            if keyword in question:
                intent = "closed"
                matched_keyword = keyword
                break
    
    intent_prompt = INTENT_PROMPTS.get(intent, INTENT_PROMPTS["general"])
    
    log_msg = f"ğŸ¯ æ„å›¾åˆ†ç±»: {intent}" + (f" (å…³é”®è¯: {matched_keyword})" if matched_keyword else " (é»˜è®¤)")
    logger.info(log_msg)
    
    return {
        "intent": intent,
        "intent_prompt": intent_prompt,
        "processing_log": [log_msg]
    }


# ============================================================
# ä¸Šä¸‹æ–‡æ£€ç´¢å™¨
# ============================================================

def retrieve_context_node(state: FollowupAgentState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹2: ä¸Šä¸‹æ–‡æ£€ç´¢
    
    ä»æŠ¥å‘Šä¸­æå–ç›¸å…³ç« èŠ‚
    """
    report_context = state.get("report_context", {})
    question = state.get("question", "")
    
    sections = []
    
    # ä» final_report æå–
    final_report = report_context.get("final_report", {})
    if isinstance(final_report, dict):
        for key, value in final_report.items():
            if isinstance(value, str):
                sections.append({"title": key, "content": value[:1000]})  # æˆªæ–­
            elif isinstance(value, dict):
                sections.append({"title": key, "content": str(value)[:1000]})
    elif isinstance(final_report, str):
        sections.append({"title": "å®Œæ•´æŠ¥å‘Š", "content": final_report[:2000]})
    
    # ä» agent_results æå–
    agent_results = report_context.get("agent_results", {})
    if isinstance(agent_results, dict):
        for agent_id, result in agent_results.items():
            if isinstance(result, dict):
                content = result.get("content", "") or str(result)
            else:
                content = str(result)
            sections.append({"title": f"ä¸“å®¶åˆ†æ: {agent_id}", "content": content[:800]})
    
    log_msg = f"ğŸ“š æ£€ç´¢åˆ° {len(sections)} ä¸ªç›¸å…³ç« èŠ‚"
    logger.info(log_msg)
    
    return {
        "relevant_sections": sections,
        "processing_log": [log_msg]
    }


# ============================================================
# å›ç­”ç”Ÿæˆå™¨
# ============================================================

def generate_answer_node(state: FollowupAgentState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹3: å›ç­”ç”Ÿæˆ
    
    ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”
    """
    from ..services.llm_factory import LLMFactory
    from ..services.followup_history_manager import FollowupHistoryManager
    
    question = state.get("question", "")
    intent = state.get("intent", "general")
    intent_prompt = state.get("intent_prompt", "")
    relevant_sections = state.get("relevant_sections", [])
    conversation_history = state.get("conversation_history", [])
    
    # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡æ‘˜è¦
    context_parts = []
    for section in relevant_sections:
        content = section.get("content", "")
        truncated = content[:500] + "..." if len(content) > 500 else content
        context_parts.append(f"ã€{section.get('title', 'æœªå‘½å')}ã€‘\n{truncated}")
    
    context_summary = "\n\n".join(context_parts) if context_parts else "ï¼ˆæš‚æ— ç›¸å…³ä¸Šä¸‹æ–‡ï¼‰"
    
    # ğŸ”¥ ä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    temp_manager = FollowupHistoryManager(session_manager=None)
    context_result = temp_manager.build_context_for_llm(
        history=conversation_history,
        report_summary=context_summary,
        current_question=question,
        enable_memory_all=True
    )
    context_str = context_result["context_str"]
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®åˆ†æé¡¾é—®åŠ©æ‰‹ï¼Œåå«ã€Œè®¾è®¡é«˜å‚ AIã€ã€‚

ä½ çš„èŒè´£ï¼š
1. å¸®åŠ©ç”¨æˆ·ç†è§£åˆšåˆšå®Œæˆçš„é¡¹ç›®åˆ†ææŠ¥å‘Š
2. å›ç­”å…³äºæŠ¥å‘Šå†…å®¹çš„ä»»ä½•é—®é¢˜
3. æä¾›æ·±å…¥çš„è§£é‡Šå’Œè¡¥å……ä¿¡æ¯
4. ğŸ”¥ å……åˆ†å‘æŒ¥ä¸“ä¸šçŸ¥è¯†ï¼Œæä¾›é«˜ä»·å€¼æ´å¯Ÿ
5. ä¿æŒä¸“ä¸šã€å‹å¥½ã€è€å¿ƒçš„è¯­æ°”

{intent_prompt}

å›ç­”è§„èŒƒï¼š
âœ… ä½¿ç”¨ç»“æ„åŒ–æ ¼å¼ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€è¦ç‚¹ï¼‰
âœ… æ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºï¼ˆğŸ“–æŠ¥å‘Š/ğŸŒæ‰©å±•/ğŸ’¡åˆ›æ„ï¼‰
âœ… é¼“åŠ±ç”¨æˆ·ç»§ç»­è¿½é—®å’Œæ·±æŒ–
âŒ ä¸è¦ä½¿ç”¨è¿‡äºæŠ€æœ¯åŒ–çš„æœ¯è¯­

{context_str}
"""
    
    # è°ƒç”¨ LLM
    llm = LLMFactory.create_llm()
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šè¿°æŠ¥å‘Šå†…å®¹å›ç­”ï¼Œå¹¶åœ¨å›ç­”æœ«å°¾æ ‡æ³¨å¼•ç”¨çš„ç« èŠ‚ï¼ˆæ ¼å¼ï¼šğŸ“– å¼•ç”¨ï¼šç¬¬Xç« ï¼‰ã€‚""")
    ]
    
    try:
        response = llm.invoke(messages)
        answer = response.content
        log_msg = f"âœ… å›ç­”ç”ŸæˆæˆåŠŸ ({len(answer)} å­—ç¬¦)"
    except Exception as e:
        answer = f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶é‡åˆ°é—®é¢˜: {str(e)}"
        log_msg = f"âŒ å›ç­”ç”Ÿæˆå¤±è´¥: {e}"
    
    logger.info(log_msg)
    
    # æå–å¼•ç”¨
    references = []
    for section in relevant_sections:
        title = section.get("title", "")
        if title and title in answer:
            references.append(title)
    
    return {
        "answer": answer,
        "references": list(set(references)),
        "processing_log": [log_msg]
    }


# ============================================================
# å»ºè®®ç”Ÿæˆå™¨
# ============================================================

def generate_suggestions_node(state: FollowupAgentState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹4: ç”Ÿæˆåç»­é—®é¢˜å»ºè®®
    
    æ ¹æ®æ„å›¾æ™ºèƒ½æ¨è
    """
    intent = state.get("intent", "general")
    
    # åŸºç¡€å»ºè®®æ± 
    closed_suggestions = [
        "è¿™éƒ¨åˆ†æŠ¥å‘Šçš„å…·ä½“æ•°æ®æ¥æºæ˜¯ä»€ä¹ˆï¼Ÿ",
        "ä¸“å®¶æ˜¯åŸºäºä»€ä¹ˆç†ç”±å¾—å‡ºè¿™ä¸ªç»“è®ºçš„ï¼Ÿ",
        "æŠ¥å‘Šä¸­æœ‰æ²¡æœ‰æåˆ°ç›¸å…³çš„é£é™©ç‚¹ï¼Ÿ",
        "èƒ½å±•å¼€è¯´è¯´è¿™ä¸ªæ–¹æ¡ˆçš„æ‰§è¡Œæ­¥éª¤å—ï¼Ÿ"
    ]
    
    open_suggestions = [
        "æœ‰æ²¡æœ‰ç±»ä¼¼çš„æˆåŠŸæ¡ˆä¾‹å¯ä»¥å‚è€ƒï¼Ÿ",
        "ä¸šç•Œç›®å‰çš„æœ€ä½³å®è·µæ˜¯æ€æ ·çš„ï¼Ÿ",
        "è¿™ä¸ªæ–¹å‘æœªæ¥3-5å¹´çš„è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è¿˜æœ‰å“ªäº›æˆ‘å¯èƒ½å¿½ç•¥çš„å…³é”®ç‚¹ï¼Ÿ"
    ]
    
    creative_suggestions = [
        "å¦‚æœé¢„ç®—ç¿»å€ï¼Œæ–¹æ¡ˆä¼šæ€ä¹ˆå˜åŒ–ï¼Ÿ",
        "å…¶ä»–è¡Œä¸šæœ‰ä»€ä¹ˆå¯ä»¥å€Ÿé‰´çš„åˆ›æ–°åšæ³•ï¼Ÿ",
        "æœ‰æ²¡æœ‰æ›´å¤§èƒ†çš„æ›¿ä»£æ–¹æ¡ˆï¼Ÿ",
        "å¦‚æœä»é›¶å¼€å§‹è®¾è®¡ï¼Œä½ ä¼šæ€ä¹ˆåšï¼Ÿ"
    ]
    
    general_suggestions = [
        "èƒ½è¯¦ç»†å±•å¼€è¿™éƒ¨åˆ†å—ï¼Ÿ",
        "ä½ æ€ä¹ˆçœ‹è¿™ä¸ªæ–¹æ¡ˆçš„å¯è¡Œæ€§ï¼Ÿ",
        "è¿˜æœ‰ä»€ä¹ˆéœ€è¦æˆ‘ç‰¹åˆ«æ³¨æ„çš„ï¼Ÿ"
    ]
    
    # æ ¹æ®æ„å›¾é€‰æ‹©å»ºè®®
    if intent == "closed":
        suggestions = open_suggestions[:2] + creative_suggestions[:1]
    elif intent == "open_with_context":
        suggestions = closed_suggestions[:1] + creative_suggestions[:2]
    elif intent == "creative":
        suggestions = creative_suggestions[:2] + closed_suggestions[:1]
    else:
        suggestions = general_suggestions[:3]
    
    log_msg = f"ğŸ’¡ ç”Ÿæˆ {len(suggestions)} æ¡åç»­å»ºè®®"
    logger.info(log_msg)
    
    return {
        "suggestions": suggestions,
        "processing_log": [log_msg]
    }


# ============================================================
# æ„å»º Agent å›¾
# ============================================================

def build_followup_agent() -> StateGraph:
    """
    æ„å»ºè¿½é—® Agent çŠ¶æ€å›¾
    
    æµç¨‹ï¼šclassify_intent â†’ retrieve_context â†’ generate_answer â†’ generate_suggestions â†’ END
    """
    graph = StateGraph(FollowupAgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("classify_intent", classify_intent_node)
    graph.add_node("retrieve_context", retrieve_context_node)
    graph.add_node("generate_answer", generate_answer_node)
    graph.add_node("generate_suggestions", generate_suggestions_node)
    
    # è®¾ç½®å…¥å£
    graph.set_entry_point("classify_intent")
    
    # æ·»åŠ è¾¹ï¼ˆçº¿æ€§æµç¨‹ï¼‰
    graph.add_edge("classify_intent", "retrieve_context")
    graph.add_edge("retrieve_context", "generate_answer")
    graph.add_edge("generate_answer", "generate_suggestions")
    graph.add_edge("generate_suggestions", END)
    
    return graph.compile()


# ============================================================
# FollowupAgent å°è£…ç±»
# ============================================================

class FollowupAgent:
    """
    ğŸ”¥ v7.15: è¿½é—®æ™ºèƒ½ä½“ - åŸºäº LangGraph
    
    æ›¿ä»£åŸæœ‰çš„ ConversationAgentï¼ˆæœåŠ¡ç±»ï¼‰
    å‡çº§ä¸ºçœŸæ­£çš„ç‹¬ç«‹ Agent
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è¿½é—®æ™ºèƒ½ä½“"""
        self.graph = build_followup_agent()
        logger.info("ğŸš€ FollowupAgent (LangGraph) å·²åˆå§‹åŒ–")
    
    def answer_question(
        self,
        question: str,
        report_context: Dict[str, Any],
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        å›ç­”ç”¨æˆ·é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            report_context: æŠ¥å‘Šä¸Šä¸‹æ–‡ (final_report, agent_results, requirements)
            conversation_history: å¯¹è¯å†å²
        
        Returns:
            {
                "answer": str,
                "intent": str,
                "references": List[str],
                "suggestions": List[str],
                "processing_log": List[str]
            }
        """
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state: FollowupAgentState = {
            "question": question,
            "report_context": report_context or {},
            "conversation_history": conversation_history or [],
            "intent": "",
            "relevant_sections": [],
            "intent_prompt": "",
            "answer": "",
            "references": [],
            "suggestions": [],
            "processing_log": []
        }
        
        logger.info(f"ğŸ¤– FollowupAgent å¤„ç†é—®é¢˜: {question[:50]}...")
        
        # è¿è¡Œå›¾
        try:
            final_state = self.graph.invoke(initial_state)
            
            return {
                "answer": final_state.get("answer", ""),
                "intent": final_state.get("intent", "general"),
                "references": final_state.get("references", []),
                "suggestions": final_state.get("suggestions", []),
                "processing_log": final_state.get("processing_log", [])
            }
        except Exception as e:
            logger.error(f"âŒ FollowupAgent æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "answer": f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶é‡åˆ°é”™è¯¯: {str(e)}",
                "intent": "error",
                "references": [],
                "suggestions": ["è¯·å°è¯•é‡æ–°æé—®"],
                "processing_log": [f"âŒ æ‰§è¡Œå¤±è´¥: {e}"]
            }
    
    async def answer_question_async(
        self,
        question: str,
        report_context: Dict[str, Any],
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """å¼‚æ­¥ç‰ˆæœ¬"""
        import asyncio
        return await asyncio.to_thread(
            self.answer_question,
            question=question,
            report_context=report_context,
            conversation_history=conversation_history
        )


# ============================================================
# å‘åå…¼å®¹ï¼šä¿ç•™åŸ ConversationAgent æ¥å£
# ============================================================

class ConversationAgentCompat:
    """
    å‘åå…¼å®¹å±‚ï¼šä¿æŒåŸ ConversationAgent çš„è°ƒç”¨æ¥å£
    å†…éƒ¨ä½¿ç”¨ FollowupAgent (LangGraph)
    """
    
    def __init__(self):
        self.agent = FollowupAgent()
        logger.info("ConversationAgentCompat å·²åˆå§‹åŒ–ï¼ˆå†…éƒ¨ä½¿ç”¨ FollowupAgentï¼‰")
    
    def answer_question(
        self,
        question: str,
        context,  # ConversationContext
        conversation_history = None
    ) -> Dict[str, Any]:
        """ä¿æŒåŸæ¥å£"""
        # è½¬æ¢ context æ ¼å¼
        report_context = {
            "final_report": context.final_report if hasattr(context, 'final_report') else {},
            "agent_results": context.agent_results if hasattr(context, 'agent_results') else {},
            "requirements": context.requirements if hasattr(context, 'requirements') else {},
            "user_input": context.user_input if hasattr(context, 'user_input') else ""
        }
        
        # è½¬æ¢ conversation_history æ ¼å¼
        history_data = []
        if conversation_history:
            for turn in conversation_history:
                if hasattr(turn, 'dict'):
                    history_data.append(turn.dict())
                elif isinstance(turn, dict):
                    history_data.append(turn)
                else:
                    history_data.append({
                        "question": getattr(turn, 'question', ''),
                        "answer": getattr(turn, 'answer', ''),
                        "intent": getattr(turn, 'intent', 'general'),
                        "referenced_sections": getattr(turn, 'referenced_sections', []),
                        "timestamp": getattr(turn, 'timestamp', '')
                    })
        
        return self.agent.answer_question(
            question=question,
            report_context=report_context,
            conversation_history=history_data
        )
