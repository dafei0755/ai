"""
éœ€æ±‚åˆ†æå¸ˆæ™ºèƒ½ä½“

è´Ÿè´£ç†è§£å’Œç»“æ„åŒ–ç”¨æˆ·éœ€æ±‚ï¼Œä¸ºåç»­åˆ†ææä¾›åŸºç¡€
"""

import json
from typing import Dict, List, Optional, Any
import time

from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from langgraph.store.base import BaseStore
from loguru import logger

from .base import LLMAgent
from ..core.state import ProjectAnalysisState, AgentType
from ..core.types import AnalysisResult
from ..core.prompt_manager import PromptManager
from ..utils.jtbd_parser import transform_jtbd_to_natural_language


class RequirementsAnalystAgent(LLMAgent):
    """éœ€æ±‚åˆ†æå¸ˆæ™ºèƒ½ä½“"""
    
    def __init__(self, llm_model, config: Optional[Dict[str, Any]] = None):
        super().__init__(
            agent_type=AgentType.REQUIREMENTS_ANALYST,
            name="éœ€æ±‚åˆ†æå¸ˆ",
            description="ç†è§£å’Œç»“æ„åŒ–ç”¨æˆ·é¡¹ç›®éœ€æ±‚ï¼Œè¯†åˆ«å…³é”®è¦ç´ å’Œçº¦æŸæ¡ä»¶",
            llm_model=llm_model,
            config=config
        )

        # åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨
        self.prompt_manager = PromptManager()
    
    def validate_input(self, state: ProjectAnalysisState) -> bool:
        """éªŒè¯è¾“å…¥æ˜¯å¦æœ‰æ•ˆ"""
        user_input = state.get("user_input", "").strip()
        return len(user_input) > 10  # è‡³å°‘10ä¸ªå­—ç¬¦
    
    def get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯ - ä»å¤–éƒ¨é…ç½®åŠ è½½ v3.4 (ä¼˜åŒ–ç‰ˆæœ¬)"""
        # âœ… v3.4ä¼˜åŒ–: ä¼˜å…ˆåŠ è½½ç²¾ç®€ç‰ˆé…ç½®ï¼Œæå‡3-5å€å“åº”é€Ÿåº¦
        # å°è¯•åŠ è½½ç²¾ç®€ç‰ˆ (requirements_analyst_lite.yaml)
        prompt_config = self.prompt_manager.get_prompt("requirements_analyst_lite", return_full_config=True)
        
        # å¦‚æœç²¾ç®€ç‰ˆä¸å­˜åœ¨ï¼Œå›é€€åˆ°å®Œæ•´ç‰ˆ
        if not prompt_config:
            logger.info("[INFO] ç²¾ç®€ç‰ˆé…ç½®æœªæ‰¾åˆ°ï¼ŒåŠ è½½å®Œæ•´ç‰ˆ requirements_analyst.yaml")
            prompt_config = self.prompt_manager.get_prompt("requirements_analyst", return_full_config=True)

        # å¦‚æœé…ç½®ä¸å­˜åœ¨ï¼ŒæŠ›å‡ºé”™è¯¯ï¼ˆä¸å†ä½¿ç”¨ç¡¬ç¼–ç  fallbackï¼‰
        if not prompt_config:
            raise ValueError(
                "âŒ æœªæ‰¾åˆ°æç¤ºè¯é…ç½®: requirements_analyst æˆ– requirements_analyst_lite\n"
                "è¯·ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨: config/prompts/requirements_analyst_lite.yaml\n"
                "ç³»ç»Ÿæ— æ³•ä½¿ç”¨ç¡¬ç¼–ç æç¤ºè¯ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶ã€‚"
            )

        # è·å–ç³»ç»Ÿæç¤ºè¯
        system_prompt = prompt_config.get("system_prompt", "")

        if not system_prompt:
            raise ValueError(
                "âŒ é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘ system_prompt å­—æ®µ\n"
                "è¯·ç¡®ä¿é…ç½®æ–‡ä»¶åŒ…å«å®Œæ•´çš„ system_prompt å­—æ®µã€‚"
            )
        
        # âœ… v3.4ä¼˜åŒ–æ—¥å¿—
        prompt_length = len(system_prompt)
        estimated_tokens = prompt_length // 4
        logger.info(f"[v3.4 ä¼˜åŒ–] å·²åŠ è½½æç¤ºè¯: {prompt_length} å­—ç¬¦, çº¦ {estimated_tokens} tokens")

        return system_prompt

    def get_task_description(self, state: ProjectAnalysisState) -> str:
        """è·å–å…·ä½“ä»»åŠ¡æè¿° - v3.4ç‰ˆæœ¬ï¼ˆä¼˜å…ˆä½¿ç”¨ç²¾ç®€ç‰ˆé…ç½®ï¼‰"""
        user_input = state.get("user_input", "")

        # âœ… v3.4ä¼˜åŒ–: ä¼˜å…ˆä½¿ç”¨ç²¾ç®€ç‰ˆé…ç½®
        # ä½¿ç”¨ PromptManager çš„æ–°æ–¹æ³•è·å–ä»»åŠ¡æè¿°
        task_description = self.prompt_manager.get_task_description(
            agent_name="requirements_analyst_lite",
            user_input=user_input,
            include_datetime=True
        )
        
        # å¦‚æœç²¾ç®€ç‰ˆä¸å­˜åœ¨ï¼Œå›é€€åˆ°å®Œæ•´ç‰ˆ
        if not task_description:
            logger.info("[INFO] ç²¾ç®€ç‰ˆä»»åŠ¡æè¿°æœªæ‰¾åˆ°ï¼Œä½¿ç”¨å®Œæ•´ç‰ˆ")
            task_description = self.prompt_manager.get_task_description(
                agent_name="requirements_analyst",
                user_input=user_input,
                include_datetime=True
            )

        # å¦‚æœé…ç½®ä¸å­˜åœ¨ï¼ŒæŠ›å‡ºé”™è¯¯
        if not task_description:
            raise ValueError(
                "âŒ é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘ task_description_template å­—æ®µ\n"
                "è¯·ç¡®ä¿é…ç½®æ–‡ä»¶åŒ…å«å®Œæ•´çš„ task_description_template å­—æ®µã€‚"
            )

        return task_description
    
    def execute(
        self,
        state: ProjectAnalysisState,
        config: RunnableConfig,
        store: Optional[BaseStore] = None
    ) -> AnalysisResult:
        """æ‰§è¡Œéœ€æ±‚åˆ†æ"""
        start_time = time.time()
        
        try:
            logger.info(f"Starting requirements analysis for session {state.get('session_id')}")
            
            # éªŒè¯è¾“å…¥
            if not self.validate_input(state):
                raise ValueError("Invalid input: user input is too short or empty")
            
            # æ£€ç´¢ç”¨æˆ·å†å²åå¥½ï¼ˆå¦‚æœæœ‰storeï¼‰
            user_context = ""
            if store and config.get("configurable", {}).get("user_id"):
                user_context = self._retrieve_user_preferences(store, config)
            
            # å‡†å¤‡æ¶ˆæ¯
            messages = self.prepare_messages(state)
            
            # æ·»åŠ ç”¨æˆ·åå¥½ä¸Šä¸‹æ–‡
            if user_context:
                messages.append(HumanMessage(content=f"ç”¨æˆ·å†å²åå¥½ï¼š\n{user_context}"))
            
            # è°ƒç”¨LLM
            response = self.invoke_llm(messages)
            
            # è§£æç»“æ„åŒ–ç»“æœ
            structured_requirements = self._parse_requirements(response.content)

            # ğŸ†• v7.3: é—®å·ç”Ÿæˆå·²åˆ†ç¦»åˆ°ä¸“é—¨èŠ‚ç‚¹ï¼Œæ­¤å¤„ä¸å†å¤„ç†é—®å·
            # åŸå› ï¼šåªæœ‰å……åˆ†åˆ†ææ‰èƒ½æŒ‡å¯¼é—®å·çš„ç”Ÿæˆ
            # æ–°æ¶æ„ï¼šéœ€æ±‚åˆ†æï¼ˆä¸“æ³¨åˆ†æï¼‰â†’ calibration_questionnaireèŠ‚ç‚¹ï¼ˆåŠ¨æ€ç”Ÿæˆé—®å·ï¼‰

            # å‘åå…¼å®¹ï¼šå¦‚æœLLMä»ç„¶è¿”å›äº†calibration_questionnaireå­—æ®µï¼ˆæ—§æ¨¡å‹æˆ–ç¼“å­˜ï¼‰ï¼Œä¿ç•™ä½†æ ‡è®°ä¸ºå¾…æ›¿æ¢
            if "calibration_questionnaire" in structured_requirements:
                logger.info("â„¹ï¸ æ£€æµ‹åˆ°LLMè¿”å›äº†calibration_questionnaireï¼ˆæ—§è¡Œä¸ºï¼‰ï¼Œå°†ä¿ç•™ä½†ç”±ä¸“é—¨èŠ‚ç‚¹é‡æ–°ç”Ÿæˆ")
                structured_requirements["calibration_questionnaire"]["source"] = "llm_legacy"
                structured_requirements["calibration_questionnaire"]["note"] = "æ­¤é—®å·å°†è¢«ä¸“é—¨èŠ‚ç‚¹é‡æ–°ç”Ÿæˆ"
            
            # ä¿å­˜ç”¨æˆ·åå¥½ï¼ˆå¦‚æœæœ‰æ–°çš„åå¥½ä¿¡æ¯ï¼‰
            if store and config.get("configurable", {}).get("user_id"):
                self._save_user_preferences(store, config, structured_requirements)
            
            # åˆ›å»ºåˆ†æç»“æœ
            result = self.create_analysis_result(
                content=response.content,
                structured_data=structured_requirements,
                confidence=self._calculate_confidence(structured_requirements),
                sources=["user_input", "llm_analysis"]
            )
            
            end_time = time.time()
            self._track_execution_time(start_time, end_time)
            
            logger.info("Requirements analysis completed successfully")
            return result
            
        except Exception as e:
            error = self.handle_error(e, "requirements analysis")
            raise error
    
    def _parse_requirements(self, llm_response: str) -> Dict[str, Any]:
        """è§£æLLMå“åº”ä¸­çš„ç»“æ„åŒ–éœ€æ±‚ - æ”¯æŒv1.0æ ¼å¼ - v3.6ä¿®å¤JSONè§£æ"""
        try:
            # ğŸ”¥ v3.6ä¼˜åŒ–ï¼šä½¿ç”¨å¤šç§æ–¹æ³•æå–JSONï¼Œé˜²æ­¢å†…å®¹æˆªæ–­
            json_str = None

            # æ–¹æ³•1: å°è¯•æå–JSONä»£ç å—ï¼ˆæ”¯æŒmarkdown code fenceï¼‰
            import re
            json_pattern = r'```json\s*\n(.*?)\n```'
            match = re.search(json_pattern, llm_response, re.DOTALL)
            if match:
                json_str = match.group(1)
                logger.info("[JSONè§£æ] âœ… ä½¿ç”¨code fenceæå–")

            # æ–¹æ³•2: å°è¯•æå– ```{ ... }``` æ ¼å¼ï¼ˆæ— jsonæ ‡è®°ï¼‰
            if not json_str:
                code_block_pattern = r'```\s*\n(\{.*?\})\n```'
                match = re.search(code_block_pattern, llm_response, re.DOTALL)
                if match:
                    json_str = match.group(1)
                    logger.info("[JSONè§£æ] âœ… ä½¿ç”¨æ— æ ‡è®°ä»£ç å—æå–")

            # æ–¹æ³•3: ä½¿ç”¨æ ˆåŒ¹é…æ³•æ‰¾åˆ°å®Œæ•´JSONï¼ˆå¹³è¡¡å¤§æ‹¬å·ï¼‰
            if not json_str:
                json_str = self._extract_balanced_json(llm_response)
                if json_str:
                    logger.info("[JSONè§£æ] âœ… ä½¿ç”¨å¹³è¡¡æ‹¬å·æå–")

            # æ–¹æ³•4: ğŸ†• å°è¯•æŸ¥æ‰¾æœ€å¤§çš„JSONå¯¹è±¡ï¼ˆä»ç¬¬ä¸€ä¸ª{åˆ°æœ€åä¸€ä¸ª}ï¼‰
            if not json_str:
                first_brace = llm_response.find('{')
                last_brace = llm_response.rfind('}')
                if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                    json_candidate = llm_response[first_brace:last_brace+1]
                    # å°è¯•è§£æéªŒè¯
                    try:
                        json.loads(json_candidate)
                        json_str = json_candidate
                        logger.info("[JSONè§£æ] âœ… ä½¿ç”¨é¦–å°¾æ‹¬å·æå–å¹¶éªŒè¯æˆåŠŸ")
                    except:
                        logger.warning("[JSONè§£æ] âš ï¸ é¦–å°¾æ‹¬å·æå–éªŒè¯å¤±è´¥")

            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
            if not json_str:
                logger.warning("[JSONè§£æ] âš ï¸ æ‰€æœ‰æå–æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨fallback")
                logger.debug(f"[JSONè§£æ] LLMå“åº”å‰200å­—ç¬¦: {llm_response[:200]}")
                logger.debug(f"[JSONè§£æ] LLMå“åº”å200å­—ç¬¦: {llm_response[-200:]}")
                # ğŸ”¥ v3.6è°ƒè¯•ï¼šä¿å­˜å®Œæ•´å“åº”ä»¥ä¾¿åˆ†æ
                try:
                    import os
                    from datetime import datetime
                    debug_dir = os.path.join(os.path.dirname(__file__), "..", "..", "data", "debug")
                    os.makedirs(debug_dir, exist_ok=True)
                    debug_file = os.path.join(debug_dir, f"llm_response_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
                    with open(debug_file, 'w', encoding='utf-8') as f:
                        f.write(llm_response)
                    logger.info(f"[JSONè§£æ] å®Œæ•´LLMå“åº”å·²ä¿å­˜åˆ°: {debug_file}")
                except Exception as save_error:
                    logger.warning(f"[JSONè§£æ] æ— æ³•ä¿å­˜è°ƒè¯•æ–‡ä»¶: {save_error}")

            if json_str:
                structured_data = json.loads(json_str)
                logger.info(f"[JSONè§£æ] âœ… æˆåŠŸè§£æï¼ŒåŒ…å« {len(structured_data)} ä¸ªå­—æ®µ")
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œåˆ›å»ºåŸºç¡€ç»“æ„
                structured_data = self._create_fallback_structure(llm_response)

            # éªŒè¯æ–°æ ¼å¼çš„å¿…éœ€å­—æ®µ
            new_format_fields = [
                "project_task", "character_narrative", "space_constraints",
                "inspiration_references", "experience_behavior", "core_tension"
            ]

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°æ ¼å¼
            is_new_format = any(field in structured_data for field in new_format_fields)

            if is_new_format:
                # æ–°æ ¼å¼ï¼ˆv2.0ï¼‰ï¼šéªŒè¯å¹¶å¡«å……ç¼ºå¤±å­—æ®µ
                for field in new_format_fields:
                    if field not in structured_data:
                        structured_data[field] = "å¾…è¿›ä¸€æ­¥åˆ†æ"

                # ğŸ†• v7.3: é—®å·ç”Ÿæˆå·²åˆ†ç¦»ï¼Œæ­¤å¤„ä¸å†éªŒè¯å’Œä¿®æ­£é—®å·
                # åŸå› ï¼šé—®å·åº”åœ¨æ·±åº¦åˆ†æå®Œæˆåï¼Œç”±ä¸“é—¨èŠ‚ç‚¹åŸºäºåˆ†æç»“æœåŠ¨æ€ç”Ÿæˆ
                # æ—§é€»è¾‘ï¼ˆ_validate_and_fix_questionnaireï¼‰å·²å¼ƒç”¨ï¼Œé—®å·ç”Ÿæˆç§»è‡³ calibration_questionnaire.py

                # å‘åå…¼å®¹ï¼šå¦‚æœå­˜åœ¨æ—§é—®å·å­—æ®µï¼Œä¿ç•™ä½†æ ‡è®°
                if "calibration_questionnaire" in structured_data:
                    logger.info("â„¹ï¸ æ£€æµ‹åˆ°æ—§é—®å·å­—æ®µï¼Œå°†ç”±ä¸“é—¨èŠ‚ç‚¹é‡æ–°ç”Ÿæˆ")
                    structured_data["calibration_questionnaire"]["source"] = "to_be_regenerated"

                # ğŸ†• v7.2: æ„å»ºå®Œæ•´çš„6å­—æ®µæ•°æ®ç»“æ„ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºï¼‰
                # ä»æ—§å­—æ®µæ˜ å°„åˆ°æ–°å­—æ®µï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®æ˜¾ç¤ºæ‰€æœ‰å†…å®¹
                project_task = structured_data.get("project_task", "")
                character_narrative = structured_data.get("character_narrative", "")
                physical_context = structured_data.get("physical_context", "")
                resource_constraints = structured_data.get("resource_constraints", "")
                regulatory_requirements = structured_data.get("regulatory_requirements", "")
                
                # 1. project_overview: é¡¹ç›®æ¦‚è§ˆï¼ˆç›´æ¥ä½¿ç”¨ project_taskï¼‰
                structured_data["project_overview"] = project_task
                
                # 2. core_objectives: æ ¸å¿ƒç›®æ ‡ï¼ˆä» project_task æå–ï¼Œæˆ–ä½¿ç”¨ design_goalsï¼‰
                design_goals = structured_data.get("design_goals", "")
                if design_goals and len(design_goals) > 20:
                    # å¦‚æœæœ‰ design_goalsï¼ŒæŒ‰å¥å·åˆ†å‰²ä¸ºåˆ—è¡¨
                    goals_list = [g.strip() for g in design_goals.split('ã€‚') if g.strip() and len(g.strip()) > 5]
                    structured_data["core_objectives"] = goals_list[:5]  # æœ€å¤š5ä¸ªç›®æ ‡
                elif project_task and len(project_task) > 50:
                    # ä» project_task æå–æ ¸å¿ƒç›®æ ‡
                    core_obj = project_task[:80].strip()
                    if 'ï¼Œ' in core_obj or 'ã€‚' in core_obj:
                        core_obj = core_obj.split('ï¼Œ')[0].split('ã€‚')[0]
                    structured_data["core_objectives"] = [core_obj]
                else:
                    structured_data["core_objectives"] = [project_task] if project_task else []
                
                # 3. project_tasks: é¡¹ç›®ä»»åŠ¡ï¼ˆä» project_task æå–å…³é”®è¯ï¼Œæˆ–ä½¿ç”¨ functional_requirementsï¼‰
                functional_req = structured_data.get("functional_requirements", "")
                if functional_req and len(functional_req) > 20:
                    # æŒ‰å¥å·/åˆ†å·åˆ†å‰²åŠŸèƒ½éœ€æ±‚ä¸ºä»»åŠ¡åˆ—è¡¨
                    tasks_list = [t.strip() for t in functional_req.replace('ï¼›', 'ã€‚').split('ã€‚') if t.strip() and len(t.strip()) > 5]
                    structured_data["project_tasks"] = tasks_list[:8]  # æœ€å¤š8ä¸ªä»»åŠ¡
                else:
                    # é»˜è®¤ä» project_task æå–ä¸€ä¸ªä»»åŠ¡
                    structured_data["project_tasks"] = [project_task] if project_task else []
                
                # 4. narrative_characters: å™äº‹è§’è‰²ï¼ˆä» character_narrative åˆ†æ®µæå–ï¼‰
                if character_narrative and len(character_narrative) > 20:
                    # æŒ‰ "â†’" æˆ– "ã€" åˆ†å‰²äººç‰©å™äº‹
                    if 'â†’' in character_narrative:
                        char_list = [c.strip() for c in character_narrative.split('â†’') if c.strip()]
                        structured_data["narrative_characters"] = char_list[:6]  # æœ€å¤š6ä¸ªé˜¶æ®µ
                    elif 'ã€' in character_narrative:
                        char_list = [c.strip() for c in character_narrative.split('ã€') if c.strip()]
                        structured_data["narrative_characters"] = char_list[:6]
                    else:
                        # æ•´æ®µä½œä¸ºä¸€ä¸ªè§’è‰²æè¿°
                        structured_data["narrative_characters"] = [character_narrative]
                else:
                    structured_data["narrative_characters"] = [character_narrative] if character_narrative else []
                
                # 5. physical_contexts: ç‰©ç†ç¯å¢ƒï¼ˆä» physical_context åˆ†å¥æå–ï¼‰
                if physical_context and len(physical_context) > 20:
                    # æŒ‰é€—å·/å¥å·åˆ†å‰²ç‰©ç†ç¯å¢ƒ
                    context_list = [c.strip() for c in physical_context.replace('ï¼Œ', 'ã€‚').split('ã€‚') if c.strip() and len(c.strip()) > 5]
                    structured_data["physical_contexts"] = context_list[:6]  # æœ€å¤š6ä¸ªç¯å¢ƒ
                else:
                    structured_data["physical_contexts"] = [physical_context] if physical_context else []
                
                # 6. constraints_opportunities: çº¦æŸä¸æœºé‡ï¼ˆç»“æ„åŒ–å¯¹è±¡ï¼‰
                space_constraints = structured_data.get("space_constraints", "")
                core_tension = structured_data.get("core_tension", "")
                design_challenge = structured_data.get("design_challenge", "")
                inspiration_refs = structured_data.get("inspiration_references", "")
                
                # çº¦æŸç±»å­—æ®µï¼ˆæŒ‰é‡è¦æ€§åˆ†å¥ï¼‰
                constraints_parts = []
                if resource_constraints:
                    constraints_parts.append(f"èµ„æºçº¦æŸï¼š{resource_constraints}")
                if regulatory_requirements:
                    constraints_parts.append(f"è§„èŒƒè¦æ±‚ï¼š{regulatory_requirements}")
                if space_constraints:
                    constraints_parts.append(f"ç©ºé—´çº¦æŸï¼š{space_constraints}")
                if core_tension:
                    constraints_parts.append(f"æ ¸å¿ƒçŸ›ç›¾ï¼š{core_tension}")
                
                # æœºé‡ç±»å­—æ®µ
                opportunities_parts = []
                if design_challenge:
                    opportunities_parts.append(f"è®¾è®¡æŒ‘æˆ˜ï¼š{design_challenge}")
                if inspiration_refs:
                    opportunities_parts.append(f"çµæ„Ÿå‚è€ƒï¼š{inspiration_refs}")
                
                structured_data["constraints_opportunities"] = {
                    "constraints": constraints_parts if constraints_parts else ["æš‚æ— æ˜ç¡®çº¦æŸ"],
                    "opportunities": opportunities_parts if opportunities_parts else ["å¾…å‘æ˜æœºé‡"]
                }
                
                # å…¼å®¹æ—§æ ¼å¼ï¼šä¿ç•™æ—§å­—æ®µï¼ˆç”¨äºå…¶ä»–å¯èƒ½ä¾èµ–æ—§å­—æ®µçš„æ¨¡å—ï¼‰
                structured_data["target_users"] = character_narrative[:100].strip() if character_narrative else ""
                physical = physical_context
                resource = resource_constraints
                regulatory = regulatory_requirements
                combined_constraints = f"{physical} {resource} {regulatory}".strip()
                structured_data["constraints"] = {"description": combined_constraints}
            else:
                # æ—§æ ¼å¼ï¼šéªŒè¯æ—§å­—æ®µ
                old_format_fields = [
                    "project_overview", "core_objectives", "functional_requirements",
                    "target_users", "constraints"
                ]

                for field in old_format_fields:
                    if field not in structured_data:
                        structured_data[field] = "å¾…è¿›ä¸€æ­¥åˆ†æ"

            self._normalize_jtbd_fields(structured_data)
            
            # ğŸ†• æ¨æ–­é¡¹ç›®ç±»å‹ï¼ˆç”¨äºæœ¬ä½“è®ºæ³¨å…¥ï¼‰
            project_type = self._infer_project_type(structured_data)
            structured_data["project_type"] = project_type
            
            return structured_data

        except json.JSONDecodeError as e:
            logger.error(f"[JSONè§£æ] âŒ JSONDecodeError: {str(e)}")
            logger.error(f"[JSONè§£æ] é—®é¢˜ä½ç½®: line {e.lineno}, col {e.colno}")
            if json_str:
                # æ˜¾ç¤ºé”™è¯¯å‰åçš„æ–‡æœ¬ç‰‡æ®µ
                error_pos = getattr(e, 'pos', 0)
                start_pos = max(0, error_pos - 50)
                end_pos = min(len(json_str), error_pos + 50)
                logger.error(f"[JSONè§£æ] å‰åæ–‡æœ¬: ...{json_str[start_pos:end_pos]}...")
            logger.warning("[JSONè§£æ] ä½¿ç”¨fallbackç»“æ„")
            return self._create_fallback_structure(llm_response)
        except Exception as e:
            logger.error(f"[JSONè§£æ] âŒ æœªçŸ¥é”™è¯¯: {str(e)}")
            logger.warning("[JSONè§£æ] ä½¿ç”¨fallbackç»“æ„")
            return self._create_fallback_structure(llm_response)

    def _extract_balanced_json(self, text: str) -> str | None:
        """
        ä½¿ç”¨æ ˆåŒ¹é…æ³•æå–å®Œæ•´çš„JSONå¯¹è±¡

        ğŸ”¥ v3.6æ–°å¢ï¼šé˜²æ­¢ç®€å•çš„find('{')å’Œrfind('}')åœ¨é‡åˆ°åµŒå¥—JSONæˆ–å­—ç¬¦ä¸²ä¸­çš„å¤§æ‹¬å·æ—¶å¤±è´¥

        Args:
            text: åŒ…å«JSONçš„æ–‡æœ¬

        Returns:
            å®Œæ•´çš„JSONå­—ç¬¦ä¸²ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        start_idx = text.find('{')
        if start_idx == -1:
            return None

        stack = []
        in_string = False
        escape = False

        for i in range(start_idx, len(text)):
            ch = text[i]

            # å¤„ç†è½¬ä¹‰å­—ç¬¦
            if escape:
                escape = False
                continue
            if ch == '\\':
                escape = True
                continue

            # å¤„ç†å­—ç¬¦ä¸²çŠ¶æ€ï¼ˆåªåœ¨åŒå¼•å·æ—¶åˆ‡æ¢ï¼‰
            if ch == '"':
                in_string = not in_string
                continue

            # åªåœ¨éå­—ç¬¦ä¸²çŠ¶æ€ä¸‹å¤„ç†æ‹¬å·
            if not in_string:
                if ch == '{':
                    stack.append(ch)
                elif ch == '}':
                    if stack:
                        stack.pop()
                    if not stack:  # æ ˆç©ºï¼Œæ‰¾åˆ°å®Œæ•´JSON
                        json_candidate = text[start_idx:i+1]
                        logger.info(f"[JSONè§£æ] å¹³è¡¡æ‹¬å·æå–æˆåŠŸï¼Œé•¿åº¦: {len(json_candidate)} å­—ç¬¦")
                        return json_candidate

        logger.warning("[JSONè§£æ] æœªæ‰¾åˆ°å¹³è¡¡çš„JSONç»“æ„")
        return None

    def _create_fallback_structure(self, content: str) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨çš„ç»“æ„åŒ–æ•°æ® - æ”¯æŒæ–°æ ¼å¼"""
        return {
            # æ–°æ ¼å¼å­—æ®µ
            "project_task": content[:500] + "..." if len(content) > 500 else content,
            "character_narrative": "å¾…è¿›ä¸€æ­¥åˆ†ææ ¸å¿ƒäººç‰©ç‰¹å¾",
            "physical_context": "å¾…æ˜ç¡®ç‰©ç†ç¯å¢ƒæ¡ä»¶",
            "resource_constraints": "å¾…æ˜ç¡®èµ„æºé™åˆ¶",
            "regulatory_requirements": "å¾…æ˜ç¡®è§„èŒƒè¦æ±‚",
            "inspiration_references": "ã€å¾…åç»­ä¸“å®¶è¡¥é½ã€‘V4è®¾è®¡ç ”ç©¶å‘˜å°†æä¾›å›½é™…æ¡ˆä¾‹å‚è€ƒï¼ŒV5åœºæ™¯ä¸“å®¶å°†ç»“åˆè¡Œä¸šè¶‹åŠ¿è¡¥å……çµæ„Ÿæ¥æº",
            "experience_behavior": "ã€å¾…åç»­ä¸“å®¶è¡¥é½ã€‘V3å™äº‹ä¸“å®¶å°†æ„å»ºå®Œæ•´ç”¨æˆ·æ—…ç¨‹ï¼ŒV5åœºæ™¯ä¸“å®¶å°†ç»†åŒ–å…¸å‹ä½¿ç”¨åœºæ™¯",
            "design_challenge": "å¾…è¯†åˆ«è®¾è®¡æŒ‘æˆ˜",
            "calibration_questionnaire": {
                "introduction": "ä»¥ä¸‹é—®é¢˜æ—¨åœ¨ç²¾å‡†æ•æ‰æ‚¨åœ¨æˆ˜æœ¯æ‰§è¡Œå’Œç¾å­¦è¡¨è¾¾å±‚é¢çš„ä¸ªäººåå¥½",
                "questions": []
            },
            # å…¼å®¹æ—§æ ¼å¼å­—æ®µ
            "project_overview": content[:500] + "..." if len(content) > 500 else content,
            "core_objectives": ["åŸºäºç”¨æˆ·æè¿°çš„é¡¹ç›®ç›®æ ‡"],
            "functional_requirements": ["å¾…è¯¦ç»†åˆ†æ"],
            "non_functional_requirements": {"performance": "å¾…å®šä¹‰", "security": "å¾…å®šä¹‰"},
            "target_users": "å¾…è¯†åˆ«",
            "use_cases": ["ä¸»è¦ä½¿ç”¨åœºæ™¯å¾…åˆ†æ"],
            "constraints": {"budget": "æœªæ˜ç¡®", "timeline": "æœªæ˜ç¡®", "technology": "æœªæ˜ç¡®"},
            "assumptions": ["åŸºäºå½“å‰ä¿¡æ¯çš„å‡è®¾"],
            "risks": ["å¾…è¯†åˆ«æ½œåœ¨é£é™©"],
            "success_criteria": ["å¾…å®šä¹‰æˆåŠŸæ ‡å‡†"],
            "raw_analysis": content
        }

    def _normalize_jtbd_fields(self, structured_data: Dict[str, Any]) -> None:
        """å°† JTBD ç›¸å…³å­—æ®µè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€ï¼Œé¿å…åœ¨ UI ä¸­å‡ºç°å…¬å¼æœ¯è¯­"""
        if not structured_data:
            return

        for field in ["project_task", "project_overview"]:
            value = structured_data.get(field)
            if isinstance(value, str):
                structured_data[field] = transform_jtbd_to_natural_language(value)

        core_objectives = structured_data.get("core_objectives")
        if isinstance(core_objectives, list):
            structured_data["core_objectives"] = [
                transform_jtbd_to_natural_language(obj) if isinstance(obj, str) else obj
                for obj in core_objectives
            ]

    def _validate_and_fix_questionnaire(self, structured_data: Dict[str, Any]) -> None:
        """
        ğŸš« v7.3 å·²åºŸå¼ƒï¼šæ­¤æ–¹æ³•ä¸å†ä½¿ç”¨

        åŸå› ï¼šé—®å·ç”Ÿæˆå·²åˆ†ç¦»åˆ°ä¸“é—¨èŠ‚ç‚¹
        - æ—§æ¶æ„ï¼šéœ€æ±‚åˆ†æå¸ˆåœ¨å•æ¬¡LLMè°ƒç”¨ä¸­åŒæ—¶ç”Ÿæˆåˆ†æç»“æœå’Œé—®å·ï¼Œç„¶åéªŒè¯ä¿®æ­£é—®å·
        - æ–°æ¶æ„ï¼šéœ€æ±‚åˆ†æå¸ˆä¸“æ³¨äºæ·±åº¦åˆ†æï¼Œé—®å·ç”± calibration_questionnaire.py èŠ‚ç‚¹åŸºäºåˆ†æç»“æœåŠ¨æ€ç”Ÿæˆ

        è¿ç§»è¯´æ˜ï¼š
        - é—®å·ç”Ÿæˆé€»è¾‘å·²è¿ç§»è‡³ intelligent_project_analyzer/interaction/questionnaire/
        - åŒ…å«å¤šä¸ªä¸“é—¨ç”Ÿæˆå™¨ï¼šFallbackQuestionGenerator, PhilosophyQuestionGenerator ç­‰

        å‘åå…¼å®¹ï¼šä¿ç•™æ­¤æ–¹æ³•å­˜æ ¹ï¼Œé¿å…æ—§ä»£ç è°ƒç”¨æ—¶æŠ¥é”™
        """
        logger.warning("[DEPRECATED] _validate_and_fix_questionnaire å·²åºŸå¼ƒï¼Œé—®å·ç”Ÿæˆå·²ç§»è‡³ä¸“é—¨èŠ‚ç‚¹")
        return  # ç©ºå®ç°ï¼Œç›´æ¥è¿”å›

    def _validate_and_fix_questionnaire_legacy(self, structured_data: Dict[str, Any]) -> None:
        """
        [å·²åºŸå¼ƒ] æ—§ç‰ˆé—®å·éªŒè¯é€»è¾‘ - ä»…ä¿ç•™ä½œä¸ºå‚è€ƒ
        1. å¿…é¡»ç”Ÿæˆ 7-10ä¸ªé—®é¢˜ï¼ˆç¦æ­¢åªç”Ÿæˆ2-3ä¸ªï¼‰
        2. é¢˜å‹é¡ºåºï¼šå•é€‰é¢˜(2-3ä¸ª) â†’ å¤šé€‰é¢˜(2-3ä¸ª) â†’ å¼€æ”¾é¢˜(2ä¸ª)
        3. ä»ç”¨æˆ·è¾“å…¥ä¸­æ™ºèƒ½ç”Ÿæˆé—®é¢˜ï¼Œè€Œä¸æ˜¯ä½¿ç”¨é€šç”¨æ¨¡æ¿
        """
        questionnaire = structured_data.get("calibration_questionnaire", {})
        questions = questionnaire.get("questions", [])

        # ç»Ÿè®¡å„ç±»é¢˜å‹æ•°é‡
        single_choice_count = sum(1 for q in questions if q.get("type") == "single_choice")
        multiple_choice_count = sum(1 for q in questions if q.get("type") == "multiple_choice")
        open_ended_count = sum(1 for q in questions if q.get("type") == "open_ended")
        total_count = len(questions)

        logger.info(f"[é—®å·éªŒè¯] å½“å‰é—®å·: æ€»æ•°={total_count}, å•é€‰={single_choice_count}, å¤šé€‰={multiple_choice_count}, å¼€æ”¾={open_ended_count}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®æ­£
        needs_fix = (
            total_count < 7 or  # å°‘äº7ä¸ªé—®é¢˜
            single_choice_count < 2 or  # å•é€‰é¢˜å°‘äº2ä¸ª
            multiple_choice_count < 2 or  # å¤šé€‰é¢˜å°‘äº2ä¸ª
            open_ended_count < 2  # å¼€æ”¾é¢˜å°‘äº2ä¸ª
        )

        if not needs_fix:
            logger.info("[é—®å·éªŒè¯] âœ… é—®å·ç»“æ„ç¬¦åˆè¦æ±‚")
            return

        logger.warning(f"[é—®å·éªŒè¯] âŒ é—®å·ä¸ç¬¦åˆè¦æ±‚ï¼Œå¼€å§‹æ™ºèƒ½è¡¥é½...")

        # ğŸ”¥ æ™ºèƒ½è¡¥é½ï¼šä»ç”¨æˆ·è¾“å…¥å’Œå·²åˆ†æçš„ç»“æ„åŒ–æ•°æ®ä¸­æå–å…³é”®ä¿¡æ¯
        project_task = structured_data.get("project_task", "")
        character_narrative = structured_data.get("character_narrative", "")
        design_challenge = structured_data.get("design_challenge", "")
        physical_context = structured_data.get("physical_context", "")
        resource_constraints = structured_data.get("resource_constraints", "")

        # æå–æ ¸å¿ƒçŸ›ç›¾ï¼ˆä»design_challengeä¸­ï¼‰
        tension_a = "åŠŸèƒ½æ€§éœ€æ±‚"
        tension_b = "æƒ…æ„ŸåŒ–éœ€æ±‚"

        # ğŸ” å°è¯•å¤šç§æ­£åˆ™æ¨¡å¼åŒ¹é…æ ¸å¿ƒçŸ›ç›¾
        import re

        # æ¨¡å¼1: "A"...ä¸..."B" æ ¼å¼ï¼ˆä¸­æ–‡å¼•å·ï¼‰
        match = re.search(r'"([^"]{2,30?})"[^"]{0,50?}ä¸[^"]{0,50?}"([^"]{2,30?})"', design_challenge)
        if match:
            tension_a = match.group(1).strip()
            tension_b = match.group(2).strip()
            logger.info(f"[çŸ›ç›¾æå–] ä½¿ç”¨æ¨¡å¼1: \"{tension_a}\" vs \"{tension_b}\"")
        else:
            # æ¨¡å¼2: A vs B æˆ– Aä¸å…¶å¯¹B æ ¼å¼
            match = re.search(r'(.{5,30}?)[çš„éœ€æ±‚]*(?:vs|ä¸å…¶å¯¹)(.{5,30}?)[çš„éœ€æ±‚]*', design_challenge)
            if match:
                tension_a = match.group(1).strip()
                tension_b = match.group(2).strip()
                logger.info(f"[çŸ›ç›¾æå–] ä½¿ç”¨æ¨¡å¼2: {tension_a} vs {tension_b}")

        # æå–é¡¹ç›®ç±»å‹å…³é”®è¯
        project_type = structured_data.get("project_type", "personal_residential")
        is_residential = "residential" in project_type
        is_commercial = "commercial" in project_type

        # åˆ†ç¦»ç°æœ‰é—®é¢˜
        existing_single = [q for q in questions if q.get("type") == "single_choice"]
        existing_multiple = [q for q in questions if q.get("type") == "multiple_choice"]
        existing_open = [q for q in questions if q.get("type") == "open_ended"]

        # ğŸ¯ è¡¥å……å•é€‰é¢˜ï¼ˆç¡®ä¿è‡³å°‘2ä¸ªï¼‰- ä»æ ¸å¿ƒçŸ›ç›¾ç”Ÿæˆï¼ˆæ¦‚å¿µé˜¶æ®µå‹å¥½ç‰ˆï¼‰
        while len(existing_single) < 2:
            template_idx = len(existing_single)
            if template_idx == 0 and tension_a and tension_b and tension_a != "åŠŸèƒ½æ€§éœ€æ±‚" and tension_b != "æƒ…æ„ŸåŒ–éœ€æ±‚":
                # å¦‚æœæˆåŠŸæå–äº†å…·ä½“çš„æ ¸å¿ƒçŸ›ç›¾ï¼ˆéé»˜è®¤å€¼ï¼‰ï¼Œä½¿ç”¨å…·ä½“é—®é¢˜
                existing_single.append({
                    "question": f"å½“{tension_a}ä¸{tension_b}äº§ç”Ÿå†²çªæ—¶ï¼Œæ‚¨æ›´å€¾å‘äºï¼Ÿ(å•é€‰)",
                    "context": f"è¿™æ˜¯æœ¬é¡¹ç›®æœ€æ ¸å¿ƒçš„æˆ˜ç•¥é€‰æ‹©ï¼Œå°†å†³å®šè®¾è®¡çš„æ ¹æœ¬æ–¹å‘ã€‚",
                    "type": "single_choice",
                    "options": [
                        f"ä¼˜å…ˆä¿è¯{tension_a}ï¼Œå¯ä»¥åœ¨{tension_b}ä¸Šåšå‡ºå¦¥å",
                        f"ä¼˜å…ˆä¿è¯{tension_b}ï¼Œ{tension_a}å¯ä»¥é€šè¿‡å…¶ä»–æ–¹å¼è¡¥å¿",
                        f"å¯»æ±‚å¹³è¡¡ç‚¹ï¼Œé€šè¿‡åˆ›æ–°è®¾è®¡åŒæ—¶æ»¡è¶³ä¸¤è€…"
                    ]
                })
            elif template_idx == 0:
                # ç¬¬ä¸€ä¸ªå…œåº•ï¼šé€‚åˆæ¦‚å¿µé˜¶æ®µçš„å¼€æ”¾æ€§é—®é¢˜
                existing_single.append({
                    "question": "æ‚¨å¸Œæœ›è¿™ä¸ªç©ºé—´é¦–å…ˆç»™äººä»€ä¹ˆæ ·çš„æ„Ÿè§‰ï¼Ÿ(å•é€‰)",
                    "context": "å¸®åŠ©æˆ‘ä»¬ç¡®å®šè®¾è®¡çš„æ ¸å¿ƒæƒ…æ„ŸåŸºè°ƒï¼Œè¿™å°†æŒ‡å¯¼æ‰€æœ‰åç»­å†³ç­–ã€‚",
                    "type": "single_choice",
                    "options": [
                        "æ¸©æš–èˆ’é€‚ï¼šåƒå®¶ä¸€æ ·æ”¾æ¾è‡ªåœ¨",
                        "ç®€æ´é«˜æ•ˆï¼šä¸“æ³¨äºåŠŸèƒ½å’Œæ•ˆç‡",
                        "ç‹¬ç‰¹ä¸ªæ€§ï¼šè¡¨è¾¾è‡ªæˆ‘å’Œå“å‘³",
                        "å¹³è¡¡åŒ…å®¹ï¼šå…¼é¡¾å¤šç§éœ€æ±‚å’Œåœºæ™¯"
                    ]
                })
            elif template_idx == 1 and resource_constraints and len(resource_constraints) > 10:
                # å¦‚æœæœ‰æ˜ç¡®çš„èµ„æºçº¦æŸï¼Œä½¿ç”¨å…·ä½“é—®é¢˜
                existing_single.append({
                    "question": f"é¢å¯¹{resource_constraints}çš„é™åˆ¶ï¼Œæ‚¨çš„å–èˆç­–ç•¥æ˜¯ï¼Ÿ(å•é€‰)",
                    "context": "å¸®åŠ©æˆ‘ä»¬åœ¨èµ„æºæœ‰é™æ—¶åšå‡ºæ˜æ™ºçš„ä¼˜å…ˆçº§å†³ç­–ã€‚",
                    "type": "single_choice",
                    "options": [
                        "é›†ä¸­èµ„æºæ‰“é€ æ ¸å¿ƒä½“éªŒåŒºï¼Œå…¶ä»–åŒºåŸŸä»ç®€",
                        "å¹³å‡åˆ†é…ï¼Œç¡®ä¿æ•´ä½“åè°ƒç»Ÿä¸€",
                        "å…ˆæ»¡è¶³åŸºæœ¬åŠŸèƒ½ï¼Œé¢„ç•™åæœŸå‡çº§ç©ºé—´"
                    ]
                })
            else:
                # ç¬¬äºŒä¸ªå…œåº•ï¼šå…³äºè®¾è®¡ä¼˜å…ˆçº§çš„æ¢ç´¢æ€§é—®é¢˜
                existing_single.append({
                    "question": "åœ¨è®¾è®¡å†³ç­–ä¸­ï¼Œæ‚¨è®¤ä¸ºä»€ä¹ˆæœ€ä¸èƒ½å¦¥åï¼Ÿ(å•é€‰)",
                    "context": "è¯†åˆ«æ‚¨çš„æ ¸å¿ƒä»·å€¼è§‚ï¼Œç¡®ä¿è®¾è®¡ä¸ä¼šåç¦»æœ€é‡è¦çš„è¯‰æ±‚ã€‚",
                    "type": "single_choice",
                    "options": [
                        "ä½¿ç”¨ä¾¿åˆ©æ€§ï¼šæ—¥å¸¸ç”Ÿæ´»æµç•…æ— é˜»",
                        "ç¾å­¦å“è´¨ï¼šè§†è§‰å’Œæ„Ÿå®˜çš„æ„‰æ‚¦",
                        "é•¿æœŸä»·å€¼ï¼šç»å¾—èµ·æ—¶é—´è€ƒéªŒ",
                        "åˆ›æ–°çªç ´ï¼šä¸ä¼—ä¸åŒçš„ç‹¬ç‰¹ä½“éªŒ"
                    ]
                })

        # ğŸ¯ è¡¥å……å¤šé€‰é¢˜ï¼ˆç¡®ä¿è‡³å°‘2ä¸ªï¼‰- çœŸæ­£éœ€è¦æ€è€ƒçš„é€‰æ‹©ï¼ˆéå¸¸è¯†æ€§é—®é¢˜ï¼‰
        while len(existing_multiple) < 2:
            template_idx = len(existing_multiple)
            if template_idx == 0:
                # ç¬¬ä¸€ä¸ªå¤šé€‰ï¼šå…³äºç©ºé—´ä½¿ç”¨èŠ‚å¥å’Œæ—¶é—´æ„Ÿ
                if is_residential:
                    existing_multiple.append({
                        "question": "ä»¥ä¸‹å“ªäº›æ—¶åˆ»/åœºæ™¯ï¼Œæ‚¨å¸Œæœ›ç©ºé—´èƒ½ç‰¹åˆ«æ”¯æŒï¼Ÿ(å¤šé€‰)",
                        "context": "å¸®åŠ©æˆ‘ä»¬ç†è§£æ‚¨çš„ç”Ÿæ´»èŠ‚å¥å’Œå…³é”®åœºæ™¯ï¼Œè®¾è®¡ä¼šå›´ç»•è¿™äº›æ—¶åˆ»å±•å¼€ã€‚",
                        "type": "multiple_choice",
                        "options": [
                            "æ¸…æ™¨ç‹¬å¤„ï¼šæ²‰æ€ã€é˜…è¯»æˆ–è¿åŠ¨çš„ç§å¯†æ—¶å…‰",
                            "å·¥ä½œä¸“æ³¨ï¼šéœ€è¦é«˜åº¦é›†ä¸­çš„æ·±åº¦å·¥ä½œæ—¶æ®µ",
                            "å®¶åº­äº’åŠ¨ï¼šä¸å®¶äººå…±åº¦çš„æ¸©é¦¨æ—¶åˆ»",
                            "ç¤¾äº¤å¨±ä¹ï¼šæ¥å¾…æœ‹å‹æˆ–ä¸¾åŠèšä¼š",
                            "å¤œé—´æ”¾æ¾ï¼šå¸ä¸‹ä¸€å¤©ç–²æƒ«çš„ç‹¬å¤„æ—¶å…‰",
                            "çµæ´»åˆ‡æ¢ï¼šåœ¨å¤šç§çŠ¶æ€é—´å¿«é€Ÿè½¬æ¢"
                        ]
                    })
                elif is_commercial:
                    existing_multiple.append({
                        "question": "ä»¥ä¸‹å“ªäº›ä½“éªŒåœºæ™¯ï¼Œæ‚¨å¸Œæœ›ç©ºé—´èƒ½ç‰¹åˆ«å¼ºåŒ–ï¼Ÿ(å¤šé€‰)",
                        "context": "å•†ä¸šç©ºé—´çš„æˆåŠŸåœ¨äºå…³é”®åœºæ™¯çš„æè‡´ä½“éªŒï¼Œè¯·é€‰æ‹©æ‚¨è®¤ä¸ºæœ€é‡è¦çš„ã€‚",
                        "type": "multiple_choice",
                        "options": [
                            "åˆæ¬¡ç›¸é‡ï¼šç¬¬ä¸€å°è±¡å’Œå“ç‰Œæ„ŸçŸ¥çš„é»„é‡‘æ—¶åˆ»",
                            "æ ¸å¿ƒä½“éªŒï¼šç”¨æˆ·ä½¿ç”¨æ ¸å¿ƒåŠŸèƒ½/æœåŠ¡çš„å…³é”®æ—¶åˆ»",
                            "æƒ…æ„Ÿå…±é¸£ï¼šå»ºç«‹å“ç‰Œè®¤åŒå’Œæƒ…æ„Ÿè¿æ¥çš„æ—¶åˆ»",
                            "é«˜æ•ˆæµè½¬ï¼šç”¨æˆ·å®Œæˆç›®æ ‡çš„æµç•…åº¦å’Œæ•ˆç‡",
                            "åœç•™é©»è¶³ï¼šè®©ç”¨æˆ·æ„¿æ„å¤šå¾…ä¸€ä¼šå„¿çš„å¸å¼•åŠ›",
                            "è®°å¿†é”šç‚¹ï¼šç¦»å¼€åä»èƒ½å›æƒ³èµ·çš„ç‹¬ç‰¹ä½“éªŒ"
                        ]
                    })
                else:
                    existing_multiple.append({
                        "question": "æ‚¨å¸Œæœ›è¿™ä¸ªç©ºé—´åœ¨å“ªäº›æ–¹é¢è¶…å‡ºå¸¸è§„ï¼Ÿ(å¤šé€‰)",
                        "context": "å¸®åŠ©æˆ‘ä»¬è¯†åˆ«æ‚¨çš„ç‹¬ç‰¹è¯‰æ±‚ï¼Œé¿å…è®¾è®¡æˆåƒç¯‡ä¸€å¾‹çš„æ ‡å‡†æ–¹æ¡ˆã€‚",
                        "type": "multiple_choice",
                        "options": [
                            "æ„Ÿå®˜ä½“éªŒï¼šå…‰å½±/æè´¨/å£°éŸ³ç­‰è¶…è¶Šå¸¸è§„çš„æ„Ÿå®˜è®¾è®¡",
                            "ç©ºé—´å™äº‹ï¼šæœ‰æ•…äº‹æ€§å’Œæƒ…æ„Ÿæ·±åº¦çš„ç©ºé—´åºåˆ—",
                            "åŠŸèƒ½åˆ›æ–°ï¼šæ‰“ç ´å¸¸è§„çš„ä½¿ç”¨æ–¹å¼æˆ–ç©ºé—´ç»„ç»‡",
                            "å¯æŒç»­æ€§ï¼šç¯ä¿ã€èŠ‚èƒ½æˆ–ä¸è‡ªç„¶çš„æ·±åº¦è¿æ¥",
                            "æŠ€æœ¯èåˆï¼šæ™ºèƒ½åŒ–æˆ–æ–°æŠ€æœ¯çš„å·§å¦™åº”ç”¨",
                            "æ–‡åŒ–è¡¨è¾¾ï¼šç‰¹å®šæ–‡åŒ–/è‰ºæœ¯çš„æ·±åº¦ä½“ç°"
                        ]
                    })
            else:
                # ç¬¬äºŒä¸ªå¤šé€‰ï¼šå…³äºè®¾è®¡è¿‡ç¨‹ä¸­çš„ä»·å€¼æ’åº
                if is_residential:
                    existing_multiple.append({
                        "question": "å½“é¢„ç®—/æ—¶é—´æœ‰é™éœ€è¦å–èˆæ—¶ï¼Œä»¥ä¸‹å“ªäº›æ‚¨æ„¿æ„ä¼˜å…ˆä¿éšœï¼Ÿ(å¤šé€‰)",
                        "context": "è¿™ä¸æ˜¯ç†æƒ³çŠ¶æ€çš„å…¨éƒ¨éœ€æ±‚ï¼Œè€Œæ˜¯å¸®åŠ©æˆ‘ä»¬ç†è§£æ‚¨çœŸæ­£çš„ä¼˜å…ˆçº§ã€‚",
                        "type": "multiple_choice",
                        "options": [
                            "ç»“æ„ä¼˜åŒ–ï¼šåŠ¨çº¿/é‡‡å…‰/é€šé£ç­‰åŸºç¡€ä½“éªŒçš„ä¼˜åŒ–",
                            "æè´¨å“è´¨ï¼šå…³é”®åŒºåŸŸä½¿ç”¨æ›´å¥½çš„ææ–™",
                            "å®šåˆ¶è®¾è®¡ï¼šä¸ºç‰¹æ®Šéœ€æ±‚ä¸“é—¨è®¾è®¡çš„åŠŸèƒ½",
                            "å‚¨ç‰©ç³»ç»Ÿï¼šå……è¶³ä¸”åˆç†çš„æ”¶çº³è§£å†³æ–¹æ¡ˆ",
                            "æ°›å›´è¥é€ ï¼šç¯å…‰/è‰²å½©/è‰ºæœ¯å“ç­‰æ°›å›´è¦ç´ ",
                            "æ™ºèƒ½é›†æˆï¼šæ™ºèƒ½å®¶å±…æˆ–è‡ªåŠ¨åŒ–ç³»ç»Ÿ"
                        ]
                    })
                elif is_commercial:
                    existing_multiple.append({
                        "question": "åœ¨å•†ä¸šç©ºé—´çš„æŠ•å…¥åˆ†é…ä¸Šï¼Œæ‚¨æ›´å€¾å‘äºåŠ å¼ºå“ªäº›æ–¹é¢ï¼Ÿ(å¤šé€‰)",
                        "context": "å¸®åŠ©æˆ‘ä»¬ç†è§£æ‚¨çš„å•†ä¸šç­–ç•¥å’Œä»·å€¼å–å‘ï¼Œä¼˜åŒ–èµ„æºé…ç½®ã€‚",
                        "type": "multiple_choice",
                        "options": [
                            "é—¨é¢å½¢è±¡ï¼šå¤–ç«‹é¢/å…¥å£ç­‰ç¬¬ä¸€å°è±¡çš„æŠ•å…¥",
                            "æ ¸å¿ƒåŒºåŸŸï¼šæœ€å…³é”®åŠŸèƒ½åŒºçš„å“è´¨æå‡",
                            "å“ç‰Œæ°›å›´ï¼šæ•´ä½“è°ƒæ€§å’Œå“ç‰Œè¡¨è¾¾çš„å®Œæ•´æ€§",
                            "è¿è¥çµæ´»ï¼šåæœŸè°ƒæ•´å’Œå¤šåœºæ™¯é€‚é…çš„èƒ½åŠ›",
                            "ä½“éªŒç»†èŠ‚ï¼šå°è€Œç¾çš„è§¦ç‚¹è®¾è®¡å’ŒæƒŠå–œæ—¶åˆ»",
                            "é•¿æœŸè€ç”¨ï¼šææ–™/è®¾å¤‡çš„å“è´¨å’Œç»´æŠ¤æˆæœ¬æ§åˆ¶"
                        ]
                    })
                else:
                    existing_multiple.append({
                        "question": "ä»¥ä¸‹å“ªäº›å› ç´ ä¼šæ˜¾è‘—å½±å“æ‚¨å¯¹æœ€ç»ˆæ–¹æ¡ˆçš„æ»¡æ„åº¦ï¼Ÿ(å¤šé€‰)",
                        "context": "å¸®åŠ©æˆ‘ä»¬ç†è§£æ‚¨çš„è¯„åˆ¤æ ‡å‡†ï¼Œç¡®ä¿è®¾è®¡æ–¹å‘ç¬¦åˆæ‚¨çš„é¢„æœŸã€‚",
                        "type": "multiple_choice",
                        "options": [
                            "è§†è§‰å®Œæˆåº¦ï¼šå‘ˆç°æ•ˆæœä¸é¢„æœŸçš„ä¸€è‡´æ€§",
                            "åŠŸèƒ½å®Œæ•´æ€§ï¼šæ‰€éœ€åŠŸèƒ½çš„å®ç°ç¨‹åº¦",
                            "ä½¿ç”¨ä¾¿åˆ©æ€§ï¼šæ—¥å¸¸ä½¿ç”¨çš„èˆ’é€‚å’Œæµç•…",
                            "ç‹¬ç‰¹æ€§ï¼šä¸å…¶ä»–é¡¹ç›®çš„å·®å¼‚åŒ–",
                            "å¯æŒç»­æ€§ï¼šé•¿æœŸä½¿ç”¨å’Œç»´æŠ¤çš„åˆç†æ€§",
                            "æˆæœ¬æ§åˆ¶ï¼šåœ¨é¢„ç®—èŒƒå›´å†…çš„å®ç°ç¨‹åº¦"
                        ]
                    })

        # ğŸ¯ è¡¥å……å¼€æ”¾é¢˜ï¼ˆç¡®ä¿è‡³å°‘2ä¸ªï¼‰- æ•æ‰æ·±å±‚éœ€æ±‚ï¼ˆæ¦‚å¿µé˜¶æ®µå‹å¥½ç‰ˆï¼‰
        while len(existing_open) < 2:
            template_idx = len(existing_open)
            if template_idx == 0:
                # ç¬¬ä¸€ä¸ªå¼€æ”¾é¢˜ï¼šå…³äºç†æƒ³çŠ¶æ€çš„æƒ³è±¡
                existing_open.append({
                    "question": "è¯·æè¿°ä¸€ä¸ªè®©æ‚¨å°è±¡æ·±åˆ»çš„ç©ºé—´ä½“éªŒï¼ˆå¯ä»¥æ˜¯ä»»ä½•åœ°æ–¹ï¼‰ï¼Œä»¥åŠå®ƒæ‰“åŠ¨æ‚¨çš„ç‰¹è´¨ã€‚(å¼€æ”¾é¢˜)",
                    "context": "è¿™å°†æˆä¸ºè®¾è®¡çš„'ç²¾ç¥å‚è€ƒ'ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£æ‚¨è¿½æ±‚çš„ç©ºé—´å“è´¨ã€‚",
                    "type": "open_ended"
                })
            else:
                # ç¬¬äºŒä¸ªå¼€æ”¾é¢˜ï¼šå…³äºä½¿ç”¨è€…çš„çœŸå®çŠ¶æ€
                if is_residential:
                    existing_open.append({
                        "question": "åœ¨æ‚¨è®¾æƒ³çš„æ—¥å¸¸ç”Ÿæ´»ä¸­ï¼Œæœ‰å“ªäº›æ—¶åˆ»æˆ–åœºæ™¯æ˜¯ç‰¹åˆ«é‡è¦çš„ï¼Ÿ(å¼€æ”¾é¢˜)",
                        "context": "ä¸å¿…æ˜¯ã€Œæ—©æ™¨ã€æˆ–ã€Œå¤œæ™šã€è¿™æ ·çš„å…·ä½“æ—¶é—´ï¼Œå¯ä»¥æ˜¯ä»»ä½•å¯¹æ‚¨æœ‰æ„ä¹‰çš„çŠ¶æ€æˆ–åœºæ™¯ã€‚",
                        "type": "open_ended"
                    })
                elif is_commercial:
                    existing_open.append({
                        "question": "æ‚¨å¸Œæœ›ç”¨æˆ·/å®¢æˆ·åœ¨è¿™ä¸ªç©ºé—´ä¸­ç»å†æ€æ ·çš„ä½“éªŒæ—…ç¨‹ï¼Ÿ(å¼€æ”¾é¢˜)",
                        "context": "ä»è¿›å…¥åˆ°ç¦»å¼€ï¼Œæè¿°æ‚¨ç†æƒ³ä¸­çš„ä½“éªŒè¿‡ç¨‹å’Œå…³é”®æ„Ÿå—ã€‚",
                        "type": "open_ended"
                    })
                else:
                    existing_open.append({
                        "question": "å¦‚æœç”¨ä¸‰ä¸ªå…³é”®è¯æè¿°æ‚¨ç†æƒ³ä¸­çš„ç©ºé—´ï¼Œä¼šæ˜¯ä»€ä¹ˆï¼Ÿè¯·ç®€å•è§£é‡ŠåŸå› ã€‚(å¼€æ”¾é¢˜)",
                        "context": "å¸®åŠ©æˆ‘ä»¬å¿«é€ŸæŠŠæ¡æ‚¨çš„æ ¸å¿ƒè¯‰æ±‚å’Œä»·å€¼å–å‘ã€‚",
                        "type": "open_ended"
                    })

        # æŒ‰ç…§è¦æ±‚çš„é¡ºåºé‡æ–°ç»„ç»‡é—®é¢˜ï¼šå•é€‰ â†’ å¤šé€‰ â†’ å¼€æ”¾
        fixed_questions = existing_single + existing_multiple + existing_open

        logger.info(f"[é—®å·éªŒè¯] âœ… æ™ºèƒ½è¡¥é½å®Œæˆ: æ€»æ•°={len(fixed_questions)}, å•é€‰={len(existing_single)}, å¤šé€‰={len(existing_multiple)}, å¼€æ”¾={len(existing_open)}")
        logger.info(f"[é—®å·éªŒè¯] ğŸ“Š è¡¥é½ç­–ç•¥: åŸºäºç”¨æˆ·è¾“å…¥çš„æ ¸å¿ƒçŸ›ç›¾({tension_a} vs {tension_b})å’Œé¡¹ç›®ç±»å‹({project_type})ç”Ÿæˆ")

        # æ›´æ–°é—®å·
        structured_data["calibration_questionnaire"]["questions"] = fixed_questions
    
    def _infer_project_type(self, structured_data: Dict[str, Any]) -> str:
        """
        æ¨æ–­é¡¹ç›®ç±»å‹ï¼ˆç”¨äºæœ¬ä½“è®ºæ³¨å…¥ï¼‰
        
        æ ¹æ®éœ€æ±‚å†…å®¹ä¸­çš„å…³é”®è¯åŒ¹é…ï¼Œè¯†åˆ«é¡¹ç›®ç±»å‹ï¼š
        - personal_residential: ä¸ªäºº/å®¶åº­ä½å®…ç±»é¡¹ç›®
        - hybrid_residential_commercial: æ··åˆå‹ï¼ˆä½å®…+å•†ä¸šï¼‰
        - commercial_enterprise: çº¯å•†ä¸š/ä¼ä¸šçº§é¡¹ç›®
        
        Returns:
            é¡¹ç›®ç±»å‹æ ‡è¯†å­—ç¬¦ä¸²
        """
        # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹è¿›è¡Œå…³é”®è¯åŒ¹é…
        all_text = " ".join([
            str(structured_data.get("project_task", "")),
            str(structured_data.get("character_narrative", "")),
            str(structured_data.get("project_overview", "")),
            str(structured_data.get("target_users", "")),
        ]).lower()
        
        # å®šä¹‰å…³é”®è¯é›†åˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
        personal_keywords = [
            "ä½å®…", "å®¶", "å…¬å¯“", "åˆ«å¢…", "æˆ¿å­", "å±…ä½", "å§å®¤", "å®¢å…", 
            "å®¶åº­", "ä¸ªäºº", "ç§å®…", "å®¶å±…", "æˆ·å‹", "ä½æˆ¿", "æ°‘å®¿"
        ]
        
        commercial_keywords = [
            # åŠå…¬ç±»
            "åŠå…¬", "å•†ä¸š", "ä¼ä¸š", "å…¬å¸", "å†™å­—æ¥¼", "å·¥ä½œå®¤", "åˆ›æ„å›­", "äº§ä¸šå›­", "å‚æˆ¿", "ä»“å‚¨", "å“ç‰Œ", "è¿é”",
            # é›¶å”®/å±•ç¤ºç±»
            "åº—é“º", "å•†åº—", "å±•å…", "é›¶å”®", "è´­ç‰©", "å•†åœº", "ä¸“å–åº—", "æ——èˆ°åº—", "ä½“éªŒåº—",
            # é¤é¥®ç±»
            "é¤å…", "é¤é¥®", "ä¸­é¤", "è¥¿é¤", "æ—¥æ–™", "åŒ…æˆ¿", "åŒ…é—´", "å®´ä¼šå…", "é£Ÿå ‚", "èŒ¶é¤å…",
            "å’–å•¡", "å’–å•¡å…", "å’–å•¡é¦†", "èŒ¶å®¤", "èŒ¶é¦†", "é…’å§", "æ¸…å§",
            # ä½å®¿/ä¼šæ‰€ç±»
            "é…’åº—", "å®¾é¦†", "æ°‘å®¿", "ä¼šæ‰€", "ä¿±ä¹éƒ¨", "ä¼šè®®å®¤",
            # ğŸ”¥ å…¬å…±/å¸‚æ”¿ç±»ï¼ˆåŸå¸‚æ›´æ–°ã€èœå¸‚åœºç­‰ï¼‰
            "èœå¸‚åœº", "å¸‚åœº", "å†œè´¸å¸‚åœº", "é›†å¸‚", "åŸå¸‚æ›´æ–°", "æ—§æ”¹", "æ”¹é€ ", "å…¬å…±ç©ºé—´",
            "ç¤¾åŒºä¸­å¿ƒ", "æ–‡åŒ–ä¸­å¿ƒ", "æ´»åŠ¨ä¸­å¿ƒ", "ä½“è‚²é¦†", "å›¾ä¹¦é¦†", "åšç‰©é¦†", "ç¾æœ¯é¦†",
            "æ ‡æ†", "ç¤ºèŒƒ", "åœ°æ ‡", "åŸå¸‚åç‰‡",
            # ğŸ”¥ æ–‡åŒ–/ä½“éªŒç±»
            "æ–‡åŒ–", "ä¼ ç»Ÿ", "æ¸”æ‘", "å†å²", "é—äº§", "éé—", "æ°‘ä¿—", "åœ¨åœ°æ–‡åŒ–",
            # ğŸ”¥ æ•™è‚²/åŒ»ç–—/å¥åº·ç±»
            "å­¦æ ¡", "æ•™è‚²", "åŸ¹è®­", "å¹¼å„¿å›­", "æ—©æ•™", "æ‰˜è‚²",
            "åŒ»é™¢", "è¯Šæ‰€", "åŒ»ç–—", "å…»è€é™¢", "åº·å…»", "å¥åº·ä¸­å¿ƒ", "ä½“æ£€ä¸­å¿ƒ", "åº·å¤ä¸­å¿ƒ",
            "å¥åº·ç®¡ç†", "å¥åº·", "åŒ»ç¾", "ç†ç–—", "å…»ç”Ÿ", "ä¿å¥",
            # ğŸ”¥ å•†ä¸šè¿è¥ç±»ï¼ˆå¼ºçƒˆè¡¨æ˜æ˜¯å•†ä¸šé¡¹ç›®ï¼‰
            "ç»è¥", "è¿è¥", "å¸‚åœºè¥é”€", "è¥é”€", "ç”¨æˆ·ä½“éªŒ", "å•†ä¸šæ¨¡å¼", "ç›ˆåˆ©"
        ]
        
        # ç»Ÿè®¡å…³é”®è¯å‘½ä¸­æ•°
        personal_score = sum(1 for kw in personal_keywords if kw in all_text)
        commercial_score = sum(1 for kw in commercial_keywords if kw in all_text)
        
        logger.info(f"[é¡¹ç›®ç±»å‹æ¨æ–­] ä¸ªäºº/ä½å®…å¾—åˆ†: {personal_score}, å•†ä¸š/ä¼ä¸šå¾—åˆ†: {commercial_score}")
        
        # åˆ¤å®šé€»è¾‘
        if personal_score > 0 and commercial_score > 0:
            # åŒæ—¶åŒ…å«ä½å®…å’Œå•†ä¸šå…³é”®è¯
            logger.info("[é¡¹ç›®ç±»å‹æ¨æ–­] è¯†åˆ«ä¸ºæ··åˆå‹é¡¹ç›® (hybrid_residential_commercial)")
            return "hybrid_residential_commercial"
        elif personal_score > commercial_score:
            # ä¸»è¦æ˜¯ä½å®…ç±»å…³é”®è¯
            logger.info("[é¡¹ç›®ç±»å‹æ¨æ–­] è¯†åˆ«ä¸ºä¸ªäºº/ä½å®…é¡¹ç›® (personal_residential)")
            return "personal_residential"
        elif commercial_score > personal_score:
            # ä¸»è¦æ˜¯å•†ä¸šç±»å…³é”®è¯
            logger.info("[é¡¹ç›®ç±»å‹æ¨æ–­] è¯†åˆ«ä¸ºå•†ä¸š/ä¼ä¸šé¡¹ç›® (commercial_enterprise)")
            return "commercial_enterprise"
        else:
            # æœªå‘½ä¸­ä»»ä½•å…³é”®è¯ï¼Œè¿”å› Noneï¼ˆå°†è§¦å‘ meta_frameworkï¼‰
            logger.warning("[é¡¹ç›®ç±»å‹æ¨æ–­] æ— æ³•è¯†åˆ«é¡¹ç›®ç±»å‹ï¼Œå°†ä½¿ç”¨é€šç”¨æ¡†æ¶ (meta_framework)")
            return None
    
    def _calculate_confidence(self, structured_data: Dict[str, Any]) -> float:
        """è®¡ç®—åˆ†æç»“æœçš„ç½®ä¿¡åº¦"""
        confidence_factors = []
        
        # æ£€æŸ¥å…³é”®å­—æ®µçš„å®Œæ•´æ€§
        key_fields = ["project_overview", "core_objectives", "functional_requirements"]
        for field in key_fields:
            value = structured_data.get(field, "")
            if isinstance(value, str) and len(value) > 20:
                confidence_factors.append(0.3)
            elif isinstance(value, list) and len(value) > 0:
                confidence_factors.append(0.3)
            else:
                confidence_factors.append(0.1)
        
        # æ£€æŸ¥è¯¦ç»†ç¨‹åº¦
        total_content_length = sum(
            len(str(v)) for v in structured_data.values()
        )
        if total_content_length > 1000:
            confidence_factors.append(0.1)
        
        return min(sum(confidence_factors), 1.0)
    
    def _retrieve_user_preferences(self, store: BaseStore, config: RunnableConfig) -> str:
        """æ£€ç´¢ç”¨æˆ·å†å²åå¥½"""
        try:
            user_id = config["configurable"]["user_id"]
            namespace = ("user_preferences", user_id)
            
            # æœç´¢ç›¸å…³çš„ç”¨æˆ·åå¥½
            memories = store.search(namespace, limit=5)
            
            if memories:
                preferences = []
                for memory in memories:
                    if "preference" in memory.value:
                        preferences.append(memory.value["preference"])
                
                return "\n".join(preferences) if preferences else ""
            
            return ""
            
        except Exception as e:
            logger.warning(f"Failed to retrieve user preferences: {str(e)}")
            return ""
    
    def _save_user_preferences(
        self,
        store: BaseStore,
        config: RunnableConfig,
        structured_requirements: Dict[str, Any]
    ):
        """ä¿å­˜ç”¨æˆ·åå¥½"""
        try:
            user_id = config["configurable"]["user_id"]
            namespace = ("user_preferences", user_id)
            
            # æå–å¯èƒ½çš„åå¥½ä¿¡æ¯
            preferences = []
            
            # ä»ç›®æ ‡ç”¨æˆ·ä¸­æå–åå¥½
            target_users = structured_requirements.get("target_users", "")
            if target_users and len(target_users) > 10:
                preferences.append(f"ç›®æ ‡ç”¨æˆ·åå¥½: {target_users}")
            
            # ä»çº¦æŸæ¡ä»¶ä¸­æå–åå¥½
            constraints = structured_requirements.get("constraints", {})
            if isinstance(constraints, dict):
                for key, value in constraints.items():
                    if value and value != "æœªæ˜ç¡®" and value != "å¾…å®šä¹‰":
                        preferences.append(f"{key}åå¥½: {value}")
            
            # ä¿å­˜åå¥½
            for i, preference in enumerate(preferences):
                memory_id = f"req_analysis_{int(time.time())}_{i}"
                store.put(namespace, memory_id, {
                    "preference": preference,
                    "source": "requirements_analysis",
                    "timestamp": time.time()
                })
            
        except Exception as e:
            logger.warning(f"Failed to save user preferences: {str(e)}")


# æ³¨å†Œæ™ºèƒ½ä½“
from .base import AgentFactory
AgentFactory.register_agent(AgentType.REQUIREMENTS_ANALYST, RequirementsAnalystAgent)
