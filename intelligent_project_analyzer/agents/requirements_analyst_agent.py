"""
éœ€æ±‚åˆ†æå¸ˆ StateGraph Agent (v7.17 P3)

å°†éœ€æ±‚åˆ†æå¸ˆå‡çº§ä¸ºå®Œæ•´çš„ LangGraph StateGraph Agentï¼Œ
æ”¯æŒç¨‹åºåŒ–é¢„æ£€æµ‹ã€ä¸¤é˜¶æ®µåˆ†æã€æ¡ä»¶è·¯ç”±ç­‰èƒ½åŠ›ã€‚

æ¶æ„è®¾è®¡ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   precheck      â”‚ â† ç¨‹åºåŒ–èƒ½åŠ›è¾¹ç•Œé¢„æ£€æµ‹
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    phase1       â”‚ â† å¿«é€Ÿå®šæ€§ + äº¤ä»˜ç‰©è¯†åˆ«
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
 [info       [info
 sufficient]  insufficient]
    â”‚              â”‚
    â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ phase2  â”‚   â”‚ output   â”‚ â† è·³è¿‡ Phase2
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚
     â–¼             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚ output  â”‚ â—„â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â–¼
   [END]
"""

import json
import time
from datetime import datetime
from typing import Any, Dict, List, Literal, Optional, Tuple, TypedDict

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.graph import END, START, StateGraph
from loguru import logger

from ..core.prompt_manager import PromptManager
from ..core.state import AgentType
from ..core.types import AnalysisResult
from ..services.capability_boundary_service import CapabilityBoundaryService, CheckType
from ..utils.capability_detector import CapabilityDetector, check_capability
from ..utils.jtbd_parser import transform_jtbd_to_natural_language

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. çŠ¶æ€å®šä¹‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class RequirementsAnalystState(TypedDict):
    """éœ€æ±‚åˆ†æå¸ˆ StateGraph çŠ¶æ€å®šä¹‰"""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # è¾“å…¥
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    user_input: str  # ç”¨æˆ·åŸå§‹è¾“å…¥
    session_id: str  # ä¼šè¯ ID

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # é…ç½®
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _llm_model: Any  # LLM æ¨¡å‹å®ä¾‹
    _prompt_manager: Any  # æç¤ºè¯ç®¡ç†å™¨

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä¸­é—´çŠ¶æ€ - Precheck é˜¶æ®µ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    precheck_result: Dict[str, Any]  # ç¨‹åºåŒ–é¢„æ£€æµ‹ç»“æœ
    precheck_elapsed_ms: float  # é¢„æ£€æµ‹è€—æ—¶
    info_sufficient: bool  # ä¿¡æ¯æ˜¯å¦å……è¶³ï¼ˆç¨‹åºåŒ–åˆ¤æ–­ï¼‰
    capability_score: float  # èƒ½åŠ›åŒ¹é…åº¦

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä¸­é—´çŠ¶æ€ - Phase1 é˜¶æ®µ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    phase1_result: Dict[str, Any]  # Phase1 LLM è¾“å‡º
    phase1_elapsed_ms: float  # Phase1 è€—æ—¶
    phase1_info_status: str  # Phase1 åˆ¤å®šçš„ä¿¡æ¯çŠ¶æ€
    recommended_next_step: str  # æ¨èçš„ä¸‹ä¸€æ­¥
    primary_deliverables: List[Dict]  # ä¸»è¦äº¤ä»˜ç‰©åˆ—è¡¨

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä¸­é—´çŠ¶æ€ - Phase2 é˜¶æ®µ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    phase2_result: Dict[str, Any]  # Phase2 LLM è¾“å‡º
    phase2_elapsed_ms: float  # Phase2 è€—æ—¶
    analysis_layers: Dict[str, Any]  # L1-L5 åˆ†æå±‚
    expert_handoff: Dict[str, Any]  # ä¸“å®¶æ¥å£

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # è¾“å‡º
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    structured_data: Dict[str, Any]  # ç»“æ„åŒ–è¾“å‡º
    confidence: float  # ç½®ä¿¡åº¦
    analysis_mode: str  # "phase1_only" | "two_phase"
    project_type: Optional[str]  # é¡¹ç›®ç±»å‹

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å…ƒæ•°æ®
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    processing_log: List[str]  # å¤„ç†æ—¥å¿—
    total_elapsed_ms: float  # æ€»è€—æ—¶
    node_path: List[str]  # ç»è¿‡çš„èŠ‚ç‚¹è·¯å¾„


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. èŠ‚ç‚¹å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def precheck_node(state: RequirementsAnalystState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹1: ç¨‹åºåŒ–èƒ½åŠ›è¾¹ç•Œé¢„æ£€æµ‹

    ä¸è°ƒç”¨ LLMï¼Œçº¯ç¨‹åºåŒ–æ£€æµ‹ï¼š
    - ä¿¡æ¯å……è¶³æ€§æ£€æµ‹ï¼ˆ7ä¸ªç»´åº¦ï¼‰
    - äº¤ä»˜ç‰©èƒ½åŠ›åŒ¹é…æ£€æµ‹
    - èƒ½åŠ›è½¬åŒ–å»ºè®®ç”Ÿæˆ
    """
    start_time = time.time()
    user_input = state.get("user_input", "")

    logger.info("ğŸ” [Precheck] ç¨‹åºåŒ–èƒ½åŠ›è¾¹ç•Œé¢„æ£€æµ‹...")

    # è°ƒç”¨ç¨‹åºåŒ–æ£€æµ‹å™¨
    precheck_result = check_capability(user_input)

    elapsed_ms = (time.time() - start_time) * 1000

    # æå–å…³é”®æŒ‡æ ‡
    info_suff = precheck_result.get("info_sufficiency", {})
    deliv_cap = precheck_result.get("deliverable_capability", {})

    logger.info(f"âœ… [Precheck] å®Œæˆï¼Œè€—æ—¶ {elapsed_ms:.1f}ms")
    logger.info(f"   - ä¿¡æ¯å……è¶³: {info_suff.get('is_sufficient')}")
    logger.info(f"   - èƒ½åŠ›åŒ¹é…: {deliv_cap.get('capability_score', 1.0):.0%}")

    return {
        "precheck_result": precheck_result,
        "precheck_elapsed_ms": elapsed_ms,
        "info_sufficient": info_suff.get("is_sufficient", False),
        "capability_score": deliv_cap.get("capability_score", 1.0),
        "processing_log": state.get("processing_log", [])
        + [f"[Precheck] å®Œæˆ ({elapsed_ms:.1f}ms) - ä¿¡æ¯{'å……è¶³' if info_suff.get('is_sufficient') else 'ä¸è¶³'}"],
        "node_path": state.get("node_path", []) + ["precheck"],
    }


def phase1_node(state: RequirementsAnalystState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹2: Phase1 - å¿«é€Ÿå®šæ€§ + äº¤ä»˜ç‰©è¯†åˆ«

    LLM è°ƒç”¨ï¼ˆ~1.5sï¼‰ï¼š
    - L0 é¡¹ç›®å®šæ€§
    - äº¤ä»˜ç‰©è¯†åˆ« + èƒ½åŠ›è¾¹ç•Œåˆ¤æ–­
    - è¾“å‡º: info_status, primary_deliverables, recommended_next_step
    """
    start_time = time.time()
    user_input = state.get("user_input", "")
    precheck_result = state.get("precheck_result", {})
    llm_model = state.get("_llm_model")
    prompt_manager = state.get("_prompt_manager")

    logger.info("ğŸ“‹ [Phase1] å¼€å§‹å¿«é€Ÿå®šæ€§ + äº¤ä»˜ç‰©è¯†åˆ«...")

    # åŠ è½½ Phase1 æç¤ºè¯
    phase1_config = prompt_manager.get_prompt("requirements_analyst_phase1", return_full_config=True)

    if not phase1_config:
        logger.warning("[Phase1] æœªæ‰¾åˆ°ä¸“ç”¨é…ç½®ï¼Œä½¿ç”¨ fallback")
        return _phase1_fallback(state, start_time)

    system_prompt = phase1_config.get("system_prompt", "")
    task_template = phase1_config.get("task_description_template", "")

    # æ„å»ºä»»åŠ¡æè¿°
    datetime_info = f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}ã€‚"
    task_description = task_template.replace("{datetime_info}", datetime_info).replace("{user_input}", user_input)

    # æ³¨å…¥é¢„æ£€æµ‹ç»“æœ
    if precheck_result:
        precheck_hints = _format_precheck_hints(precheck_result)
        task_description = f"{precheck_hints}\n\n{task_description}"

    # è°ƒç”¨ LLM
    try:
        messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": task_description}]
        response = llm_model.invoke(messages)
        response_content = response.content if hasattr(response, "content") else str(response)

        # è§£æ JSON
        phase1_result = _parse_json_response(response_content)
        phase1_result["phase"] = 1

    except Exception as e:
        logger.error(f"[Phase1] LLM è°ƒç”¨å¤±è´¥: {e}")
        return _phase1_fallback(state, start_time)

    elapsed_ms = (time.time() - start_time) * 1000

    # æå–å…³é”®ä¿¡æ¯
    info_status = phase1_result.get("info_status", "insufficient")
    recommended_next = phase1_result.get("recommended_next_step", "questionnaire_first")
    deliverables = phase1_result.get("primary_deliverables", [])

    logger.info(f"âœ… [Phase1] å®Œæˆï¼Œè€—æ—¶ {elapsed_ms:.0f}ms")
    logger.info(f"   - info_status: {info_status}")
    logger.info(f"   - deliverables: {len(deliverables)}ä¸ª")
    logger.info(f"   - next_step: {recommended_next}")

    # ğŸ†• èƒ½åŠ›è¾¹ç•Œæ£€æŸ¥ï¼šéªŒè¯Phase1è¾“å‡ºçš„äº¤ä»˜ç‰©
    if deliverables:
        logger.info("ğŸ” [CapabilityBoundary] éªŒè¯Phase1è¾“å‡ºçš„äº¤ä»˜ç‰©èƒ½åŠ›")
        boundary_check = CapabilityBoundaryService.check_deliverable_list(
            deliverables=deliverables,
            context={
                "node": "requirements_analyst_phase1",
                "user_input": state.get("user_input", ""),
                "session_id": state.get("session_id", ""),
            },
        )

        logger.info(f"ğŸ“Š äº¤ä»˜ç‰©èƒ½åŠ›è¾¹ç•Œæ£€æŸ¥ç»“æœ:")
        logger.info(f"   åœ¨èƒ½åŠ›èŒƒå›´å†…: {boundary_check.within_capability}")
        logger.info(f"   èƒ½åŠ›åŒ¹é…åº¦: {boundary_check.capability_score:.2f}")

        # å¦‚æœæœ‰è¶…å‡ºèƒ½åŠ›çš„äº¤ä»˜ç‰©ï¼Œåº”ç”¨è½¬åŒ–
        if not boundary_check.within_capability:
            logger.warning(f"âš ï¸ Phase1è¾“å‡ºåŒ…å«è¶…å‡ºèƒ½åŠ›çš„äº¤ä»˜ç‰©")
            logger.info(f"   è½¬åŒ–å»ºè®®: {len(boundary_check.transformations_needed)} é¡¹")

            # æ›´æ–°äº¤ä»˜ç‰©æ¸…å•ï¼ˆåº”ç”¨è½¬åŒ–ï¼‰
            transformed_deliverables = []
            for i, deliv in enumerate(deliverables):
                deliv_type = deliv.get("type", "")

                # æŸ¥æ‰¾æ˜¯å¦éœ€è¦è½¬åŒ–
                needs_transform = False
                for check in boundary_check.deliverable_checks:
                    if not check.within_capability and check.original_type == deliv_type:
                        # åº”ç”¨è½¬åŒ–
                        deliv["type"] = check.transformed_type or "design_strategy"
                        deliv["capability_transformed"] = True
                        deliv["original_type"] = check.original_type
                        deliv["transformation_reason"] = check.transformation_reason
                        needs_transform = True
                        logger.info(f"     - D{i+1}: '{check.original_type}' â†’ '{check.transformed_type}'")
                        break

                transformed_deliverables.append(deliv)

            deliverables = transformed_deliverables
        else:
            logger.info("âœ… æ‰€æœ‰äº¤ä»˜ç‰©åœ¨èƒ½åŠ›èŒƒå›´å†…")

    return {
        "phase1_result": phase1_result,
        "phase1_elapsed_ms": elapsed_ms,
        "phase1_info_status": info_status,
        "recommended_next_step": recommended_next,
        "primary_deliverables": deliverables,
        "processing_log": state.get("processing_log", [])
        + [f"[Phase1] å®Œæˆ ({elapsed_ms:.0f}ms) - {info_status}, {len(deliverables)}ä¸ªäº¤ä»˜ç‰©"],
        "node_path": state.get("node_path", []) + ["phase1"],
    }


def phase2_node(state: RequirementsAnalystState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹3: Phase2 - æ·±åº¦åˆ†æ + ä¸“å®¶æ¥å£æ„å»º

    LLM è°ƒç”¨ï¼ˆ~3sï¼‰ï¼š
    - L1-L5 æ·±åº¦åˆ†æ
    - ä¸“å®¶æ¥å£æ„å»º
    - è¾“å‡º: analysis_layers, structured_output, expert_handoff
    """
    start_time = time.time()
    user_input = state.get("user_input", "")
    phase1_result = state.get("phase1_result", {})
    llm_model = state.get("_llm_model")
    prompt_manager = state.get("_prompt_manager")

    logger.info("ğŸ”¬ [Phase2] å¼€å§‹æ·±åº¦åˆ†æ + ä¸“å®¶æ¥å£æ„å»º...")

    # åŠ è½½ Phase2 æç¤ºè¯
    phase2_config = prompt_manager.get_prompt("requirements_analyst_phase2", return_full_config=True)

    if not phase2_config:
        logger.warning("[Phase2] æœªæ‰¾åˆ°ä¸“ç”¨é…ç½®ï¼Œä½¿ç”¨ fallback")
        return _phase2_fallback(state, start_time)

    system_prompt = phase2_config.get("system_prompt", "")
    task_template = phase2_config.get("task_description_template", "")

    # æ„å»ºä»»åŠ¡æè¿°
    datetime_info = f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}ã€‚"
    phase1_output_str = json.dumps(phase1_result, ensure_ascii=False, indent=2)

    task_description = (
        task_template.replace("{datetime_info}", datetime_info)
        .replace("{user_input}", user_input)
        .replace("{phase1_output}", phase1_output_str)
    )

    # è°ƒç”¨ LLM
    try:
        messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": task_description}]
        response = llm_model.invoke(messages)
        response_content = response.content if hasattr(response, "content") else str(response)

        # è§£æ JSON
        phase2_result = _parse_json_response(response_content)
        phase2_result["phase"] = 2

    except Exception as e:
        logger.error(f"[Phase2] LLM è°ƒç”¨å¤±è´¥: {e}")
        return _phase2_fallback(state, start_time)

    elapsed_ms = (time.time() - start_time) * 1000

    logger.info(f"âœ… [Phase2] å®Œæˆï¼Œè€—æ—¶ {elapsed_ms:.0f}ms")

    return {
        "phase2_result": phase2_result,
        "phase2_elapsed_ms": elapsed_ms,
        "analysis_layers": phase2_result.get("analysis_layers", {}),
        "expert_handoff": phase2_result.get("expert_handoff", {}),
        "processing_log": state.get("processing_log", []) + [f"[Phase2] å®Œæˆ ({elapsed_ms:.0f}ms)"],
        "node_path": state.get("node_path", []) + ["phase2"],
    }


def output_node(state: RequirementsAnalystState) -> Dict[str, Any]:
    """
    èŠ‚ç‚¹4: è¾“å‡ºæ„å»º

    æ ¹æ®æ‰§è¡Œè·¯å¾„ï¼Œæ„å»ºæœ€ç»ˆè¾“å‡ºï¼š
    - phase1_only: ä»… Phase1 å®Œæˆ
    - two_phase: Phase1 + Phase2 å®Œæˆ
    """
    start_time = time.time()
    user_input = state.get("user_input", "")
    phase1_result = state.get("phase1_result", {})
    phase2_result = state.get("phase2_result", {})

    # åˆ¤æ–­æ‰§è¡Œæ¨¡å¼
    has_phase2 = bool(phase2_result)
    analysis_mode = "two_phase" if has_phase2 else "phase1_only"

    logger.info(f"ğŸ“¦ [Output] æ„å»ºè¾“å‡º ({analysis_mode})...")

    if has_phase2:
        # åˆå¹¶ Phase1 å’Œ Phase2 ç»“æœ
        structured_data = _merge_phase_results(phase1_result, phase2_result, user_input)
        confidence = _calculate_two_phase_confidence(phase1_result, phase2_result)
    else:
        # ä»… Phase1 ç»“æœ
        structured_data = _build_phase1_only_result(phase1_result, user_input)
        confidence = 0.5

    # åå¤„ç†
    _normalize_jtbd_fields(structured_data)
    project_type = _infer_project_type(structured_data)

    structured_data["analysis_mode"] = analysis_mode
    structured_data["project_type"] = project_type

    # æ·»åŠ è€—æ—¶ä¿¡æ¯
    structured_data["precheck_elapsed_ms"] = state.get("precheck_elapsed_ms", 0)
    structured_data["phase1_elapsed_ms"] = state.get("phase1_elapsed_ms", 0)
    if has_phase2:
        structured_data["phase2_elapsed_ms"] = state.get("phase2_elapsed_ms", 0)

    elapsed_ms = (time.time() - start_time) * 1000
    total_elapsed = (
        state.get("precheck_elapsed_ms", 0)
        + state.get("phase1_elapsed_ms", 0)
        + state.get("phase2_elapsed_ms", 0)
        + elapsed_ms
    )

    logger.info(f"âœ… [Output] å®Œæˆï¼Œæ€»è€—æ—¶ {total_elapsed:.0f}ms")

    return {
        "structured_data": structured_data,
        "confidence": confidence,
        "analysis_mode": analysis_mode,
        "project_type": project_type,
        "total_elapsed_ms": total_elapsed,
        "processing_log": state.get("processing_log", [])
        + [f"[Output] å®Œæˆ ({elapsed_ms:.0f}ms) - æ¨¡å¼: {analysis_mode}, ç½®ä¿¡åº¦: {confidence:.2f}"],
        "node_path": state.get("node_path", []) + ["output"],
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. æ¡ä»¶è·¯ç”±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def should_execute_phase2(state: RequirementsAnalystState) -> Literal["phase2", "output"]:
    """
    æ¡ä»¶è·¯ç”±: åˆ¤æ–­æ˜¯å¦æ‰§è¡Œ Phase2

    æ¡ä»¶:
    - info_status == "sufficient" AND
    - recommended_next_step != "questionnaire_first"
    â†’ æ‰§è¡Œ Phase2

    å¦åˆ™:
    â†’ è·³è¿‡ Phase2ï¼Œç›´æ¥è¾“å‡º
    """
    info_status = state.get("phase1_info_status", "insufficient")
    recommended_next = state.get("recommended_next_step", "questionnaire_first")

    if info_status == "sufficient" and recommended_next != "questionnaire_first":
        logger.info("ğŸ”€ [è·¯ç”±] ä¿¡æ¯å……è¶³ï¼Œè¿›å…¥ Phase2")
        return "phase2"
    else:
        logger.info(f"ğŸ”€ [è·¯ç”±] è·³è¿‡ Phase2 (info_status={info_status}, next={recommended_next})")
        return "output"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. è¾…åŠ©å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def _format_precheck_hints(precheck_result: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–é¢„æ£€æµ‹ç»“æœä¸º LLM æç¤º"""
    hints = ["### ğŸ” ç¨‹åºåŒ–é¢„æ£€æµ‹ç»“æœï¼ˆå·²å®Œæˆï¼Œè¯·å‚è€ƒï¼‰"]

    info_suff = precheck_result.get("info_sufficiency", {})
    if info_suff.get("is_sufficient"):
        hints.append(f"âœ… **ä¿¡æ¯å……è¶³æ€§**: å……è¶³ï¼ˆå¾—åˆ† {info_suff.get('score', 0):.2f}ï¼‰")
        hints.append(f"   - å·²è¯†åˆ«: {', '.join(info_suff.get('present_elements', []))}")
    else:
        hints.append(f"âš ï¸ **ä¿¡æ¯å……è¶³æ€§**: ä¸è¶³ï¼ˆå¾—åˆ† {info_suff.get('score', 0):.2f}ï¼‰")
        hints.append(f"   - ç¼ºå°‘: {', '.join(info_suff.get('missing_elements', [])[:5])}")

    deliv_cap = precheck_result.get("deliverable_capability", {})
    hints.append(f"âœ… **èƒ½åŠ›åŒ¹é…åº¦**: {deliv_cap.get('capability_score', 1.0):.0%}")

    capable = precheck_result.get("capable_deliverables", [])
    if capable:
        deliverable_types = [d.get("type", "") for d in capable[:3]]
        hints.append(f"   - å¯äº¤ä»˜: {', '.join(deliverable_types)}")

    transformations = precheck_result.get("transformations", [])
    if transformations:
        hints.append("âš ï¸ **éœ€è¦è½¬åŒ–çš„éœ€æ±‚**:")
        for t in transformations[:3]:
            hints.append(f"   - '{t.get('original')}' â†’ '{t.get('transformed_to')}'")

    hints.append("")
    return "\n".join(hints)


def _parse_json_response(response: str) -> Dict[str, Any]:
    """è§£æ JSON å“åº”"""
    # å°è¯•ä»£ç å—æå–
    import re

    json_pattern = r"```(?:json)?\s*\n(.*?)\n```"
    match = re.search(json_pattern, response, re.DOTALL)
    if match:
        return json.loads(match.group(1))

    # å°è¯•å¹³è¡¡æ‹¬å·æå–
    start_idx = response.find("{")
    if start_idx == -1:
        raise ValueError("æ— æ³•æ‰¾åˆ° JSON å¼€å§‹")

    stack = []
    in_string = False
    escape = False

    for i in range(start_idx, len(response)):
        ch = response[i]
        if escape:
            escape = False
            continue
        if ch == "\\":
            escape = True
            continue
        if ch == '"':
            in_string = not in_string
            continue
        if not in_string:
            if ch == "{":
                stack.append(ch)
            elif ch == "}":
                if stack:
                    stack.pop()
                if not stack:
                    return json.loads(response[start_idx : i + 1])

    raise ValueError("æ— æ³•æ‰¾åˆ°å®Œæ•´ JSON")


def _phase1_fallback(state: RequirementsAnalystState, start_time: float) -> Dict[str, Any]:
    """Phase1 é™çº§é€»è¾‘"""
    user_input = state.get("user_input", "")
    precheck_result = state.get("precheck_result", {})

    info_suff = precheck_result.get("info_sufficiency", {})
    capable = precheck_result.get("capable_deliverables", [])

    phase1_result = {
        "phase": 1,
        "info_status": "sufficient" if info_suff.get("is_sufficient") else "insufficient",
        "info_status_reason": "åŸºäºç¨‹åºåŒ–é¢„æ£€æµ‹",
        "project_summary": user_input[:100] + "...",
        "primary_deliverables": [
            {"deliverable_id": f"D{i+1}", "type": d.get("type", "design_strategy"), "priority": "MUST_HAVE"}
            for i, d in enumerate(capable[:3])
        ]
        or [{"deliverable_id": "D1", "type": "design_strategy", "priority": "MUST_HAVE"}],
        "recommended_next_step": precheck_result.get("recommended_action", "questionnaire_first"),
        "fallback": True,
    }

    elapsed_ms = (time.time() - start_time) * 1000

    return {
        "phase1_result": phase1_result,
        "phase1_elapsed_ms": elapsed_ms,
        "phase1_info_status": phase1_result["info_status"],
        "recommended_next_step": phase1_result["recommended_next_step"],
        "primary_deliverables": phase1_result["primary_deliverables"],
        "processing_log": state.get("processing_log", []) + [f"[Phase1] Fallback ({elapsed_ms:.0f}ms)"],
        "node_path": state.get("node_path", []) + ["phase1"],
    }


def _phase2_fallback(state: RequirementsAnalystState, start_time: float) -> Dict[str, Any]:
    """Phase2 é™çº§é€»è¾‘"""
    user_input = state.get("user_input", "")

    phase2_result = {
        "phase": 2,
        "analysis_layers": {
            "L1_facts": [f"ç”¨æˆ·è¾“å…¥: {user_input[:100]}..."],
            "L2_user_model": {},
            "L3_core_tension": "å¾…è¯†åˆ«",
            "L4_project_task": user_input[:200],
            "L5_sharpness": {"score": 50},
        },
        "structured_output": {
            "project_task": user_input[:200],
            "character_narrative": "å¾…åˆ†æ",
            "physical_context": "å¾…æ˜ç¡®",
            "resource_constraints": "å¾…æ˜ç¡®",
        },
        "expert_handoff": {},
        "fallback": True,
    }

    elapsed_ms = (time.time() - start_time) * 1000

    return {
        "phase2_result": phase2_result,
        "phase2_elapsed_ms": elapsed_ms,
        "analysis_layers": phase2_result["analysis_layers"],
        "expert_handoff": phase2_result["expert_handoff"],
        "processing_log": state.get("processing_log", []) + [f"[Phase2] Fallback ({elapsed_ms:.0f}ms)"],
        "node_path": state.get("node_path", []) + ["phase2"],
    }


def _build_phase1_only_result(phase1_result: Dict[str, Any], user_input: str) -> Dict[str, Any]:
    """æ„å»ºä»… Phase1 çš„ç»“æœ"""
    return {
        "project_task": phase1_result.get("project_summary", user_input[:200]),
        "character_narrative": "å¾…é—®å·è¡¥å……ååˆ†æ",
        "physical_context": "å¾…æ˜ç¡®",
        "resource_constraints": "å¾…æ˜ç¡®",
        "regulatory_requirements": "å¾…æ˜ç¡®",
        "inspiration_references": "å¾…è¡¥é½",
        "experience_behavior": "å¾…è¡¥é½",
        "design_challenge": "å¾…è¯†åˆ«",
        "primary_deliverables": phase1_result.get("primary_deliverables", []),
        "info_status": phase1_result.get("info_status"),
        "info_gaps": phase1_result.get("info_gaps", []),
        "skip_phase2_reason": phase1_result.get("info_status_reason", "ä¿¡æ¯ä¸è¶³"),
        "project_overview": phase1_result.get("project_summary", user_input[:200]),
        "core_objectives": [],
        "project_tasks": [],
    }


def _merge_phase_results(phase1: Dict, phase2: Dict, user_input: str) -> Dict[str, Any]:
    """åˆå¹¶ Phase1 å’Œ Phase2 ç»“æœ"""
    structured_output = phase2.get("structured_output", {})

    return {
        "project_task": structured_output.get("project_task", ""),
        "character_narrative": structured_output.get("character_narrative", ""),
        "physical_context": structured_output.get("physical_context", ""),
        "resource_constraints": structured_output.get("resource_constraints", ""),
        "regulatory_requirements": structured_output.get("regulatory_requirements", ""),
        "inspiration_references": structured_output.get("inspiration_references", ""),
        "experience_behavior": structured_output.get("experience_behavior", ""),
        "design_challenge": structured_output.get("design_challenge", ""),
        "primary_deliverables": phase1.get("primary_deliverables", []),
        "info_status": phase1.get("info_status"),
        "project_type_preliminary": phase1.get("project_type_preliminary"),
        "analysis_layers": phase2.get("analysis_layers", {}),
        "expert_handoff": phase2.get("expert_handoff", {}),
        "project_overview": structured_output.get("project_task", ""),
        "core_objectives": [structured_output.get("project_task", "")[:100]]
        if structured_output.get("project_task")
        else [],
        "project_tasks": [structured_output.get("project_task", "")] if structured_output.get("project_task") else [],
    }


def _calculate_two_phase_confidence(phase1: Dict, phase2: Dict) -> float:
    """è®¡ç®—ä¸¤é˜¶æ®µç½®ä¿¡åº¦"""
    confidence = 0.5

    if phase1.get("info_status") == "sufficient":
        confidence += 0.1
    if len(phase1.get("primary_deliverables", [])) > 0:
        confidence += 0.1

    sharpness = phase2.get("analysis_layers", {}).get("L5_sharpness", {})
    if isinstance(sharpness, dict):
        score = sharpness.get("score", 0)
        confidence += min(score / 200, 0.2)

    if phase2.get("expert_handoff", {}).get("critical_questions_for_experts"):
        confidence += 0.1

    return min(confidence, 1.0)


def _normalize_jtbd_fields(structured_data: Dict[str, Any]) -> None:
    """JTBD å­—æ®µè§„èŒƒåŒ–"""
    for field in ["project_task", "project_overview"]:
        value = structured_data.get(field)
        if isinstance(value, str):
            structured_data[field] = transform_jtbd_to_natural_language(value)


def _infer_project_type(structured_data: Dict[str, Any]) -> Optional[str]:
    """æ¨æ–­é¡¹ç›®ç±»å‹"""
    all_text = " ".join(
        [
            str(structured_data.get("project_task", "")),
            str(structured_data.get("character_narrative", "")),
            str(structured_data.get("project_overview", "")),
        ]
    ).lower()

    personal_keywords = ["ä½å®…", "å®¶", "å…¬å¯“", "åˆ«å¢…", "æˆ¿å­", "å±…ä½", "å§å®¤", "å®¢å…", "å®¶åº­"]
    commercial_keywords = ["åŠå…¬", "å•†ä¸š", "ä¼ä¸š", "é¤å…", "é…’åº—", "åº—é“º", "å±•å…", "èœå¸‚åœº"]

    personal_score = sum(1 for kw in personal_keywords if kw in all_text)
    commercial_score = sum(1 for kw in commercial_keywords if kw in all_text)

    if personal_score > 0 and commercial_score > 0:
        return "hybrid_residential_commercial"
    elif personal_score > commercial_score:
        return "personal_residential"
    elif commercial_score > personal_score:
        return "commercial_enterprise"
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. StateGraph æ„å»º
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def build_requirements_analyst_graph() -> StateGraph:
    """
    æ„å»ºéœ€æ±‚åˆ†æå¸ˆ StateGraph

    èŠ‚ç‚¹æµè½¬:
    START â†’ precheck â†’ phase1 â†’ [æ¡ä»¶] â†’ phase2 â†’ output â†’ END
                                    â†“
                                  output â†’ END
    """
    workflow = StateGraph(RequirementsAnalystState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("precheck", precheck_node)
    workflow.add_node("phase1", phase1_node)
    workflow.add_node("phase2", phase2_node)
    workflow.add_node("output", output_node)

    # æ·»åŠ è¾¹
    workflow.add_edge(START, "precheck")
    workflow.add_edge("precheck", "phase1")

    # æ¡ä»¶è¾¹: Phase1 â†’ Phase2 æˆ– Output
    workflow.add_conditional_edges("phase1", should_execute_phase2, {"phase2": "phase2", "output": "output"})

    workflow.add_edge("phase2", "output")
    workflow.add_edge("output", END)

    return workflow


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. Agent å°è£…ç±»
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class RequirementsAnalystAgentV2:
    """
    éœ€æ±‚åˆ†æå¸ˆ StateGraph Agent (v7.17 P3)

    å°è£… StateGraphï¼Œæä¾›ç»Ÿä¸€çš„æ‰§è¡Œæ¥å£
    """

    def __init__(self, llm_model, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ– Agent

        Args:
            llm_model: LLM æ¨¡å‹å®ä¾‹
            config: å¯é€‰é…ç½®
        """
        self.llm_model = llm_model
        self.config = config or {}
        self.prompt_manager = PromptManager()

        # æ„å»ºå¹¶ç¼–è¯‘å›¾
        self._graph = build_requirements_analyst_graph().compile()

        logger.info("âœ… [RequirementsAnalystAgentV2] StateGraph Agent åˆå§‹åŒ–å®Œæˆ")

    def execute(self, user_input: str, session_id: str = "unknown") -> AnalysisResult:
        """
        æ‰§è¡Œéœ€æ±‚åˆ†æ

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ ID

        Returns:
            AnalysisResult åˆ†æç»“æœ
        """
        logger.info(f"ğŸš€ [RequirementsAnalystAgentV2] å¯åŠ¨åˆ†æ (session: {session_id})")

        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_state: RequirementsAnalystState = {
            "user_input": user_input,
            "session_id": session_id,
            "_llm_model": self.llm_model,
            "_prompt_manager": self.prompt_manager,
            "processing_log": [],
            "node_path": [],
        }

        # æ‰§è¡Œå›¾
        final_state = self._graph.invoke(initial_state)

        # æ„å»º AnalysisResult
        result = AnalysisResult(
            agent_type=AgentType.REQUIREMENTS_ANALYST,
            content=json.dumps(final_state.get("structured_data", {}), ensure_ascii=False, indent=2),
            structured_data=final_state.get("structured_data", {}),
            confidence=final_state.get("confidence", 0.5),
            sources=["user_input", "stategraph_analysis"],
            metadata={
                "analysis_mode": final_state.get("analysis_mode"),
                "project_type": final_state.get("project_type"),
                "total_elapsed_ms": final_state.get("total_elapsed_ms"),
                "node_path": final_state.get("node_path"),
                "processing_log": final_state.get("processing_log"),
            },
        )

        logger.info(f"ğŸ [RequirementsAnalystAgentV2] åˆ†æå®Œæˆï¼Œè€—æ—¶ {final_state.get('total_elapsed_ms', 0):.0f}ms")

        return result

    def get_graph(self):
        """è¿”å›ç¼–è¯‘åçš„å›¾ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        return self._graph


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. å‘åå…¼å®¹å±‚
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class RequirementsAnalystCompat:
    """
    å‘åå…¼å®¹å±‚

    ä¿æŒä¸åŸ RequirementsAnalystAgent ç›¸åŒçš„æ¥å£ï¼Œ
    å†…éƒ¨ä½¿ç”¨ StateGraph Agent æ‰§è¡Œ
    """

    def __init__(self, llm_model, config: Optional[Dict[str, Any]] = None):
        self._agent = RequirementsAnalystAgentV2(llm_model, config)
        self.llm_model = llm_model
        self.config = config

    def execute(
        self, state: Dict[str, Any], config=None, store=None, use_two_phase: bool = True  # é»˜è®¤ä½¿ç”¨ StateGraph æ¨¡å¼
    ) -> AnalysisResult:
        """
        å…¼å®¹åŸæ¥å£çš„ execute æ–¹æ³•
        """
        user_input = state.get("user_input", "")
        session_id = state.get("session_id", "unknown")

        return self._agent.execute(user_input, session_id)
