"""
ç»“æœèšåˆæ™ºèƒ½ä½“ (LangGraph StateGraph)

ğŸ”¥ v7.16: å°† ResultAggregatorAgent å‡çº§ä¸ºçœŸæ­£çš„ LangGraph Agent

æ ¸å¿ƒåŠŸèƒ½:
1. æå–ä¸“å®¶æŠ¥å‘Š (Extract Reports)
2. æå–é—®å·/éœ€æ±‚æ•°æ® (Extract Context Data)
3. LLMç»“æ„åŒ–è¾“å‡º (Generate Structured Report)
4. éªŒè¯å®Œæ•´æ€§ (Validate Report)

èŠ‚ç‚¹æµè½¬:
    extract_reports â†’ extract_context â†’ generate_report â†’ validate_output â†’ END
"""

from typing import TypedDict, Dict, Any, List, Optional
from loguru import logger
from datetime import datetime
import json
import time

from langgraph.graph import StateGraph, START, END

# å¯¼å…¥å…±äº«å·¥å…·å‡½æ•°
from ..utils.shared_agent_utils import PerformanceMonitor, extract_expert_reports


# ============================================================================
# çŠ¶æ€å®šä¹‰
# ============================================================================

class ResultAggregatorState(TypedDict):
    """ç»“æœèšåˆæ™ºèƒ½ä½“çŠ¶æ€"""
    
    # è¾“å…¥
    agent_results: Dict[str, Any]   # æ‰€æœ‰ä¸“å®¶çš„åˆ†æç»“æœ
    selected_roles: List[Dict]      # é€‰å®šçš„è§’è‰²åˆ—è¡¨
    structured_requirements: Dict    # ç»“æ„åŒ–éœ€æ±‚
    user_input: str                 # ç”¨æˆ·åŸå§‹è¾“å…¥
    questionnaire_data: Dict        # é—®å·æ•°æ®
    review_history: List[Dict]      # å®¡æ ¸å†å²
    
    # ä¸­é—´çŠ¶æ€
    expert_reports: Dict[str, str]  # æå–çš„ä¸“å®¶æŠ¥å‘Š
    context_data: Dict[str, Any]    # ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆé—®å·ã€éœ€æ±‚ç­‰ï¼‰
    llm_response: Dict[str, Any]    # LLMåŸå§‹å“åº”
    
    # è¾“å‡º
    final_report: Dict[str, Any]    # æœ€ç»ˆæŠ¥å‘Š
    validation_result: Dict[str, Any]  # éªŒè¯ç»“æœ
    is_valid: bool                  # æŠ¥å‘Šæ˜¯å¦æœ‰æ•ˆ
    
    # é…ç½®
    _llm_model: Any                 # LLMæ¨¡å‹
    _config: Dict[str, Any]         # é…ç½®å‚æ•°
    
    # å¤„ç†æ—¥å¿—
    processing_log: List[str]


# ============================================================================
# èŠ‚ç‚¹å‡½æ•°
# ============================================================================

def extract_reports_node(state: ResultAggregatorState) -> Dict[str, Any]:
    """
    æå–ä¸“å®¶æŠ¥å‘ŠèŠ‚ç‚¹ - ä» agent_results ä¸­æå–å„ä¸“å®¶çš„è¾“å‡º
    """
    logger.info("ğŸ“‹ æ‰§è¡Œä¸“å®¶æŠ¥å‘Šæå–èŠ‚ç‚¹")
    
    agent_results = state.get("agent_results", {})
    selected_roles = state.get("selected_roles", [])
    
    # æ„å»º role_id -> æ˜¾ç¤ºåç§° æ˜ å°„
    role_display_names = {}
    for role in selected_roles:
        if isinstance(role, dict):
            role_id = role.get("role_id", "")
            dynamic_name = role.get("dynamic_role_name", role.get("role_name", ""))
            if role_id:
                # æå–å±‚çº§ç¼–å·ï¼ˆå¦‚ V4_xxx_4-1 â†’ 4-1ï¼‰
                parts = role_id.split("_")
                suffix = parts[-1] if len(parts) > 1 else role_id
                # æ„å»ºæ˜¾ç¤ºåç§°ï¼šç¼–å· + åŠ¨æ€åç§°
                display_name = f"{suffix} {dynamic_name}" if dynamic_name else role_id
                role_display_names[role_id] = display_name
    
    # æå–ä¸“å®¶æŠ¥å‘Š
    expert_reports = {}
    skip_agents = {"requirements_analyst", "project_director", "RESULT_AGGREGATOR", "REPORT_GENERATOR"}
    
    for agent_id, result in agent_results.items():
        # è·³è¿‡éä¸“å®¶ç»“æœ
        if agent_id in skip_agents:
            continue
        
        # åªå¤„ç† V2-V6 ä¸“å®¶
        if not any(agent_id.startswith(f"V{i}") for i in range(2, 7)):
            continue
        
        if not isinstance(result, dict):
            continue
        
        # è·å–æ˜¾ç¤ºåç§°
        display_name = role_display_names.get(agent_id, agent_id)
        
        # æå–å†…å®¹
        content = _extract_agent_content(result)
        
        if content:
            expert_reports[display_name] = content
            logger.debug(f"  âœ… æå– {display_name}: {len(content)} å­—ç¬¦")
    
    log_entry = f"ğŸ“‹ æå–å®Œæˆ: {len(expert_reports)} ä¸ªä¸“å®¶æŠ¥å‘Š"
    logger.info(log_entry)
    
    return {
        "expert_reports": expert_reports,
        "processing_log": [log_entry]
    }


def extract_context_node(state: ResultAggregatorState) -> Dict[str, Any]:
    """
    æå–ä¸Šä¸‹æ–‡æ•°æ®èŠ‚ç‚¹ - é—®å·å›ç­”ã€éœ€æ±‚åˆ†æç­‰
    """
    logger.info("ğŸ“ æ‰§è¡Œä¸Šä¸‹æ–‡æ•°æ®æå–èŠ‚ç‚¹")
    
    context_data = {}
    
    # æå–é—®å·æ•°æ®
    questionnaire_data = state.get("questionnaire_data", {})
    if questionnaire_data:
        context_data["questionnaire_responses"] = questionnaire_data
        logger.debug(f"  âœ… é—®å·æ•°æ®: {len(questionnaire_data)} é¡¹")
    
    # æå–éœ€æ±‚åˆ†æ
    structured_requirements = state.get("structured_requirements", {})
    if structured_requirements:
        context_data["requirements_analysis"] = structured_requirements
        logger.debug("  âœ… éœ€æ±‚åˆ†æå·²æå–")
    
    # æå–å®¡æ ¸å†å²
    review_history = state.get("review_history", [])
    if review_history:
        context_data["review_history"] = review_history
        logger.debug(f"  âœ… å®¡æ ¸å†å²: {len(review_history)} è½®")
    
    log_entry = f"ğŸ“ ä¸Šä¸‹æ–‡æå–å®Œæˆ: {len(context_data)} ç±»æ•°æ®"
    logger.info(log_entry)
    
    return {
        "context_data": context_data,
        "processing_log": [log_entry]
    }


def generate_report_node(state: ResultAggregatorState) -> Dict[str, Any]:
    """
    ç”ŸæˆæŠ¥å‘ŠèŠ‚ç‚¹ - è°ƒç”¨LLMç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
    """
    logger.info("ğŸ¤– æ‰§è¡ŒLLMæŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹")
    
    llm_model = state.get("_llm_model")
    expert_reports = state.get("expert_reports", {})
    context_data = state.get("context_data", {})
    user_input = state.get("user_input", "")
    
    if not llm_model:
        logger.warning("âš ï¸ æœªæä¾›LLMæ¨¡å‹ï¼Œä½¿ç”¨æ¨¡æ¿æŠ¥å‘Š")
        return _generate_template_report(expert_reports, context_data, user_input)
    
    # æ„å»ºæŠ¥å‘Šç”Ÿæˆæç¤º
    prompt = _build_report_prompt(expert_reports, context_data, user_input)
    
    try:
        start_time = time.time()
        
        # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š
        from langchain_core.messages import HumanMessage, SystemMessage
        
        messages = [
            SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®æŠ¥å‘Šæ•´åˆä¸“å®¶ã€‚
è¯·æ ¹æ®å„ä¸“å®¶çš„åˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„é¡¹ç›®åˆ†ææŠ¥å‘Šã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1. executive_summary: æ‰§è¡Œæ‘˜è¦
2. core_answer: æ ¸å¿ƒç­”æ¡ˆ
3. insights: å…³é”®æ´å¯Ÿ
4. recommendations: å»ºè®®åˆ—è¡¨

è¯·ä½¿ç”¨JSONæ ¼å¼è¾“å‡ºã€‚"""),
            HumanMessage(content=prompt)
        ]
        
        response = llm_model.invoke(messages)
        elapsed_time = time.time() - start_time
        
        # è§£æå“åº”
        llm_response = _parse_llm_response(response.content)
        
        log_entry = f"ğŸ¤– LLMç”Ÿæˆå®Œæˆ: {elapsed_time:.2f}ç§’"
        logger.info(log_entry)
        
        return {
            "llm_response": llm_response,
            "processing_log": [log_entry]
        }
        
    except Exception as e:
        logger.error(f"âŒ LLMæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        return _generate_template_report(expert_reports, context_data, user_input)


def validate_output_node(state: ResultAggregatorState) -> Dict[str, Any]:
    """
    éªŒè¯è¾“å‡ºèŠ‚ç‚¹ - æ£€æŸ¥æŠ¥å‘Šå®Œæ•´æ€§å¹¶åˆæˆæœ€ç»ˆæŠ¥å‘Š
    """
    logger.info("âœ… æ‰§è¡ŒæŠ¥å‘ŠéªŒè¯èŠ‚ç‚¹")
    
    expert_reports = state.get("expert_reports", {})
    context_data = state.get("context_data", {})
    llm_response = state.get("llm_response", {})
    user_input = state.get("user_input", "")
    
    # åˆæˆæœ€ç»ˆæŠ¥å‘Š
    final_report = {
        "user_input": user_input,
        "expert_reports": expert_reports,
        "executive_summary": llm_response.get("executive_summary", {}),
        "core_answer": llm_response.get("core_answer", {}),
        "insights": llm_response.get("insights", {}),
        "recommendations": llm_response.get("recommendations", {}),
        "questionnaire_responses": context_data.get("questionnaire_responses", {}),
        "requirements_analysis": context_data.get("requirements_analysis", {}),
        "review_history": context_data.get("review_history", []),
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "expert_count": len(expert_reports),
            "generation_method": "langgraph_agent"
        }
    }
    
    # éªŒè¯å¿…è¦å­—æ®µ
    validation_errors = []
    
    if not expert_reports:
        validation_errors.append("ç¼ºå°‘ä¸“å®¶æŠ¥å‘Š")
    
    if not final_report.get("executive_summary"):
        validation_errors.append("ç¼ºå°‘æ‰§è¡Œæ‘˜è¦")
    
    is_valid = len(validation_errors) == 0
    
    validation_result = {
        "is_valid": is_valid,
        "errors": validation_errors,
        "warnings": [],
        "expert_count": len(expert_reports),
        "has_questionnaire": bool(context_data.get("questionnaire_responses")),
        "has_requirements": bool(context_data.get("requirements_analysis"))
    }
    
    log_entry = f"âœ… éªŒè¯å®Œæˆ: {'é€šè¿‡' if is_valid else f'å¤±è´¥({len(validation_errors)}ä¸ªé”™è¯¯)'}"
    logger.info(log_entry)
    
    return {
        "final_report": final_report,
        "validation_result": validation_result,
        "is_valid": is_valid,
        "processing_log": [log_entry]
    }


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def _extract_agent_content(result: Dict[str, Any]) -> str:
    """ä»ä¸“å®¶ç»“æœä¸­æå–å†…å®¹"""
    
    # ä¼˜å…ˆä½¿ç”¨ structured_data
    structured_data = result.get("structured_data")
    if structured_data and isinstance(structured_data, dict):
        return json.dumps(structured_data, ensure_ascii=False, indent=2)
    
    # å…¶æ¬¡ä½¿ç”¨ content
    content = result.get("content")
    if content:
        if isinstance(content, dict):
            return json.dumps(content, ensure_ascii=False, indent=2)
        return str(content)
    
    # æœ€åå°è¯• deliverable_outputs
    deliverables = result.get("deliverable_outputs", [])
    if deliverables:
        outputs = []
        for d in deliverables:
            if isinstance(d, dict):
                name = d.get("name", "æœªå‘½å")
                content = d.get("content", "")
                outputs.append(f"### {name}\n{content}")
        return "\n\n".join(outputs)
    
    return ""


def _build_report_prompt(
    expert_reports: Dict[str, str],
    context_data: Dict[str, Any],
    user_input: str
) -> str:
    """æ„å»ºæŠ¥å‘Šç”Ÿæˆæç¤º"""
    
    prompt = f"""# é¡¹ç›®åˆ†ææŠ¥å‘Šç”Ÿæˆ

## ç”¨æˆ·éœ€æ±‚
{user_input}

## ä¸“å®¶åˆ†æç»“æœ
"""
    
    for expert_name, content in expert_reports.items():
        # æˆªå–å‰2000å­—ç¬¦é¿å…è¿‡é•¿
        truncated = content[:2000] + "..." if len(content) > 2000 else content
        prompt += f"\n### {expert_name}\n{truncated}\n"
    
    # æ·»åŠ éœ€æ±‚åˆ†æ
    requirements = context_data.get("requirements_analysis", {})
    if requirements:
        prompt += f"\n## éœ€æ±‚åˆ†ææ‘˜è¦\n{json.dumps(requirements, ensure_ascii=False, indent=2)[:1000]}\n"
    
    prompt += """
## è¾“å‡ºè¦æ±‚
è¯·ç”Ÿæˆä»¥ä¸‹JSONæ ¼å¼çš„æŠ¥å‘Š:
{
    "executive_summary": {
        "project_overview": "é¡¹ç›®æ¦‚è¿°",
        "key_findings": ["å…³é”®å‘ç°1", "å…³é”®å‘ç°2"],
        "key_recommendations": ["æ ¸å¿ƒå»ºè®®1", "æ ¸å¿ƒå»ºè®®2"]
    },
    "core_answer": {
        "question": "ç”¨æˆ·çš„æ ¸å¿ƒé—®é¢˜",
        "answer": "ç›´æ¥æ˜äº†çš„ç­”æ¡ˆ"
    },
    "insights": {
        "key_insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2"],
        "cross_domain_connections": ["è·¨é¢†åŸŸå…³è”"]
    },
    "recommendations": {
        "recommendations": [
            {"content": "å»ºè®®å†…å®¹", "dimension": "critical", "reasoning": "åŸå› "}
        ]
    }
}
"""
    
    return prompt


def _parse_llm_response(content: str) -> Dict[str, Any]:
    """è§£æLLMå“åº”"""
    
    # å°è¯•æå–JSON
    try:
        # æŸ¥æ‰¾JSONä»£ç å—
        import re
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
        if json_match:
            return json.loads(json_match.group(1))
        
        # ç›´æ¥å°è¯•è§£æ
        return json.loads(content)
        
    except json.JSONDecodeError:
        logger.warning("âš ï¸ LLMå“åº”éJSONæ ¼å¼ï¼Œä½¿ç”¨æ–‡æœ¬æ‘˜è¦")
        return {
            "executive_summary": {
                "project_overview": content[:500],
                "key_findings": [],
                "key_recommendations": []
            },
            "core_answer": {
                "question": "å¾…è§£æ",
                "answer": content[:200]
            },
            "insights": {},
            "recommendations": {}
        }


def _generate_template_report(
    expert_reports: Dict[str, str],
    context_data: Dict[str, Any],
    user_input: str
) -> Dict[str, Any]:
    """ç”Ÿæˆæ¨¡æ¿æŠ¥å‘Šï¼ˆæ— LLMæ—¶çš„å›é€€ï¼‰"""
    
    log_entry = "âš ï¸ ä½¿ç”¨æ¨¡æ¿æŠ¥å‘Šç”Ÿæˆï¼ˆæ— LLMï¼‰"
    logger.warning(log_entry)
    
    return {
        "llm_response": {
            "executive_summary": {
                "project_overview": f"åŸºäº {len(expert_reports)} ä½ä¸“å®¶çš„åˆ†æ",
                "key_findings": [f"ä¸“å®¶ {name} å·²å®Œæˆåˆ†æ" for name in list(expert_reports.keys())[:3]],
                "key_recommendations": ["è¯·æŸ¥é˜…å„ä¸“å®¶è¯¦ç»†æŠ¥å‘Š"]
            },
            "core_answer": {
                "question": user_input[:100] if user_input else "æœªæä¾›",
                "answer": "è¯·æŸ¥é˜…ä¸“å®¶è¯¦ç»†åˆ†æ"
            },
            "insights": {},
            "recommendations": {}
        },
        "processing_log": [log_entry]
    }


# ============================================================================
# çŠ¶æ€å›¾æ„å»º
# ============================================================================

def build_result_aggregator_graph() -> StateGraph:
    """
    æ„å»ºç»“æœèšåˆçŠ¶æ€å›¾
    
    æµç¨‹:
        START â†’ extract_reports â†’ extract_context â†’ generate_report â†’ validate_output â†’ END
    """
    workflow = StateGraph(ResultAggregatorState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("extract_reports", extract_reports_node)
    workflow.add_node("extract_context", extract_context_node)
    workflow.add_node("generate_report", generate_report_node)
    workflow.add_node("validate_output", validate_output_node)
    
    # æ·»åŠ è¾¹
    workflow.add_edge(START, "extract_reports")
    workflow.add_edge("extract_reports", "extract_context")
    workflow.add_edge("extract_context", "generate_report")
    workflow.add_edge("generate_report", "validate_output")
    workflow.add_edge("validate_output", END)
    
    return workflow


# ============================================================================
# Agent å°è£…ç±»
# ============================================================================

class ResultAggregatorAgentV2:
    """
    ç»“æœèšåˆæ™ºèƒ½ä½“ V2 - LangGraph å°è£…
    
    ä½¿ç”¨æ–¹å¼:
        agent = ResultAggregatorAgentV2(llm_model)
        result = agent.execute(state)
    """
    
    def __init__(self, llm_model=None, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–ç»“æœèšåˆæ™ºèƒ½ä½“
        
        Args:
            llm_model: LLMæ¨¡å‹å®ä¾‹
            config: é…ç½®å‚æ•°
        """
        self.llm_model = llm_model
        self.config = config or {}
        
        # æ„å»ºå¹¶ç¼–è¯‘çŠ¶æ€å›¾
        self._graph = build_result_aggregator_graph().compile()
        
        logger.info("ğŸš€ ResultAggregatorAgentV2 (LangGraph) å·²åˆå§‹åŒ–")
    
    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œç»“æœèšåˆ
        
        Args:
            state: é¡¹ç›®åˆ†æçŠ¶æ€
            
        Returns:
            èšåˆç»“æœå­—å…¸
        """
        logger.info("ğŸ¯ ResultAggregatorAgentV2 å¼€å§‹æ‰§è¡Œ")
        start_time = time.time()
        
        # å‡†å¤‡åˆå§‹çŠ¶æ€
        initial_state = {
            "agent_results": state.get("agent_results", {}),
            "selected_roles": state.get("strategic_analysis", {}).get("selected_roles", []),
            "structured_requirements": state.get("structured_requirements", {}),
            "user_input": state.get("user_input", ""),
            "questionnaire_data": self._extract_questionnaire_from_state(state),
            "review_history": state.get("review_history", []),
            
            # é…ç½®
            "_llm_model": self.llm_model,
            "_config": self.config,
            
            # åˆå§‹åŒ–ä¸­é—´çŠ¶æ€
            "expert_reports": {},
            "context_data": {},
            "llm_response": {},
            
            # åˆå§‹åŒ–è¾“å‡º
            "final_report": {},
            "validation_result": {},
            "is_valid": False,
            "processing_log": []
        }
        
        # æ‰§è¡ŒçŠ¶æ€å›¾
        try:
            final_state = self._graph.invoke(initial_state)
            
            # æå–ç»“æœ
            final_report = final_state.get("final_report", {})
            
            logger.info(f"âœ… ResultAggregatorAgentV2 å®Œæˆ: {len(final_report.get('expert_reports', {}))} ä¸“å®¶æŠ¥å‘Š")
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            PerformanceMonitor.record("ResultAggregatorAgentV2", time.time() - start_time, "v7.16")
            
            return {
                "structured_data": final_report,
                "validation": final_state.get("validation_result", {}),
                "processing_log": final_state.get("processing_log", [])
            }
            
        except Exception as e:
            # è®°å½•å¤±è´¥æ—¶çš„æ€§èƒ½æŒ‡æ ‡
            PerformanceMonitor.record("ResultAggregatorAgentV2", time.time() - start_time, "v7.16-error")
            
            logger.error(f"âŒ ResultAggregatorAgentV2 æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
            return {
                "structured_data": {
                    "user_input": state.get("user_input", ""),
                    "expert_reports": {},
                    "error": str(e)
                },
                "validation": {"is_valid": False, "errors": [str(e)]},
                "processing_log": [f"âŒ æ‰§è¡Œå¤±è´¥: {e}"]
            }
    
    def _extract_questionnaire_from_state(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ä»çŠ¶æ€ä¸­æå–é—®å·æ•°æ®"""
        calibration = state.get("calibration_questionnaire", {})
        responses = state.get("questionnaire_responses", {})
        summary = state.get("questionnaire_summary", {})
        
        if calibration or responses or summary:
            return {
                "calibration": calibration,
                "responses": responses,
                "summary": summary
            }
        return {}
    
    def to_dict(self) -> Dict[str, Any]:
        """å…¼å®¹æ—§æ¥å£"""
        return {"agent_type": "ResultAggregatorAgentV2"}


# ============================================================================
# å‘åå…¼å®¹å±‚ - åŒ…è£…åŸæœ‰ ResultAggregatorAgent
# ============================================================================

class ResultAggregatorAgentCompat:
    """
    å‘åå…¼å®¹å±‚ - å¯é€‰æ‹©ä½¿ç”¨æ–°ç‰ˆæˆ–æ—§ç‰ˆ Agent
    
    é…ç½®:
        USE_LANGGRAPH_AGGREGATOR=true  â†’ ä½¿ç”¨æ–°ç‰ˆ LangGraph Agent
        USE_LANGGRAPH_AGGREGATOR=false â†’ ä½¿ç”¨åŸç‰ˆ Agent
    """
    
    def __init__(self, llm_model=None, config: Optional[Dict[str, Any]] = None):
        import os
        self.use_langgraph = os.getenv("USE_LANGGRAPH_AGGREGATOR", "false").lower() == "true"
        
        if self.use_langgraph:
            self._agent = ResultAggregatorAgentV2(llm_model, config)
            logger.info("ğŸ“Š ä½¿ç”¨ LangGraph ç‰ˆæœ¬ ResultAggregatorAgent")
        else:
            # å¯¼å…¥åŸç‰ˆ
            from ..report.result_aggregator import ResultAggregatorAgent as OriginalAgent
            self._agent = OriginalAgent(llm_model=llm_model, config=config)
            logger.info("ğŸ“Š ä½¿ç”¨åŸç‰ˆ ResultAggregatorAgent")
    
    def execute(self, state, config=None, store=None):
        """ç»Ÿä¸€æ‰§è¡Œæ¥å£"""
        if self.use_langgraph:
            result = self._agent.execute(state)
            # è½¬æ¢ä¸º AnalysisResult æ ¼å¼
            from ..core.types import AnalysisResult
            return AnalysisResult(
                content=json.dumps(result.get("structured_data", {}), ensure_ascii=False),
                structured_data=result.get("structured_data", {}),
                confidence=1.0 if result.get("validation", {}).get("is_valid") else 0.5
            )
        else:
            return self._agent.execute(state, config, store)
