"""
æœç´¢ç­–ç•¥ç”Ÿæˆå™¨

æ ¹æ®å®¢æˆ·è¦æ±‚ï¼š
- æ¯ä½ä¸“å®¶éƒ½æœ‰æ˜ç¡®çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯è‡ªå·±éšæ„æœç´¢
- å„ä¸“å®¶çš„æœç´¢ï¼Œå‡éœ€è¦ç‹¬ç«‹çš„ç­–ç•¥
- æœç´¢å…³é”®è¯åº”è¯¥æ ¹æ®é¡¹ç›®éœ€æ±‚åŠ¨æ€ç”Ÿæˆ
"""

import json
from typing import Any, Dict, Optional

from langchain_core.messages import HumanMessage, SystemMessage
from loguru import logger


class SearchStrategyGenerator:
    """æœç´¢ç­–ç•¥ç”Ÿæˆå™¨ - ä¸ºä¸“å®¶ç”Ÿæˆç‹¬ç«‹çš„æœç´¢ç­–ç•¥"""

    def __init__(self, llm_model=None):
        """
        åˆå§‹åŒ–æœç´¢ç­–ç•¥ç”Ÿæˆå™¨

        Args:
            llm_model: LLMæ¨¡å‹å®ä¾‹ï¼ˆç”¨äºåŠ¨æ€ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼‰
        """
        self.llm_model = llm_model

    def generate_deliverable_queries(
        self,
        deliverable_name: str,
        deliverable_description: str = "",
        keywords: list = None,
        constraints: dict = None,
        project_task: str = "",
        user_input: str = "",  # ğŸ”¥ v7.121: æ–°å¢ - ç”¨æˆ·åŸå§‹é—®é¢˜
        questionnaire_summary: dict = None,  # ğŸ”¥ v7.121: æ–°å¢ - é—®å·ç²¾ç‚¼æ‘˜è¦
        num_queries: int = 3,
    ) -> list:
        """
        âœ… v7.121: ä¸ºå•ä¸ªäº¤ä»˜ç‰©ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼ˆå¢å¼ºæ•°æ®åˆ©ç”¨ï¼‰

        Args:
            deliverable_name: äº¤ä»˜ç‰©åç§°
            deliverable_description: äº¤ä»˜ç‰©æè¿°
            keywords: å…³é”®è¯åˆ—è¡¨
            constraints: çº¦æŸæ¡ä»¶å­—å…¸
            project_task: é¡¹ç›®ä»»åŠ¡æè¿°
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥ï¼ˆå®Œæ•´é—®é¢˜æè¿°ï¼‰
            questionnaire_summary: é—®å·ç²¾ç‚¼æ‘˜è¦ï¼ˆé£æ ¼åå¥½ã€åŠŸèƒ½éœ€æ±‚ã€æƒ…æ„Ÿéœ€æ±‚ç­‰ï¼‰
            num_queries: ç”ŸæˆæŸ¥è¯¢æ•°é‡

        Returns:
            æœç´¢æŸ¥è¯¢åˆ—è¡¨
        """
        keywords = keywords or []
        constraints = constraints or {}

        # ğŸ”¥ v7.121: é™çº§æ–¹æ¡ˆ - ç”ŸæˆåŸºäºæ¨¡æ¿çš„æŸ¥è¯¢ï¼ˆæ•´åˆç”¨æˆ·æ•°æ®ï¼‰
        queries = []

        # ä»é—®å·æ‘˜è¦ä¸­æå–å…³é”®ä¿¡æ¯
        style_keywords = []
        emotion_keywords = []
        if questionnaire_summary:
            style_keywords = questionnaire_summary.get("style_preferences", [])[:2]
            emotion_keywords = questionnaire_summary.get("emotional_requirements", [])[:2]

        # æŸ¥è¯¢1: äº¤ä»˜ç‰© + é£æ ¼åå¥½
        style_str = " ".join(style_keywords) if style_keywords else ""
        queries.append(f"{deliverable_name} {style_str} è®¾è®¡æ¡ˆä¾‹ 2024".strip())

        # æŸ¥è¯¢2: å…³é”®è¯ + æƒ…æ„Ÿéœ€æ±‚
        keywords_str = " ".join(keywords[:2]) if keywords else deliverable_name
        emotion_str = " ".join(emotion_keywords) if emotion_keywords else "best practices"
        queries.append(f"{keywords_str} {emotion_str}".strip())

        # æŸ¥è¯¢3: æè¿° + ç”¨æˆ·åŸå§‹éœ€æ±‚
        if deliverable_description:
            # å–æè¿°çš„å‰30ä¸ªå­—ç¬¦ä½œä¸ºæŸ¥è¯¢
            desc_short = deliverable_description[:30].replace("\n", " ").strip()
            queries.append(f"{desc_short} ç ”ç©¶èµ„æ–™")
        elif user_input and len(user_input) > 20:
            # ä»ç”¨æˆ·è¾“å…¥ä¸­æå–å…³é”®çŸ­è¯­
            user_short = user_input[:50].replace("\n", " ").strip()
            queries.append(f"{user_short} ç ”ç©¶èµ„æ–™")
        else:
            queries.append(f"{deliverable_name} ç ”ç©¶èµ„æ–™")

        # å¦‚æœæœ‰LLMï¼Œå°è¯•ç”Ÿæˆæ›´æ™ºèƒ½çš„æŸ¥è¯¢
        if self.llm_model and len(project_task) > 0:
            try:
                llm_queries = self._generate_queries_with_llm(
                    deliverable_name=deliverable_name,
                    deliverable_description=deliverable_description,
                    keywords=keywords,
                    project_task=project_task,
                    user_input=user_input,  # ğŸ”¥ v7.121: ä¼ é€’ç”¨æˆ·è¾“å…¥
                    questionnaire_summary=questionnaire_summary,  # ğŸ”¥ v7.121: ä¼ é€’é—®å·æ‘˜è¦
                    num_queries=num_queries,
                )
                if llm_queries:
                    queries = llm_queries
            except Exception as e:
                logger.warning(f"âš ï¸ LLMç”ŸæˆæŸ¥è¯¢å¤±è´¥: {e}ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ")

        return queries[:num_queries]

    def _generate_queries_with_llm(
        self,
        deliverable_name: str,
        deliverable_description: str,
        keywords: list,
        project_task: str,
        user_input: str = "",  # ğŸ”¥ v7.121: æ–°å¢å‚æ•°
        questionnaire_summary: dict = None,  # ğŸ”¥ v7.121: æ–°å¢å‚æ•°
        num_queries: int = 3,
    ) -> list:
        """ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æœç´¢æŸ¥è¯¢ï¼ˆv7.121å¢å¼ºï¼‰"""

        # ğŸ”¥ v7.121: æ„å»ºé—®å·æ‘˜è¦æ–‡æœ¬
        questionnaire_text = ""
        if questionnaire_summary:
            # æå–å…³é”®ä¿¡æ¯ï¼šé£æ ¼åå¥½ã€åŠŸèƒ½éœ€æ±‚ã€æƒ…æ„Ÿéœ€æ±‚ç­‰
            style_prefs = questionnaire_summary.get("style_preferences", [])
            functional_needs = questionnaire_summary.get("functional_requirements", [])
            emotional_needs = questionnaire_summary.get("emotional_requirements", [])

            if style_prefs or functional_needs or emotional_needs:
                questionnaire_text = "\nç”¨æˆ·åå¥½ï¼ˆæ¥è‡ªé—®å·ï¼‰:\n"
                if style_prefs:
                    questionnaire_text += f"- é£æ ¼åå¥½: {', '.join(style_prefs)}\n"
                if functional_needs:
                    questionnaire_text += f"- åŠŸèƒ½éœ€æ±‚: {', '.join(functional_needs)}\n"
                if emotional_needs:
                    questionnaire_text += f"- æƒ…æ„Ÿéœ€æ±‚: {', '.join(emotional_needs)}\n"

        # ğŸ”¥ v7.121: ç”¨æˆ·åŸå§‹é—®é¢˜ï¼ˆæå–å…³é”®éƒ¨åˆ†ï¼‰
        user_context = ""
        if user_input and len(user_input) > 20:
            user_context = f"\nç”¨æˆ·åŸå§‹éœ€æ±‚:\n{user_input[:300]}\n"

        prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºè®¾è®¡äº¤ä»˜ç‰©ç”Ÿæˆ {num_queries} ä¸ªé«˜è´¨é‡çš„æœç´¢æŸ¥è¯¢ã€‚

äº¤ä»˜ç‰©åç§°: {deliverable_name}
äº¤ä»˜ç‰©æè¿°: {deliverable_description}
å…³é”®è¯: {', '.join(keywords) if keywords else 'æ— '}
é¡¹ç›®èƒŒæ™¯: {project_task[:200]}
{user_context}
{questionnaire_text}

è¦æ±‚ï¼š
1. æ¯ä¸ªæŸ¥è¯¢åº”è¯¥ç²¾å‡†ã€å…·ä½“ï¼Œå……åˆ†åæ˜ ç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚
2. ä¼˜å…ˆæ•´åˆç”¨æˆ·åå¥½å’Œæƒ…æ„Ÿéœ€æ±‚åˆ°æŸ¥è¯¢ä¸­
3. é€‚åˆåœ¨è®¾è®¡æ¡ˆä¾‹ç½‘ç«™ã€å­¦æœ¯èµ„æ–™åº“æœç´¢
4. ç»“åˆä¸­è‹±æ–‡å…³é”®è¯
5. åŒ…å«å¹´ä»½ä¿¡æ¯ï¼ˆ2023-2024ï¼‰

ä»¥JSONæ•°ç»„æ ¼å¼è¾“å‡ºï¼Œä¾‹å¦‚ï¼š
["æŸ¥è¯¢1", "æŸ¥è¯¢2", "æŸ¥è¯¢3"]
"""

        messages = [SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¾è®¡èµ„æ–™æœç´¢ä¸“å®¶ï¼Œæ“…é•¿ç”Ÿæˆé«˜è´¨é‡çš„æœç´¢æŸ¥è¯¢ã€‚"), HumanMessage(content=prompt)]

        response = self.llm_model.invoke(messages, max_tokens=200, temperature=0.5)

        # è§£æJSONå“åº”
        content = response.content.strip()
        start_idx = content.find("[")
        end_idx = content.rfind("]") + 1

        if start_idx != -1 and end_idx > start_idx:
            json_str = content[start_idx:end_idx]
            queries = json.loads(json_str)
            if isinstance(queries, list) and len(queries) > 0:
                logger.debug(f"âœ… LLMç”ŸæˆæŸ¥è¯¢: {queries}")
                return queries

        return None

    def generate_queries(
        self,
        agent_type: str,
        project_task: str,
        character_narrative: str,
        assigned_task: str,
        project_type: str = "auto",
    ) -> Dict[str, str]:
        """
        æ ¹æ®é¡¹ç›®ä¿¡æ¯å’Œåˆ†é…çš„ä»»åŠ¡ï¼ŒåŠ¨æ€ç”Ÿæˆæœç´¢æŸ¥è¯¢

        Args:
            agent_type: ä¸“å®¶ç±»å‹ (V2, V3, V4, V5, V6)
            project_task: é¡¹ç›®ä»»åŠ¡æè¿°
            character_narrative: äººç‰©å™äº‹
            assigned_task: é¡¹ç›®æ€»ç›‘åˆ†é…çš„ä»»åŠ¡
            project_type: é¡¹ç›®ç±»å‹ (auto/interior_design/software/product)

        Returns:
            æœç´¢æŸ¥è¯¢å­—å…¸
        """
        # è‡ªåŠ¨æ£€æµ‹é¡¹ç›®ç±»å‹
        if project_type == "auto":
            project_type = self._detect_project_type(project_task)

        # æå–å…³é”®è¯
        keywords = self._extract_keywords(project_task, character_narrative)

        # æ ¹æ®ä¸“å®¶ç±»å‹ç”ŸæˆæŸ¥è¯¢
        if agent_type == "V2":
            return self._generate_v2_queries(project_type, keywords, assigned_task)
        elif agent_type == "V3":
            return self._generate_v3_queries(project_type, keywords, assigned_task)
        elif agent_type == "V4":
            return self._generate_v4_queries(project_type, keywords, assigned_task)
        elif agent_type == "V5":
            return self._generate_v5_queries(project_type, keywords, assigned_task)
        elif agent_type == "V6":
            return self._generate_v6_queries(project_type, keywords, assigned_task)
        else:
            logger.warning(f"Unknown agent type: {agent_type}, using default queries")
            return self._generate_default_queries(project_type, keywords, assigned_task)

    def _detect_project_type(self, project_task: str) -> str:
        """æ£€æµ‹é¡¹ç›®ç±»å‹"""
        task_lower = project_task.lower()

        if any(
            keyword in task_lower
            for keyword in ["å®¤å†…è®¾è®¡", "ç©ºé—´è®¾è®¡", "ä½å®…", "å•†ä¸š", "åŠå…¬", "é¤é¥®", "é›¶å”®", "è£…ä¿®", "interior", "commercial"]
        ):
            return "interior_design"
        elif any(keyword in task_lower for keyword in ["è½¯ä»¶", "åº”ç”¨", "app", "ç³»ç»Ÿ", "å¹³å°", "software"]):
            return "software"
        elif any(keyword in task_lower for keyword in ["äº§å“", "product", "æœåŠ¡", "service"]):
            return "product"
        else:
            return "general"

    def _extract_keywords(self, project_task: str, character_narrative: str) -> Dict[str, Any]:
        """æå–å…³é”®è¯ - ä½¿ç”¨LLMåŠ¨æ€æå–"""
        # å¦‚æœæ²¡æœ‰LLM,ä½¿ç”¨é™çº§æ–¹æ¡ˆ
        if not self.llm_model:
            logger.warning("No LLM model available, using fallback keyword extraction")
            return self._extract_keywords_fallback(project_task, character_narrative)

        try:
            # ä½¿ç”¨LLMåŠ¨æ€æå–å…³é”®è¯
            prompt = f"""åŸºäºä»¥ä¸‹é¡¹ç›®ä¿¡æ¯,æå–å…³é”®è¯å¹¶åˆ†ç±»ã€‚

é¡¹ç›®ä»»åŠ¡: {project_task}

äººç‰©å™äº‹: {character_narrative}

è¯·æå–ä»¥ä¸‹4ç±»å…³é”®è¯:
1. style: è®¾è®¡é£æ ¼(å¦‚ç°ä»£ã€ç®€çº¦ã€ä¼˜é›…ã€å·¥ä¸šã€åŒ—æ¬§ã€ä¸­å¼ã€æ—¥å¼ç­‰)
2. target_user: ç›®æ ‡ç”¨æˆ·(å¦‚ç‹¬ç«‹å¥³æ€§ã€å®¶åº­ã€ä¼ä¸šã€å¹´è½»ç™½é¢†ã€é’å°‘å¹´ç­‰)
3. features: é¡¹ç›®ç‰¹å¾(å¦‚å•†ä¸šè¡—åŒºã€é›¶å”®ç©ºé—´ã€é¤é¥®å¨±ä¹ã€ä½å®…ã€åŠå…¬ç­‰)
4. emotions: æƒ…æ„Ÿå…³é”®è¯(å¦‚æ¸©é¦¨ã€èˆ’é€‚ã€ç§å¯†ã€è‡ªç”±ã€å½’å±æ„Ÿç­‰)

ä»¥JSONæ ¼å¼è¾“å‡º,æ ¼å¼å¦‚ä¸‹:
{{
    "style": ["ç°ä»£", "ç®€çº¦"],
    "target_user": ["å®¶åº­", "å¹´è½»ç™½é¢†"],
    "features": ["å•†ä¸šè¡—åŒº", "é›¶å”®ç©ºé—´", "é¤é¥®"],
    "emotions": ["æ´»åŠ›", "èˆ’é€‚"]
}}

æ³¨æ„:
- æ¯ç±»å…³é”®è¯2-5ä¸ªå³å¯
- å…³é”®è¯è¦å…·ä½“ã€ç²¾å‡†
- å¦‚æœæŸç±»æ²¡æœ‰ç›¸å…³ä¿¡æ¯,è¿”å›ç©ºæ•°ç»„[]
"""

            messages = [SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®¾è®¡å…³é”®è¯æå–ä¸“å®¶,æ“…é•¿ä»é¡¹ç›®æè¿°ä¸­æå–åˆ†ç±»å…³é”®è¯ã€‚"), HumanMessage(content=prompt)]

            response = self.llm_model.invoke(messages, max_tokens=300, temperature=0.3)

            # è§£æJSONå“åº”
            content = response.content.strip()
            start_idx = content.find("{")
            end_idx = content.rfind("}") + 1

            if start_idx != -1 and end_idx > start_idx:
                json_str = content[start_idx:end_idx]
                keywords = json.loads(json_str)
                logger.info(f"LLM extracted keywords: {keywords}")
                return keywords
            else:
                logger.warning("Failed to parse LLM response, using fallback")
                return self._extract_keywords_fallback(project_task, character_narrative)

        except Exception as e:
            logger.error(f"LLM keyword extraction failed: {e}, using fallback")
            return self._extract_keywords_fallback(project_task, character_narrative)

    def _extract_keywords_fallback(self, project_task: str, character_narrative: str) -> Dict[str, Any]:
        """å…³é”®è¯æå–é™çº§æ–¹æ¡ˆ - åŸºäºè§„åˆ™çš„ç®€å•åŒ¹é…"""
        keywords = {"style": [], "target_user": [], "features": [], "emotions": []}

        # æ‰©å±•çš„é£æ ¼å…³é”®è¯
        style_patterns = [
            "Audrey Hepburn",
            "èµ«æœ¬",
            "ä¼˜é›…",
            "ç®€çº¦",
            "ç°ä»£",
            "å¤å…¸",
            "å·¥ä¸š",
            "åŒ—æ¬§",
            "ä¸­å¼",
            "æ—¥å¼",
            "æ¬§å¼",
            "ç¾å¼",
            "è½»å¥¢",
            "æ··æ­",
            "minimalist",
            "elegant",
            "modern",
            "classic",
        ]
        for pattern in style_patterns:
            if pattern in project_task or pattern in character_narrative:
                keywords["style"].append(pattern)

        # æ‰©å±•çš„ç›®æ ‡ç”¨æˆ·å…³é”®è¯
        user_patterns = [
            "ç‹¬ç«‹å¥³æ€§",
            "æµ·å½’",
            "ä¸“ä¸šäººå£«",
            "å¹´è½»äºº",
            "å®¶åº­",
            "ä¼ä¸š",
            "ç™½é¢†",
            "é’å°‘å¹´",
            "å„¿ç«¥",
            "è€äºº",
            "æƒ…ä¾£",
            "independent woman",
            "professional",
            "family",
        ]
        for pattern in user_patterns:
            if pattern in project_task or pattern in character_narrative:
                keywords["target_user"].append(pattern)

        # æ–°å¢: é¡¹ç›®ç‰¹å¾å…³é”®è¯
        feature_patterns = ["å•†ä¸š", "ä½å®…", "åŠå…¬", "é¤é¥®", "é›¶å”®", "å¨±ä¹", "é…’åº—", "å±•å…", "å•†ä¸šè¡—åŒº", "è´­ç‰©ä¸­å¿ƒ", "å†™å­—æ¥¼", "å…¬å¯“", "åˆ«å¢…"]
        for pattern in feature_patterns:
            if pattern in project_task or pattern in character_narrative:
                keywords["features"].append(pattern)

        # æ‰©å±•çš„æƒ…æ„Ÿå…³é”®è¯
        emotion_patterns = [
            "å½’å±æ„Ÿ",
            "ç§å¯†",
            "æ¸©é¦¨",
            "èˆ’é€‚",
            "è‡ªç”±",
            "ç‹¬ç«‹",
            "æ´»åŠ›",
            "æ—¶å°š",
            "å“è´¨",
            "ä¼˜é›…",
            "belonging",
            "privacy",
            "comfort",
            "freedom",
        ]
        for pattern in emotion_patterns:
            if pattern in project_task or pattern in character_narrative:
                keywords["emotions"].append(pattern)

        return keywords

    def _generate_v2_queries(self, project_type: str, keywords: Dict[str, Any], assigned_task: str) -> Dict[str, str]:
        """ç”ŸæˆV2è®¾è®¡ç ”ç©¶åˆ†æå¸ˆçš„æœç´¢æŸ¥è¯¢"""
        queries = {}

        if project_type == "interior_design":
            # å®¤å†…è®¾è®¡é¡¹ç›®
            style_str = " ".join(keywords["style"][:3])
            user_str = " ".join(keywords["target_user"][:2])

            queries["design_trends"] = f"å®¤å†…è®¾è®¡è¶‹åŠ¿ {style_str} {user_str} 2024"
            queries["academic_research"] = f"interior design residential space {style_str}"
            queries["knowledge_base"] = f"å®¤å†…è®¾è®¡æŒ‡å— {style_str} æœ€ä½³å®è·µ"
        else:
            # è½¯ä»¶/äº§å“è®¾è®¡é¡¹ç›®
            queries["design_trends"] = f"UI UX design trends 2024 {' '.join(keywords['style'][:2])}"
            queries["academic_research"] = f"user experience design interface {' '.join(keywords['target_user'][:2])}"
            queries["knowledge_base"] = f"design guidelines best practices {assigned_task[:50]}"

        return queries

    def _generate_v3_queries(self, project_type: str, keywords: Dict[str, Any], assigned_task: str) -> Dict[str, str]:
        """ç”ŸæˆV3æŠ€æœ¯æ¶æ„å¸ˆçš„æœç´¢æŸ¥è¯¢"""
        queries = {}

        if project_type == "interior_design":
            # å®¤å†…è®¾è®¡é¡¹ç›® - å…³æ³¨æ™ºèƒ½å®¶å±…ã€ç…§æ˜ã€ææ–™ç­‰æŠ€æœ¯
            queries["tech_trends"] = f"æ™ºèƒ½å®¶å±…ç³»ç»Ÿ ç…§æ˜æ§åˆ¶ 2024"
            queries["academic_research"] = f"smart home automation lighting control"
            queries["knowledge_base"] = f"æ™ºèƒ½å®¶å±…æŠ€æœ¯ æœ€ä½³å®è·µ"
        else:
            # è½¯ä»¶é¡¹ç›®
            queries["tech_trends"] = f"software architecture patterns microservices 2024"
            queries["academic_research"] = f"software engineering architecture scalability"
            queries["knowledge_base"] = f"architecture patterns best practices {assigned_task[:50]}"

        return queries

    def _generate_v4_queries(self, project_type: str, keywords: Dict[str, Any], assigned_task: str) -> Dict[str, str]:
        """ç”ŸæˆV4ç”¨æˆ·ä½“éªŒè®¾è®¡å¸ˆçš„æœç´¢æŸ¥è¯¢"""
        queries = {}

        user_str = " ".join(keywords["target_user"][:2])
        emotion_str = " ".join(keywords["emotions"][:2])

        if project_type == "interior_design":
            queries["ux_trends"] = f"å±…ä½ä½“éªŒè®¾è®¡ {user_str} {emotion_str} 2024"
            queries["case_studies"] = f"residential UX design {user_str} case studies"
            queries["knowledge_base"] = f"ç”¨æˆ·ä½“éªŒè®¾è®¡ å±…ä½ç©ºé—´ {emotion_str}"
        else:
            queries["ux_trends"] = f"UX design trends 2024 {user_str}"
            queries["case_studies"] = f"UX case studies user experience design {user_str}"
            queries["knowledge_base"] = f"ç”¨æˆ·ä½“éªŒè®¾è®¡ äº¤äº’è®¾è®¡ {assigned_task[:50]}"

        return queries

    def _generate_v5_queries(self, project_type: str, keywords: Dict[str, Any], assigned_task: str) -> Dict[str, str]:
        """ç”ŸæˆV5å•†ä¸šåˆ†æå¸ˆçš„æœç´¢æŸ¥è¯¢"""
        queries = {}

        user_str = " ".join(keywords["target_user"][:2])

        if project_type == "interior_design":
            queries["market_trends"] = f"å®¤å†…è®¾è®¡å¸‚åœºè¶‹åŠ¿ {user_str} 2024"
            queries["competitor_analysis"] = f"interior design market analysis {user_str}"
            queries["revenue_models"] = f"å®¤å†…è®¾è®¡å•†ä¸šæ¨¡å¼ ç›ˆåˆ©æ¨¡å¼"
        else:
            queries["market_trends"] = f"market trends business model 2024 {user_str}"
            queries["competitor_analysis"] = f"competitor analysis market research {user_str}"
            queries["revenue_models"] = f"revenue model monetization strategy"

        return queries

    def _generate_v6_queries(self, project_type: str, keywords: Dict[str, Any], assigned_task: str) -> Dict[str, str]:
        """ç”ŸæˆV6å®æ–½è§„åˆ’å¸ˆçš„æœç´¢æŸ¥è¯¢"""
        queries = {}

        if project_type == "interior_design":
            queries["project_management"] = f"å®¤å†…è®¾è®¡é¡¹ç›®ç®¡ç† æ–½å·¥æµç¨‹ 2024"
            queries["methodology"] = f"interior design project planning methodology"
            queries["risk_management"] = f"å®¤å†…è®¾è®¡é¡¹ç›®é£é™©ç®¡ç†"
        else:
            queries["project_management"] = f"project management best practices 2024"
            queries["methodology"] = f"agile development DevOps implementation methodology"
            queries["risk_management"] = f"project risk management mitigation strategies"

        return queries

    def _generate_default_queries(
        self, project_type: str, keywords: Dict[str, Any], assigned_task: str
    ) -> Dict[str, str]:
        """ç”Ÿæˆé»˜è®¤æœç´¢æŸ¥è¯¢"""
        return {
            "general": f"{assigned_task[:100]} 2024",
            "research": f"{' '.join(keywords['style'][:2])} best practices",
            "knowledge_base": f"{assigned_task[:100]}",
        }
