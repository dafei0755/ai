# ============================================================================
# ä»»åŠ¡å¯¼å‘ä¸“å®¶å·¥å‚ - Task Oriented Expert Factory v2.1
# ============================================================================
# æ›´æ–°æ—¥æœŸ: 2025-12-17
# å˜æ›´è¯´æ˜:
# 1. ä¸“å®¶è¾“å‡ºä¸¥æ ¼å›´ç»•TaskInstruction
# 2. å¼ºåˆ¶ä½¿ç”¨TaskOrientedExpertOutputç»“æ„
# 3. ç¡®ä¿åè®®é—­ç¯æ‰§è¡Œ
# 4. ğŸ”¥ v7.18: ä½¿ç”¨ JSON Schema å¼ºåˆ¶çº¦æŸï¼ˆé™ä½è§£æå¤±è´¥ç‡ 15%â†’3%ï¼‰
# 5. ğŸ”¥ v7.19: æŒ‰è§’è‰²ç±»å‹åŠ¨æ€è°ƒå‚ï¼ˆV3é«˜åˆ›æ„/V6é«˜ç²¾ç¡®ï¼‰+ è¾“å‡ºè´¨é‡å¼•å¯¼
# ============================================================================

from typing import Dict, Any, List, Optional
from functools import lru_cache
from pydantic import ValidationError
from ..core.state import ProjectAnalysisState
from ..core.task_oriented_models import TaskOrientedExpertOutput, ProtocolExecutionReport
from ..services.llm_factory import LLMFactory
import yaml
import json
import datetime
from pathlib import Path
from loguru import logger

# ğŸ†• v7.64: å¯¼å…¥å·¥å…·è°ƒç”¨è®°å½•å™¨
try:
    from .tool_callback import ToolCallRecorder, add_references_to_state
except ImportError:
    logger.warning("âš ï¸ ToolCallRecorder not available (v7.64 feature)")
    ToolCallRecorder = None
    add_references_to_state = None

# ğŸ”¥ v7.18: å…¨å±€ç¼“å­˜è‡ªä¸»æ€§åè®®ï¼ˆæ‰€æœ‰ä¸“å®¶å…±äº«ï¼ŒåªåŠ è½½ä¸€æ¬¡ï¼‰
_autonomy_protocol_cache = None

def get_autonomy_protocol() -> Dict[str, Any]:
    """
    è·å–ç¼“å­˜çš„è‡ªä¸»æ€§åè®®ï¼ˆå…¨å±€å•ä¾‹ï¼‰

    âœ… å‡çº§1ä¼˜åŒ–ï¼šæ‰€æœ‰ä¸“å®¶å…±äº«åŒä¸€ä»½åè®®ï¼Œé¿å…é‡å¤åŠ è½½

    Returns:
        è‡ªä¸»æ€§åè®®å­—å…¸
    """
    global _autonomy_protocol_cache
    if _autonomy_protocol_cache is None:
        logger.info("ğŸ”§ [å‡çº§1] é¦–æ¬¡åŠ è½½è‡ªä¸»æ€§åè®®ï¼Œå°†ç¼“å­˜äºå†…å­˜")
        _autonomy_protocol_cache = load_yaml_config_cached("prompts/expert_autonomy_protocol_v4.yaml")
    return _autonomy_protocol_cache

@lru_cache(maxsize=20)
def load_yaml_config_cached(config_path: str) -> Dict[str, Any]:
    """
    åŠ è½½YAMLé…ç½®æ–‡ä»¶çš„è¾…åŠ©å‡½æ•°ï¼ˆå¸¦LRUç¼“å­˜ï¼‰

    âœ… å‡çº§1ä¼˜åŒ–ï¼šä½¿ç”¨LRUç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼Œmaxsize=20 è¶³å¤Ÿç¼“å­˜æ‰€æœ‰è§’è‰²é…ç½®

    Args:
        config_path: é…ç½®æ–‡ä»¶ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºconfigç›®å½•ï¼‰

    Returns:
        Dict: é…ç½®å­—å…¸
    """
    # è·å–é…ç½®ç›®å½•çš„ç»å¯¹è·¯å¾„
    current_file = Path(__file__).resolve()
    project_root = current_file.parent.parent
    config_dir = project_root / "config"

    full_path = config_dir / config_path

    if not full_path.exists():
        logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
        return {}

    try:
        with open(full_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f) or {}
            logger.debug(f"âœ… [å‡çº§1] å·²ç¼“å­˜é…ç½®æ–‡ä»¶: {config_path}")
            return config
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥ {full_path}: {str(e)}")
        return {}

def load_yaml_config(config_path: str) -> Dict[str, Any]:
    """
    åŠ è½½YAMLé…ç½®æ–‡ä»¶ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰

    âœ… å‡çº§1ä¼˜åŒ–ï¼šå†…éƒ¨è°ƒç”¨ç¼“å­˜ç‰ˆæœ¬

    Args:
        config_path: é…ç½®æ–‡ä»¶ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºconfigç›®å½•ï¼‰

    Returns:
        Dict: é…ç½®å­—å…¸
    """
    return load_yaml_config_cached(config_path)

class TaskOrientedExpertFactory:
    """
    ä»»åŠ¡å¯¼å‘ä¸“å®¶å·¥å‚ - ç¡®ä¿ä¸“å®¶è¾“å‡ºä¸¥æ ¼å›´ç»•åˆ†é…ä»»åŠ¡
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ ¹æ®RoleObjectä¸­çš„TaskInstructionæ‰§è¡Œä¸“å®¶åˆ†æ
    2. å¼ºåˆ¶è¿”å›TaskOrientedExpertOutputç»“æ„
    3. ç¡®ä¿åè®®æ‰§è¡Œå®Œæ•´é—­ç¯
    4. æ¶ˆé™¤ä¸å¯é¢„è®¡çš„é¢å¤–è¾“å‡º
    
    âœ… P3ä¼˜åŒ–ï¼šç¼“å­˜LLMå®ä¾‹ï¼Œé¿å…é‡å¤åˆ›å»º
    ğŸ”¥ v7.19ä¼˜åŒ–ï¼šæŒ‰è§’è‰²ç±»å‹åŠ¨æ€è°ƒå‚
    """
    
    # âœ… P3ä¼˜åŒ–ï¼šç±»çº§åˆ«LLMå®ä¾‹ç¼“å­˜ï¼ˆæŒ‰è§’è‰²ç±»å‹åˆ†åˆ«ç¼“å­˜ï¼‰
    _llm_instances: Dict[str, Any] = {}
    
    # ğŸ”¥ v7.19: è§’è‰²ç±»å‹ä¸“å±å‚æ•°é…ç½®
    # - V2 è®¾è®¡æ€»ç›‘ï¼šä¸­ç­‰åˆ›æ„åº¦ï¼Œéœ€è¦å¹³è¡¡åˆ›æ„ä¸åŠ¡å®
    # - V3 å™äº‹ä¸“å®¶ï¼šé«˜åˆ›æ„åº¦ï¼Œæ“…é•¿æ•…äº‹å’Œæƒ…æ„Ÿè¡¨è¾¾
    # - V4 è®¾è®¡ç ”ç©¶å‘˜ï¼šä¸­ç­‰ç²¾ç¡®åº¦ï¼Œéœ€è¦æ•°æ®æ”¯æ’‘
    # - V5 åœºæ™¯ä¸“å®¶ï¼šä¸­ç­‰åˆ›æ„åº¦ï¼Œè¡Œä¸šæ´å¯Ÿ
    # - V6 é¦–å¸­å·¥ç¨‹å¸ˆï¼šé«˜ç²¾ç¡®åº¦ï¼ŒæŠ€æœ¯æ–¹æ¡ˆå¿…é¡»ä¸¥è°¨
    ROLE_LLM_PARAMS: Dict[str, Dict[str, Any]] = {
        "V2": {"temperature": 0.6, "description": "è®¾è®¡æ€»ç›‘-å¹³è¡¡åˆ›æ„ä¸åŠ¡å®"},
        "V3": {"temperature": 0.75, "description": "å™äº‹ä¸“å®¶-é«˜åˆ›æ„åº¦"},
        "V4": {"temperature": 0.5, "description": "è®¾è®¡ç ”ç©¶å‘˜-æ•°æ®é©±åŠ¨"},
        "V5": {"temperature": 0.6, "description": "åœºæ™¯ä¸“å®¶-è¡Œä¸šæ´å¯Ÿ"},
        "V6": {"temperature": 0.4, "description": "é¦–å¸­å·¥ç¨‹å¸ˆ-é«˜ç²¾ç¡®åº¦"},
        "default": {"temperature": 0.6, "description": "é»˜è®¤-ç¨³å®šè¾“å‡º"},
    }
    
    def __init__(self):
        self.llm_factory = LLMFactory()
    
    def _get_llm(self, role_type: str = "default", deliverable_count: int = 0):
        """
        è·å–è§’è‰²ä¸“å±çš„LLMå®ä¾‹ï¼ˆæŒ‰è§’è‰²ç±»å‹ç¼“å­˜ï¼‰

        ğŸ”¥ v7.19ä¼˜åŒ–ï¼šä¸åŒè§’è‰²ä½¿ç”¨ä¸åŒçš„ temperature
        - V3 å™äº‹ä¸“å®¶ï¼štemperature=0.75ï¼ˆé«˜åˆ›æ„ï¼‰
        - V6 å·¥ç¨‹å¸ˆï¼štemperature=0.4ï¼ˆé«˜ç²¾ç¡®ï¼‰
        - å…¶ä»–è§’è‰²ï¼štemperature=0.5-0.6ï¼ˆå¹³è¡¡ï¼‰

        ğŸ”¥ v7.52ä¼˜åŒ–ï¼šåŠ¨æ€Tokenåˆ†é…æœºåˆ¶
        - æ ¹æ®è§’è‰²çº§åˆ«å’Œäº¤ä»˜ç‰©æ•°é‡è®¡ç®—max_tokens
        - é¿å…ä¸“å®¶è¾“å‡ºè¢«æˆªæ–­

        Args:
            role_type: è§’è‰²ç±»å‹ï¼ˆV2/V3/V4/V5/V6ï¼‰
            deliverable_count: äº¤ä»˜ç‰©æ•°é‡ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´tokenï¼‰

        Returns:
            é…ç½®äº†å¯¹åº”å‚æ•°çš„ LLM å®ä¾‹
        """
        # è·å–è§’è‰²ä¸“å±å‚æ•°
        params = self.ROLE_LLM_PARAMS.get(role_type, self.ROLE_LLM_PARAMS["default"])

        # ğŸ”¥ v7.52: è®¡ç®—åŠ¨æ€max_tokens
        max_tokens = self._get_max_tokens_for_expert(role_type, deliverable_count)

        cache_key = f"{role_type}_{params['temperature']}_{max_tokens}"

        if cache_key not in TaskOrientedExpertFactory._llm_instances:
            logger.info(f"ğŸ”§ [v7.19] ä¸º {role_type} åˆ›å»ºä¸“å±LLM (temperature={params['temperature']}, max_tokens={max_tokens}, {params['description']})")
            TaskOrientedExpertFactory._llm_instances[cache_key] = self.llm_factory.create_llm(
                temperature=params["temperature"],
                max_tokens=max_tokens
            )
        return TaskOrientedExpertFactory._llm_instances[cache_key]

    def _get_max_tokens_for_expert(self, role_type: str, deliverable_count: int) -> int:
        """
        ğŸ”¥ v7.52: æ ¹æ®è§’è‰²çº§åˆ«å’Œäº¤ä»˜ç‰©æ•°é‡åŠ¨æ€è®¡ç®—max_tokens

        Args:
            role_type: è§’è‰²ç±»å‹ï¼ˆV2/V3/V4/V5/V6ï¼‰
            deliverable_count: äº¤ä»˜ç‰©æ•°é‡

        Returns:
            åŠ¨æ€è®¡ç®—çš„max_tokenså€¼
        """
        # åŸºç¡€tokené…é¢ï¼ˆæŒ‰è§’è‰²ç­‰çº§ï¼‰
        base_tokens = {
            "V2": 12000,  # è®¾è®¡æ€»ç›‘ - ç»¼åˆæ€§å¼ºï¼Œè¾“å‡ºè¾ƒå¤š
            "V3": 10000,  # å™äº‹ä¸“å®¶ - å†…å®¹è¯¦ç»†
            "V4": 8000,   # ç ”ç©¶å‘˜ - æ•°æ®åˆ†æ
            "V5": 8000,   # åœºæ™¯ä¸“å®¶ - è¡Œä¸šæ´å¯Ÿ
            "V6": 8000,   # å·¥ç¨‹å¸ˆ - æŠ€æœ¯æ–¹æ¡ˆ
        }

        # æ¯ä¸ªäº¤ä»˜ç‰©é¢å¤–å¢åŠ 1500 tokens
        tokens_per_deliverable = 1500

        # è®¡ç®—æ€»token
        total_tokens = base_tokens.get(role_type, 8000) + (deliverable_count * tokens_per_deliverable)

        # ç¡¬ä¸Šé™32000 (è€ƒè™‘æˆæœ¬å’Œå“åº”æ—¶é—´)
        # ä¸‹é™ 8000 (ä¿è¯åŸºæœ¬è¾“å‡ºè´¨é‡)
        total_tokens = max(8000, min(32000, total_tokens))

        logger.debug(f"ğŸ“Š [v7.52] {role_type} tokenåˆ†é…: åŸºç¡€{base_tokens.get(role_type, 8000)} + {deliverable_count}äº¤ä»˜ç‰©Ã—{tokens_per_deliverable} = {total_tokens}")

        return total_tokens
    
    async def execute_expert(
        self,
        role_object: Dict[str, Any],
        context: str,
        state: ProjectAnalysisState,
        tools: Optional[List[Any]] = None  # ğŸ”¥ v7.63.1: æ·»åŠ å·¥å…·æ”¯æŒ
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»»åŠ¡å¯¼å‘çš„ä¸“å®¶åˆ†æ

        Args:
            role_object: åŒ…å«TaskInstructionçš„è§’è‰²å¯¹è±¡
            context: é¡¹ç›®ä¸Šä¸‹æ–‡
            state: å½“å‰çŠ¶æ€
            tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ - v7.63.1æ–°å¢

        Returns:
            æ ‡å‡†åŒ–çš„ä¸“å®¶æ‰§è¡Œç»“æœ
        """
        try:
            # æ„å»ºä»»åŠ¡å¯¼å‘çš„ä¸“å®¶æç¤ºè¯
            expert_prompt = self._build_task_oriented_expert_prompt(
                role_object=role_object,
                context=context,
                state=state
            )

            # è°ƒç”¨LLMç”Ÿæˆä¸“å®¶åˆ†æ
            # ğŸ”¥ v7.19ä¼˜åŒ–ï¼šä½¿ç”¨è§’è‰²ä¸“å±çš„LLMå®ä¾‹
            role_type = self._extract_base_type(role_object.get('role_id', ''))

            # ğŸ”¥ v7.52ä¼˜åŒ–ï¼šè®¡ç®—äº¤ä»˜ç‰©æ•°é‡ä»¥åŠ¨æ€åˆ†é…token
            task_instruction = role_object.get('task_instruction', {})
            deliverable_count = len(task_instruction.get('deliverables', []))

            llm = self._get_llm(role_type, deliverable_count)

            # ğŸ†• v7.64: åˆ›å»ºå·¥å…·è°ƒç”¨è®°å½•å™¨ï¼ˆå¦‚æœæœ‰å·¥å…·ï¼‰
            recorder = None
            if tools and ToolCallRecorder:
                role_id = role_object.get('role_id', 'unknown')
                # ä½¿ç”¨è§’è‰²IDä½œä¸ºdeliverable_idçš„å‰ç¼€
                recorder = ToolCallRecorder(role_id=role_id, deliverable_id=f"{role_id}_analysis")
                logger.info(f"ğŸ”§ [v7.64] {role_id} å¯ç”¨å·¥å…·è°ƒç”¨è®°å½•å™¨")

            # ğŸ”¥ v7.63.1: å¦‚æœæä¾›äº†å·¥å…·ï¼Œç»‘å®šåˆ°LLM
            if tools:
                tool_names = [getattr(tool, 'name', str(tool)) for tool in tools]
                logger.info(f"ğŸ”§ [v7.63.1] {role_object.get('role_id', 'unknown')} ç»‘å®š {len(tools)} ä¸ªå·¥å…·: {tool_names}")
                # ğŸ†• v7.64: ç»‘å®šå·¥å…·æ—¶ä¼ å…¥callbacks
                if recorder:
                    llm = llm.bind_tools(tools, callbacks=[recorder])
                else:
                    llm = llm.bind_tools(tools)
            else:
                logger.debug(f"â„¹ï¸ [v7.63.1] {role_object.get('role_id', 'unknown')} æ— å·¥å…·ï¼ˆç»¼åˆè€…æ¨¡å¼ï¼‰")

            # ğŸ”¥ v7.18: å¼ºåˆ¶JSON Schemaè¾“å‡ºï¼ˆé™ä½è§£æå¤±è´¥ç‡ 15% â†’ 3%ï¼‰
            llm_with_structure = llm.with_structured_output(
                TaskOrientedExpertOutput,
                method="json_schema",  # ä½¿ç”¨ä¸¥æ ¼JSON Schemaè€Œéjson_mode
                strict=True  # å¼ºåˆ¶LLMéµå®ˆschemaï¼Œæ— æ³•åç¦»
            )

            messages = [
                {"role": "system", "content": expert_prompt["system_prompt"]},
                {"role": "user", "content": expert_prompt["user_prompt"]}
            ]

            # ğŸ”¥ v7.18: responseç›´æ¥æ˜¯TaskOrientedExpertOutputå®ä¾‹ï¼Œæ— éœ€è§£æ
            response = await llm_with_structure.ainvoke(messages)

            # å°†Pydanticæ¨¡å‹è½¬æ¢ä¸ºå­—å…¸ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            structured_output = response.dict() if hasattr(response, 'dict') else response.model_dump()

            # æ„å»ºæ ‡å‡†åŒ–è¿”å›ç»“æœ
            result = {
                "expert_id": role_object.get("role_id", "unknown"),
                "expert_name": role_object.get("dynamic_role_name", role_object.get("role_name", "Unknown Expert")),
                "analysis": structured_output.get("task_execution_report", {}).get("task_completion_summary", ""),  # ğŸ”¥ v7.18: ä»ç»“æ„åŒ–è¾“å‡ºè·å–æ‘˜è¦
                "structured_output": structured_output,  # å·²éªŒè¯çš„ç»“æ„åŒ–è¾“å‡º
                "task_instruction": role_object.get("task_instruction", {}),  # ä»»åŠ¡æŒ‡ä»¤
                "role_definition": role_object,
                "execution_metadata": {
                    "timestamp": self._get_timestamp(),
                    "model_used": "gpt-4",
                    "prompt_version": "task_oriented_v2.0",
                    "output_format": "TaskOrientedExpertOutput",
                    "json_schema_enforced": True  # ğŸ”¥ v7.18: æ ‡è®°ä½¿ç”¨äº†å¼ºåˆ¶JSON Schema
                }
            }
            
            # ğŸ”¥ v7.9.3: éªŒè¯ä»»åŠ¡å®Œæˆæƒ…å†µï¼Œå¦‚æœæœ‰ç¼ºå¤±åˆ™è‡ªåŠ¨è¡¥å…¨
            validation_passed = self._validate_task_completion(structured_output, role_object.get("task_instruction", {}))

            # ğŸ”¥ v7.9.3: å¦‚æœéªŒè¯æœªé€šè¿‡ä¸”æœ‰ç¼ºå¤±äº¤ä»˜ç‰©ï¼Œå°è¯•è‡ªåŠ¨è¡¥å…¨
            if not validation_passed and structured_output.get('validation_result', {}).get('needs_completion'):
                logger.info("ğŸ”„ æ£€æµ‹åˆ°ç¼ºå¤±äº¤ä»˜ç‰©ï¼Œå¼€å§‹è‡ªåŠ¨è¡¥å…¨...")
                structured_output = await self._complete_missing_deliverables(
                    structured_output=structured_output,
                    role_object=role_object,
                    context=context,
                    state=state
                )
                # æ›´æ–°resultä¸­çš„structured_output
                result["structured_output"] = structured_output
                logger.info("âœ… äº¤ä»˜ç‰©è¡¥å…¨å®Œæˆ")

            # ğŸ†• v7.64: ä»å·¥å…·è°ƒç”¨è®°å½•å™¨æå–æœç´¢å¼•ç”¨å¹¶æ·»åŠ åˆ°state
            if recorder and add_references_to_state:
                search_references = recorder.get_search_references()
                if search_references:
                    logger.info(f"ğŸ“š [v7.64] æå–äº† {len(search_references)} æ¡æœç´¢å¼•ç”¨")
                    # æ·»åŠ åˆ°stateï¼ˆä¼šè‡ªåŠ¨å»é‡ï¼‰
                    add_references_to_state(state, recorder)

                    # ğŸ”§ å¯é€‰ï¼šå°†å¼•ç”¨æ·»åŠ åˆ°äº¤ä»˜ç‰©è¾“å‡ºï¼ˆä¾›PDFç”Ÿæˆä½¿ç”¨ï¼‰
                    task_exec_report = structured_output.get('task_execution_report', {})
                    deliverable_outputs = task_exec_report.get('deliverable_outputs', [])

                    # ä¸ºæ¯ä¸ªäº¤ä»˜ç‰©å…³è”ç›¸å…³çš„æœç´¢å¼•ç”¨
                    for deliverable in deliverable_outputs:
                        deliverable_name = deliverable.get('deliverable_name', '')
                        # ç­›é€‰ä¸æ­¤äº¤ä»˜ç‰©ç›¸å…³çš„å¼•ç”¨ï¼ˆåŸºäºdeliverable_idå‰ç¼€åŒ¹é…ï¼‰
                        related_refs = [
                            ref for ref in search_references
                            if deliverable_name in ref.get('deliverable_id', '')
                        ]
                        if related_refs:
                            deliverable['search_references'] = related_refs
                            logger.debug(f"  â†³ ä¸ºäº¤ä»˜ç‰© '{deliverable_name}' å…³è”äº† {len(related_refs)} æ¡å¼•ç”¨")

            # ğŸ†• v7.108: ä¸ºè¯¥ä¸“å®¶çš„äº¤ä»˜ç‰©ç”Ÿæˆæ¦‚å¿µå›¾
            try:
                deliverable_owner_map = state.get("deliverable_owner_map", {})
                deliverable_metadata = state.get("deliverable_metadata", {})
                role_id = role_object.get("role_id", "unknown")
                deliverable_ids = deliverable_owner_map.get(role_id, [])

                if deliverable_ids and deliverable_metadata:
                    logger.info(f"ğŸ¨ [v7.108] ä¸ºè§’è‰² {role_id} çš„ {len(deliverable_ids)} ä¸ªäº¤ä»˜ç‰©ç”Ÿæˆæ¦‚å¿µå›¾...")

                    # å¯¼å…¥å›¾ç‰‡ç”ŸæˆæœåŠ¡
                    from ..services.image_generator import ImageGeneratorService

                    # åˆå§‹åŒ–å›¾ç‰‡ç”Ÿæˆå™¨
                    image_generator = ImageGeneratorService()

                    # è·å–ä¸“å®¶åˆ†ææ‘˜è¦ï¼ˆç”¨äºå›¾ç‰‡ç”Ÿæˆï¼‰
                    expert_summary = result.get("analysis", "")[:500]  # å–å‰500å­—ç¬¦
                    session_id = state.get("session_id", "unknown")
                    project_type = state.get("project_type", "interior")

                    # ä¸ºæ¯ä¸ªäº¤ä»˜ç‰©ç”Ÿæˆæ¦‚å¿µå›¾
                    concept_images = []
                    for deliverable_id in deliverable_ids:
                        metadata = deliverable_metadata.get(deliverable_id)
                        if not metadata:
                            logger.warning(f"  âš ï¸ äº¤ä»˜ç‰© {deliverable_id} å…ƒæ•°æ®ç¼ºå¤±ï¼Œè·³è¿‡å›¾ç‰‡ç”Ÿæˆ")
                            continue

                        try:
                            image_metadata = await image_generator.generate_deliverable_image(
                                deliverable_metadata=metadata,
                                expert_analysis=expert_summary,
                                session_id=session_id,
                                project_type=project_type,
                                aspect_ratio="16:9"
                            )

                            # è½¬æ¢ä¸ºå­—å…¸å­˜å‚¨
                            concept_images.append(image_metadata.model_dump())
                            logger.info(f"  âœ… ç”Ÿæˆæ¦‚å¿µå›¾: {image_metadata.filename}")

                        except Exception as img_error:
                            logger.error(f"  âŒ ç”Ÿæˆæ¦‚å¿µå›¾å¤±è´¥ (äº¤ä»˜ç‰© {deliverable_id}): {img_error}")
                            # ä¸é˜»å¡workflowï¼Œç»§ç»­æ‰§è¡Œ

                    # å°†æ¦‚å¿µå›¾æ·»åŠ åˆ°ä¸“å®¶ç»“æœä¸­
                    if concept_images:
                        result["concept_images"] = concept_images
                        logger.info(f"âœ… [v7.108] æˆåŠŸä¸ºè§’è‰² {role_id} ç”Ÿæˆ {len(concept_images)} å¼ æ¦‚å¿µå›¾")
                    else:
                        logger.warning(f"âš ï¸ [v7.108] è§’è‰² {role_id} æœªç”Ÿæˆä»»ä½•æ¦‚å¿µå›¾")
                else:
                    logger.debug(f"[v7.108] è§’è‰² {role_id} æ— äº¤ä»˜ç‰©ï¼Œè·³è¿‡å›¾ç‰‡ç”Ÿæˆ")

            except Exception as e:
                logger.error(f"âŒ [v7.108] æ¦‚å¿µå›¾ç”Ÿæˆæµç¨‹å¤±è´¥: {e}")
                logger.exception(e)
                # ä¸é˜»å¡workflowï¼Œä¸“å®¶åˆ†æä»ç„¶æœ‰æ•ˆ

            return result

        except ValidationError as ve:
            # ğŸ”¥ v7.18: JSON Schema å¼ºåˆ¶çº¦æŸä¸‹æå°‘å‡ºç°ï¼Œä½†ä¿ç•™é˜²å¾¡æ€§å¤„ç†
            logger.error(f"âŒ PydanticéªŒè¯å¤±è´¥ {role_object.get('role_name', 'Unknown')}: {str(ve)}")
            logger.error("âš ï¸ è¿™ä¸åº”è¯¥å‘ç”Ÿåœ¨ JSON Schema å¼ºåˆ¶æ¨¡å¼ä¸‹ï¼Œè¯·æ£€æŸ¥ schema å®šä¹‰")
            return {
                "expert_id": role_object.get("role_id", "unknown"),
                "expert_name": role_object.get("dynamic_role_name", role_object.get("role_name", "Unknown Expert")),
                "analysis": f"éªŒè¯å¤±è´¥: {str(ve)}",
                "structured_output": None,
                "task_instruction": role_object.get("task_instruction", {}),
                "role_definition": role_object,
                "error": True,
                "execution_metadata": {
                    "timestamp": self._get_timestamp(),
                    "model_used": "gpt-4",
                    "prompt_version": "task_oriented_v2.0",
                    "error_type": "ValidationError",
                    "error_message": str(ve)
                }
            }
        except Exception as e:
            # ğŸ”¥ v7.60.3: æ£€æµ‹æ˜¯å¦ä¸ºè¾“å‡ºé•¿åº¦è¶…é™é”™è¯¯
            error_msg = str(e)
            if "length limit was reached" in error_msg or "completion_tokens" in error_msg:
                logger.error(f"âŒ ä¸“å®¶ {role_object.get('role_name', 'Unknown')} è¾“å‡ºè¶…é•¿è¢«æˆªæ–­")
                logger.error(f"   é”™è¯¯è¯¦æƒ…: {error_msg}")
                logger.error("   ğŸ’¡ å»ºè®®: è°ƒæ•´æç¤ºè¯è¦æ±‚æ›´ç®€æ´çš„è¾“å‡ºï¼Œæˆ–å¢åŠ è¾“å‡ºé•¿åº¦é™åˆ¶è­¦å‘Š")
            else:
                logger.error(f"æ‰§è¡Œä»»åŠ¡å¯¼å‘ä¸“å®¶ {role_object.get('role_name', 'Unknown')} æ—¶å‡ºé”™: {error_msg}")
            return {
                "expert_id": role_object.get("role_id", "unknown"),
                "expert_name": role_object.get("dynamic_role_name", role_object.get("role_name", "Unknown Expert")),
                "analysis": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "structured_output": None,
                "task_instruction": role_object.get("task_instruction", {}),
                "role_definition": role_object,
                "error": True,
                "execution_metadata": {
                    "timestamp": self._get_timestamp(),
                    "model_used": "gpt-4",
                    "prompt_version": "task_oriented_v2.0",
                    "error_message": str(e)
                }
            }
    
    def _get_role_config_filename(self, role_id: str) -> str:
        """
        ä»role_idæå–é…ç½®æ–‡ä»¶å
        
        role_idæ ¼å¼æ”¯æŒ:
        - å®Œæ•´æ ¼å¼: V2_è®¾è®¡æ€»ç›‘_2-0, V3_å™äº‹ä¸ä½“éªŒä¸“å®¶_3-3, V5_åœºæ™¯ä¸è¡Œä¸šä¸“å®¶_5-2
        - çŸ­æ ¼å¼: 2-0, 3-3, 5-2
        é…ç½®æ–‡ä»¶: v2_design_director.yaml, v3_narrative_expert.yaml, v5_scenario_expert.yaml
        """
        # åŒæ—¶æ”¯æŒå®Œæ•´æ ¼å¼ (V2_xxx) å’ŒçŸ­æ ¼å¼ (2-x)
        if role_id.startswith("V2") or role_id.startswith("2-"):
            return "roles/v2_design_director.yaml"
        elif role_id.startswith("V3") or role_id.startswith("3-"):
            return "roles/v3_narrative_expert.yaml"
        elif role_id.startswith("V4") or role_id.startswith("4-"):
            return "roles/v4_design_researcher.yaml"
        elif role_id.startswith("V5") or role_id.startswith("5-"):
            return "roles/v5_scenario_expert.yaml"
        elif role_id.startswith("V6") or role_id.startswith("6-"):
            return "roles/v6_chief_engineer.yaml"
        else:
            logger.warning(f"æœªè¯†åˆ«çš„role_idæ ¼å¼: {role_id}")
            return f"roles/{role_id}.yaml"  # å›é€€åˆ°åŸå§‹é€»è¾‘
    
    def _build_task_oriented_expert_prompt(self, role_object: Dict[str, Any], context: str, state: ProjectAnalysisState) -> Dict[str, str]:
        """
        æ„å»ºä»»åŠ¡å¯¼å‘çš„ä¸“å®¶æç¤ºè¯ï¼Œç¡®ä¿è¾“å‡ºä¸¥æ ¼å›´ç»•TaskInstruction

        ğŸ”¥ v7.18 å‡çº§1: ä½¿ç”¨ Prompt æ¨¡æ¿ç³»ç»Ÿï¼Œå‡å°‘ 80% çš„æ‹¼æ¥å¼€é”€
        """
        try:
            # åŠ è½½åŸºç¡€è§’è‰²é…ç½® - ä½¿ç”¨ç¼“å­˜çš„æ˜ å°„å‡½æ•°
            config_filename = self._get_role_config_filename(role_object['role_id'])
            role_config = load_yaml_config(config_filename)
            base_system_prompt = role_config.get("system_prompt", "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åˆ†æå¸ˆ")

            # è·å–TaskInstruction
            task_instruction = role_object.get('task_instruction', {})

            # ğŸ”¥ v7.10: æ£€æµ‹åˆ›æ„å™äº‹æ¨¡å¼
            is_creative_narrative = task_instruction.get('is_creative_narrative', False)

            # ğŸ”¥ v7.18 å‡çº§1: ä½¿ç”¨ç¼“å­˜çš„è‡ªä¸»æ€§åè®®ï¼ˆæ‰€æœ‰ä¸“å®¶å…±äº«ï¼Œé¿å…é‡å¤åŠ è½½ï¼‰
            autonomy_protocol = get_autonomy_protocol()

            # æå–è§’è‰²ç±»å‹ï¼ˆç”¨äºæ¨¡æ¿ç¼“å­˜ï¼‰
            role_type = self._extract_base_type(role_object['role_id'])

            # ğŸ”¥ v7.18 å‡çº§1: ä½¿ç”¨ Prompt æ¨¡æ¿ç³»ç»Ÿï¼ˆé¢„æ„å»ºé™æ€éƒ¨åˆ†ï¼‰
            from ..core.prompt_templates import get_expert_template

            template = get_expert_template(role_type, base_system_prompt, autonomy_protocol)

            # ğŸ”¥ v7.10: åˆ›æ„å™äº‹æ¨¡å¼çš„ç‰¹æ®Šè¯´æ˜
            creative_mode_note = ""
            if is_creative_narrative:
                creative_mode_note = f"""
# ğŸ¨ åˆ›æ„å™äº‹æ¨¡å¼ (Creative Narrative Mode)

âš ï¸ **ç‰¹åˆ«è¯´æ˜**: ä½ æ­£åœ¨åˆ›æ„å™äº‹æ¨¡å¼ä¸‹å·¥ä½œï¼Œä»¥ä¸‹çº¦æŸæ”¾å®½ï¼š
- `completion_rate` å’Œ `quality_self_assessment` **å¯é€‰å¡«**ï¼ˆå¦‚ä¸é€‚ç”¨å¯çœç•¥æˆ–è®¾ä¸ºé»˜è®¤å€¼ï¼‰
- `execution_time_estimate` **å¯é€‰å¡«**ï¼ˆåˆ›æ„è¿‡ç¨‹éš¾ä»¥ç²¾ç¡®é‡åŒ–æ—¶é—´ï¼‰
- å…è®¸æ›´è‡ªç”±çš„å™äº‹ç»“æ„å’Œè¡¨è¾¾æ–¹å¼
- è¾“å‡ºé‡ç‚¹åœ¨äº**å™äº‹è´¨é‡å’Œæƒ…æ„Ÿå…±é¸£**ï¼Œè€Œéé‡åŒ–æŒ‡æ ‡

ğŸ’¡ **å»ºè®®**: å¦‚æœå™äº‹å†…å®¹æœ¬èº«å°±åŒ…å«å®Œæ•´æ€§å’Œè´¨é‡çš„ä½“ç°ï¼Œå¯ä»¥ç®€åŒ–æˆ–çœç•¥è¿™äº›é‡åŒ–å­—æ®µã€‚
"""

            # ğŸ”¥ v7.18 å‡çº§1: ä½¿ç”¨æ¨¡æ¿æ¸²æŸ“ï¼ˆåªæ„å»º20%çš„åŠ¨æ€å†…å®¹ï¼‰
            return template.render(
                dynamic_role_name=role_object.get('dynamic_role_name', role_object.get('role_name')),
                task_instruction=task_instruction,
                context=context,
                state=state,
                creative_mode_note=creative_mode_note
            )

        except Exception as e:
            logger.error(f"æ„å»ºä»»åŠ¡å¯¼å‘ä¸“å®¶æç¤ºè¯æ—¶å‡ºé”™: {str(e)}")
            return {
                "system_prompt": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åˆ†æå¸ˆï¼Œè¯·åŸºäºæä¾›çš„ä¿¡æ¯è¿›è¡Œåˆ†æã€‚",
                "user_prompt": f"è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š\n{context}"
            }

    def _extract_base_type(self, role_id: str) -> str:
        """
        æå–è§’è‰²çš„åŸºç¡€ç±»å‹ï¼ˆç”¨äºæ¨¡æ¿ç¼“å­˜ï¼‰

        Args:
            role_id: è§’è‰² IDï¼ˆå¦‚ "3-1", "V3_å™äº‹ä¸“å®¶_3-1"ï¼‰

        Returns:
            åŸºç¡€ç±»å‹ï¼ˆå¦‚ "V3"ï¼‰
        """
        if role_id.startswith("V") and "_" in role_id:
            return role_id.split("_")[0]
        elif role_id.startswith("2-"):
            return "V2"
        elif role_id.startswith("3-"):
            return "V3"
        elif role_id.startswith("4-"):
            return "V4"
        elif role_id.startswith("5-"):
            return "V5"
        elif role_id.startswith("6-"):
            return "V6"
        else:
            logger.warning(f"æ— æ³•æå–åŸºç¡€ç±»å‹: {role_id}")
            return role_id
    
    def _parse_and_validate_output(self, expert_output: str, role_object: Dict[str, Any]) -> Dict[str, Any]:
        """
        è§£æå¹¶éªŒè¯ä¸“å®¶è¾“å‡ºæ˜¯å¦ç¬¦åˆTaskOrientedExpertOutputç»“æ„
        å¦‚æœéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨é™çº§ç­–ç•¥æ„é€ é»˜è®¤ç»“æ„
        
        ğŸ”§ v7.11 å¢å¼º: æ›´å¼ºçš„ JSON é¢„å¤„ç† + å¤šç§ä¿®å¤ç­–ç•¥
        """
        try:
            # ğŸ”§ v7.11: å…ˆè¿›è¡Œå…¨å±€é¢„å¤„ç†ï¼Œç§»é™¤æ‰€æœ‰markdownä»£ç å—æ ‡è®°
            cleaned_output = expert_output.strip()
            
            # ç§»é™¤æ‰€æœ‰markdownä»£ç å—æ ‡è®°ï¼ˆåŒ…æ‹¬```json, ```JSON, ``` ç­‰å˜ä½“ï¼‰
            import re
            # å¤„ç† ```json æˆ– ```JSON å¼€å¤´
            if re.search(r'^```(?:json|JSON)?\s*', cleaned_output):
                cleaned_output = re.sub(r'^```(?:json|JSON)?\s*', '', cleaned_output)
            # å¤„ç†ç»“å°¾çš„ ```
            cleaned_output = re.sub(r'\s*```$', '', cleaned_output)
            # å¤„ç†ä¸­é—´å¯èƒ½å­˜åœ¨çš„ä»£ç å—æ ‡è®°
            cleaned_output = re.sub(r'```(?:json|JSON)?\s*([\s\S]*?)\s*```', r'\1', cleaned_output)
            
            logger.debug(f"ğŸ”§ JSONé¢„å¤„ç†åé•¿åº¦: {len(cleaned_output)}")
            
            # æå–JSONå†…å®¹
            if "{" in cleaned_output and "}" in cleaned_output:
                json_str = cleaned_output[cleaned_output.find("{"):cleaned_output.rfind("}")+1]
            else:
                logger.warning("è¾“å‡ºä¸åŒ…å«æœ‰æ•ˆJSONï¼Œå°è¯•æ•´ä½“è§£æ")
                json_str = cleaned_output.strip()
            
            # ğŸ”§ å°è¯•è§£æJSONï¼ˆå¤šç§ä¿®å¤ç­–ç•¥ï¼‰
            parsed_output = self._try_parse_json_with_fixes(json_str)
            
            if parsed_output is None:
                raise json.JSONDecodeError("æ‰€æœ‰JSONä¿®å¤ç­–ç•¥éƒ½å¤±è´¥äº†", json_str, 0)
            
            # éªŒè¯ç»“æ„ï¼ˆä½¿ç”¨Pydanticæ¨¡å‹éªŒè¯ï¼‰
            task_oriented_output = TaskOrientedExpertOutput(**parsed_output)
            
            logger.info(f"âœ… æˆåŠŸéªŒè¯ {role_object.get('role_name', 'Unknown')} çš„TaskOrientedExpertOutputç»“æ„")
            return task_oriented_output.dict()
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            logger.error(f"åŸå§‹è¾“å‡º: {expert_output[:200]}...")
        except Exception as e:
            logger.error(f"âŒ è¾“å‡ºéªŒè¯å¤±è´¥: {str(e)}")
        
        # é™çº§ç­–ç•¥ï¼šæ„é€ ç¬¦åˆæœ€å°è§„èŒƒçš„é»˜è®¤ç»“æ„
        logger.warning(f"âš ï¸ ä½¿ç”¨é™çº§ç­–ç•¥ä¸º {role_object.get('role_name', 'Unknown')} æ„é€ é»˜è®¤è¾“å‡º")
        return self._create_fallback_output(expert_output, role_object)
    
    def _try_parse_json_with_fixes(self, json_str: str) -> Optional[Dict[str, Any]]:
        """
        å°è¯•å¤šç§ç­–ç•¥ä¿®å¤å¹¶è§£æ JSON
        
        å¸¸è§é—®é¢˜:
        1. ç¼ºå°‘é€—å·åˆ†éš”ç¬¦
        2. å¤šä½™çš„é€—å·
        3. è½¬ä¹‰å­—ç¬¦é—®é¢˜
        4. æˆªæ–­çš„ JSON
        """
        import re
        
        # ç­–ç•¥1: ç›´æ¥è§£æ
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            pass
        
        # ç­–ç•¥2: ç§»é™¤æ§åˆ¶å­—ç¬¦å¹¶é‡è¯•
        try:
            cleaned = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_str)
            return json.loads(cleaned)
        except json.JSONDecodeError:
            pass
        
        # ç­–ç•¥3: ä¿®å¤å¸¸è§çš„é€—å·é—®é¢˜
        try:
            # ç§»é™¤æ•°ç»„/å¯¹è±¡æœ«å°¾å¤šä½™çš„é€—å·
            fixed = re.sub(r',\s*([}\]])', r'\1', json_str)
            # æ·»åŠ ç¼ºå¤±çš„é€—å·ï¼ˆå¯¹è±¡å±æ€§ä¹‹é—´ï¼‰
            fixed = re.sub(r'"\s*\n\s*"', '",\n"', fixed)
            # æ·»åŠ ç¼ºå¤±çš„é€—å·ï¼ˆæ•°ç»„å…ƒç´ ä¹‹é—´ï¼‰
            fixed = re.sub(r'}\s*\n\s*{', '},\n{', fixed)
            return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        
        # ç­–ç•¥4: å°è¯•ä¿®å¤æˆªæ–­çš„ JSON
        try:
            # è®¡ç®—æœªé—­åˆçš„æ‹¬å·
            open_braces = json_str.count('{') - json_str.count('}')
            open_brackets = json_str.count('[') - json_str.count(']')
            
            if open_braces > 0 or open_brackets > 0:
                # å°è¯•è¡¥å…¨æ‹¬å·
                fixed = json_str
                fixed += '}' * open_braces
                fixed += ']' * open_brackets
                return json.loads(fixed)
        except json.JSONDecodeError:
            pass
        
        # ç­–ç•¥5: æå–æœ€å¤–å±‚çš„æœ‰æ•ˆ JSON å¯¹è±¡
        try:
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ªå¯¹åº”çš„ }
            depth = 0
            start = -1
            end = -1
            for i, c in enumerate(json_str):
                if c == '{':
                    if depth == 0:
                        start = i
                    depth += 1
                elif c == '}':
                    depth -= 1
                    if depth == 0:
                        end = i + 1
                        break
            
            if start >= 0 and end > start:
                return json.loads(json_str[start:end])
        except json.JSONDecodeError:
            pass
        
        logger.warning("âš ï¸ æ‰€æœ‰JSONä¿®å¤ç­–ç•¥éƒ½å¤±è´¥äº†")
        return None
    
    def _create_fallback_output(self, raw_output: str, role_object: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ›å»ºé™çº§è¾“å‡ºç»“æ„ï¼ˆå½“PydanticéªŒè¯å¤±è´¥æ—¶ï¼‰
        
        ğŸ”§ v7.6: å¢å¼ºå¯¹åµŒå¥— JSON çš„å¤„ç†ï¼Œé¿å…æ˜¾ç¤ºåŸå§‹ä»£ç 
        """
        role_name = role_object.get('dynamic_role_name', role_object.get('role_name', 'Unknown Expert'))
        
        # ğŸ”§ å°è¯•æå–å®é™…å†…å®¹è€Œä¸æ˜¯åŸå§‹ JSON
        cleaned_content = self._extract_meaningful_content(raw_output)
        
        return {
            "task_execution_report": {
                "deliverable_outputs": [
                    {
                        "deliverable_name": "åˆ†ææŠ¥å‘Š",
                        "content": cleaned_content,
                        "completion_status": "completed",
                        "completion_rate": 1.0,
                        "notes": "ä½¿ç”¨é™çº§ç­–ç•¥ç”Ÿæˆçš„è¾“å‡º",
                        "quality_self_assessment": 0.7
                    }
                ],
                "task_completion_summary": f"{role_name}å·²å®Œæˆåˆ†æä»»åŠ¡",
                "additional_insights": None,
                "execution_challenges": ["LLMæœªæŒ‰é¢„æœŸæ ¼å¼è¿”å›ï¼Œä½¿ç”¨é™çº§ç­–ç•¥"]
            },
            "protocol_execution": {
                "protocol_status": "complied",
                "compliance_confirmation": "æ¥å—éœ€æ±‚åˆ†æå¸ˆçš„æ´å¯Ÿ",
                "challenge_details": None,
                "reinterpretation": None
            },
            "execution_metadata": {
                "confidence": 0.7,
                "completion_rate": 1.0,
                "execution_time_estimate": "æœªçŸ¥",
                "execution_notes": "æ­¤è¾“å‡ºä½¿ç”¨é™çº§ç­–ç•¥ç”Ÿæˆï¼Œæœªç»æ ‡å‡†éªŒè¯",
                "dependencies_satisfied": True
            }
        }

    def _extract_meaningful_content(self, raw_output: str) -> Any:
        """
        ä»åŸå§‹è¾“å‡ºä¸­æå–æœ‰æ„ä¹‰çš„å†…å®¹
        
        å¤„ç†:
        1. Markdown ä»£ç å—åŒ…è£¹çš„ JSON
        2. åµŒå¥—çš„ task_execution_report
        3. ç›´æ¥è¿”å›è§£æåçš„ç»“æ„åŒ–æ•°æ®
        """
        if not raw_output:
            return "æš‚æ— è¾“å‡º"
        
        text = raw_output.strip()
        
        # ç§»é™¤ markdown ä»£ç å—
        if text.startswith("```json"):
            text = text[7:]
        elif text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()
        
        # å°è¯•è§£æ JSON
        if text.startswith("{") or text.startswith("["):
            try:
                parsed = json.loads(text)
                
                # å¦‚æœæ˜¯å®Œæ•´çš„ TaskOrientedExpertOutput ç»“æ„
                if isinstance(parsed, dict):
                    # æå– deliverable_outputs ä¸­çš„å†…å®¹
                    ter = parsed.get("task_execution_report", {})
                    if ter:
                        deliverable_outputs = ter.get("deliverable_outputs", [])
                        if deliverable_outputs:
                            # è¿”å›ç¬¬ä¸€ä¸ªäº¤ä»˜ç‰©çš„å†…å®¹
                            first = deliverable_outputs[0]
                            if isinstance(first, dict):
                                content = first.get("content")
                                if content:
                                    # å¦‚æœå†…å®¹æœ¬èº«ä¹Ÿæ˜¯ JSON å­—ç¬¦ä¸²ï¼Œé€’å½’å¤„ç†
                                    if isinstance(content, str) and (content.strip().startswith("{") or content.strip().startswith("[")):
                                        return self._extract_meaningful_content(content)
                                    return content
                    
                    # è¿”å›è§£æåçš„ç»“æ„ï¼ˆè®©å‰ç«¯è‡ªè¡Œæ¸²æŸ“ï¼‰
                    return parsed
                
            except json.JSONDecodeError:
                pass
        
        # è¿”å›æ¸…ç†åçš„æ–‡æœ¬
        return text

    
    def _validate_task_completion(self, structured_output: Dict[str, Any], task_instruction: Dict[str, Any]) -> bool:
        """
        éªŒè¯ä»»åŠ¡å®Œæˆæƒ…å†µï¼Œç¡®ä¿æ‰€æœ‰deliverableséƒ½å·²å¤„ç†

        ğŸ”¥ v7.9.3: å¢å¼ºéªŒè¯ - æ£€æµ‹åˆ°ç¼ºå¤±äº¤ä»˜ç‰©æ—¶æ ‡è®°éœ€è¦è¡¥å…¨ï¼Œè€Œéç›´æ¥é€šè¿‡

        Returns:
            bool: Trueè¡¨ç¤ºéªŒè¯é€šè¿‡ï¼ŒFalseè¡¨ç¤ºéœ€è¦è¡¥å…¨
        """
        if not structured_output:
            logger.warning("âš ï¸ æ— ç»“æ„åŒ–è¾“å‡ºï¼Œæ— æ³•éªŒè¯ä»»åŠ¡å®Œæˆæƒ…å†µ")
            return False

        try:
            # è·å–ä»»åŠ¡æŒ‡ä»¤ä¸­çš„é¢„æœŸäº¤ä»˜ç‰©
            expected_deliverables = task_instruction.get('deliverables', [])

            # è·å–å®é™…çš„äº¤ä»˜ç‰©è¾“å‡ºï¼ˆä¿®å¤å­—æ®µè·¯å¾„ï¼‰
            task_exec_report = structured_output.get('task_execution_report', {})
            actual_results = task_exec_report.get('deliverable_outputs', [])

            # å¦‚æœæ²¡æœ‰é¢„æœŸäº¤ä»˜ç‰©ï¼Œåˆ™ç›´æ¥é€šè¿‡ï¼ˆé™çº§åœºæ™¯ï¼‰
            if not expected_deliverables:
                logger.info("âœ… æ— é¢„æœŸäº¤ä»˜ç‰©è¦æ±‚ï¼ŒéªŒè¯é€šè¿‡")
                return True

            expected_names = {d.get('name', f'äº¤ä»˜ç‰©{i}') for i, d in enumerate(expected_deliverables, 1)}
            actual_names = {r.get('deliverable_name', '') for r in actual_results}

            missing_deliverables = expected_names - actual_names
            if missing_deliverables:
                logger.warning(f"âš ï¸ ç¼ºå¤±äº¤ä»˜ç‰©: {missing_deliverables}")
                # ğŸ”¥ v7.9.3: ä¸å†ç›´æ¥è¿”å›Trueï¼Œè€Œæ˜¯æ ‡è®°éœ€è¦è¡¥å…¨
                if 'validation_result' not in structured_output:
                    structured_output['validation_result'] = {}
                structured_output['validation_result']['missing_deliverables'] = list(missing_deliverables)
                structured_output['validation_result']['needs_completion'] = True
                structured_output['validation_result']['expected_deliverables'] = expected_deliverables
                logger.info(f"ğŸ“ æ ‡è®°éœ€è¦è¡¥å…¨çš„äº¤ä»˜ç‰©: {missing_deliverables}")
                return False  # ğŸ”¥ è¿”å›Falseè¡¨ç¤ºéªŒè¯æœªé€šè¿‡ï¼Œéœ€è¦è¡¥å…¨

            # éªŒè¯åè®®æ‰§è¡ŒçŠ¶æ€ï¼ˆä¿®å¤å­—æ®µåï¼‰
            protocol_execution = structured_output.get('protocol_execution', {})
            if not protocol_execution.get('protocol_status'):
                logger.warning("âš ï¸ åè®®æ‰§è¡ŒçŠ¶æ€ç¼ºå¤±")
                # é™çº§åœºæ™¯ä¸‹ä¸å¼ºåˆ¶å¤±è´¥
                return True

            logger.info("âœ… ä»»åŠ¡å®ŒæˆéªŒè¯é€šè¿‡")
            return True

        except Exception as e:
            logger.error(f"âŒ éªŒè¯ä»»åŠ¡å®Œæˆæ—¶å‡ºé”™: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿè¿”å›Trueï¼Œé¿å…é˜»å¡æµç¨‹
            return True
    
    async def _complete_missing_deliverables(
        self,
        structured_output: Dict[str, Any],
        role_object: Dict[str, Any],
        context: str,
        state: ProjectAnalysisState
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ v7.11: è‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„äº¤ä»˜ç‰©ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰

        å½“æ£€æµ‹åˆ°ä¸“å®¶è¾“å‡ºç¼ºå°‘éƒ¨åˆ†äº¤ä»˜ç‰©æ—¶ï¼Œè‡ªåŠ¨è°ƒç”¨LLMè¡¥å……ç¼ºå¤±éƒ¨åˆ†
        
        æ€§èƒ½ä¼˜åŒ–:
        - é™åˆ¶æ¯æ¬¡è¡¥å…¨æœ€å¤š3ä¸ªäº¤ä»˜ç‰©
        - æ·»åŠ è¶…æ—¶æ§åˆ¶ï¼ˆ30ç§’ï¼‰
        - å¦‚æœç¼ºå¤±è¿‡å¤šï¼Œä¼˜å…ˆè¡¥å…¨æ ¸å¿ƒäº¤ä»˜ç‰©

        Args:
            structured_output: å½“å‰çš„ç»“æ„åŒ–è¾“å‡ºï¼ˆåŒ…å«validation_resultï¼‰
            role_object: è§’è‰²å¯¹è±¡
            context: é¡¹ç›®ä¸Šä¸‹æ–‡
            state: å½“å‰çŠ¶æ€

        Returns:
            Dict: è¡¥å…¨åçš„ç»“æ„åŒ–è¾“å‡º
        """
        import asyncio
        
        try:
            validation_result = structured_output.get('validation_result', {})
            missing_deliverables = validation_result.get('missing_deliverables', [])
            expected_deliverables = validation_result.get('expected_deliverables', [])

            if not missing_deliverables:
                logger.warning("âš ï¸ æ²¡æœ‰ç¼ºå¤±çš„äº¤ä»˜ç‰©ï¼Œæ— éœ€è¡¥å…¨")
                return structured_output

            # ğŸ”§ v7.11: æ€§èƒ½ä¼˜åŒ– - é™åˆ¶æ¯æ¬¡è¡¥å…¨çš„æ•°é‡
            MAX_COMPLETION_COUNT = 3
            if len(missing_deliverables) > MAX_COMPLETION_COUNT:
                logger.warning(f"âš ï¸ ç¼ºå¤±äº¤ä»˜ç‰©è¿‡å¤š({len(missing_deliverables)}ä¸ª)ï¼Œåªè¡¥å…¨å‰{MAX_COMPLETION_COUNT}ä¸ª")
                missing_deliverables = missing_deliverables[:MAX_COMPLETION_COUNT]

            logger.info(f"ğŸ”„ å¼€å§‹è¡¥å…¨ç¼ºå¤±çš„äº¤ä»˜ç‰©: {missing_deliverables}")

            # æ„å»ºè¡¥å…¨æç¤ºè¯
            completion_prompt = self._build_completion_prompt(
                role_object=role_object,
                context=context,
                state=state,
                missing_deliverables=missing_deliverables,
                expected_deliverables=expected_deliverables,
                existing_output=structured_output
            )

            # ğŸ”§ v7.11: æ·»åŠ è¶…æ—¶æ§åˆ¶ï¼ˆ30ç§’ï¼‰
            # ğŸ”¥ v7.52: ä½¿ç”¨ JSON æ¨¡å¼å¼ºåˆ¶ JSON è¾“å‡º
            llm = self._get_llm()

            # å°è¯•ä½¿ç”¨ with_structured_output (JSONæ¨¡å¼)
            try:
                llm_json_mode = llm.with_structured_output(method="json_mode")
                logger.info("ğŸ”§ [v7.52] ä½¿ç”¨ JSON æ¨¡å¼å¼ºåˆ¶è¾“å‡º")
            except Exception as e:
                logger.debug(f"âš ï¸ JSONæ¨¡å¼ä¸å¯ç”¨ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼: {e}")
                llm_json_mode = llm

            messages = [
                {"role": "system", "content": completion_prompt["system_prompt"]},
                {"role": "user", "content": completion_prompt["user_prompt"]}
            ]

            try:
                response = await asyncio.wait_for(
                    llm_json_mode.ainvoke(messages),
                    timeout=30.0  # 30ç§’è¶…æ—¶
                )
                completion_output = response.content if hasattr(response, 'content') else str(response)
            except asyncio.TimeoutError:
                logger.warning("âš ï¸ äº¤ä»˜ç‰©è¡¥å…¨è¶…æ—¶ï¼ˆ30ç§’ï¼‰ï¼Œä½¿ç”¨åŸå§‹è¾“å‡º")
                return structured_output

            # è§£æè¡¥å……çš„äº¤ä»˜ç‰©
            completed_deliverables = self._parse_completion_output(completion_output, missing_deliverables)

            # ğŸ”¥ v7.52: æ‰¹é‡å¤±è´¥æ—¶å°è¯•é€ä¸ªç”Ÿæˆ
            if not completed_deliverables and len(missing_deliverables) > 1:
                logger.warning(f"âš ï¸ æ‰¹é‡è¡¥å…¨å¤±è´¥ï¼Œå°è¯•é€ä¸ªç”Ÿæˆ {len(missing_deliverables)} ä¸ªäº¤ä»˜ç‰©")
                completed_deliverables = await self._complete_deliverables_one_by_one(
                    role_object, context, state, missing_deliverables
                )

            # ğŸ”§ v7.23: æ›´å‡†ç¡®çš„æ—¥å¿—ä¿¡æ¯
            if not completed_deliverables:
                logger.warning(f"âš ï¸ äº¤ä»˜ç‰©è¡¥å…¨å®Œå…¨å¤±è´¥ï¼šå°è¯•è¡¥å…¨ {len(missing_deliverables)} ä¸ªï¼Œå®é™…è§£æå‡º 0 ä¸ª")
                # ğŸ”¥ v7.52: ç”Ÿæˆå ä½ç¬¦ï¼Œé¿å…å®Œå…¨å¤±è´¥
                completed_deliverables = self._generate_placeholder_deliverables(missing_deliverables)
                logger.info(f"ğŸ”§ [v7.52] å·²ç”Ÿæˆ {len(completed_deliverables)} ä¸ªå ä½äº¤ä»˜ç‰©")

            # åˆå¹¶åˆ°åŸå§‹è¾“å‡º
            task_exec_report = structured_output.get('task_execution_report', {})
            deliverable_outputs = task_exec_report.get('deliverable_outputs', [])

            # æ·»åŠ è¡¥å……çš„äº¤ä»˜ç‰©
            for deliverable in completed_deliverables:
                deliverable_outputs.append(deliverable)
                logger.info(f"âœ… å·²è¡¥å…¨äº¤ä»˜ç‰©: {deliverable.get('deliverable_name')}")

            # æ›´æ–°ç»“æ„åŒ–è¾“å‡º
            task_exec_report['deliverable_outputs'] = deliverable_outputs
            structured_output['task_execution_report'] = task_exec_report

            # æ¸…é™¤validation_resultæ ‡è®°
            if 'validation_result' in structured_output:
                del structured_output['validation_result']

            logger.info(f"âœ… æˆåŠŸè¡¥å…¨ {len(completed_deliverables)}/{len(missing_deliverables)} ä¸ªäº¤ä»˜ç‰©")
            return structured_output

        except Exception as e:
            logger.error(f"âŒ è¡¥å…¨ç¼ºå¤±äº¤ä»˜ç‰©æ—¶å‡ºé”™: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›åŸå§‹è¾“å‡ºï¼Œä¸é˜»å¡æµç¨‹
            logger.warning("âš ï¸ è¡¥å…¨å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è¾“å‡º")
            return structured_output

    def _build_completion_prompt(
        self,
        role_object: Dict[str, Any],
        context: str,
        state: ProjectAnalysisState,
        missing_deliverables: List[str],
        expected_deliverables: List[Dict[str, Any]],
        existing_output: Dict[str, Any]
    ) -> Dict[str, str]:
        """
        ğŸ”¥ v7.9.3: æ„å»ºè¡¥å…¨æç¤ºè¯ï¼Œåªè¦æ±‚LLMè¾“å‡ºç¼ºå¤±çš„äº¤ä»˜ç‰©

        Args:
            role_object: è§’è‰²å¯¹è±¡
            context: é¡¹ç›®ä¸Šä¸‹æ–‡
            state: å½“å‰çŠ¶æ€
            missing_deliverables: ç¼ºå¤±çš„äº¤ä»˜ç‰©åç§°åˆ—è¡¨
            expected_deliverables: é¢„æœŸçš„æ‰€æœ‰äº¤ä»˜ç‰©å®šä¹‰
            existing_output: å·²æœ‰çš„è¾“å‡ºï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰

        Returns:
            Dict: åŒ…å«system_promptå’Œuser_promptçš„å­—å…¸
        """
        # ç­›é€‰å‡ºç¼ºå¤±çš„äº¤ä»˜ç‰©å®šä¹‰
        missing_defs = [d for d in expected_deliverables if d.get('name') in missing_deliverables]

        # è·å–å·²å®Œæˆçš„äº¤ä»˜ç‰©ï¼ˆä½œä¸ºå‚è€ƒï¼‰
        existing_deliverables = existing_output.get('task_execution_report', {}).get('deliverable_outputs', [])
        existing_names = [d.get('deliverable_name') for d in existing_deliverables]

        system_prompt = f"""
ä½ æ˜¯ {role_object.get('dynamic_role_name', role_object.get('role_name'))}ã€‚

# ğŸ¯ è¡¥å…¨ä»»åŠ¡

ä½ ä¹‹å‰å·²ç»å®Œæˆäº†éƒ¨åˆ†äº¤ä»˜ç‰©ï¼š{', '.join(existing_names)}

ä½†è¿˜æœ‰ä»¥ä¸‹äº¤ä»˜ç‰©**å°šæœªå®Œæˆ**ï¼Œéœ€è¦ä½ ç°åœ¨è¡¥å……ï¼š

"""
        for i, deliverable in enumerate(missing_defs, 1):
            system_prompt += f"""
**ç¼ºå¤±äº¤ä»˜ç‰© {i}: {deliverable.get('name')}**
- æè¿°: {deliverable.get('description', '')}
- æ ¼å¼: {deliverable.get('format', 'analysis')}
- æˆåŠŸæ ‡å‡†: {', '.join(deliverable.get('success_criteria', []))}
"""

        system_prompt += """

# ğŸ“Š è¾“å‡ºè¦æ±‚

**è¯·åªè¾“å‡ºç¼ºå¤±çš„äº¤ä»˜ç‰©**ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```json
{
  "deliverable_outputs": [
    {
      "deliverable_name": "ç¼ºå¤±äº¤ä»˜ç‰©çš„åç§°ï¼ˆå¿…é¡»ä¸ä¸Šé¢åˆ—å‡ºçš„åç§°å®Œå…¨ä¸€è‡´ï¼‰",
      "content": "è¯¦ç»†çš„åˆ†æå†…å®¹ï¼ˆå®Œæ•´ã€ä¸“ä¸šã€ç¬¦åˆæˆåŠŸæ ‡å‡†ï¼‰",
      "completion_status": "completed",
      "completion_rate": 0.95,
      "notes": "è¡¥å……è¯´æ˜",
      "quality_self_assessment": 0.9
    }
  ]
}
```

# âš ï¸ å…³é”®è¦æ±‚

1. **åªè¾“å‡ºç¼ºå¤±çš„äº¤ä»˜ç‰©**ï¼Œä¸è¦é‡å¤å·²å®Œæˆçš„äº¤ä»˜ç‰©
2. **deliverable_nameå¿…é¡»ä¸ä»»åŠ¡æŒ‡ä»¤ä¸­çš„åç§°å®Œå…¨ä¸€è‡´**
3. **contentè¦è¯¦ç»†å®Œæ•´**ï¼Œä¸è¦ç®€åŒ–æˆ–çœç•¥
4. **è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼**ï¼Œä¸è¦æœ‰é¢å¤–æ–‡å­—
5. **ä¸è¦ä½¿ç”¨markdownä»£ç å—åŒ…è£¹JSON**

å¼€å§‹è¡¥å……ç¼ºå¤±çš„äº¤ä»˜ç‰©ï¼š
"""

        user_prompt = f"""
# ğŸ“‚ é¡¹ç›®ä¸Šä¸‹æ–‡
{context}

# ğŸ“Š å½“å‰é¡¹ç›®çŠ¶æ€
- é¡¹ç›®é˜¶æ®µ: {state.get('current_phase', 'åˆ†æé˜¶æ®µ')}
- å·²å®Œæˆåˆ†æ: {len(state.get('expert_analyses', {}))}ä¸ªä¸“å®¶

# ğŸ¯ ä½ çš„ä»»åŠ¡

è¯·åŸºäºä¸Šè¿°é¡¹ç›®ä¸Šä¸‹æ–‡ï¼Œè¡¥å……ä»¥ä¸‹ç¼ºå¤±çš„äº¤ä»˜ç‰©ï¼š
{', '.join(missing_deliverables)}

**è®°ä½**ï¼šåªè¾“å‡ºç¼ºå¤±çš„äº¤ä»˜ç‰©ï¼Œæ ¼å¼ä¸ºJSONï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–æ–‡å­—ã€‚
"""

        return {
            "system_prompt": system_prompt,
            "user_prompt": user_prompt
        }

    def _parse_completion_output(self, completion_output: str, missing_deliverables: List[str]) -> List[Dict[str, Any]]:
        """
        ğŸ”¥ v7.9.3: è§£æè¡¥å…¨è¾“å‡ºï¼Œæå–äº¤ä»˜ç‰©åˆ—è¡¨
        ğŸ”§ v7.23: å¢å¼º JSON è§£æå®¹é”™æ€§ï¼Œæ”¯æŒå¤šç§æ ¼å¼

        Args:
            completion_output: LLMè¿”å›çš„è¡¥å…¨å†…å®¹
            missing_deliverables: é¢„æœŸçš„ç¼ºå¤±äº¤ä»˜ç‰©åç§°åˆ—è¡¨

        Returns:
            List[Dict]: è§£æåçš„äº¤ä»˜ç‰©åˆ—è¡¨
        """
        import re
        
        try:
            json_str = None
            
            # ç­–ç•¥1: æå– ```json ... ``` ä»£ç å—
            if "```json" in completion_output:
                json_start = completion_output.find("```json") + 7
                json_end = completion_output.find("```", json_start)
                if json_end > json_start:
                    json_str = completion_output[json_start:json_end].strip()
            
            # ç­–ç•¥2: æå– ``` ... ``` ä»£ç å—ï¼ˆæ— è¯­è¨€æ ‡è¯†ï¼‰
            if not json_str and "```" in completion_output:
                matches = re.findall(r'```\s*([\s\S]*?)\s*```', completion_output)
                for match in matches:
                    if '{' in match and '}' in match:
                        json_str = match.strip()
                        break
            
            # ç­–ç•¥3: æå–æœ€å¤–å±‚ {...} æˆ– [...]
            if not json_str:
                # ä¼˜å…ˆå°è¯•æå–å¯¹è±¡
                obj_match = re.search(r'\{[\s\S]*\}', completion_output)
                if obj_match:
                    json_str = obj_match.group()
                else:
                    # å°è¯•æå–æ•°ç»„
                    arr_match = re.search(r'\[[\s\S]*\]', completion_output)
                    if arr_match:
                        json_str = arr_match.group()
            
            if not json_str:
                logger.warning("âš ï¸ è¡¥å…¨è¾“å‡ºä¸åŒ…å«æœ‰æ•ˆJSONç»“æ„")
                return []
            
            # ğŸ”§ v7.23: æ¸…ç†å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
            # ç§»é™¤ JavaScript é£æ ¼çš„æ³¨é‡Š
            json_str = re.sub(r'//.*?(?=\n|$)', '', json_str)
            json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
            # ç§»é™¤å°¾éšé€—å·
            json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
            
            # è§£æJSON
            parsed = json.loads(json_str)

            # æå–deliverable_outputsï¼ˆæ”¯æŒå¤šç§å­—æ®µåï¼‰
            if isinstance(parsed, dict):
                deliverables = (
                    parsed.get('deliverable_outputs') or 
                    parsed.get('deliverables') or 
                    parsed.get('outputs') or
                    []
                )
                if deliverables:
                    logger.info(f"âœ… æˆåŠŸè§£æ {len(deliverables)} ä¸ªè¡¥å…¨äº¤ä»˜ç‰©")
                    return deliverables
                else:
                    logger.warning("âš ï¸ è§£æçš„JSONä¸­æ²¡æœ‰deliverable_outputså­—æ®µ")
                    return []
            elif isinstance(parsed, list):
                # å¦‚æœç›´æ¥è¿”å›æ•°ç»„
                if parsed:
                    logger.info(f"âœ… æˆåŠŸè§£æ {len(parsed)} ä¸ªè¡¥å…¨äº¤ä»˜ç‰©ï¼ˆæ•°ç»„æ ¼å¼ï¼‰")
                    return parsed
                return []
            else:
                logger.warning(f"âš ï¸ è§£æç»“æœç±»å‹ä¸ç¬¦åˆé¢„æœŸ: {type(parsed)}")
                return []

        except json.JSONDecodeError as e:
            logger.error(f"âŒ è§£æè¡¥å…¨è¾“å‡ºJSONå¤±è´¥: {str(e)}")
            logger.debug(f"åŸå§‹è¾“å‡ºç‰‡æ®µ: {completion_output[:300]}...")
            
            # ğŸ”§ v7.23: å°è¯•ä»åŸå§‹è¾“å‡ºæ„é€ é»˜è®¤äº¤ä»˜ç‰©
            fallback_deliverables = []
            for name in missing_deliverables[:2]:  # æœ€å¤šæ„é€ 2ä¸ª
                fallback_deliverables.append({
                    "deliverable_name": name,
                    "content": f"[è§£æå¤±è´¥ï¼Œéœ€è¦äººå·¥è¡¥å……] åŸå§‹è¾“å‡º: {completion_output[:200]}...",
                    "completion_status": "partial",
                    "completion_rate": 0.3,
                    "notes": "LLMè¾“å‡ºæ ¼å¼å¼‚å¸¸ï¼Œå·²ä½¿ç”¨é™çº§ç­–ç•¥"
                })
            if fallback_deliverables:
                logger.warning(f"âš ï¸ ä½¿ç”¨é™çº§ç­–ç•¥ï¼Œæ„é€  {len(fallback_deliverables)} ä¸ªå ä½äº¤ä»˜ç‰©")
            return fallback_deliverables
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è¡¥å…¨è¾“å‡ºæ—¶å‡ºé”™: {str(e)}")
            return []

    async def _complete_deliverables_one_by_one(
        self,
        role_object: Dict[str, Any],
        context: str,
        state: ProjectAnalysisState,
        missing_deliverables: List[str]
    ) -> List[Dict[str, Any]]:
        """
        ğŸ”¥ v7.52: é€ä¸ªç”Ÿæˆç¼ºå¤±äº¤ä»˜ç‰©ï¼ˆé™çº§ç­–ç•¥ï¼‰

        å½“æ‰¹é‡ç”Ÿæˆå¤±è´¥æ—¶ï¼Œå°è¯•é€ä¸ªç”Ÿæˆæ¯ä¸ªäº¤ä»˜ç‰©ï¼Œ
        æé«˜æˆåŠŸç‡ã€‚

        Args:
            role_object: è§’è‰²å¯¹è±¡
            context: é¡¹ç›®ä¸Šä¸‹æ–‡
            state: å½“å‰çŠ¶æ€
            missing_deliverables: ç¼ºå¤±çš„äº¤ä»˜ç‰©åç§°åˆ—è¡¨

        Returns:
            List[Dict]: ç”Ÿæˆçš„äº¤ä»˜ç‰©åˆ—è¡¨
        """
        import asyncio

        completed = []
        llm = self._get_llm()

        for deliverable_name in missing_deliverables:
            try:
                logger.info(f"ğŸ”„ é€ä¸ªç”Ÿæˆ: {deliverable_name}")

                # æ„å»ºå•ä¸ªäº¤ä»˜ç‰©çš„æç¤ºè¯
                single_prompt = f"""ä½ æ˜¯ {role_object.get('name', 'ä¸“å®¶')}ã€‚

è¯·ç”Ÿæˆä»¥ä¸‹äº¤ä»˜ç‰©ï¼š
**{deliverable_name}**

# ğŸ“‚ é¡¹ç›®ä¸Šä¸‹æ–‡
{context[:1000]}...

# ğŸ¯ è¦æ±‚
1. è¾“å‡ºJSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
   - deliverable_name: "{deliverable_name}"
   - content: è¯¦ç»†å†…å®¹
   - key_insights: å…³é”®æ´å¯Ÿï¼ˆåˆ—è¡¨ï¼‰
   - completion_rate: å®Œæˆåº¦ï¼ˆ0-1ï¼‰

2. ç›´æ¥è¿”å›JSONï¼Œä¸è¦æœ‰é¢å¤–æ–‡å­—

è¾“å‡ºç¤ºä¾‹ï¼š
{{
  "deliverable_name": "{deliverable_name}",
  "content": "...",
  "key_insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2"],
  "completion_rate": 1.0
}}
"""

                # è°ƒç”¨LLMï¼ˆ10ç§’è¶…æ—¶ï¼‰
                response = await asyncio.wait_for(
                    llm.ainvoke([{"role": "user", "content": single_prompt}]),
                    timeout=10.0
                )
                output = response.content if hasattr(response, 'content') else str(response)

                # è§£æå•ä¸ªäº¤ä»˜ç‰©
                single_result = self._parse_single_deliverable_output(output, deliverable_name)
                if single_result:
                    completed.append(single_result)
                    logger.info(f"âœ… æˆåŠŸç”Ÿæˆ: {deliverable_name}")
                else:
                    logger.warning(f"âš ï¸ è§£æå¤±è´¥: {deliverable_name}")

            except asyncio.TimeoutError:
                logger.warning(f"âš ï¸ ç”Ÿæˆè¶…æ—¶: {deliverable_name}")
            except Exception as e:
                logger.error(f"âŒ ç”Ÿæˆå¤±è´¥ {deliverable_name}: {e}")

            # é™åˆ¶æœ€å¤šå°è¯•3ä¸ª
            if len(completed) >= 3:
                logger.info("ğŸ”§ å·²æˆåŠŸç”Ÿæˆ3ä¸ªäº¤ä»˜ç‰©ï¼Œåœæ­¢é€ä¸ªç”Ÿæˆ")
                break

        return completed

    def _parse_single_deliverable_output(self, output: str, expected_name: str) -> Optional[Dict[str, Any]]:
        """
        ğŸ”¥ v7.52: è§£æå•ä¸ªäº¤ä»˜ç‰©çš„LLMè¾“å‡º

        Args:
            output: LLMåŸå§‹è¾“å‡º
            expected_name: æœŸæœ›çš„äº¤ä»˜ç‰©åç§°

        Returns:
            Dict | None: è§£ææˆåŠŸè¿”å›äº¤ä»˜ç‰©å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        import re
        import json

        try:
            # æå–JSON
            json_str = None
            if "```json" in output:
                json_start = output.find("```json") + 7
                json_end = output.find("```", json_start)
                if json_end > json_start:
                    json_str = output[json_start:json_end].strip()
            elif "```" in output:
                matches = re.findall(r'```\s*([\s\S]*?)\s*```', output)
                for match in matches:
                    if '{' in match:
                        json_str = match.strip()
                        break

            if not json_str:
                obj_match = re.search(r'\{[\s\S]*\}', output)
                if obj_match:
                    json_str = obj_match.group()

            if not json_str:
                return None

            # è§£æJSON
            parsed = json.loads(json_str)

            # éªŒè¯å¿…éœ€å­—æ®µ
            if not parsed.get("deliverable_name"):
                parsed["deliverable_name"] = expected_name

            if not parsed.get("content"):
                return None

            # è¡¥å……å¯é€‰å­—æ®µ
            if "completion_rate" not in parsed:
                parsed["completion_rate"] = 0.8
            if "key_insights" not in parsed:
                parsed["key_insights"] = []

            return parsed

        except Exception as e:
            logger.debug(f"âš ï¸ å•ä¸ªäº¤ä»˜ç‰©è§£æå¤±è´¥: {e}")
            return None

    def _generate_placeholder_deliverables(self, missing_names: List[str]) -> List[Dict[str, Any]]:
        """
        ğŸ”¥ v7.52: ç”Ÿæˆå ä½äº¤ä»˜ç‰©ï¼ˆæœ€ç»ˆé™çº§ç­–ç•¥ï¼‰

        å½“æ‰€æœ‰ç”Ÿæˆç­–ç•¥éƒ½å¤±è´¥æ—¶ï¼Œç”Ÿæˆå ä½å†…å®¹ï¼Œ
        é¿å…æµç¨‹å®Œå…¨å¤±è´¥ã€‚

        Args:
            missing_names: ç¼ºå¤±çš„äº¤ä»˜ç‰©åç§°åˆ—è¡¨

        Returns:
            List[Dict]: å ä½äº¤ä»˜ç‰©åˆ—è¡¨
        """
        placeholders = []
        for name in missing_names[:3]:  # æœ€å¤š3ä¸ª
            placeholders.append({
                "deliverable_name": name,
                "content": f"[å¾…è¡¥å……] {name}\n\nç”±äºLLMç”Ÿæˆå¤±è´¥ï¼Œæ­¤äº¤ä»˜ç‰©éœ€è¦äººå·¥è¡¥å……ã€‚å»ºè®®å®¡æŸ¥é¡¹ç›®éœ€æ±‚åæ‰‹åŠ¨å®Œæˆã€‚",
                "completion_status": "pending",
                "completion_rate": 0.0,
                "key_insights": [],
                "notes": "ğŸ”§ v7.52: è‡ªåŠ¨ç”Ÿæˆçš„å ä½å†…å®¹ï¼Œéœ€è¦äººå·¥è¡¥å……"
            })
        return placeholders

    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        return datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# å…¼å®¹æ€§æ¥å£ï¼šä¸ºç°æœ‰ä»£ç æä¾›å¹³æ»‘è¿‡æ¸¡
class SpecializedAgentFactory:
    """
    å…¼å®¹æ€§åŒ…è£…å™¨ - é€æ­¥è¿ç§»åˆ°TaskOrientedExpertFactory
    """
    
    def __init__(self):
        self._task_oriented_factory = TaskOrientedExpertFactory()
        self._legacy_mode = True  # å¯ä»¥é€šè¿‡é…ç½®åˆ‡æ¢
    
    async def execute_expert(self, role_object: Dict[str, Any], context: str, state: ProjectAnalysisState) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¸“å®¶åˆ†æ - è‡ªåŠ¨é€‰æ‹©ä»»åŠ¡å¯¼å‘æˆ–ä¼ ç»Ÿæ¨¡å¼
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰TaskInstructionï¼Œå†³å®šä½¿ç”¨å“ªç§æ¨¡å¼
        if 'task_instruction' in role_object and not self._legacy_mode:
            logger.info(f"ğŸ“‹ ä½¿ç”¨ä»»åŠ¡å¯¼å‘æ¨¡å¼æ‰§è¡Œä¸“å®¶: {role_object.get('role_name')}")
            return await self._task_oriented_factory.execute_expert(role_object, context, state)
        else:
            # é™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            logger.info(f"ğŸ“ ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼æ‰§è¡Œä¸“å®¶: {role_object.get('role_name')}")
            return await self._execute_legacy_expert(role_object, context, state)
    
    async def _execute_legacy_expert(self, role_object: Dict[str, Any], context: str, state: ProjectAnalysisState) -> Dict[str, Any]:
        """
        ä¼ ç»Ÿä¸“å®¶æ‰§è¡Œæ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        """
        try:
            # è¿™é‡Œå¯ä»¥ä¿ç•™åŸæœ‰çš„æ‰§è¡Œé€»è¾‘
            # æˆ–è€…è°ƒç”¨åŸå§‹çš„specialized_agent_factory
            logger.warning("Legacy expert execution not fully implemented - using basic fallback")
            
            return {
                "expert_id": role_object.get("role_id", "unknown"),
                "expert_name": role_object.get("dynamic_role_name", role_object.get("role_name", "Unknown Expert")),
                "analysis": "Legacy mode placeholder analysis",
                "structured_output": None,
                "role_definition": role_object,
                "execution_metadata": {
                    "timestamp": self._task_oriented_factory._get_timestamp(),
                    "model_used": "gpt-4",
                    "prompt_version": "legacy",
                    "mode": "fallback"
                }
            }
            
        except Exception as e:
            logger.error(f"ä¼ ç»Ÿä¸“å®¶æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "expert_id": role_object.get("role_id", "unknown"),
                "expert_name": role_object.get("role_name", "Unknown Expert"),
                "analysis": f"æ‰§è¡Œå¤±è´¥: {str(e)}",
                "error": True
            }