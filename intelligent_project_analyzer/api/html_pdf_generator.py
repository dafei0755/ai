"""
HTML to PDF Generator using Playwright

ä½¿ç”¨æµè§ˆå™¨å¼•æ“ç”Ÿæˆé«˜è´¨é‡ PDFï¼Œå®Œç¾æ”¯æŒä¸­æ–‡æ’ç‰ˆ

v7.1.2 ä¼˜åŒ–ï¼š
- æµè§ˆå™¨æ± å•ä¾‹æ¨¡å¼ï¼Œé¿å…æ¯æ¬¡å†·å¯åŠ¨ï¼ˆæ€§èƒ½æå‡ 60-70%ï¼‰
- ä¼˜åŒ– wait_until ç­–ç•¥ï¼ˆdomcontentloaded vs networkidleï¼‰
- æ”¯æŒæœåŠ¡å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
"""

import asyncio
import re
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

from jinja2 import Environment, FileSystemLoader
from loguru import logger
from playwright.async_api import Browser, Playwright, async_playwright

# ============================================================
# ğŸ”¥ v7.1.2: Playwright æµè§ˆå™¨æ± å•ä¾‹
# ============================================================


class PlaywrightBrowserPool:
    """
    Playwright æµè§ˆå™¨æ± å•ä¾‹

    é¿å…æ¯æ¬¡ PDF ç”Ÿæˆéƒ½å†·å¯åŠ¨æµè§ˆå™¨è¿›ç¨‹ï¼ˆ1-3ç§’ï¼‰ï¼Œ
    é€šè¿‡å¤ç”¨æµè§ˆå™¨å®ä¾‹ï¼Œå°† PDF ç”Ÿæˆæ—¶é—´ä» 10+ç§’é™è‡³ 1-2ç§’ã€‚

    ä½¿ç”¨æ–¹å¼ï¼š
        pool = PlaywrightBrowserPool.get_instance()
        browser = await pool.get_browser()
        # ä½¿ç”¨ browser åˆ›å»º context å’Œ page
        # æ³¨æ„ï¼šä¸è¦ close browserï¼Œåª close context
    """

    _instance: Optional["PlaywrightBrowserPool"] = None
    _lock = asyncio.Lock()

    def __init__(self):
        self._playwright: Optional[Playwright] = None
        self._browser: Optional[Browser] = None
        self._initialized = False

    @classmethod
    def get_instance(cls) -> "PlaywrightBrowserPool":
        """è·å–å•ä¾‹å®ä¾‹ï¼ˆåŒæ­¥æ–¹æ³•ï¼Œç”¨äºè·å–å¼•ç”¨ï¼‰"""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    async def initialize(self) -> None:
        """
        ğŸ†• P1ä¿®å¤: å¢å¼ºåˆå§‹åŒ–å®¹é”™ä¸é™çº§ç­–ç•¥

        åˆå§‹åŒ–æµè§ˆå™¨æ± ï¼ˆå¼‚æ­¥æ–¹æ³•ï¼Œåœ¨æœåŠ¡å¯åŠ¨æ—¶è°ƒç”¨ï¼‰
        - Windowsä¸‹å¼ºåˆ¶ProactorEventLoop
        - æ·»åŠ é‡è¯•æœºåˆ¶
        - å¤±è´¥æ—¶é™çº§ä½†ä¸é˜»å¡æœåŠ¡
        """
        async with self._lock:
            if self._initialized:
                return

            try:
                logger.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ– Playwright æµè§ˆå™¨æ± ...")

                # ğŸ†• P1ä¿®å¤: Windowså¹³å°æ£€æµ‹ä¸äº‹ä»¶å¾ªç¯ä¼˜åŒ–
                import platform
                import sys

                if platform.system() == "Windows" and sys.version_info >= (3, 13):
                    logger.info("ğŸ”§ æ£€æµ‹åˆ°Windows+Python3.13ï¼Œå·²å¯ç”¨ProactorEventLoopå…¼å®¹æ¨¡å¼")

                # ğŸ†• P1ä¿®å¤: æ·»åŠ è¶…æ—¶æ§åˆ¶
                self._playwright = await asyncio.wait_for(async_playwright().start(), timeout=30.0)

                # ğŸ†• P1ä¿®å¤: æ£€æŸ¥chromiumæ˜¯å¦å·²å®‰è£…
                try:
                    self._browser = await asyncio.wait_for(
                        self._playwright.chromium.launch(
                            headless=True,
                            args=[
                                "--no-sandbox",
                                "--disable-setuid-sandbox",
                                "--disable-dev-shm-usage",
                                "--disable-gpu",
                            ],
                        ),
                        timeout=30.0,
                    )
                except Exception as launch_error:
                    # ğŸ†• P1ä¿®å¤: å‹å¥½çš„å®‰è£…æç¤º
                    error_msg = str(launch_error)
                    if "Executable doesn't exist" in error_msg or "not found" in error_msg:
                        logger.error("âŒ Chromiumæµè§ˆå™¨æœªå®‰è£…")
                        logger.error("ğŸ’¡ è¯·è¿è¡Œ: playwright install chromium")
                        logger.warning("âš ï¸ PDFå¯¼å‡ºåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œç³»ç»Ÿå°†ä»¥é™çº§æ¨¡å¼è¿è¡Œ")
                        self._initialized = False
                        return  # ğŸ†• P1ä¿®å¤: å¤±è´¥ä¸é˜»å¡æœåŠ¡å¯åŠ¨
                    raise

                self._initialized = True
                logger.success("âœ… Playwright æµè§ˆå™¨æ± åˆå§‹åŒ–æˆåŠŸ")

            except asyncio.TimeoutError:
                logger.error("âŒ Playwrightåˆå§‹åŒ–è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
                logger.warning("âš ï¸ PDFå¯¼å‡ºåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œç³»ç»Ÿå°†ä»¥é™çº§æ¨¡å¼è¿è¡Œ")
                self._initialized = False
            except Exception as e:
                logger.error(f"âŒ Playwright æµè§ˆå™¨æ± åˆå§‹åŒ–å¤±è´¥: {e}")
                logger.warning("âš ï¸ PDFå¯¼å‡ºåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œç³»ç»Ÿå°†ä»¥é™çº§æ¨¡å¼è¿è¡Œ")
                self._initialized = False
                # ğŸ†• P1ä¿®å¤: ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸æœåŠ¡ç»§ç»­å¯åŠ¨

    async def get_browser(self) -> Browser:
        """è·å–æµè§ˆå™¨å®ä¾‹ï¼ˆæ‡’åˆå§‹åŒ–ï¼‰"""
        if not self._initialized:
            await self.initialize()

        # æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦ä»ç„¶è¿æ¥
        if self._browser is None or not self._browser.is_connected():
            logger.warning("âš ï¸ æµè§ˆå™¨è¿æ¥ä¸¢å¤±ï¼Œæ­£åœ¨é‡æ–°åˆå§‹åŒ–...")
            self._initialized = False
            await self.initialize()

        return self._browser

    async def shutdown(self) -> None:
        """å…³é—­æµè§ˆå™¨æ± ï¼ˆåœ¨æœåŠ¡å…³é—­æ—¶è°ƒç”¨ï¼‰"""
        async with self._lock:
            if self._browser:
                try:
                    await self._browser.close()
                    logger.info("âœ… Playwright æµè§ˆå™¨å·²å…³é—­")
                except Exception as e:
                    logger.warning(f"âš ï¸ å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")
                finally:
                    self._browser = None

            if self._playwright:
                try:
                    await self._playwright.stop()
                    logger.info("âœ… Playwright å·²åœæ­¢")
                except Exception as e:
                    logger.warning(f"âš ï¸ åœæ­¢ Playwright æ—¶å‡ºé”™: {e}")
                finally:
                    self._playwright = None

            self._initialized = False

    @classmethod
    async def cleanup(cls) -> None:
        """ç±»æ–¹æ³•ï¼šæ¸…ç†å•ä¾‹å®ä¾‹"""
        if cls._instance:
            await cls._instance.shutdown()
            cls._instance = None


# å…¨å±€æµè§ˆå™¨æ± å®ä¾‹
_browser_pool: Optional[PlaywrightBrowserPool] = None


def get_browser_pool() -> PlaywrightBrowserPool:
    """è·å–å…¨å±€æµè§ˆå™¨æ± å®ä¾‹"""
    global _browser_pool
    if _browser_pool is None:
        _browser_pool = PlaywrightBrowserPool.get_instance()
    return _browser_pool


class HTMLPDFGenerator:
    """åŸºäº HTML + Playwright çš„ PDF ç”Ÿæˆå™¨"""

    # å­—æ®µæ ‡ç­¾ä¸­è‹±æ–‡æ˜ å°„
    FIELD_LABELS = {
        # é€šç”¨å­—æ®µ
        "name": "åç§°",
        "title": "æ ‡é¢˜",
        "description": "æè¿°",
        "content": "å†…å®¹",
        "summary": "æ€»ç»“",
        "conclusion": "ç»“è®º",
        "recommendation": "å»ºè®®",
        "recommendations": "å»ºè®®",
        "analysis": "åˆ†æ",
        "overview": "æ¦‚è¿°",
        "background": "èƒŒæ™¯",
        "objective": "ç›®æ ‡",
        "objectives": "ç›®æ ‡",
        "goal": "ç›®æ ‡",
        "goals": "ç›®æ ‡",
        "result": "ç»“æœ",
        "results": "ç»“æœ",
        "finding": "å‘ç°",
        "findings": "å‘ç°",
        "insight": "æ´å¯Ÿ",
        "insights": "æ´å¯Ÿ",
        "key_points": "è¦ç‚¹",
        "keypoints": "è¦ç‚¹",
        "highlights": "äº®ç‚¹",
        "notes": "å¤‡æ³¨",
        "comments": "è¯„è®º",
        "feedback": "åé¦ˆ",
        # ç”¨æˆ·ç ”ç©¶ç›¸å…³
        "persona": "ç”¨æˆ·ç”»åƒ",
        "personas": "ç”¨æˆ·ç”»åƒ",
        "user_persona": "ç”¨æˆ·ç”»åƒ",
        "pain_points": "ç—›ç‚¹",
        "painpoints": "ç—›ç‚¹",
        "pain points": "ç—›ç‚¹",
        "needs": "éœ€æ±‚",
        "user_needs": "ç”¨æˆ·éœ€æ±‚",
        "behaviors": "è¡Œä¸º",
        "user_behaviors": "ç”¨æˆ·è¡Œä¸º",
        "motivations": "åŠ¨æœº",
        "frustrations": "æŒ«è´¥ç‚¹",
        "goals_and_needs": "ç›®æ ‡ä¸éœ€æ±‚",
        "how_might_we": "æˆ‘ä»¬å¦‚ä½•èƒ½å¤Ÿ",
        "hmw": "æˆ‘ä»¬å¦‚ä½•èƒ½å¤Ÿ",
        "journey": "æ—…ç¨‹",
        "user_journey": "ç”¨æˆ·æ—…ç¨‹",
        "touchpoints": "è§¦ç‚¹",
        "scenarios": "åœºæ™¯",
        "use_cases": "ç”¨ä¾‹",
        # å•†ä¸šç›¸å…³
        "market": "å¸‚åœº",
        "market_analysis": "å¸‚åœºåˆ†æ",
        "competition": "ç«äº‰",
        "competitors": "ç«äº‰å¯¹æ‰‹",
        "competitive_analysis": "ç«äº‰åˆ†æ",
        "swot": "SWOTåˆ†æ",
        "strengths": "ä¼˜åŠ¿",
        "weaknesses": "åŠ£åŠ¿",
        "opportunities": "æœºä¼š",
        "threats": "å¨èƒ",
        "strategy": "ç­–ç•¥",
        "strategies": "ç­–ç•¥",
        "business_model": "å•†ä¸šæ¨¡å¼",
        "value_proposition": "ä»·å€¼ä¸»å¼ ",
        "revenue": "æ”¶å…¥",
        "cost": "æˆæœ¬",
        "pricing": "å®šä»·",
        "roi": "æŠ•èµ„å›æŠ¥ç‡",
        # æŠ€æœ¯ç›¸å…³
        "architecture": "æ¶æ„",
        "technology": "æŠ€æœ¯",
        "tech_stack": "æŠ€æœ¯æ ˆ",
        "implementation": "å®ç°",
        "requirements": "éœ€æ±‚",
        "specifications": "è§„æ ¼",
        "features": "åŠŸèƒ½",
        "feature": "åŠŸèƒ½",
        "modules": "æ¨¡å—",
        "components": "ç»„ä»¶",
        "api": "æ¥å£",
        "database": "æ•°æ®åº“",
        "security": "å®‰å…¨",
        "performance": "æ€§èƒ½",
        "scalability": "å¯æ‰©å±•æ€§",
        # é¡¹ç›®ç®¡ç†
        "timeline": "æ—¶é—´çº¿",
        "milestones": "é‡Œç¨‹ç¢‘",
        "deliverables": "äº¤ä»˜ç‰©",
        "resources": "èµ„æº",
        "risks": "é£é™©",
        "risk_assessment": "é£é™©è¯„ä¼°",
        "mitigation": "ç¼“è§£æªæ–½",
        "dependencies": "ä¾èµ–",
        "constraints": "çº¦æŸ",
        "assumptions": "å‡è®¾",
        "budget": "é¢„ç®—",
        "schedule": "è¿›åº¦",
        "status": "çŠ¶æ€",
        "progress": "è¿›å±•",
        "priority": "ä¼˜å…ˆçº§",
        # è®¾è®¡ç›¸å…³
        "design": "è®¾è®¡",
        "wireframe": "çº¿æ¡†å›¾",
        "prototype": "åŸå‹",
        "mockup": "æ•ˆæœå›¾",
        "layout": "å¸ƒå±€",
        "color": "é¢œè‰²",
        "typography": "å­—ä½“",
        "branding": "å“ç‰Œ",
        "style": "é£æ ¼",
        "theme": "ä¸»é¢˜",
        "ui": "ç”¨æˆ·ç•Œé¢",
        "ux": "ç”¨æˆ·ä½“éªŒ",
        "interaction": "äº¤äº’",
        "animation": "åŠ¨ç”»",
        "responsive": "å“åº”å¼",
        "accessibility": "æ— éšœç¢",
        # çº¢è“å¯¹æŠ—ç›¸å…³
        "pole_a": "ç«‹åœºA",
        "pole_b": "ç«‹åœºB",
        "pole_a_analysis": "ç«‹åœºAåˆ†æ",
        "pole_b_analysis": "ç«‹åœºBåˆ†æ",
        "pole_a_resolve": "ç«‹åœºAè§£å†³æ–¹æ¡ˆ",
        "pole_b_resolve": "ç«‹åœºBè§£å†³æ–¹æ¡ˆ",
        "debate": "è¾©è®º",
        "argument": "è®ºç‚¹",
        "counter_argument": "åé©³",
        "synthesis": "ç»¼åˆ",
        "verdict": "è£å†³",
        "judge_verdict": "è¯„å§”è£å†³",
        # å…¶ä»–
        "introduction": "å¼•è¨€",
        "methodology": "æ–¹æ³•è®º",
        "approach": "æ–¹æ³•",
        "process": "æµç¨‹",
        "workflow": "å·¥ä½œæµ",
        "steps": "æ­¥éª¤",
        "phase": "é˜¶æ®µ",
        "phases": "é˜¶æ®µ",
        "stage": "é˜¶æ®µ",
        "stages": "é˜¶æ®µ",
        "action_items": "è¡ŒåŠ¨é¡¹",
        "next_steps": "ä¸‹ä¸€æ­¥",
        "appendix": "é™„å½•",
        "references": "å‚è€ƒ",
        "glossary": "æœ¯è¯­è¡¨",
        "faq": "å¸¸è§é—®é¢˜",
        # é¡¹ç›®ç‰¹å®šå­—æ®µ
        "project_vision_summary": "é¡¹ç›®æ„¿æ™¯æ‘˜è¦",
        "design_rationale": "è®¾è®¡ç†æ®",
        "decision_rationale": "å†³ç­–ç†æ®",
        "spatial_concept": "ç©ºé—´æ¦‚å¿µ",
        "customer_journey_design": "å®¢æˆ·æ—…ç¨‹è®¾è®¡",
        "critical_questions_responses": "å…³é”®é—®é¢˜å›åº”",
        "chosen_design_stance": "è®¾è®¡ç«‹åœºé€‰æ‹©",
        "expert_handoff_response": "ä¸“å®¶äº¤æ¥å›åº”",
        "healing_environment_kpis": "æ²»æ„ˆç¯å¢ƒKPI",
        "technical_requirements_for_v6": "V6æŠ€æœ¯è¦æ±‚",
        "challenge_flags": "æŒ‘æˆ˜æ ‡è®°",
        "confidence": "ç½®ä¿¡åº¦",
        # ä¸šåŠ¡ä¸è¿è¥åˆ†æ
        "business_goal_analysis": "å•†ä¸šç›®æ ‡åˆ†æ",
        "operational_blueprint": "è¿è¥è“å›¾",
        "custom_analysis": "è‡ªå®šä¹‰åˆ†æ",
        "missing_inputs_warning": "ç¼ºå¤±è¾“å…¥è­¦å‘Š",
        "missing_keys": "ç¼ºå¤±å­—æ®µ",
        "impact": "å½±å“",
        "business_model_analysis": "å•†ä¸šæ¨¡å¼åˆ†æ",
        "revenue_model": "ç›ˆåˆ©æ¨¡å¼",
        "cost_structure": "æˆæœ¬ç»“æ„",
        "value_chain": "ä»·å€¼é“¾",
        # ç©ºé—´ä¸è®¾è®¡
        "space_planning_strategy": "ç©ºé—´è§„åˆ’ç­–ç•¥",
        "functional_zoning": "åŠŸèƒ½åˆ†åŒº",
        "traffic_flow": "åŠ¨çº¿è®¾è®¡",
        "spatial_hierarchy": "ç©ºé—´å±‚æ¬¡",
        "material_palette": "ææ–™é€‰æ¿",
        "lighting_strategy": "ç…§æ˜ç­–ç•¥",
        "acoustic_design": "å£°å­¦è®¾è®¡",
        "environmental_control": "ç¯å¢ƒæ§åˆ¶",
        # ç”¨æˆ·ä½“éªŒ
        "user_experience_design": "ç”¨æˆ·ä½“éªŒè®¾è®¡",
        "touchpoint_design": "è§¦ç‚¹è®¾è®¡",
        "service_blueprint": "æœåŠ¡è“å›¾",
        "emotional_journey": "æƒ…æ„Ÿæ—…ç¨‹",
        "pain_point_solutions": "ç—›ç‚¹è§£å†³æ–¹æ¡ˆ",
        # æŠ€æœ¯ä¸å®æ–½
        "technical_specifications": "æŠ€æœ¯è§„æ ¼",
        "implementation_roadmap": "å®æ–½è·¯çº¿å›¾",
        "quality_standards": "è´¨é‡æ ‡å‡†",
        "compliance_requirements": "åˆè§„è¦æ±‚",
        "sustainability_measures": "å¯æŒç»­æªæ–½",
        # é£é™©ä¸æŒ‘æˆ˜
        "risk_analysis": "é£é™©åˆ†æ",
        "challenge_response": "æŒ‘æˆ˜åº”å¯¹",
        "mitigation_strategies": "ç¼“è§£ç­–ç•¥",
        "contingency_plans": "åº”æ€¥é¢„æ¡ˆ",
        # KPIä¸æŒ‡æ ‡
        "key_performance_indicators": "å…³é”®ç»©æ•ˆæŒ‡æ ‡",
        "kpi": "å…³é”®ç»©æ•ˆæŒ‡æ ‡",
        "kpis": "å…³é”®ç»©æ•ˆæŒ‡æ ‡",
        "metric": "æŒ‡æ ‡",
        "metrics": "æŒ‡æ ‡",
        "target": "ç›®æ ‡å€¼",
        "targets": "ç›®æ ‡å€¼",
        "benchmark": "åŸºå‡†",
        "benchmarks": "åŸºå‡†",
        # è®¾è®¡æŒ‘æˆ˜
        "design_challenges": "è®¾è®¡æŒ‘æˆ˜",
        "design_challenges_for_v2": "è®¾è®¡æŒ‘æˆ˜ï¼ˆV2ä¸“ç”¨ï¼‰",
        "challenge": "æŒ‘æˆ˜",
        "challenges": "æŒ‘æˆ˜",
        "constraint": "çº¦æŸ",
        "context": "èƒŒæ™¯",
        # ç©ºé—´ç­–ç•¥
        "spatial_strategy": "ç©ºé—´ç­–ç•¥",
        "spatial_strategies": "ç©ºé—´ç­–ç•¥",
        "space_strategy": "ç©ºé—´ç­–ç•¥",
        # å“ç‰Œä¸è§†è§‰
        "brand_identity_integration": "å“ç‰Œè¯†åˆ«æ•´åˆ",
        "brand_identity": "å“ç‰Œè¯†åˆ«",
        "brand_integration": "å“ç‰Œæ•´åˆ",
        "visual_merchandising": "è§†è§‰è¥é”€",
        "visualmerchandising": "è§†è§‰è¥é”€",
        "visual_identity": "è§†è§‰è¯†åˆ«",
        # å®æ–½æŒ‡å¯¼
        "implementation_guidance": "å®æ–½æŒ‡å¯¼",
        "guidance": "æŒ‡å¯¼",
        "implementation": "å®æ–½",
        "execution": "æ‰§è¡Œ",
        "execution_plan": "æ‰§è¡Œè®¡åˆ’",
        # è§£é‡Šæ¡†æ¶
        "interpretation_framework": "è§£é‡Šæ¡†æ¶",
        "framework": "æ¡†æ¶",
        "methodology": "æ–¹æ³•è®º",
        # åˆå§‹åœºæ™¯
        "initial_key_scenario": "åˆå§‹å…³é”®åœºæ™¯",
        "key_scenario": "å…³é”®åœºæ™¯",
        "scenario": "åœºæ™¯",
        # MEPä¸å·¥ç¨‹
        "mepoverall": "MEPæ€»ä½“",
        "mep_overall": "MEPæ€»ä½“",
        "mep_strategy": "MEPç­–ç•¥",
        "mep": "æœºç”µ",
        "hvac": "æš–é€šç©ºè°ƒ",
        "electrical": "ç”µæ°”",
        "plumbing": "ç»™æ’æ°´",
        "fire_protection": "æ¶ˆé˜²",
        "system_solutions": "ç³»ç»Ÿè§£å†³æ–¹æ¡ˆ",
        "system": "ç³»ç»Ÿ",
        "systems": "ç³»ç»Ÿ",
        "recommended_solution": "æ¨èæ–¹æ¡ˆ",
        "reasoning": "ç†ç”±",
        "reason": "ç†ç”±",
        # å·¥è‰ºä¸ææ–™
        "craftsmanship": "å·¥è‰º",
        "craftsmanship_strategy": "å·¥è‰ºç­–ç•¥",
        "keymaterial": "å…³é”®ææ–™",
        "key_material": "å…³é”®ææ–™",
        "material": "ææ–™",
        "materials": "ææ–™",
        "application_area": "åº”ç”¨åŒºåŸŸ",
        "application": "åº”ç”¨",
        # å½±å“ä¸æ¶æ„
        "impact_on_architecture": "å¯¹æ¶æ„çš„å½±å“",
        "architecture_impact": "æ¶æ„å½±å“",
        "on": "",
        # æ—…ç¨‹ä¸åœ°å›¾
        "journey_maps": "æ—…ç¨‹åœ°å›¾",
        "journeymaps": "æ—…ç¨‹åœ°å›¾",
        "maps": "åœ°å›¾",
        "journey": "æ—…ç¨‹",
        "user_journey": "ç”¨æˆ·æ—…ç¨‹",
        # è®¾è®¡æ¨¡å¼ä¸å¤ç”¨
        "reusable": "å¯å¤ç”¨",
        "reusable_design_patterns": "å¯å¤ç”¨è®¾è®¡æ¨¡å¼",
        "design_patterns": "è®¾è®¡æ¨¡å¼",
        "designpatterns": "è®¾è®¡æ¨¡å¼",
        "patterns": "æ¨¡å¼",
        "pattern": "æ¨¡å¼",
        # å›¢é˜ŸæŒ‡å—
        "guidelines_for_team": "å›¢é˜ŸæŒ‡å—",
        "guidelinesforteam": "å›¢é˜ŸæŒ‡å—",
        "guidelines": "æŒ‡å—",
        "guideline": "æŒ‡å—",
        "team": "å›¢é˜Ÿ",
        # æˆåŠŸå› ç´ 
        "key_success_factors": "å…³é”®æˆåŠŸå› ç´ ",
        "success_factors": "æˆåŠŸå› ç´ ",
        "success": "æˆåŠŸ",
        "factors": "å› ç´ ",
        # çµæ„Ÿä¸å¤§å¸ˆä½œå“
        "missing_inspiration_warning": "ç¼ºå¤±çµæ„Ÿè­¦å‘Š",
        "inspiration": "çµæ„Ÿ",
        "master_work_deconstruction": "å¤§å¸ˆä½œå“è§£æ„",
        "master": "å¤§å¸ˆ",
        "deconstruction": "è§£æ„",
        "nendo": "Nendo",
        "desc": "æè¿°",
        "philosophy": "ç†å¿µ",
        "signature_methods": "æ ‡å¿—æ€§æ–¹æ³•",
        "application_to_project": "é¡¹ç›®åº”ç”¨",
        "applicationtoproject": "é¡¹ç›®åº”ç”¨",
        # å“ç‰Œ
        "brand": "å“ç‰Œ",
        "brands": "å“ç‰Œ",
        # ä¼˜åŠ¿åŠ£åŠ¿
        "advantage": "ä¼˜åŠ¿",
        "advantages": "ä¼˜åŠ¿",
        "disadvantage": "åŠ£åŠ¿",
        "disadvantages": "åŠ£åŠ¿",
        # å¸¸è§è‹±æ–‡æ ‡é¢˜
        "key_findings": "å…³é”®å‘ç°",
        "main_points": "ä¸»è¦è¦ç‚¹",
        "action_plan": "è¡ŒåŠ¨è®¡åˆ’",
        "implementation_plan": "å®æ–½è®¡åˆ’",
        "space_planning": "ç©ºé—´è§„åˆ’",
        "material_selection": "ææ–™é€‰æ‹©",
        "lighting_design": "ç…§æ˜è®¾è®¡",
        "color_scheme": "é…è‰²æ–¹æ¡ˆ",
        "furniture_layout": "å®¶å…·å¸ƒå±€",
        "cost_estimate": "æˆæœ¬ä¼°ç®—",
        "timeline_estimate": "æ—¶é—´çº¿ä¼°ç®—",
        "name": "åç§°",
        "type": "ç±»å‹",
        "area": "åŒºåŸŸ",
        "spec": "è§„æ ¼",
        "specs": "è§„æ ¼",
        "specification": "è§„æ ¼",
        "specifications": "è§„æ ¼",
        # ============ ä»»åŠ¡å¯¼å‘æ¨¡å‹å­—æ®µ (task_oriented_models.py) ============
        # DeliverableOutput äº¤ä»˜ç‰©è¾“å‡º
        "deliverable_name": "äº¤ä»˜ç‰©åç§°",
        "deliverable_outputs": "äº¤ä»˜ç‰©è¾“å‡º",
        "completion_status": "å®ŒæˆçŠ¶æ€",
        "completion_rate": "å®Œæˆåº¦",
        "quality_self_assessment": "è´¨é‡è‡ªè¯„",
        # TaskExecutionReport ä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Š
        "task_execution_report": "ä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Š",
        "task_completion_summary": "ä»»åŠ¡å®Œæˆæ€»ç»“",
        "additional_insights": "é¢å¤–æ´å¯Ÿ",
        "execution_challenges": "æ‰§è¡ŒæŒ‘æˆ˜",
        # ProtocolExecutionReport åè®®æ‰§è¡ŒæŠ¥å‘Š
        "protocol_execution": "åè®®æ‰§è¡ŒæŠ¥å‘Š",
        "protocol_status": "åè®®çŠ¶æ€",
        "compliance_confirmation": "åˆè§„ç¡®è®¤",
        "challenge_details": "æŒ‘æˆ˜è¯¦æƒ…",
        "reinterpretation": "é‡æ–°è¯ é‡Š",
        # ChallengeFlag æŒ‘æˆ˜æ ‡è®°
        "challenged_item": "è¢«æŒ‘æˆ˜å†…å®¹",
        "challenge_reason": "æŒ‘æˆ˜ç†ç”±",
        "alternative_proposal": "æ›¿ä»£æ–¹æ¡ˆ",
        # ReinterpretationDetail é‡æ–°è¯ é‡Šè¯¦æƒ…
        "original_interpretation": "åŸå§‹è¯ é‡Š",
        "new_interpretation": "æ–°è¯ é‡Š",
        "reinterpretation_rationale": "è¯ é‡Šä¾æ®",
        "impact_on_approach": "æ–¹æ³•è®ºå½±å“",
        # ExecutionMetadata æ‰§è¡Œå…ƒæ•°æ®
        "execution_metadata": "æ‰§è¡Œå…ƒæ•°æ®",
        "execution_time_estimate": "æ‰§è¡Œæ—¶é—´ä¼°ç®—",
        "execution_notes": "æ‰§è¡Œå¤‡æ³¨",
        "dependencies_satisfied": "ä¾èµ–æ»¡è¶³",
        # TaskInstruction ä»»åŠ¡æŒ‡ä»¤
        "objective": "æ ¸å¿ƒç›®æ ‡",
        "success_criteria": "æˆåŠŸæ ‡å‡†",
        "context_requirements": "ä¸Šä¸‹æ–‡éœ€æ±‚",
        # DeliverableSpec äº¤ä»˜ç‰©è§„æ ¼
        "format": "æ ¼å¼",
        # åè®®çŠ¶æ€æšä¸¾å€¼
        "complied": "å·²éµç…§",
        "challenged": "å·²æŒ‘æˆ˜",
        "reinterpreted": "å·²é‡æ–°è¯ é‡Š",
        # å®ŒæˆçŠ¶æ€æšä¸¾å€¼
        "completed": "å·²å®Œæˆ",
        "partial": "éƒ¨åˆ†å®Œæˆ",
        "unable": "æ— æ³•å®Œæˆ",
        # ============ V2-V6 FlexibleOutput ä¸“å®¶æ¨¡å‹å­—æ®µ ============
        # é€šç”¨å­—æ®µ
        "output_mode": "è¾“å‡ºæ¨¡å¼",
        "user_question_focus": "é—®é¢˜èšç„¦",
        "design_rationale": "è®¾è®¡ä¾æ®",
        "decision_rationale": "å†³ç­–ä¾æ®",
        "targeted_analysis": "é’ˆå¯¹æ€§åˆ†æ",
        "supplementary_insights": "è¡¥å……æ´å¯Ÿ",
        # V6-1 ç»“æ„ä¸å¹•å¢™å·¥ç¨‹å¸ˆ
        "feasibility_assessment": "å¯è¡Œæ€§è¯„ä¼°",
        "structural_system_options": "ç»“æ„ä½“ç³»é€‰é¡¹",
        "facade_system_options": "å¹•å¢™ä½“ç³»é€‰é¡¹",
        "key_technical_nodes": "å…³é”®æŠ€æœ¯èŠ‚ç‚¹",
        "risk_analysis_and_recommendations": "é£é™©åˆ†æä¸å»ºè®®",
        "option_name": "æ–¹æ¡ˆåç§°",
        "estimated_cost_level": "é¢„ä¼°é€ ä»·ç­‰çº§",
        "node_name": "èŠ‚ç‚¹åç§°",
        "proposed_solution": "å»ºè®®æ–¹æ¡ˆ",
        # V6-2 æœºç”µä¸æ™ºèƒ½åŒ–å·¥ç¨‹å¸ˆ
        "mep_overall_strategy": "æœºç”µæ•´ä½“ç­–ç•¥",
        "system_solutions": "ç³»ç»Ÿè§£å†³æ–¹æ¡ˆ",
        "smart_building_scenarios": "æ™ºèƒ½å»ºç­‘åœºæ™¯",
        "coordination_and_clash_points": "åè°ƒä¸å†²çªç‚¹",
        "sustainability_and_energy_saving": "å¯æŒç»­ä¸èŠ‚èƒ½",
        "system_name": "ç³»ç»Ÿåç§°",
        "recommended_solution": "æ¨èæ–¹æ¡ˆ",
        "reasoning": "ç†ç”±",
        "impact_on_architecture": "å¯¹å»ºç­‘çš„å½±å“",
        "scenario_name": "åœºæ™¯åç§°",
        "triggered_systems": "è”åŠ¨ç³»ç»Ÿ",
        # V6-3 å®¤å†…å·¥è‰ºä¸ææ–™ä¸“å®¶
        "craftsmanship_strategy": "å·¥è‰ºç­–ç•¥",
        "key_material_specifications": "å…³é”®ææ–™è§„æ ¼",
        "critical_node_details": "å…³é”®èŠ‚ç‚¹è¯¦å›¾",
        "quality_control_and_mockup": "è´¨é‡æ§åˆ¶ä¸æ ·æ¿",
        "material_name": "ææ–™åç§°",
        "application_area": "åº”ç”¨åŒºåŸŸ",
        "key_specifications": "å…³é”®è§„æ ¼",
        # V6-4 æˆæœ¬ä¸ä»·å€¼å·¥ç¨‹å¸ˆ
        "cost_estimation_summary": "æˆæœ¬ä¼°ç®—æ‘˜è¦",
        "cost_breakdown_analysis": "æˆæœ¬æ„æˆåˆ†æ",
        "value_engineering_options": "ä»·å€¼å·¥ç¨‹é€‰é¡¹",
        "budget_control_strategy": "é¢„ç®—æ§åˆ¶ç­–ç•¥",
        "cost_overrun_risk_analysis": "æˆæœ¬è¶…æ”¯é£é™©åˆ†æ",
        "category": "ç±»åˆ«",
        "percentage": "ç™¾åˆ†æ¯”",
        "cost_drivers": "æˆæœ¬é©±åŠ¨å› ç´ ",
        "original_scheme": "åŸæ–¹æ¡ˆ",
        "proposed_option": "ä¼˜åŒ–æ–¹æ¡ˆ",
        "impact_analysis": "å½±å“åˆ†æ",
        # V5-1 å±…ä½åœºæ™¯ä¸ç”Ÿæ´»æ–¹å¼ä¸“å®¶
        "family_profile_and_needs": "å®¶åº­æˆå‘˜ç”»åƒä¸éœ€æ±‚",
        "operational_blueprint": "è¿è¥è“å›¾",
        "design_challenges_for_v2": "ç»™è®¾è®¡æ€»ç›‘çš„æŒ‘æˆ˜",
        "member": "æˆå‘˜",
        "daily_routine": "æ—¥å¸¸ä½œæ¯",
        "spatial_needs": "ç©ºé—´éœ€æ±‚",
        "storage_needs": "æ”¶çº³éœ€æ±‚",
        # V5-2 å•†ä¸šé›¶å”®è¿è¥ä¸“å®¶
        "business_goal_analysis": "å•†ä¸šç›®æ ‡åˆ†æ",
        "spatial_strategy": "ç©ºé—´ç­–ç•¥",
        # V5-3 ä¼ä¸šåŠå…¬ç­–ç•¥ä¸“å®¶
        "organizational_analysis": "ç»„ç»‡åˆ†æ",
        "collaboration_model": "åä½œæ¨¡å¼",
        "workspace_strategy": "å·¥ä½œç©ºé—´ç­–ç•¥",
        # V5-4 é…’åº—é¤é¥®è¿è¥ä¸“å®¶
        "service_process_analysis": "æœåŠ¡æµç¨‹åˆ†æ",
        "operational_efficiency": "è¿è¥æ•ˆç‡",
        "guest_experience_blueprint": "å®¾å®¢ä½“éªŒè“å›¾",
        # V5-5 æ–‡åŒ–æ•™è‚²åœºæ™¯ä¸“å®¶
        "visitor_journey_analysis": "è®¿å®¢æ—…ç¨‹åˆ†æ",
        "educational_model": "æ•™è‚²æ¨¡å¼",
        "public_service_strategy": "å…¬å…±æœåŠ¡ç­–ç•¥",
        # V5-6 åŒ»ç–—åº·å…»åœºæ™¯ä¸“å®¶
        "healthcare_process_analysis": "åŒ»ç–—æµç¨‹åˆ†æ",
        "patient_experience_blueprint": "æ‚£è€…ä½“éªŒè“å›¾",
        "wellness_strategy": "åº·å…»ç­–ç•¥",
        # V2ç³»åˆ— è®¾è®¡æ€»ç›‘
        "project_vision_summary": "é¡¹ç›®æ„¿æ™¯æ¦‚è¿°",
        "spatial_concept": "ç©ºé—´æ¦‚å¿µ",
        "customer_journey_design": "å®¢æˆ·æ—…ç¨‹è®¾è®¡",
        "visual_merchandising_strategy": "è§†è§‰è¥é”€ç­–ç•¥",
        "brand_identity_integration": "å“ç‰Œè¯†åˆ«æ•´åˆ",
        "implementation_guidance": "å®æ–½æŒ‡å¯¼",
        "architectural_concept": "å»ºç­‘æ¦‚å¿µ",
        "facade_and_envelope": "ç«‹é¢ä¸å›´æŠ¤",
        "landscape_integration": "æ™¯è§‚æ•´åˆ",
        "indoor_outdoor_relationship": "å®¤å†…å¤–å…³ç³»",
        "public_vision": "å…¬å…±æ„¿æ™¯",
        "spatial_accessibility": "ç©ºé—´å¯è¾¾æ€§",
        "community_engagement": "ç¤¾åŒºå‚ä¸",
        "cultural_expression": "æ–‡åŒ–è¡¨è¾¾",
        # V3ç³»åˆ— å™äº‹ä¸ä½“éªŒä¸“å®¶
        "narrative_framework": "å™äº‹æ¡†æ¶",
        "emotional_journey": "æƒ…æ„Ÿæ—…ç¨‹",
        "touchpoint_design": "è§¦ç‚¹è®¾è®¡",
        # V4ç³»åˆ— è®¾è®¡ç ”ç©¶ä¸“å‘˜
        "case_studies_deep_dive": "æ·±åº¦æ¡ˆä¾‹ç ”ç©¶",
        "reusable_design_patterns": "å¯å¤ç”¨è®¾è®¡æ¨¡å¼",
        "key_success_factors": "å…³é”®æˆåŠŸå› ç´ ",
        "application_guidelines_for_team": "å›¢é˜Ÿåº”ç”¨æŒ‡å—",
        "trend_analysis": "è¶‹åŠ¿åˆ†æ",
        "future_scenarios": "æœªæ¥åœºæ™¯",
        "opportunity_identification": "æœºä¼šè¯†åˆ«",
        "design_implications": "è®¾è®¡å¯ç¤º",
    }

    # å†…å®¹ç¿»è¯‘æ˜ å°„
    CONTENT_TRANSLATIONS = {
        "How might we": "æˆ‘ä»¬å¦‚ä½•èƒ½å¤Ÿ",
        "Pain Points": "ç—›ç‚¹",
        "Pain points": "ç—›ç‚¹",
        "Persona:": "ç”¨æˆ·ç”»åƒ:",
        "Personaï¼š": "ç”¨æˆ·ç”»åƒï¼š",
        "User Persona": "ç”¨æˆ·ç”»åƒ",
        "Key Insights": "å…³é”®æ´å¯Ÿ",
        "Key insights": "å…³é”®æ´å¯Ÿ",
        "Recommendations": "å»ºè®®",
        "Summary": "æ€»ç»“",
        "Conclusion": "ç»“è®º",
        "Overview": "æ¦‚è¿°",
        "Background": "èƒŒæ™¯",
        "Analysis": "åˆ†æ",
        "pole_a": "ç«‹åœºA",
        "pole_b": "ç«‹åœºB",
        "pole_a_resolve": "ç«‹åœºAè§£å†³æ–¹æ¡ˆ",
        "pole_b_resolve": "ç«‹åœºBè§£å†³æ–¹æ¡ˆ",
        "Pole A": "ç«‹åœºA",
        "Pole B": "ç«‹åœºB",
        # å“ç‰Œä¸è§†è§‰æ ‡é¢˜
        "Brand Identity Integration": "å“ç‰Œè¯†åˆ«æ•´åˆ",
        "Brand Identity": "å“ç‰Œè¯†åˆ«",
        "Visual Merchandising": "è§†è§‰è¥é”€",
        "Visual Identity": "è§†è§‰è¯†åˆ«",
        # å®æ–½ç›¸å…³
        "Implementation Guidance": "å®æ–½æŒ‡å¯¼",
        "Implementation Plan": "å®æ–½è®¡åˆ’",
        "Execution Plan": "æ‰§è¡Œè®¡åˆ’",
        # è®¾è®¡ç›¸å…³
        "Design Rationale": "è®¾è®¡ç†æ®",
        "Design Challenges": "è®¾è®¡æŒ‘æˆ˜",
        "Spatial Strategy": "ç©ºé—´ç­–ç•¥",
        "Space Planning": "ç©ºé—´è§„åˆ’",
        # å…¶ä»–å¸¸è§æ ‡é¢˜
        "Key Performance Indicators": "å…³é”®ç»©æ•ˆæŒ‡æ ‡",
        "Key Findings": "å…³é”®å‘ç°",
        "Key Success Factors": "å…³é”®æˆåŠŸå› ç´ ",
        "Action Items": "è¡ŒåŠ¨é¡¹",
        "Next Steps": "ä¸‹ä¸€æ­¥",
        "Risk Analysis": "é£é™©åˆ†æ",
        "Quality Standards": "è´¨é‡æ ‡å‡†",
        "Master Work Deconstruction Nendo": "å¤§å¸ˆä½œå“è§£æ„ Nendo",
        "Missing Inspiration Warning": "ç¼ºå¤±çµæ„Ÿè­¦å‘Š",
        "Case Studies Deep Dive": "æ¡ˆä¾‹æ·±åº¦ç ”ç©¶",
        "Case Studies": "æ¡ˆä¾‹ç ”ç©¶",
        "Key Takeaways": "å…³é”®è¦ç‚¹",
        # MEPä¸å·¥ç¨‹ç³»ç»Ÿ
        "System Solutions": "ç³»ç»Ÿè§£å†³æ–¹æ¡ˆ",
        "Recommended Solution": "æ¨èæ–¹æ¡ˆ",
        "Reasoning": "ç†ç”±",
        "Application Area": "åº”ç”¨åŒºåŸŸ",
        # æ··åˆä¸­è‹±æ–‡æ ¼å¼ä¿®æ­£ - æ‰©å±•åˆ—è¡¨
        "mepoverallç­–ç•¥": "MEPæ€»ä½“ç­–ç•¥",
        "craftsmanshipç­–ç•¥": "å·¥è‰ºç­–ç•¥",
        "keymaterialè§„æ ¼": "å…³é”®ææ–™è§„æ ¼",
        "visualmerchandisingç­–ç•¥": "è§†è§‰è¥é”€ç­–ç•¥",
        "visualmerchandising": "è§†è§‰è¥é”€",
        "visual merchandising": "è§†è§‰è¥é”€",
        "å®ç°guidance": "å®æ–½æŒ‡å¯¼",
        "systemåç§°": "ç³»ç»Ÿåç§°",
        "materialåç§°": "ææ–™åç§°",
        "keyè§„æ ¼": "å…³é”®è§„æ ¼",
        "å½±å“onæ¶æ„": "å¯¹æ¶æ„çš„å½±å“",
        "reusableè®¾è®¡patterns": "å¯å¤ç”¨è®¾è®¡æ¨¡å¼",
        "åº”ç”¨guidelinesforteam": "å›¢é˜Ÿåº”ç”¨æŒ‡å—",
        "åº”ç”¨æŒ‡å—forå›¢é˜Ÿ": "å›¢é˜Ÿåº”ç”¨æŒ‡å—",
        "forå›¢é˜Ÿ": "å›¢é˜Ÿ",
        "æ—…ç¨‹maps": "æ—…ç¨‹åœ°å›¾",
        "patternåç§°": "æ¨¡å¼åç§°",
        "journey maps": "æ—…ç¨‹åœ°å›¾",
        "journeymaps": "æ—…ç¨‹åœ°å›¾",
        "design patterns": "è®¾è®¡æ¨¡å¼",
        "designpatterns": "è®¾è®¡æ¨¡å¼",
        "guidelines for team": "å›¢é˜ŸæŒ‡å—",
        "guidelinesforteam": "å›¢é˜ŸæŒ‡å—",
        "å¤§å¸ˆworkè§£æ„Nendo": "å¤§å¸ˆä½œå“è§£æ„ Nendo",
        "work": "ä½œå“",
        # æ–°å¢å¸¸è§è‹±æ–‡è¯æ±‡
        "for": "",  # å•ç‹¬çš„ for é€šå¸¸å¯ä»¥çœç•¥
        "team": "å›¢é˜Ÿ",
        "guidance": "æŒ‡å¯¼",
        "guidelines": "æŒ‡å—",
        "strategy": "ç­–ç•¥",
        "strategies": "ç­–ç•¥",
        "analysis": "åˆ†æ",
        "design": "è®¾è®¡",
        "system": "ç³»ç»Ÿ",
        "material": "ææ–™",
        "materials": "ææ–™",
        "pattern": "æ¨¡å¼",
        "patterns": "æ¨¡å¼",
        "journey": "æ—…ç¨‹",
        "map": "åœ°å›¾",
        "maps": "åœ°å›¾",
        "key": "å…³é”®",
        "implementation": "å®æ–½",
        "execution": "æ‰§è¡Œ",
        "plan": "è®¡åˆ’",
        "recommendation": "å»ºè®®",
        "solution": "è§£å†³æ–¹æ¡ˆ",
        "solutions": "è§£å†³æ–¹æ¡ˆ",
    }

    def __init__(self, template_dir: Optional[str] = None):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            template_dir: æ¨¡æ¿ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å†…ç½®æ¨¡æ¿
        """
        if template_dir is None:
            template_dir = Path(__file__).parent / "templates"

        self.template_dir = Path(template_dir)
        self.env = Environment(loader=FileSystemLoader(str(self.template_dir)), autoescape=True)
        # æ·»åŠ è‡ªå®šä¹‰è¿‡æ»¤å™¨
        self.env.filters["nl2br"] = self._nl2br
        self.env.filters["markdown"] = self._simple_markdown

    @staticmethod
    def _nl2br(text: str) -> str:
        """å°†æ¢è¡Œç¬¦è½¬ä¸º <br> æ ‡ç­¾"""
        if not text:
            return ""
        return text.replace("\n", "<br>\n")

    def _normalize_newlines(self, text: str) -> str:
        """ç»Ÿä¸€å¤„ç†æ‰€æœ‰æ¢è¡Œç¬¦æ ¼å¼

        å¤„ç†ä»¥ä¸‹æƒ…å†µï¼š
        1. å­—é¢å­—ç¬¦ä¸² \\nï¼ˆåæ–œæ +nï¼‰â†’ å®é™…æ¢è¡Œ
        2. è¿ç»­ç©ºæ ¼+\\n â†’ æ¢è¡Œ
        3. \\n\\n â†’ æ®µè½åˆ†éš”
        """
        if not text:
            return text

        # å¤„ç†å­—é¢ \nï¼ˆJSON ä¸­çš„è½¬ä¹‰æ¢è¡Œï¼‰
        text = text.replace("\\n\\n", "\n\n")  # æ®µè½å…ˆå¤„ç†
        text = text.replace("\\n", "\n")  # å•æ¢è¡Œ

        # å¤„ç† \r\n
        text = text.replace("\r\n", "\n")

        return text

    def _simple_markdown(self, text: str) -> str:
        """ç®€å•çš„ Markdown è½¬ HTMLï¼ŒåŒ…å«æ ¼å¼æ¸…ç†"""
        if not text:
            return ""

        # ç¬¬é›¶æ­¥ï¼šç»Ÿä¸€æ¢è¡Œç¬¦æ ¼å¼ï¼ˆå¤„ç†å­—é¢ \nï¼‰
        text = self._normalize_newlines(text)

        # ç¬¬ä¸€æ­¥ï¼šæ¸…ç† JSON ç¬¦å·
        text = self._clean_json_artifacts(text)

        # ç¬¬äºŒæ­¥ï¼šç¿»è¯‘è‹±æ–‡å†…å®¹
        text = self._translate_all_english(text)

        # ç¬¬ä¸‰æ­¥ï¼šç»Ÿä¸€åˆ—è¡¨æ ¼å¼
        text = self._unify_list_format(text)

        # è½¬ä¹‰ HTMLï¼ˆåœ¨æ¸…ç†ä¹‹åï¼‰
        text = text.replace("&", "&amp;")

        # æ ‡é¢˜
        text = re.sub(r"^### (.+)$", r"<h3>\1</h3>", text, flags=re.MULTILINE)
        text = re.sub(r"^## (.+)$", r"<h2>\1</h2>", text, flags=re.MULTILINE)
        text = re.sub(r"^# (.+)$", r"<h1>\1</h1>", text, flags=re.MULTILINE)

        # ç²—ä½“å’Œæ–œä½“
        text = re.sub(r"\*\*(.+?)\*\*", r"<strong>\1</strong>", text)
        text = re.sub(r"\*(.+?)\*", r"<em>\1</em>", text)

        # ä»£ç å—
        text = re.sub(r"`([^`]+)`", r"<code>\1</code>", text)

        # æ®µè½åˆ†éš”ï¼ˆåŒæ¢è¡Œå˜æˆæ®µè½é—´è·ï¼‰
        text = re.sub(r"\n\n+", "<br><br>\n", text)

        # å•æ¢è¡Œ
        text = text.replace("\n", "<br>\n")

        return text

    def _translate_all_english(self, text: str) -> str:
        """ä»æ ¹æºä¸Šç¿»è¯‘æ‰€æœ‰è‹±æ–‡å†…å®¹

        ç­–ç•¥ï¼š
        1. å…ˆæ›¿æ¢å·²çŸ¥çš„å›ºå®šçŸ­è¯­
        2. å¤„ç†è‹±æ–‡+ä¸­æ–‡æ··åˆæ ¼å¼
        3. å¤„ç†çº¯è‹±æ–‡å•è¯ï¼ˆé€šè¿‡è¯å…¸ï¼‰
        """
        if not text:
            return text

        result = text

        # 1. æ›¿æ¢å·²çŸ¥çš„å›ºå®šçŸ­è¯­ï¼ˆæŒ‰é•¿åº¦é™åºï¼Œé¿å…çŸ­ä¸²å¹²æ‰°é•¿ä¸²ï¼‰
        sorted_translations = sorted(self.CONTENT_TRANSLATIONS.items(), key=lambda x: len(x[0]), reverse=True)
        for eng, chn in sorted_translations:
            result = result.replace(eng, chn)

        # 2. å¤„ç†è‹±æ–‡+ä¸­æ–‡æ··åˆæ ¼å¼ (å¦‚ visualmerchandisingç­–ç•¥)
        def replace_mixed(match):
            eng_part = match.group(1).lower()
            chn_part = match.group(2)
            # å…ˆæŸ¥å®Œæ•´ç»„åˆ
            full_key = eng_part + chn_part
            if full_key in self.CONTENT_TRANSLATIONS:
                return self.CONTENT_TRANSLATIONS[full_key]
            # æŸ¥è‹±æ–‡éƒ¨åˆ†
            if eng_part in self.FIELD_LABELS:
                return self.FIELD_LABELS[eng_part] + chn_part
            # åœ¨ CONTENT_TRANSLATIONS ä¸­æ¨¡ç³ŠåŒ¹é…
            for eng, chn in self.CONTENT_TRANSLATIONS.items():
                if eng.lower().replace(" ", "").replace("_", "") == eng_part:
                    return chn + chn_part
            return match.group(0)

        result = re.sub(r"([a-zA-Z]{3,})([\u4e00-\u9fff]+)", replace_mixed, result)

        # 3. å¤„ç†ç‹¬ç«‹çš„çº¯è‹±æ–‡å•è¯/çŸ­è¯­ï¼ˆ3ä¸ªå­—æ¯ä»¥ä¸Šï¼‰
        def replace_pure_english(match):
            word = match.group(0)
            word_lower = word.lower().replace(" ", "_")
            # åœ¨ FIELD_LABELS ä¸­æŸ¥æ‰¾
            if word_lower in self.FIELD_LABELS:
                return self.FIELD_LABELS[word_lower]
            # åœ¨ CONTENT_TRANSLATIONS ä¸­æŸ¥æ‰¾
            for eng, chn in self.CONTENT_TRANSLATIONS.items():
                if eng.lower() == word.lower():
                    return chn
            return word

        # åŒ¹é…è¿ç»­çš„è‹±æ–‡å•è¯ï¼ˆå¯èƒ½å¸¦ç©ºæ ¼ï¼‰
        result = re.sub(r"\b[A-Za-z][a-z]{2,}(?:\s+[A-Za-z][a-z]+)*\b", replace_pure_english, result)

        return result

    def _unify_list_format(self, text: str, is_sublist: bool = False) -> str:
        """ç»Ÿä¸€æ‰€æœ‰åˆ—è¡¨æ ¼å¼

        Args:
            text: è¦å¤„ç†çš„æ–‡æœ¬
            is_sublist: æ˜¯å¦ä¸ºå­åˆ—è¡¨ï¼ˆå­åˆ—è¡¨æ·»åŠ ç¼©è¿›ï¼‰

        ä¸€çº§åˆ—è¡¨ï¼ˆåŠ ç²—æ ‡ç­¾å‰ï¼‰ï¼š1. **æ ‡ç­¾**: å†…å®¹
        äºŒçº§åˆ—è¡¨ï¼ˆå­åˆ—è¡¨ï¼‰ï¼š    1. å†…å®¹ï¼ˆå¸¦ç¼©è¿›ï¼‰
        """
        if not text:
            return text

        # ç¼©è¿›å‰ç¼€
        indent = "&nbsp;&nbsp;&nbsp;&nbsp;" if is_sublist else ""

        # === ç¬¬ä¸€æ­¥ï¼šå°†æ‰€æœ‰ç¼–å·æ ¼å¼ç»Ÿä¸€ä¸ºä¸´æ—¶æ ‡è®° ===
        # å¤„ç†åœ†åœˆæ•°å­— â‘ â‘¡â‘¢
        circled_numbers = "â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©"
        for i, cn in enumerate(circled_numbers, 1):
            text = text.replace(cn, f"__LIST_ITEM_{i}__")

        # å¤„ç† 1) 2) æ ¼å¼
        text = re.sub(r"(\d+)\)\s*", r"__LIST_ITEM_\1__", text)

        # å¤„ç† 1ï¼‰ 2ï¼‰ æ ¼å¼ï¼ˆå…¨è§’æ‹¬å·ï¼‰
        text = re.sub(r"(\d+)ï¼‰\s*", r"__LIST_ITEM_\1__", text)

        # å¤„ç† 1ã€ 2ã€ æ ¼å¼
        text = re.sub(r"(\d+)ã€\s*", r"__LIST_ITEM_\1__", text)

        # å¤„ç† 1. 2. æ ¼å¼ï¼ˆä¿ç•™ï¼Œä½†ç»Ÿä¸€åŒ–ï¼‰- ä½†ä¸å¤„ç†åŠ ç²—æ ‡ç­¾å‰çš„ç¼–å·
        # æ£€æµ‹ "æ•°å­—. **" æ¨¡å¼ï¼Œè¿™æ˜¯ä¸€çº§ç¼–å·ï¼Œä¿ç•™åŸæ ·
        text = re.sub(r"(\d+)\.\s+(?!\*\*)", r"__LIST_ITEM_\1__", text)

        # === ç¬¬äºŒæ­¥ï¼šå°†ä¸´æ—¶æ ‡è®°è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ ===
        def format_list_item(match):
            num = match.group(1)
            return f"<br>{indent}{num}. "

        text = re.sub(r"__LIST_ITEM_(\d+)__", format_list_item, text)

        # === ç¬¬ä¸‰æ­¥ï¼šæ¸…ç†æ ¼å¼ ===
        # ç§»é™¤å¼€å¤´çš„æ¢è¡Œ
        text = re.sub(r"^(<br>\s*)+", "", text)
        # åˆå¹¶è¿ç»­æ¢è¡Œ
        text = re.sub(r"(<br>\s*)+", "<br>", text)

        return text

    def translate_label(self, key: str) -> str:
        """ç¿»è¯‘å­—æ®µæ ‡ç­¾

        æ”¯æŒå¤„ç†ä»¥ä¸‹æ ¼å¼:
        - æ™®é€šå­—æ®µ: design_rationale -> è®¾è®¡ç†æ®
        - å¸¦ç¼–å·å­—æ®µ: q1_é«˜æ•ˆæµè½¬ä½“éªŒ -> é—®é¢˜1: é«˜æ•ˆæµè½¬ä½“éªŒ
        - ä¸‹åˆ’çº¿è¿æ¥: project_vision_summary -> é¡¹ç›®æ„¿æ™¯æ‘˜è¦
        - æ··åˆä¸­è‹±æ–‡: mepoverallç­–ç•¥ -> MEPæ€»ä½“ç­–ç•¥
        """
        if not key:
            return key

        # é¦–å…ˆæ£€æŸ¥ CONTENT_TRANSLATIONS ä¸­æ˜¯å¦æœ‰ç›´æ¥åŒ¹é…ï¼ˆå¤„ç†æ··åˆä¸­è‹±æ–‡ï¼‰
        if key in self.CONTENT_TRANSLATIONS:
            return self.CONTENT_TRANSLATIONS[key]

        key_lower = key.lower().replace(" ", "_").replace("-", "_")

        # æ£€æŸ¥æ˜¯å¦åœ¨æ˜ å°„è¡¨ä¸­ï¼ˆå®Œå…¨åŒ¹é…ï¼‰
        if key_lower in self.FIELD_LABELS:
            return self.FIELD_LABELS[key_lower]

        # æ£€æŸ¥ CONTENT_TRANSLATIONS ä¸­æ˜¯å¦æœ‰åŒ¹é…ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        for eng, chn in self.CONTENT_TRANSLATIONS.items():
            if eng.lower().replace(" ", "").replace("_", "") == key_lower.replace("_", ""):
                return chn

        # å¤„ç†æ··åˆä¸­è‹±æ–‡æ ¼å¼ï¼šå°†è‹±æ–‡éƒ¨åˆ†ç¿»è¯‘
        # ä¾‹å¦‚: mepoverallç­–ç•¥ -> MEPæ€»ä½“ç­–ç•¥
        # ä¹Ÿå¤„ç†: visualmerchandisingç­–ç•¥ -> è§†è§‰è¥é”€ç­–ç•¥
        if not key.isascii():
            # æå–è‹±æ–‡éƒ¨åˆ†å’Œä¸­æ–‡éƒ¨åˆ†
            eng_part_match = re.match(r"^([a-zA-Z_]+)([\u4e00-\u9fff]+)$", key)
            if eng_part_match:
                eng_part = eng_part_match.group(1).lower()
                chn_part = eng_part_match.group(2)
                # å…ˆæ£€æŸ¥å®Œæ•´çš„æ··åˆæ ¼å¼æ˜¯å¦æœ‰ç¿»è¯‘
                full_key = eng_part + chn_part
                if full_key in self.CONTENT_TRANSLATIONS:
                    return self.CONTENT_TRANSLATIONS[full_key]
                # å†æ£€æŸ¥è‹±æ–‡éƒ¨åˆ†
                if eng_part in self.FIELD_LABELS:
                    return self.FIELD_LABELS[eng_part] + chn_part
                # å°è¯•åœ¨ CONTENT_TRANSLATIONS ä¸­æŸ¥æ‰¾
                for eng_key, chn_val in self.CONTENT_TRANSLATIONS.items():
                    if eng_key.lower().replace(" ", "").replace("_", "") == eng_part:
                        return chn_val + chn_part

        # å¤„ç† q1_xxx, q2_xxx, q10_xxx ç­‰æ ¼å¼ (é—®å·é—®é¢˜)
        q_match = re.match(r"^[qQ](\d+)[_\s]*(.*)$", key)
        if q_match:
            q_num = q_match.group(1)
            q_content = q_match.group(2)
            if q_content:
                # å°†ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œä½†ä¿ç•™ä¸­æ–‡
                q_content = q_content.replace("_", " ").strip()
                # å¦‚æœå†…å®¹æ˜¯å…¨è‹±æ–‡ä¸‹åˆ’çº¿æ ¼å¼ï¼Œå°è¯•ç¿»è¯‘
                content_key = q_content.lower().replace(" ", "_")
                if content_key in self.FIELD_LABELS:
                    q_content = self.FIELD_LABELS[content_key]
                return f"é—®é¢˜{q_num}: {q_content}"
            return f"é—®é¢˜{q_num}"

        # å°è¯•åˆ†è¯ç¿»è¯‘ï¼šå°† business_goal_analysis æ‹†åˆ†ä¸ºå„ä¸ªå•è¯
        parts = key_lower.split("_")
        translated_parts = []
        for part in parts:
            if part in self.FIELD_LABELS:
                translated_parts.append(self.FIELD_LABELS[part])
            else:
                translated_parts.append(part)

        # å¦‚æœæœ‰ä»»ä½•éƒ¨åˆ†è¢«ç¿»è¯‘äº†ï¼Œç»„åˆè¿”å›
        if any(p != parts[i] for i, p in enumerate(translated_parts)):
            return "".join(translated_parts)

        # å°è¯•å°†ä¸‹åˆ’çº¿è½¬ä¸ºç©ºæ ¼ï¼Œä½¿æ ‡ç­¾æ›´å¯è¯»
        readable = key.replace("_", " ").strip()

        # å¦‚æœæ˜¯å…¨è‹±æ–‡ï¼Œé¦–å­—æ¯å¤§å†™
        if readable and readable.isascii():
            return readable.title()

        return readable if readable else key

    def translate_content(self, text: str) -> str:
        """ç¿»è¯‘å†…å®¹ä¸­çš„è‹±æ–‡çŸ­è¯­å’Œå­—æ®µå

        å¤„ç†ä»¥ä¸‹æƒ…å†µ:
        1. å›ºå®šçŸ­è¯­ç¿»è¯‘ (CONTENT_TRANSLATIONS)
        2. JSON æ ¼å¼ä¸­çš„å­—æ®µå: "field_name": -> "ä¸­æ–‡å":
        3. å­—å…¸æ˜¾ç¤ºæ ¼å¼ä¸­çš„å­—æ®µå: 'field_name': -> 'ä¸­æ–‡å':
        4. ç‹¬ç«‹å‡ºç°çš„ä¸‹åˆ’çº¿å­—æ®µå
        5. | xxx: æ ¼å¼çš„æ ‡é¢˜è¡Œ -> ç¿»è¯‘å¹¶æ¢è¡Œ
        6. çº¯è‹±æ–‡æ ‡é¢˜è‡ªåŠ¨ç¿»è¯‘
        """
        if not text:
            return text

        result = text

        # 0. å¤„ç† | xxx: æ ¼å¼çš„æ ‡é¢˜ï¼ˆå¦‚ | Key Takeaways:ï¼‰
        def replace_pipe_heading(match):
            heading = match.group(1).strip()
            # æŸ¥æ‰¾ç¿»è¯‘
            translated = heading
            for eng, chn in self.CONTENT_TRANSLATIONS.items():
                if eng.lower() == heading.lower() or eng.lower() == heading.rstrip(":").lower():
                    translated = chn
                    break
            # å¦‚æœæ²¡æ‰¾åˆ°ç¿»è¯‘ï¼Œå°è¯•ç”¨ translate_label
            if translated == heading:
                translated = self.translate_label(heading.rstrip(":"))
            return f"<br><strong>{translated.rstrip(':')}</strong>ï¼š<br>"

        result = re.sub(r"\|\s*([A-Za-z][A-Za-z\s]+:?)\s*", replace_pipe_heading, result)

        # 1. æ›¿æ¢å›ºå®šçŸ­è¯­
        for eng, chn in self.CONTENT_TRANSLATIONS.items():
            result = result.replace(eng, chn)

        # 2. å¤„ç†çº¯è‹±æ–‡æ ‡é¢˜ï¼ˆå¦‚ visualmerchandisingç­–ç•¥ï¼‰
        # åŒ¹é…è‹±æ–‡+ä¸­æ–‡çš„æ··åˆæ ¼å¼
        def replace_mixed_label(match):
            eng_part = match.group(1).lower()
            chn_part = match.group(2)
            # åœ¨ FIELD_LABELS ä¸­æŸ¥æ‰¾
            if eng_part in self.FIELD_LABELS:
                return self.FIELD_LABELS[eng_part] + chn_part
            # åœ¨ CONTENT_TRANSLATIONS ä¸­æŸ¥æ‰¾
            for eng, chn in self.CONTENT_TRANSLATIONS.items():
                if eng.lower().replace(" ", "").replace("_", "") == eng_part:
                    return chn + chn_part
            return match.group(0)

        result = re.sub(r"([a-zA-Z]+)([\u4e00-\u9fff]+)", replace_mixed_label, result)

        # 2. æ›¿æ¢ JSON/å­—å…¸æ ¼å¼ä¸­çš„å­—æ®µå: "field_name": æˆ– 'field_name':
        def replace_field_in_quotes(match):
            quote = match.group(1)  # " æˆ– '
            field = match.group(2)  # å­—æ®µå
            translated = self.translate_label(field)
            # å¦‚æœç¿»è¯‘åä»æ˜¯è‹±æ–‡ï¼ˆé¦–å­—æ¯å¤§å†™æ ¼å¼ï¼‰ï¼Œä¿æŒåŸæ ·
            if translated == field.replace("_", " ").title():
                return match.group(0)
            return f"{quote}{translated}{quote}:"

        # åŒ¹é… "xxx_xxx": æˆ– 'xxx_xxx': æ ¼å¼
        result = re.sub(r'(["\'])([a-z][a-z0-9_]*)\1\s*:', replace_field_in_quotes, result)

        # 3. æ›¿æ¢ç‹¬ç«‹å‡ºç°çš„ä¸‹åˆ’çº¿å­—æ®µåï¼ˆä½œä¸ºæ ‡é¢˜ï¼‰
        def replace_standalone_field(match):
            field = match.group(1)
            translated = self.translate_label(field)
            if translated == field.replace("_", " ").title():
                return match.group(0)
            return translated

        # åŒ¹é…è¡Œé¦–æˆ–ç©ºæ ¼åçš„ xxx_xxx æ ¼å¼ï¼ˆé€šå¸¸æ˜¯å­—æ®µåä½œä¸ºæ ‡é¢˜ï¼‰
        result = re.sub(
            r"(?:^|(?<=\s))([a-z][a-z0-9]*(?:_[a-z0-9]+)+)(?=\s*[:ï¼š]|\s*$)",
            replace_standalone_field,
            result,
            flags=re.MULTILINE,
        )

        return result

    def _try_parse_dict_string(self, text: str) -> Optional[Dict]:
        """å°è¯•å°†å­—ç¬¦ä¸²è§£æä¸ºå­—å…¸

        æ”¯æŒ Python å­—å…¸æ ¼å¼: {'key': 'value', ...}
        å’Œ JSON æ ¼å¼: {"key": "value", ...}
        """
        if not text or not isinstance(text, str):
            return None

        text = text.strip()

        # æ£€æŸ¥æ˜¯å¦åƒå­—å…¸æ ¼å¼
        if not (text.startswith("{") and text.endswith("}")):
            # ä¹Ÿæ£€æŸ¥æ˜¯å¦åƒ 'q1_xxx': è¿™ç§é”®å€¼å¯¹æ ¼å¼
            if not re.search(r"'[a-zA-Z_][a-zA-Z0-9_]*'\s*:", text):
                return None

        try:
            # å°è¯•ç”¨ ast.literal_eval è§£æ Python å­—å…¸
            import ast

            result = ast.literal_eval(text)
            if isinstance(result, dict):
                return result
        except:
            pass

        try:
            # å°è¯•ç”¨ JSON è§£æ
            import json

            result = json.loads(text)
            if isinstance(result, dict):
                return result
        except:
            pass

        return None

    def _clean_json_artifacts(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ä¸­æ®‹ç•™çš„JSON/å­—å…¸ç¬¦å·

        ğŸ”¥ v7.1 å¢å¼ºï¼šå¤„ç† deliverable_outputs ç­‰å¤æ‚ç»“æ„
        """
        if not text:
            return text

        text = text.strip()

        # ğŸ”¥ é¦–å…ˆå¤„ç†å­—é¢æ¢è¡Œç¬¦ï¼ˆ\n ä½œä¸ºå­—ç¬¦ä¸²ï¼‰
        text = text.replace("\\n\\n", "\n\n")
        text = text.replace("\\n", "\n")

        # ç§»é™¤ç©ºæ•°ç»„æ ‡è®° [''] æˆ– [""] æˆ– []
        text = re.sub(r"\[''\]", "", text)
        text = re.sub(r'\[""\]', "", text)
        text = re.sub(r"\[\]", "", text)
        text = re.sub(r"\[\s*\]", "", text)

        # ğŸ”¥ å¤„ç† 'key': 'value', 'key2': 'value2' æ ¼å¼ï¼ˆå­—å…¸å±•å¼€ä¸ºå¯è¯»æ ¼å¼ï¼‰
        # å…ˆæ£€æµ‹æ˜¯å¦ä¸ºå­—å…¸å­—ç¬¦ä¸²æ ¼å¼
        if re.match(r"^\s*['\"][a-zA-Z_\u4e00-\u9fff]", text):
            # å°†å­—å…¸é”®å€¼å¯¹è½¬ä¸ºå¯è¯»æ ¼å¼
            # 'deliverable_name': 'xxx', 'content': 'yyy' â†’
            # **äº¤ä»˜ç‰©åç§°**: xxx\n**å†…å®¹**: yyy
            def format_dict_pair(match):
                key = match.group(1)
                value = match.group(2)
                # ç¿»è¯‘é”®å
                translated_key = self.translate_label(key)
                # æ¸…ç†å€¼ä¸­çš„å¼•å·
                value = value.strip("'\"")
                return f"\n**{translated_key}**ï¼š{value}"

            # åŒ¹é… 'key': 'value' æˆ– "key": "value" æ¨¡å¼
            text = re.sub(r"['\"]([a-zA-Z_][a-zA-Z0-9_]*)['\"]:\s*['\"]([^'\"]+)['\"]", format_dict_pair, text)
            # ç§»é™¤æ®‹ç•™çš„é€—å·åˆ†éš”ç¬¦
            text = re.sub(r",\s*(?=\n\*\*)", "", text)

        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„å¤§æ‹¬å·
        while text.startswith("{") and text.endswith("}"):
            text = text[1:-1].strip()

        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„æ–¹æ‹¬å·
        while text.startswith("[") and text.endswith("]"):
            text = text[1:-1].strip()

        # ç§»é™¤å¼€å¤´çš„æ–¹æ‹¬å·ï¼ˆå¦‚æœå†…å®¹ä»¥ [ å¼€å¤´ä½†ä¸ä»¥ ] ç»“å°¾ï¼‰
        if text.startswith("["):
            text = text[1:].strip()
        if text.endswith("]"):
            text = text[:-1].strip()

        # ç§»é™¤å­—æ®µåæ ¼å¼çš„å¼•å·: 'key': æˆ– "key":
        text = re.sub(r"['\"]([a-zA-Z_][a-zA-Z0-9_]*)['\"]:\s*", r"\1: ", text)

        # ç§»é™¤å€¼å‘¨å›´çš„å•å¼•å·ï¼ˆä½†ä¿ç•™ä¸­æ–‡å†…å®¹ï¼‰
        # åŒ¹é… ': 'xxx' æˆ– ', 'xxx' æ ¼å¼
        text = re.sub(r":\s*'([^']+)'", r": \1", text)
        text = re.sub(r",\s*'([^']+)'", r", \1", text)

        # ç§»é™¤æ®‹ç•™çš„å•ç‹¬å¼•å·
        text = re.sub(r"(?<![a-zA-Z\u4e00-\u9fff])'(?![a-zA-Z\u4e00-\u9fff])", "", text)

        # ç§»é™¤æ®‹ç•™çš„å¤§æ‹¬å·
        text = text.replace("{", "").replace("}", "")

        # å¤„ç† Q&A æ ¼å¼: "é—®é¢˜ï¼Ÿ: ç­”æ¡ˆ" -> "é—®é¢˜ï¼Ÿ<br>ç­”æ¡ˆ"
        # åŒ¹é…ä¸­æ–‡é—®å·æˆ–è‹±æ–‡é—®å·åè·Ÿå†’å·çš„æ¨¡å¼
        text = re.sub(r"([ï¼Ÿ?])\s*[:ï¼š]\s*", r"\1<br>", text)

        # å°†é€—å·åˆ†éš”çš„é¡¹ç›®è½¬ä¸ºæ¢è¡Œï¼ˆå¦‚æœæ˜¯åˆ—è¡¨é¡¹ï¼‰
        # æ£€æµ‹ ', ' åè·Ÿå­—æ¯æˆ–ä¸­æ–‡çš„æ¨¡å¼
        if ", " in text and not re.search(r"\d+[)ï¼‰]", text):
            # ä¸æ˜¯ç¼–å·åˆ—è¡¨ï¼Œå¯èƒ½æ˜¯é€—å·åˆ†éš”çš„é¡¹ç›®
            pass  # æš‚ä¸å¤„ç†ï¼Œé¿å…è¯¯ä¼¤æ­£å¸¸å¥å­

        return text.strip()

    def _clean_and_format_value(self, value: Any, is_nested: bool = False) -> str:
        """æ¸…ç†å’Œæ ¼å¼åŒ–å€¼ï¼Œç”¨äºæ˜¾ç¤º

        Args:
            value: è¦æ ¼å¼åŒ–çš„å€¼
            is_nested: æ˜¯å¦æ˜¯åµŒå¥—çš„å­é¡¹ï¼ˆç”¨äºæ§åˆ¶ bullet å±‚çº§ï¼‰
        """
        if value is None:
            return ""

        if isinstance(value, (list, tuple)):
            # è¿‡æ»¤ç©ºå€¼
            valid_items = [item for item in value if item is not None and item != "" and item != []]
            if not valid_items:
                return ""
            # åªæœ‰ä¸€ä¸ªé¡¹ç›®æ—¶ä¸åŠ åºå·
            if len(valid_items) == 1:
                return self._clean_and_format_value(valid_items[0], is_nested)
            # å¤šä¸ªé¡¹ç›®ï¼Œä½¿ç”¨åºå·åˆ—è¡¨
            items = [self._clean_and_format_value(item, is_nested=True) for item in valid_items]
            formatted_items = []
            for i, item in enumerate(items, 1):
                if item:
                    # å­åˆ—è¡¨ä½¿ç”¨ç¼©è¿›æ ·å¼
                    formatted_items.append(f"&nbsp;&nbsp;&nbsp;&nbsp;{i}. {item}")
            return "<br>".join(formatted_items)

        if isinstance(value, dict):
            # è·³è¿‡ confidence å­—æ®µ
            filtered_dict = {k: v for k, v in value.items() if k.lower() not in ("confidence", "ç½®ä¿¡åº¦", "conf")}
            if not filtered_dict:
                return ""
            # å­—å…¸å±•å¼€ä¸ºé”®å€¼å¯¹ï¼ŒåŠ ç²—æ ‡ç­¾å‰ä¸åŠ åºå·
            parts = []
            for k, v in filtered_dict.items():
                label = self.translate_label(k)
                val = self._clean_and_format_value(v, is_nested=True)
                if val:
                    # å¦‚æœå€¼åŒ…å«å¤šè¡Œï¼ˆæœ‰æ¢è¡Œï¼‰ï¼Œåœ¨æ ‡ç­¾åä¹Ÿæ¢è¡Œ
                    if "<br>" in val:
                        parts.append(f"<strong>{label}</strong>:<br>{val}")
                    else:
                        parts.append(f"<strong>{label}</strong>: {val}")
            return "<br><br>".join(parts)  # ğŸ”¥ ç”¨åŒæ¢è¡Œåˆ†éš”ä¸åŒå­—æ®µ

        text = str(value)
        # ğŸ”¥ å…ˆå¤„ç†å­—é¢æ¢è¡Œç¬¦
        text = self._normalize_newlines(text)
        # æ¸…ç† JSON ç¬¦å·
        text = self._clean_json_artifacts(text)
        # ç¿»è¯‘è‹±æ–‡
        text = self._translate_all_english(text)
        # ç»Ÿä¸€åˆ—è¡¨æ ¼å¼ï¼ˆä½œä¸ºå­åˆ—è¡¨å¤„ç†ï¼‰
        text = self._unify_list_format(text, is_sublist=True)
        # ğŸ”¥ æœ€åå°†æ¢è¡Œç¬¦è½¬ä¸º <br>
        text = text.replace("\n\n", "<br><br>")
        text = text.replace("\n", "<br>")

        return text

    def _format_object_list(self, obj_list: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¯¹è±¡åˆ—è¡¨ä¸ºHTMLå†…å®¹

        ç”¨äºæ¡ˆä¾‹ç ”ç©¶ã€ç«äº‰åˆ†æç­‰ç»“æ„åŒ–æ•°æ®
        åŠ ç²—æ ‡ç­¾å‰ä¸åŠ åºå·
        """
        if not obj_list:
            return ""

        parts = []
        for obj in obj_list:
            obj_parts = []
            for k, v in obj.items():
                # è·³è¿‡ confidence å­—æ®µ
                if k.lower() in ("confidence", "ç½®ä¿¡åº¦", "conf"):
                    continue
                if v is None or v == "":
                    continue

                label = self.translate_label(k)

                # å¤„ç†å€¼
                if isinstance(v, list):
                    # åˆ—è¡¨å€¼ï¼Œæ ¼å¼åŒ–ä¸ºå¸¦ç¼©è¿›çš„åºå·åˆ—è¡¨
                    list_items = []
                    for i, item in enumerate(v, 1):
                        cleaned = self._clean_json_artifacts(str(item))
                        cleaned = self._translate_all_english(cleaned)
                        if cleaned:
                            # å­åˆ—è¡¨æ·»åŠ ç¼©è¿›
                            list_items.append(f"&nbsp;&nbsp;&nbsp;&nbsp;{i}. {cleaned}")
                    val = "<br>".join(list_items)
                elif isinstance(v, dict):
                    val = self._clean_and_format_value(v)
                else:
                    val = self._clean_json_artifacts(str(v))
                    val = self._translate_all_english(val)
                    # å­åˆ—è¡¨å¤„ç†
                    val = self._unify_list_format(val, is_sublist=True)

                if val:
                    # å¦‚æœå€¼åŒ…å«å¤šè¡Œï¼Œåœ¨æ ‡ç­¾åæ¢è¡Œ
                    if "<br>" in val:
                        obj_parts.append(f"<strong>{label}</strong>:<br>{val}")
                    else:
                        obj_parts.append(f"<strong>{label}</strong>: {val}")

            if obj_parts:
                parts.append("<br>".join(obj_parts))

        # ç”¨åŒæ¢è¡Œåˆ†éš”ä¸åŒå¯¹è±¡
        return "<br><br>".join(parts)

    def _format_numbered_text(self, text: str) -> str:
        """æ ¼å¼åŒ–ç¼–å·æ–‡æœ¬ï¼Œåœ¨ç¼–å·å‰æ·»åŠ æ¢è¡Œ

        å¤„ç†è§„åˆ™:
        - å¦‚æœåªæœ‰ä¸€ä¸ªç¼–å·é¡¹ï¼ˆå¦‚ 0) æˆ– 1)ï¼‰ï¼Œç§»é™¤ç¼–å·å‰ç¼€
        - å¦‚æœæœ‰å¤šä¸ªç¼–å·é¡¹ï¼Œåœ¨æ¯ä¸ªç¼–å·å‰æ·»åŠ æ¢è¡Œ
        """
        if not text:
            return text

        # å…ˆç»Ÿè®¡ç¼–å·æ•°é‡
        number_matches = list(re.finditer(r"(\d+)[)ï¼‰\.ã€]\s*", text))

        if len(number_matches) == 0:
            return text

        if len(number_matches) == 1:
            # åªæœ‰ä¸€ä¸ªç¼–å·ï¼Œç§»é™¤ç¼–å·å‰ç¼€
            result = re.sub(r"^(\d+)[)ï¼‰\.ã€]\s*", "", text.strip())
            return result

        # å¤šä¸ªç¼–å·ï¼Œåœ¨ç¼–å·å‰æ·»åŠ æ¢è¡Œï¼ˆé™¤äº†ç¬¬ä¸€ä¸ªï¼‰
        result = re.sub(r"(?<!\A)(?<![<\n])(\s*)(\d+)[)ï¼‰\.ã€]\s*", r"<br>\2) ", text)

        # ç¡®ä¿ç¬¬ä¸€ä¸ªç¼–å·æ ¼å¼æ­£ç¡®
        result = re.sub(r"^(\d+)[)ï¼‰\.ã€]\s*", r"\1) ", result)

        return result

    def format_numbered_list(self, text: str) -> List[str]:
        """è§£æç¼–å·åˆ—è¡¨ï¼Œè¿”å›å„é¡¹å†…å®¹"""
        if not text:
            return []

        # æ£€æµ‹æ˜¯å¦åŒ…å«ç¼–å·åˆ—è¡¨æ¨¡å¼
        pattern = r"(\d+)[\.\ã€\)ï¼‰]\s*"

        # å°è¯•åˆ†å‰²
        parts = re.split(pattern, text)

        if len(parts) <= 1:
            # ä¸æ˜¯ç¼–å·åˆ—è¡¨ï¼Œè¿”å›åŸæ–‡
            return [text]

        items = []
        # parts æ ¼å¼: ['å‰ç¼€', '1', 'å†…å®¹1', '2', 'å†…å®¹2', ...]
        i = 1
        while i < len(parts) - 1:
            num = parts[i]
            content = parts[i + 1].strip() if i + 1 < len(parts) else ""
            if content:
                items.append(content)
            i += 2

        return items if items else [text]

    def _parse_deliverable_outputs(self, title: str, value: Any) -> Optional[Dict[str, Any]]:
        """ğŸ”¥ v7.1: ä¸“é—¨å¤„ç†äº¤ä»˜ç‰©è¾“å‡ºå­—æ®µ

        äº¤ä»˜ç‰©è¾“å‡ºæ˜¯ v7.0 ä»»åŠ¡å¯¼å‘æ¶æ„çš„æ ¸å¿ƒè¾“å‡ºæ ¼å¼ï¼ŒåŒ…å«ï¼š
        - deliverable_name: äº¤ä»˜ç‰©åç§°
        - content: äº¤ä»˜ç‰©å†…å®¹ï¼ˆå¯èƒ½åŒ…å«å¤§é‡ \n æ¢è¡Œï¼‰
        - completion_status: å®ŒæˆçŠ¶æ€
        - quality_self_assessment: è´¨é‡è‡ªè¯„

        Args:
            title: å·²ç¿»è¯‘çš„æ ‡é¢˜
            value: å­—æ®µå€¼ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²ã€å­—å…¸æˆ–åˆ—è¡¨ï¼‰
        """
        if not value:
            return None

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
        if isinstance(value, str):
            # å…ˆå¤„ç†æ¢è¡Œç¬¦
            value = self._normalize_newlines(value)

            # å°è¯•è§£æä¸ºå­—å…¸/åˆ—è¡¨
            try:
                import ast

                parsed = ast.literal_eval(value)
                value = parsed
            except:
                try:
                    import json

                    parsed = json.loads(value)
                    value = parsed
                except:
                    # æ— æ³•è§£æï¼ŒæŒ‰æ™®é€šæ–‡æœ¬å¤„ç†
                    return {"title": title, "type": "text", "content": self._simple_markdown(value)}

        # å¤„ç†åˆ—è¡¨æ ¼å¼ï¼ˆå¤šä¸ªäº¤ä»˜ç‰©ï¼‰
        if isinstance(value, list):
            formatted_parts = []
            for idx, item in enumerate(value, 1):
                if isinstance(item, dict):
                    formatted_parts.append(self._format_single_deliverable(item, idx))
                else:
                    # å­—ç¬¦ä¸²é¡¹
                    text = self._normalize_newlines(str(item))
                    formatted_parts.append(self._simple_markdown(text))

            return {"title": title, "type": "text", "content": "<br><br>".join(formatted_parts)}

        # å¤„ç†å•ä¸ªå­—å…¸æ ¼å¼
        if isinstance(value, dict):
            return {"title": title, "type": "text", "content": self._format_single_deliverable(value)}

        return None

    def _format_single_deliverable(self, deliverable: Dict[str, Any], index: int = None) -> str:
        """æ ¼å¼åŒ–å•ä¸ªäº¤ä»˜ç‰©

        Args:
            deliverable: äº¤ä»˜ç‰©å­—å…¸
            index: åºå·ï¼ˆå¯é€‰ï¼‰
        """
        parts = []

        # äº¤ä»˜ç‰©åç§°ï¼ˆä½œä¸ºæ ‡é¢˜ï¼‰
        name = deliverable.get("deliverable_name", deliverable.get("name", ""))
        if name:
            if index:
                parts.append(f"<strong>{index}. {name}</strong>")
            else:
                parts.append(f"<strong>{name}</strong>")

        # å®ŒæˆçŠ¶æ€
        status = deliverable.get("completion_status", "")
        if status:
            status_label = self.translate_label(status)
            parts.append(f"<em>çŠ¶æ€: {status_label}</em>")

        # å†…å®¹ï¼ˆæœ€é‡è¦ï¼Œéœ€è¦ä»”ç»†å¤„ç†æ¢è¡Œï¼‰
        content = deliverable.get("content", "")
        if content:
            # å¤„ç†æ¢è¡Œç¬¦
            content = self._normalize_newlines(str(content))
            # æ¸…ç† JSON ç¬¦å·
            content = self._clean_json_artifacts(content)
            # ç¿»è¯‘
            content = self._translate_all_english(content)
            # è½¬æ¢æ¢è¡Œä¸º HTML
            content = content.replace("\n\n", "<br><br>")
            content = content.replace("\n", "<br>")
            parts.append(content)

        # è´¨é‡è‡ªè¯„
        quality = deliverable.get("quality_self_assessment", "")
        if quality:
            parts.append(f"<br><em>è´¨é‡è‡ªè¯„: {quality}</em>")

        return "<br>".join(parts)

    def parse_expert_content(self, expert_data: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æä¸“å®¶æ•°æ®ï¼Œè½¬æ¢ä¸ºæ¨¡æ¿æ‰€éœ€æ ¼å¼

        Args:
            expert_data: ä¸“å®¶åŸå§‹æ•°æ®

        Returns:
            æ ¼å¼åŒ–åçš„ä¸“å®¶æ•°æ®ï¼ŒåŒ…å« sections åˆ—è¡¨
        """
        expert_name = expert_data.get("expert_name", expert_data.get("name", "ä¸“å®¶"))
        expert_role = expert_data.get("role", expert_data.get("expert_role", ""))
        content = expert_data.get("content", expert_data.get("analysis", {}))

        sections = []

        if isinstance(content, str):
            # çº¯æ–‡æœ¬å†…å®¹
            translated = self.translate_content(content)
            sections.append({"title": "åˆ†æå†…å®¹", "type": "text", "content": self._simple_markdown(translated)})
        elif isinstance(content, dict):
            # å­—å…¸å†…å®¹ï¼ŒæŒ‰å­—æ®µå¤„ç†
            for key, value in content.items():
                section = self._parse_field(key, value)
                if section:
                    sections.append(section)
        elif isinstance(content, list):
            # åˆ—è¡¨å†…å®¹
            sections.append(
                {"title": "åˆ†æè¦ç‚¹", "type": "list", "list_items": [self.translate_content(str(item)) for item in content]}
            )

        return {"name": expert_name, "role": expert_role, "sections": sections}

    def _parse_field(self, key: str, value: Any) -> Optional[Dict[str, Any]]:
        """è§£æå•ä¸ªå­—æ®µ

        Args:
            key: å­—æ®µå
            value: å­—æ®µå€¼

        Returns:
            è§£æåçš„ section æ•°æ®
        """
        if value is None or value == "" or value == []:
            return None

        # è·³è¿‡ç½®ä¿¡åº¦å­—æ®µ
        key_lower = key.lower()
        if key_lower in ("confidence", "ç½®ä¿¡åº¦", "conf"):
            return None

        title = self.translate_label(key)

        # ğŸ”¥ v7.1: ç‰¹æ®Šå¤„ç† deliverable_outputsï¼ˆäº¤ä»˜ç‰©è¾“å‡ºï¼‰
        if key_lower in ("deliverable_outputs", "deliverable_answers"):
            return self._parse_deliverable_outputs(title, value)

        if isinstance(value, str):
            # å°è¯•è§£æå­—ç¬¦ä¸²ä¸­çš„å­—å…¸æ ¼å¼
            parsed_dict = self._try_parse_dict_string(value)
            if parsed_dict:
                # æˆåŠŸè§£æä¸ºå­—å…¸ï¼Œé€’å½’å¤„ç†
                # å¦‚æœåªæœ‰ä¸€ä¸ªé”®ä¸”æ˜¯ q1_xxx æ ¼å¼ï¼Œç›´æ¥å±•å¼€ä¸ºé—®ç­”æ ¼å¼
                if len(parsed_dict) == 1:
                    single_key = list(parsed_dict.keys())[0]
                    single_value = parsed_dict[single_key]
                    # å¯¹äºå•ä¸ª q_xxx æ ¼å¼çš„é—®é¢˜ï¼Œæå–çº¯é—®é¢˜å†…å®¹
                    q_match = re.match(r"^[qQ](\d+)[_\s]*(.*)$", single_key)
                    if q_match:
                        q_content = q_match.group(2)
                        if q_content:
                            # å°†ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼
                            q_content = q_content.replace("_", " ").strip()
                            q_label = q_content
                        else:
                            q_label = self.translate_label(single_key)
                    else:
                        q_label = self.translate_label(single_key)
                    q_value = self._clean_and_format_value(single_value)
                    # æ ¼å¼åŒ–ä¸ºé—®ç­”
                    return {
                        "title": title,
                        "type": "qa",
                        "question": q_label.replace(": ", "").rstrip(":"),
                        "answer": q_value,
                    }

                fields = []
                for k, v in parsed_dict.items():
                    # è·³è¿‡ confidence å­—æ®µ
                    if k.lower() in ("confidence", "ç½®ä¿¡åº¦", "conf"):
                        continue
                    label = self.translate_label(k)
                    if isinstance(v, dict):
                        # åµŒå¥—å­—å…¸ï¼Œç»§ç»­å±•å¼€ï¼Œä¹Ÿè¦è·³è¿‡ confidence
                        nested_fields = []
                        for nk, nv in v.items():
                            if nk.lower() in ("confidence", "ç½®ä¿¡åº¦", "conf"):
                                continue
                            nested_fields.append(
                                {"label": self.translate_label(nk), "value": self._clean_and_format_value(nv)}
                            )
                        if nested_fields:
                            fields.append({"label": label, "value": "", "nested": nested_fields})
                    else:
                        fields.append({"label": label, "value": self._clean_and_format_value(v)})
                if fields:
                    return {"title": title, "type": "fields", "fields": fields}

            translated = self.translate_content(value)
            # æ¸…ç†å¯èƒ½æ®‹ç•™çš„JSONç¬¦å·
            translated = self._clean_json_artifacts(translated)

            # æ£€æµ‹æ˜¯å¦ä¸ºç¼–å·åˆ—è¡¨
            if re.search(r"\d+[\.ã€\)ï¼‰]\s*\S", translated):
                items = self.format_numbered_list(translated)
                if len(items) > 1:
                    return {"title": title, "type": "numbered_list", "list_items": items}

            # æ™®é€šæ–‡æœ¬
            return {"title": title, "type": "text", "content": self._simple_markdown(translated)}

        elif isinstance(value, list):
            if all(isinstance(item, str) for item in value):
                # å­—ç¬¦ä¸²åˆ—è¡¨ - ä½¿ç”¨åºå·åˆ—è¡¨
                cleaned_items = [self._clean_json_artifacts(self.translate_content(item)) for item in value if item]
                return {"title": title, "type": "numbered_list", "list_items": cleaned_items}
            elif all(isinstance(item, dict) for item in value):
                # å¯¹è±¡åˆ—è¡¨ï¼Œæ ¼å¼åŒ–ä¸ºç»“æ„åŒ–å†…å®¹ï¼ˆåŠ ç²—æ ‡ç­¾ï¼Œä¸åŠ åºå·ï¼‰
                if len(value) > 0:
                    # å°†å¯¹è±¡åˆ—è¡¨è½¬ä¸ºæ ¼å¼åŒ–çš„å­—æ®µæ˜¾ç¤º
                    formatted_content = self._format_object_list(value)
                    return {"title": title, "type": "text", "content": formatted_content}
            else:
                # æ··åˆåˆ—è¡¨
                cleaned_items = [
                    self._clean_json_artifacts(self.translate_content(str(item))) for item in value if item
                ]
                return {"title": title, "type": "numbered_list", "list_items": cleaned_items}

        elif isinstance(value, dict):
            # åµŒå¥—å­—å…¸ï¼Œå±•å¼€ä¸ºå­—æ®µç»„
            fields = []
            for k, v in value.items():
                # è·³è¿‡ confidence å­—æ®µ
                if k.lower() in ("confidence", "ç½®ä¿¡åº¦", "conf"):
                    continue
                if v is not None and v != "":
                    fields.append(
                        {
                            "label": self.translate_label(k),
                            "value": self._simple_markdown(self.translate_content(str(v))),
                        }
                    )
            if fields:
                return {"title": title, "type": "fields", "fields": fields}

        else:
            # å…¶ä»–ç±»å‹
            return {"title": title, "type": "text", "content": str(value)}

        return None

    def render_html(
        self,
        experts: List[Dict[str, Any]],
        title: str = "ä¸“å®¶åˆ†ææŠ¥å‘Š",
        subtitle: Optional[str] = None,
        session_id: Optional[str] = None,
        template_name: str = "expert_report.html",
    ) -> str:
        """æ¸²æŸ“ HTML å†…å®¹

        Args:
            experts: ä¸“å®¶æ•°æ®åˆ—è¡¨
            title: æŠ¥å‘Šæ ‡é¢˜
            subtitle: å‰¯æ ‡é¢˜
            session_id: ä¼šè¯ ID
            template_name: æ¨¡æ¿æ–‡ä»¶å

        Returns:
            æ¸²æŸ“åçš„ HTML å­—ç¬¦ä¸²
        """
        # è§£æä¸“å®¶æ•°æ®
        parsed_experts = [self.parse_expert_content(exp) for exp in experts]

        # æ¸²æŸ“æ¨¡æ¿
        template = self.env.get_template(template_name)
        html = template.render(
            title=title,
            subtitle=subtitle,
            session_id=session_id,
            generated_time=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M"),
            experts=parsed_experts,
        )

        return html

    async def generate_pdf_async(
        self,
        experts: List[Dict[str, Any]],
        output_path: Optional[str] = None,
        title: str = "ä¸“å®¶åˆ†ææŠ¥å‘Š",
        subtitle: Optional[str] = None,
        session_id: Optional[str] = None,
        **pdf_options,
    ) -> bytes:
        """å¼‚æ­¥ç”Ÿæˆ PDF

        ğŸ†• P1ä¿®å¤: æ·»åŠ Playwrightå¯ç”¨æ€§æ£€æŸ¥ä¸é™çº§ç­–ç•¥

        Args:
            experts: ä¸“å®¶æ•°æ®åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            title: æŠ¥å‘Šæ ‡é¢˜
            subtitle: å‰¯æ ‡é¢˜
            session_id: ä¼šè¯ ID
            **pdf_options: ä¼ é€’ç»™ Playwright PDF æ–¹æ³•çš„å‚æ•°

        Returns:
            PDF å­—èŠ‚æ•°æ®

        Raises:
            RuntimeError: Playwrightä¸å¯ç”¨ä¸”æ— é™çº§é€‰é¡¹
        """
        import time

        start_time = time.time()

        # æ¸²æŸ“ HTML
        html = self.render_html(experts, title, subtitle, session_id)
        html_time = time.time()
        logger.debug(f"ğŸ“„ HTML æ¸²æŸ“è€—æ—¶: {html_time - start_time:.2f}s")

        # ğŸ†• P1ä¿®å¤: æ£€æŸ¥æµè§ˆå™¨æ± å¥åº·çŠ¶æ€
        browser_pool = get_browser_pool()

        try:
            browser = await asyncio.wait_for(browser_pool.get_browser(), timeout=15.0)

            # ğŸ†• P1ä¿®å¤: äºŒæ¬¡éªŒè¯æµè§ˆå™¨è¿æ¥
            if browser is None or not browser.is_connected():
                raise RuntimeError("æµè§ˆå™¨æœªåˆå§‹åŒ–æˆ–è¿æ¥å·²æ–­å¼€")

        except (asyncio.TimeoutError, RuntimeError, Exception) as browser_error:
            logger.error(f"âŒ è·å–Playwrightæµè§ˆå™¨å¤±è´¥: {browser_error}")
            logger.warning("âš ï¸ æ­£åœ¨å°è¯•é™çº§ç­–ç•¥ï¼šè¿”å›HTMLå†…å®¹")

            # ğŸ†• P1ä¿®å¤: é™çº§åˆ°HTML
            # è¿”å›HTMLå­—èŠ‚ï¼ˆå‰ç«¯å¯æ£€æµ‹Content-Typeå¹¶æ˜¾ç¤ºæç¤ºï¼‰
            logger.info("ğŸ“„ ä½¿ç”¨HTMLé™çº§æ¨¡å¼ä»£æ›¿PDF")
            return html.encode("utf-8")

        browser_time = time.time()
        logger.debug(f"ğŸŒ è·å–æµè§ˆå™¨è€—æ—¶: {browser_time - html_time:.2f}s")

        # åˆ›å»ºæ–°çš„ context å’Œ pageï¼ˆcontext æ¯” browser è½»é‡å¾ˆå¤šï¼‰
        context = await browser.new_context()
        page = await context.new_page()

        try:
            # ğŸ”¥ v7.1.2: ä¼˜åŒ–ç­‰å¾…ç­–ç•¥
            # ä½¿ç”¨ domcontentloaded è€Œé networkidle
            # å› ä¸º HTML ä½¿ç”¨å†…åµŒæ ·å¼ï¼Œæ— éœ€ç­‰å¾…å¤–éƒ¨èµ„æº
            await page.set_content(html, wait_until="domcontentloaded")
            content_time = time.time()
            logger.debug(f"ğŸ“ è®¾ç½®å†…å®¹è€—æ—¶: {content_time - browser_time:.2f}s")

            # PDF é»˜è®¤é€‰é¡¹
            default_options = {
                "format": "A4",
                "print_background": True,
                "margin": {"top": "20mm", "bottom": "25mm", "left": "15mm", "right": "15mm"},
                "display_header_footer": True,
                "header_template": "<div></div>",
                "footer_template": """
                    <div style="width: 100%; font-size: 9pt; color: #666; text-align: center; padding: 10px;">
                        <span class="pageNumber"></span> / <span class="totalPages"></span>
                    </div>
                """,
            }
            default_options.update(pdf_options)

            # ç”Ÿæˆ PDF
            if output_path:
                default_options["path"] = output_path

            pdf_bytes = await page.pdf(**default_options)
            pdf_time = time.time()
            logger.debug(f"ğŸ“‘ PDF ç”Ÿæˆè€—æ—¶: {pdf_time - content_time:.2f}s")

        finally:
            # ğŸ”¥ åªå…³é—­ contextï¼Œä¸å…³é—­ browserï¼ˆå¤ç”¨ï¼‰
            await context.close()

        total_time = time.time() - start_time
        logger.info(f"âœ… PDF ç”Ÿæˆå®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}s")

        return pdf_bytes

    async def generate_pdf_async_legacy(
        self,
        experts: List[Dict[str, Any]],
        output_path: Optional[str] = None,
        title: str = "ä¸“å®¶åˆ†ææŠ¥å‘Š",
        subtitle: Optional[str] = None,
        session_id: Optional[str] = None,
        **pdf_options,
    ) -> bytes:
        """
        [åºŸå¼ƒ] å¼‚æ­¥ç”Ÿæˆ PDFï¼ˆæ—§ç‰ˆæœ¬ï¼Œæ¯æ¬¡å¯åŠ¨æ–°æµè§ˆå™¨ï¼‰

        ä¿ç•™æ­¤æ–¹æ³•ä½œä¸ºå¤‡ç”¨ï¼Œå¦‚æœæµè§ˆå™¨æ± å‡ºé—®é¢˜å¯ä»¥å›é€€
        """
        html = self.render_html(experts, title, subtitle, session_id)

        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            await page.set_content(html, wait_until="networkidle")

            default_options = {
                "format": "A4",
                "print_background": True,
                "margin": {"top": "20mm", "bottom": "25mm", "left": "15mm", "right": "15mm"},
            }
            default_options.update(pdf_options)

            if output_path:
                default_options["path"] = output_path

            pdf_bytes = await page.pdf(**default_options)
            await browser.close()

        return pdf_bytes

    def generate_pdf(
        self,
        experts: List[Dict[str, Any]],
        output_path: Optional[str] = None,
        title: str = "ä¸“å®¶åˆ†ææŠ¥å‘Š",
        subtitle: Optional[str] = None,
        session_id: Optional[str] = None,
        **pdf_options,
    ) -> bytes:
        """åŒæ­¥ç”Ÿæˆ PDF

        Args:
            experts: ä¸“å®¶æ•°æ®åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            title: æŠ¥å‘Šæ ‡é¢˜
            subtitle: å‰¯æ ‡é¢˜
            session_id: ä¼šè¯ ID
            **pdf_options: ä¼ é€’ç»™ Playwright PDF æ–¹æ³•çš„å‚æ•°

        Returns:
            PDF å­—èŠ‚æ•°æ®
        """
        # æ£€æŸ¥æ˜¯å¦åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯ä¸­
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None

        if loop is not None:
            # åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨ nest_asyncio æˆ–æ–°çº¿ç¨‹
            import concurrent.futures

            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    asyncio.run,
                    self.generate_pdf_async(experts, output_path, title, subtitle, session_id, **pdf_options),
                )
                return future.result()
        else:
            # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥è¿è¡Œ
            return asyncio.run(
                self.generate_pdf_async(experts, output_path, title, subtitle, session_id, **pdf_options)
            )


# ä¾¿æ·å‡½æ•°
def generate_expert_report_pdf(
    experts: List[Dict[str, Any]],
    title: str = "ä¸“å®¶åˆ†ææŠ¥å‘Š",
    subtitle: Optional[str] = None,
    session_id: Optional[str] = None,
    output_path: Optional[str] = None,
) -> bytes:
    """ç”Ÿæˆä¸“å®¶æŠ¥å‘Š PDF çš„ä¾¿æ·å‡½æ•°

    Args:
        experts: ä¸“å®¶æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªä¸“å®¶åŒ…å«:
            - expert_name/name: ä¸“å®¶åç§°
            - role/expert_role: ä¸“å®¶è§’è‰²ï¼ˆå¯é€‰ï¼‰
            - content/analysis: åˆ†æå†…å®¹ï¼ˆå­—ç¬¦ä¸²/å­—å…¸/åˆ—è¡¨ï¼‰
        title: æŠ¥å‘Šæ ‡é¢˜
        subtitle: å‰¯æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
        session_id: ä¼šè¯ IDï¼ˆå¯é€‰ï¼‰
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰

    Returns:
        PDF å­—èŠ‚æ•°æ®
    """
    generator = HTMLPDFGenerator()
    return generator.generate_pdf(
        experts=experts, title=title, subtitle=subtitle, session_id=session_id, output_path=output_path
    )


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    test_experts = [
        {
            "expert_name": "ç”¨æˆ·ç ”ç©¶ä¸“å®¶",
            "role": "è´Ÿè´£ç”¨æˆ·éœ€æ±‚åˆ†æå’Œç”¨æˆ·ç”»åƒæ„å»º",
            "content": {
                "persona": "ç›®æ ‡ç”¨æˆ·ä¸º25-35å²çš„éƒ½å¸‚ç™½é¢†ï¼Œæ³¨é‡ç”Ÿæ´»å“è´¨ï¼Œè¿½æ±‚ä¾¿æ·é«˜æ•ˆã€‚",
                "pain_points": ["ç°æœ‰æ–¹æ¡ˆæµç¨‹ç¹çï¼Œç”¨æˆ·ä½“éªŒå·®", "ç¼ºä¹ä¸ªæ€§åŒ–æ¨è", "ä»·æ ¼ä¸é€æ˜"],
                "how_might_we": "æˆ‘ä»¬å¦‚ä½•èƒ½å¤Ÿç®€åŒ–ç”¨æˆ·æ“ä½œæµç¨‹ï¼ŒåŒæ—¶æä¾›ä¸ªæ€§åŒ–çš„æœåŠ¡ä½“éªŒï¼Ÿ",
                "recommendations": "1. ä¼˜åŒ–æ³¨å†Œæµç¨‹ 2. å¢åŠ æ™ºèƒ½æ¨è 3. å®ç°ä»·æ ¼é€æ˜åŒ–",
            },
        },
        {
            "expert_name": "æŠ€æœ¯æ¶æ„ä¸“å®¶",
            "role": "è´Ÿè´£ç³»ç»Ÿæ¶æ„è®¾è®¡å’ŒæŠ€æœ¯é€‰å‹",
            "content": {
                "architecture": "é‡‡ç”¨å¾®æœåŠ¡æ¶æ„ï¼Œå‰åç«¯åˆ†ç¦»ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•ã€‚",
                "tech_stack": {
                    "frontend": "React + TypeScript",
                    "backend": "Python FastAPI",
                    "database": "PostgreSQL + Redis",
                    "deployment": "Docker + Kubernetes",
                },
                "performance": "ç³»ç»Ÿæ”¯æŒ 10000 QPSï¼Œå¹³å‡å“åº”æ—¶é—´ < 100msã€‚",
            },
        },
    ]

    # ç”Ÿæˆæµ‹è¯• PDF
    pdf_bytes = generate_expert_report_pdf(
        experts=test_experts,
        title="é¡¹ç›®åˆ†ææŠ¥å‘Š",
        subtitle="æ™ºèƒ½é¡¹ç›®åˆ†æç³»ç»Ÿ",
        session_id="test-001",
        output_path="test_html_pdf.pdf",
    )

    print(f"PDF ç”ŸæˆæˆåŠŸï¼Œå¤§å°: {len(pdf_bytes)} bytes")
