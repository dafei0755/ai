"""
æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶ - è®°å½• API å“åº”æ—¶é—´å’Œæ€§èƒ½æŒ‡æ ‡

åŠŸèƒ½ï¼š
1. è®°å½•æ¯ä¸ªè¯·æ±‚çš„å“åº”æ—¶é—´
2. è®°å½•æ…¢è¯·æ±‚ï¼ˆ>1ç§’ï¼‰
3. ç»Ÿè®¡ API è°ƒç”¨æ¬¡æ•°
4. æ€§èƒ½æŒ‡æ ‡å¯¼å‡º
"""

import time
import asyncio
from typing import Callable
from fastapi import Request, Response
from loguru import logger
import json
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import threading


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§ç®¡ç†å™¨"""
    
    def __init__(self):
        self.metrics = defaultdict(list)
        self.lock = threading.Lock()
        self.slow_request_threshold = 1.0  # ç§’
        self.metrics_file = Path(__file__).parent.parent.parent / "logs" / "performance_metrics.jsonl"
        self.metrics_file.parent.mkdir(exist_ok=True)
        
    def record_request(self, path: str, method: str, duration: float, status_code: int):
        """è®°å½•è¯·æ±‚æ€§èƒ½"""
        with self.lock:
            self.metrics[path].append({
                "method": method,
                "duration": duration,
                "status_code": status_code,
                "timestamp": datetime.now().isoformat()
            })
            
            # æ…¢è¯·æ±‚è­¦å‘Š
            if duration > self.slow_request_threshold:
                logger.warning(f"ğŸŒ æ…¢è¯·æ±‚æ£€æµ‹: {method} {path} è€—æ—¶ {duration:.2f}ç§’")
            
            # å†™å…¥æŒä¹…åŒ–æ—¥å¿—
            self._write_metric(path, method, duration, status_code)
    
    def _write_metric(self, path: str, method: str, duration: float, status_code: int):
        """å†™å…¥æ€§èƒ½æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        # ğŸ”¥ v7.105: æ·»åŠ æ–‡ä»¶é”å®šä¿æŠ¤ï¼Œé¿å…Permission deniedé”™è¯¯
        try:
            metric = {
                "timestamp": datetime.now().isoformat(),
                "path": path,
                "method": method,
                "duration": round(duration, 3),
                "status_code": status_code
            }
            
            # å°è¯•å†™å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™é™é»˜å¿½ç•¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰
            try:
                with open(self.metrics_file, "a", encoding="utf-8") as f:
                    f.write(json.dumps(metric, ensure_ascii=False) + "\n")
            except (PermissionError, OSError) as file_error:
                # æ–‡ä»¶é”å®šæˆ–æƒé™é—®é¢˜ï¼Œé™é»˜å¿½ç•¥ï¼ˆæ¯10æ¬¡è®°å½•ä¸€æ¬¡è­¦å‘Šï¼‰
                if not hasattr(self, '_write_error_count'):
                    self._write_error_count = 0
                self._write_error_count += 1
                if self._write_error_count % 10 == 1:
                    logger.debug(f"âš ï¸ æ€§èƒ½æŒ‡æ ‡å†™å…¥è·³è¿‡ (æ–‡ä»¶è¢«å ç”¨ï¼Œå·²è·³è¿‡{self._write_error_count}æ¬¡)")
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ä¹Ÿä¸å½±å“ä¸»æµç¨‹
            pass
    
    def get_stats(self, path: str = None):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        with self.lock:
            if path:
                metrics = self.metrics.get(path, [])
            else:
                metrics = [m for ms in self.metrics.values() for m in ms]
            
            if not metrics:
                return {}
            
            durations = [m["duration"] for m in metrics]
            return {
                "count": len(metrics),
                "avg_duration": sum(durations) / len(durations),
                "max_duration": max(durations),
                "min_duration": min(durations),
                "slow_requests": len([d for d in durations if d > self.slow_request_threshold])
            }


# å…¨å±€æ€§èƒ½ç›‘æ§å®ä¾‹
performance_monitor = PerformanceMonitor()


async def performance_monitoring_middleware(request: Request, call_next: Callable):
    """
    æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶
    
    è®°å½•æ‰€æœ‰ API è¯·æ±‚çš„å“åº”æ—¶é—´
    """
    # è·³è¿‡é™æ€æ–‡ä»¶å’Œ WebSocket
    if request.url.path.startswith("/static") or request.url.path.startswith("/ws"):
        return await call_next(request)
    
    start_time = time.time()
    
    try:
        response = await call_next(request)
        duration = time.time() - start_time
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        performance_monitor.record_request(
            path=request.url.path,
            method=request.method,
            duration=duration,
            status_code=response.status_code
        )
        
        # æ·»åŠ æ€§èƒ½å“åº”å¤´
        response.headers["X-Response-Time"] = f"{duration:.3f}s"
        
        # æ­£å¸¸è¯·æ±‚è®°å½•ï¼ˆINFO çº§åˆ«ï¼‰
        if duration < 0.5:
            logger.info(f"âš¡ {request.method} {request.url.path} - {response.status_code} - {duration:.3f}s")
        elif duration < 1.0:
            logger.info(f"ğŸ”¶ {request.method} {request.url.path} - {response.status_code} - {duration:.3f}s")
        else:
            logger.warning(f"ğŸŒ {request.method} {request.url.path} - {response.status_code} - {duration:.3f}s")
        
        return response
        
    except Exception as e:
        duration = time.time() - start_time
        logger.error(f"âŒ {request.method} {request.url.path} - ERROR - {duration:.3f}s - {str(e)}")
        
        # è®°å½•å¤±è´¥è¯·æ±‚
        performance_monitor.record_request(
            path=request.url.path,
            method=request.method,
            duration=duration,
            status_code=500
        )
        
        raise


class LLMPerformanceTracker:
    """LLM è°ƒç”¨æ€§èƒ½è¿½è¸ªå™¨"""
    
    def __init__(self):
        self.llm_metrics_file = Path(__file__).parent.parent.parent / "logs" / "llm_metrics.jsonl"
        self.llm_metrics_file.parent.mkdir(exist_ok=True)
    
    def record_llm_call(self, model: str, operation: str, duration: float, tokens: int = 0, success: bool = True):
        """è®°å½• LLM è°ƒç”¨æ€§èƒ½"""
        try:
            metric = {
                "timestamp": datetime.now().isoformat(),
                "model": model,
                "operation": operation,
                "duration": round(duration, 3),
                "tokens": tokens,
                "success": success
            }
            
            with open(self.llm_metrics_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(metric, ensure_ascii=False) + "\n")
            
            # è®°å½•æ…¢ LLM è°ƒç”¨
            if duration > 5.0:
                logger.warning(f"ğŸŒ LLM æ…¢è°ƒç”¨: {model} - {operation} - {duration:.2f}ç§’")
            else:
                logger.debug(f"ğŸ¤– LLM è°ƒç”¨: {model} - {operation} - {duration:.2f}ç§’ - {tokens} tokens")
                
        except Exception as e:
            logger.error(f"âŒ è®°å½• LLM æ€§èƒ½å¤±è´¥: {e}")


# å…¨å±€ LLM æ€§èƒ½è¿½è¸ªå™¨
llm_tracker = LLMPerformanceTracker()
