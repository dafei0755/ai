# -*- coding: utf-8 -*-
"""
FastAPI åç«¯æœåŠ¡å™¨

æä¾› RESTful API æ¥å£ï¼Œæ”¯æŒå‰åç«¯åˆ†ç¦»æ¶æ„
"""

import asyncio
import io
import json
import math  # ğŸ”¥ v7.109: ç”¨äºåˆ†é¡µè¯Šæ–­æ—¥å¿—
import os
import re
import sys
import uuid
from collections import OrderedDict, defaultdict
from contextlib import asynccontextmanager
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

# è®¾ç½®è¾“å‡ºç¼–ç ä¸º UTF-8
if sys.platform == "win32":
    # Do NOT replace sys.stdout/sys.stderr with new TextIOWrapper objects at import time.
    # Doing so can close the underlying stream later (pytest/colorama/loggers then crash with
    # "ValueError: I/O operation on closed file"). Prefer reconfigure when available.
    for _stream in (getattr(sys, "stdout", None), getattr(sys, "stderr", None)):
        if _stream is None:
            continue
        if hasattr(_stream, "reconfigure"):
            try:
                _stream.reconfigure(encoding="utf-8", errors="replace")
            except Exception:
                pass

import time
from functools import wraps

from fastapi import (
    BackgroundTasks,
    Body,
    Depends,
    FastAPI,
    File,
    Form,
    HTTPException,
    Query,
    Request,
    UploadFile,
    WebSocket,
    WebSocketDisconnect,
)
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response, StreamingResponse
from fastapi.staticfiles import StaticFiles
from loguru import logger
from pydantic import AliasChoices, BaseModel, ConfigDict, Field

# ğŸ”¥ v7.120: åˆå§‹åŒ–ç”Ÿäº§çº§æ—¥å¿—ç³»ç»Ÿï¼ˆç¯å¢ƒæ„ŸçŸ¥é…ç½®ï¼‰
from intelligent_project_analyzer.config.logging_config import setup_logging

# ğŸŒ å¯¼å…¥GeoIPæœåŠ¡ï¼ˆIPåœ°ç†ä½ç½®è¯†åˆ«ï¼‰
from intelligent_project_analyzer.services.geoip_service import get_geoip_service

# ğŸ”¥ v7.60.4: å¯¼å…¥ ImageAspectRatio æšä¸¾ç”¨äºç±»å‹è½¬æ¢
from intelligent_project_analyzer.services.image_generator import ImageAspectRatio

setup_logging()

# æ—¥å¿—æ–‡ä»¶è¾“å‡ºé…ç½®ï¼Œç¡®ä¿ä¸»æµç¨‹æ—¥å¿—å®Œæ•´å†™å…¥ logs/server.log
log_dir = Path(__file__).parent.parent.parent / "logs"
log_dir.mkdir(exist_ok=True)

# ä¸»æ—¥å¿—æ–‡ä»¶ï¼ˆæ‰€æœ‰çº§åˆ«ï¼‰- å¯ç”¨å‹ç¼©
logger.add(
    str(log_dir / "server.log"),
    rotation="10 MB",
    retention="10 days",
    encoding="utf-8",
    enqueue=True,
    backtrace=True,
    diagnose=True,
    compression="zip",  # ğŸ†• è½®è½¬æ—¶è‡ªåŠ¨å‹ç¼©ä¸º .zip æ–‡ä»¶
    level="INFO",
)

# è®¤è¯ç›¸å…³æ—¥å¿—ï¼ˆæ–¹ä¾¿ SSO è°ƒè¯•ï¼‰- å¯ç”¨å‹ç¼©
logger.add(
    str(log_dir / "auth.log"),
    rotation="5 MB",
    retention="7 days",
    encoding="utf-8",
    enqueue=True,
    compression="zip",  # ğŸ†• è‡ªåŠ¨å‹ç¼©
    filter=lambda record: "auth" in record["name"].lower()
    or "sso" in record["message"].lower()
    or "token" in record["message"].lower(),
    level="DEBUG",
)

# é”™è¯¯æ—¥å¿—ï¼ˆåªè®°å½• ERROR åŠä»¥ä¸Šï¼‰- å¯ç”¨å‹ç¼©
logger.add(
    str(log_dir / "errors.log"),
    rotation="5 MB",
    retention="30 days",
    encoding="utf-8",
    enqueue=True,
    compression="zip",  # ğŸ†• è‡ªåŠ¨å‹ç¼©
    level="ERROR",
)

# ğŸ†• å¯ç”¨å‘Šè­¦ç›‘æ§ï¼ˆæ‹¦æˆªé”™è¯¯æ—¥å¿—ï¼‰
from intelligent_project_analyzer.api.alert_monitor import alert_monitor, alert_sink

logger.add(alert_sink, level="ERROR")
from typing import List

from fpdf import FPDF


# ğŸ”¥ v7.60.4: è¾…åŠ©å‡½æ•° - å°†å‰ç«¯ä¼ é€’çš„å­—ç¬¦ä¸²å®½é«˜æ¯”è½¬æ¢ä¸º ImageAspectRatio æšä¸¾
def _parse_aspect_ratio(ratio_str: str = None) -> ImageAspectRatio:
    """å°†å‰ç«¯ä¼ é€’çš„å­—ç¬¦ä¸²å®½é«˜æ¯”è½¬æ¢ä¸º ImageAspectRatio æšä¸¾

    Args:
        ratio_str: å®½é«˜æ¯”å­—ç¬¦ä¸²ï¼Œå¦‚ "16:9", "1:1" ç­‰

    Returns:
        ImageAspectRatio æšä¸¾å€¼ï¼Œé»˜è®¤ä¸º LANDSCAPE
    """
    if not ratio_str:
        return ImageAspectRatio.LANDSCAPE

    mapping = {
        "1:1": ImageAspectRatio.SQUARE,
        "16:9": ImageAspectRatio.LANDSCAPE,
        "9:16": ImageAspectRatio.PORTRAIT,
        "4:3": ImageAspectRatio.WIDE,
        "21:9": ImageAspectRatio.ULTRAWIDE,
    }
    return mapping.get(ratio_str, ImageAspectRatio.LANDSCAPE)


# HTML PDF ç”Ÿæˆå™¨
from intelligent_project_analyzer.api.html_pdf_generator import HTMLPDFGenerator
from intelligent_project_analyzer.api.html_pdf_generator import generate_expert_report_pdf as generate_html_pdf

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from langgraph.types import Command, Interrupt

# âœ… v3.8æ–°å¢: å¯¹è¯æ™ºèƒ½ä½“
from intelligent_project_analyzer.agents.conversation_agent import ConversationAgent, ConversationContext

# ğŸ”¥ v7.15æ–°å¢: è¿½é—®æ™ºèƒ½ä½“ (LangGraph)
from intelligent_project_analyzer.agents.followup_agent import FollowupAgent
from intelligent_project_analyzer.core.state import StateManager

# âœ… v3.7æ–°å¢: æ–‡ä»¶å¤„ç†æœåŠ¡
from intelligent_project_analyzer.services.file_processor import build_combined_input, file_processor

# âœ… v3.11æ–°å¢: è¿½é—®å†å²ç®¡ç†å™¨
from intelligent_project_analyzer.services.followup_history_manager import FollowupHistoryManager

# âœ… Redis ä¼šè¯ç®¡ç†å™¨
from intelligent_project_analyzer.services.redis_session_manager import RedisSessionManager

# âœ… v3.6æ–°å¢: ä¼šè¯å½’æ¡£ç®¡ç†å™¨
from intelligent_project_analyzer.services.session_archive_manager import SessionArchiveManager

# âœ… v7.10æ–°å¢: WordPress JWT è®¤è¯æœåŠ¡
from intelligent_project_analyzer.services.wordpress_jwt_service import WordPressJWTService

# âœ… ä½¿ç”¨æ–°çš„ç»Ÿä¸€é…ç½® - ä¸å†éœ€è¦load_dotenv()
from intelligent_project_analyzer.settings import settings
from intelligent_project_analyzer.workflow.main_workflow import MainWorkflow

# åˆå§‹åŒ– JWT æœåŠ¡
jwt_service = WordPressJWTService()


# ğŸ”¥ v7.120 P1ä¼˜åŒ–: TTLç¼“å­˜å·¥å…·ç±»ï¼ˆç”¨äºä¼šè¯åˆ—è¡¨ç¼“å­˜ 4.09sâ†’0.05sï¼‰
class TTLCache:
    """ç®€å•çš„å¸¦TTLçš„å¼‚æ­¥ç¼“å­˜ï¼ˆå†…å­˜çº§åˆ«ï¼‰"""

    def __init__(self, ttl_seconds: int = 5):
        self._cache = {}
        self._timestamps = {}
        self.ttl = ttl_seconds

    def get(self, key: str):
        if key in self._cache:
            age = time.time() - self._timestamps[key]
            if age < self.ttl:
                return self._cache[key]
            else:
                del self._cache[key]
                del self._timestamps[key]
        return None

    def set(self, key: str, value: Any):
        self._cache[key] = value
        self._timestamps[key] = time.time()

    def invalidate(self, key: str = None):
        """ä½¿ç¼“å­˜å¤±æ•ˆ"""
        if key:
            self._cache.pop(key, None)
            self._timestamps.pop(key, None)
        else:
            self._cache.clear()
            self._timestamps.clear()


# å…¨å±€ä¼šè¯åˆ—è¡¨ç¼“å­˜ï¼ˆ5ç§’TTLï¼Œé€‚åˆé«˜é¢‘åˆ·æ–°åœºæ™¯ï¼‰
sessions_cache = TTLCache(ttl_seconds=5)

# âœ… v7.35: å¼€å‘æ¨¡å¼æ£€æµ‹
# å…¼å®¹ï¼šæ˜¾å¼ DEV_MODE=true æˆ– ENVIRONMENT=devï¼ˆå•æµ‹/æœ¬åœ°å¼€å‘å¸¸ç”¨ï¼‰
DEV_MODE = (
    os.getenv("DEV_MODE", "false").lower() == "true"
    or os.getenv("ENVIRONMENT", "").lower() == "dev"
    or getattr(settings, "environment", None) == "dev"
)


# ğŸ”’ è®¤è¯ä¾èµ–å‡½æ•°
async def get_current_user(request: Request) -> dict:
    """
    FastAPI ä¾èµ–å‡½æ•°ï¼šä»è¯·æ±‚å¤´éªŒè¯ JWT Token å¹¶è¿”å›ç”¨æˆ·ä¿¡æ¯

    ç”¨äºä¿æŠ¤éœ€è¦è®¤è¯çš„ç«¯ç‚¹

    ğŸ”§ v7.35: æ”¯æŒå¼€å‘æ¨¡å¼ï¼Œæ¥å— "dev-token-mock" ä½œä¸ºæœ‰æ•ˆ Token
    """
    auth_header = request.headers.get("Authorization", "")
    # ğŸ”§ å¼€å‘/æµ‹è¯•ç¯å¢ƒï¼šå…è®¸ä¸å¸¦ Token ç›´æ¥è®¿é—®ï¼ˆä¾¿äºæœ¬åœ°è°ƒè¯•ä¸è‡ªåŠ¨åŒ–æµ‹è¯•ï¼‰
    # ç”Ÿäº§ç¯å¢ƒ DEV_MODE=False æ—¶ä¸ä¼šç”Ÿæ•ˆã€‚
    if DEV_MODE and (not auth_header or not auth_header.startswith("Bearer ")):
        logger.info("ğŸ”§ [DEV_MODE] æœªæä¾› Tokenï¼Œä½¿ç”¨å¼€å‘æµ‹è¯•ç”¨æˆ·")
        return {
            "user_id": 9999,
            "username": "dev_user",
            "email": "dev@localhost",
            "name": "å¼€å‘æµ‹è¯•ç”¨æˆ·",
            "roles": ["administrator"],
        }

    if not auth_header.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="ç¼ºå°‘è®¤è¯ Token")

    token = auth_header[7:]  # ç§»é™¤ "Bearer " å‰ç¼€

    # ğŸ”§ v7.35: å¼€å‘æ¨¡å¼æ”¯æŒ - æ¥å— mock token
    if DEV_MODE and token == "dev-token-mock":
        logger.info("ğŸ”§ [DEV_MODE] ä½¿ç”¨å¼€å‘æµ‹è¯•ç”¨æˆ·")
        return {
            "user_id": 9999,
            "username": "dev_user",
            "email": "dev@localhost",
            "name": "å¼€å‘æµ‹è¯•ç”¨æˆ·",
            "roles": ["administrator"],
        }

    payload = jwt_service.verify_jwt_token(token)

    if not payload:
        raise HTTPException(status_code=401, detail="Token æ— æ•ˆæˆ–å·²è¿‡æœŸ")

    return {
        "user_id": payload.get("user_id"),
        "username": payload.get("username"),
        "email": payload.get("email"),
        "name": payload.get("name"),
        "roles": payload.get("roles", []),
    }


# ğŸ†• v7.130: å¯é€‰è®¤è¯ä¾èµ–å‡½æ•°ï¼ˆTokenå­˜åœ¨åˆ™éªŒè¯ï¼Œä¸å­˜åœ¨ä¹Ÿå…è®¸è®¿é—®ï¼‰
async def optional_auth(request: Request) -> Optional[dict]:
    """
    å¯é€‰è®¤è¯ä¾èµ–å‡½æ•°ï¼šå¦‚æœæœ‰JWT Tokenåˆ™éªŒè¯ï¼Œæ²¡æœ‰ä¹Ÿä¸æŠ¥é”™

    ç”¨äºæ”¯æŒç™»å½•å’Œæœªç™»å½•ç”¨æˆ·éƒ½èƒ½è®¿é—®çš„ç«¯ç‚¹
    """
    auth_header = request.headers.get("Authorization", "")

    if not auth_header or not auth_header.startswith("Bearer "):
        return None  # æœªæä¾› Tokenï¼Œè¿”å› None

    token = auth_header[7:]

    # å¼€å‘æ¨¡å¼æ”¯æŒ
    if DEV_MODE and token == "dev-token-mock":
        return {
            "user_id": 9999,
            "username": "dev_user",
            "email": "dev@localhost",
            "name": "å¼€å‘æµ‹è¯•ç”¨æˆ·",
            "roles": ["administrator"],
        }

    payload = jwt_service.verify_jwt_token(token)

    if not payload:
        return None  # Tokenæ— æ•ˆï¼Œè¿”å›Noneè€Œä¸æ˜¯æŠ›å¼‚å¸¸

    # âš ï¸ å…¼å®¹ï¼šéƒ¨åˆ†JWTä½¿ç”¨æ ‡å‡†å­—æ®µ sub ä½œä¸ºç”¨æˆ·å/ä¸»ä½“
    # åœ¨æŸäº›SSOå®ç°é‡Œï¼Œusername å­—æ®µå¯èƒ½ä¸ºç©ºæˆ–ä¸ºå ä½å€¼ï¼ˆä¾‹å¦‚ apiï¼‰ï¼Œ
    # è¿™ä¼šå¯¼è‡´ä¼šè¯ç®¡ç†é¡µé¢æ˜¾ç¤ºé”™è¯¯çš„ç”¨æˆ·ã€‚è¿™é‡Œä¼˜å…ˆä½¿ç”¨ subã€‚
    resolved_username = payload.get("sub") or payload.get("username")

    return {
        "user_id": payload.get("user_id"),
        "username": resolved_username,
        "email": payload.get("email"),
        "name": payload.get("display_name") or payload.get("name"),
        "roles": payload.get("roles", []),
    }


# å…¨å±€å˜é‡å­˜å‚¨å·¥ä½œæµå®ä¾‹
workflows: Dict[str, MainWorkflow] = {}

# âœ… Redis ä¼šè¯ç®¡ç†å™¨å®ä¾‹ï¼ˆæ›¿ä»£å†…å­˜å­—å…¸ï¼‰
session_manager: Optional[RedisSessionManager] = None


async def _get_session_manager() -> RedisSessionManager:
    """è·å–ä¼šè¯ç®¡ç†å™¨ï¼ˆæ”¯æŒåœ¨æœªè§¦å‘ç”Ÿå‘½å‘¨æœŸäº‹ä»¶æ—¶æƒ°æ€§åˆå§‹åŒ–ï¼‰ã€‚

    è¯´æ˜ï¼šåœ¨ä½¿ç”¨ ASGITransport/æŸäº›æµ‹è¯•å®¢æˆ·ç«¯æ—¶ï¼ŒFastAPI lifespan å¯èƒ½ä¸ä¼šè‡ªåŠ¨è§¦å‘ï¼Œ
    å¯¼è‡´å…¨å±€ session_manager ä»ä¸º Noneã€‚è¿™é‡Œæä¾›ä¸€ä¸ªå®‰å…¨å…œåº•ã€‚
    """
    global session_manager
    if session_manager is None:
        session_manager = RedisSessionManager()
        # connect() å†…éƒ¨ä¼šåœ¨ Redis ä¸å¯ç”¨æ—¶å›é€€åˆ°å†…å­˜æ¨¡å¼ï¼ˆfallback_to_memory=Trueï¼‰ã€‚
        try:
            await session_manager.connect()
        except Exception as e:
            logger.warning(f"âš ï¸ session_manager æƒ°æ€§åˆå§‹åŒ–å¤±è´¥: {e}")
    return session_manager


# âœ… v3.6æ–°å¢: ä¼šè¯å½’æ¡£ç®¡ç†å™¨å®ä¾‹
archive_manager: Optional[SessionArchiveManager] = None

# âœ… v3.11æ–°å¢: è¿½é—®å†å²ç®¡ç†å™¨å®ä¾‹
followup_history_manager: Optional[FollowupHistoryManager] = None

# WebSocket è¿æ¥ç®¡ç†
websocket_connections: Dict[str, List[WebSocket]] = {}  # session_id -> [websocket1, websocket2, ...]

# Redis Pub/Sub æ”¯æŒ
import redis.asyncio as aioredis

redis_pubsub_client: Optional[aioredis.Redis] = None
redis_pubsub_task: Optional[asyncio.Task] = None

# âœ… v7.1.2æ–°å¢: PDF ç¼“å­˜ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
from cachetools import TTLCache

pdf_cache: TTLCache = TTLCache(maxsize=100, ttl=3600)  # 100é¡¹ï¼Œ1å°æ—¶è¿‡æœŸ


def _serialize_for_json(data: Any) -> Any:
    if isinstance(data, Command):
        return {
            "__type__": "Command",
            "goto": data.goto,
            "update": _serialize_for_json(data.update) if data.update else None,
        }
    if isinstance(data, Interrupt):
        value = getattr(data, "value", None)
        return {
            "__type__": "Interrupt",
            "value": _serialize_for_json(value) if value is not None else None,
        }
    if isinstance(data, BaseModel):
        return _serialize_for_json(data.model_dump())
    if isinstance(data, dict):
        return {k: _serialize_for_json(v) for k, v in data.items()}
    if isinstance(data, (list, tuple)):
        return [_serialize_for_json(item) for item in data]
    if isinstance(data, datetime):
        return data.isoformat()
    return data


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global session_manager, archive_manager, followup_history_manager, redis_pubsub_client, redis_pubsub_task

    # å¯åŠ¨æ—¶
    print("=" * 60)
    print("  ğŸ¤– æ™ºèƒ½é¡¹ç›®åˆ†æç³»ç»Ÿ - API æœåŠ¡å™¨")
    print("=" * 60)
    print()

    # âœ… åˆå§‹åŒ– Redis ä¼šè¯ç®¡ç†å™¨
    try:
        session_manager = RedisSessionManager()
        await session_manager.connect()
        print("âœ… Redis ä¼šè¯ç®¡ç†å™¨å·²å¯åŠ¨")
    except Exception as e:
        logger.error(f"âŒ Redis ä¼šè¯ç®¡ç†å™¨å¯åŠ¨å¤±è´¥: {e}")
        print("âš ï¸ Redis ä¼šè¯ç®¡ç†å™¨å¯åŠ¨å¤±è´¥ï¼ˆä½¿ç”¨å†…å­˜æ¨¡å¼ï¼‰")

    # âœ… v3.11æ–°å¢: åˆå§‹åŒ–è¿½é—®å†å²ç®¡ç†å™¨
    try:
        followup_history_manager = FollowupHistoryManager(session_manager)
        print("âœ… è¿½é—®å†å²ç®¡ç†å™¨å·²å¯åŠ¨")
    except Exception as e:
        logger.error(f"âŒ è¿½é—®å†å²ç®¡ç†å™¨å¯åŠ¨å¤±è´¥: {e}")
        print("âš ï¸ è¿½é—®å†å²ç®¡ç†å™¨å¯åŠ¨å¤±è´¥ï¼ˆè¿½é—®åŠŸèƒ½å—é™ï¼‰")

    # âœ… v3.6æ–°å¢: åˆå§‹åŒ–ä¼šè¯å½’æ¡£ç®¡ç†å™¨
    try:
        archive_manager = SessionArchiveManager()
        print("âœ… ä¼šè¯å½’æ¡£ç®¡ç†å™¨å·²å¯åŠ¨ï¼ˆæ°¸ä¹…ä¿å­˜åŠŸèƒ½å·²å¯ç”¨ï¼‰")
    except Exception as e:
        logger.error(f"âŒ ä¼šè¯å½’æ¡£ç®¡ç†å™¨å¯åŠ¨å¤±è´¥: {e}")
        print("âš ï¸ ä¼šè¯å½’æ¡£ç®¡ç†å™¨å¯åŠ¨å¤±è´¥ï¼ˆæ— æ³•ä½¿ç”¨æ°¸ä¹…ä¿å­˜åŠŸèƒ½ï¼‰")

    # âœ… åˆå§‹åŒ– Redis Pub/Subï¼ˆç”¨äº WebSocket å¤šå®ä¾‹å¹¿æ’­ï¼‰
    try:
        redis_pubsub_client = await aioredis.from_url(settings.redis_url, encoding="utf-8", decode_responses=True)
        # å¯åŠ¨è®¢é˜…ç›‘å¬ä»»åŠ¡
        redis_pubsub_task = asyncio.create_task(subscribe_to_redis_pubsub())
        print("âœ… Redis Pub/Sub å·²å¯åŠ¨")
    except Exception as e:
        logger.warning(f"âš ï¸ Redis Pub/Sub å¯åŠ¨å¤±è´¥: {e}")
        print("âš ï¸ Redis Pub/Sub å¯åŠ¨å¤±è´¥ï¼ˆWebSocket ä»…æ”¯æŒå•å®ä¾‹ï¼‰")

    # âœ… v7.1.2æ–°å¢: åˆå§‹åŒ– Playwright æµè§ˆå™¨æ± ï¼ˆPDF ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–ï¼‰
    try:
        from intelligent_project_analyzer.api.html_pdf_generator import get_browser_pool

        browser_pool = get_browser_pool()
        await browser_pool.initialize()
        print("âœ… Playwright æµè§ˆå™¨æ± å·²å¯åŠ¨ï¼ˆPDF ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–ï¼‰")
    except Exception as e:
        logger.warning(f"âš ï¸ Playwright æµè§ˆå™¨æ± å¯åŠ¨å¤±è´¥: {e}")
        print("âš ï¸ Playwright æµè§ˆå™¨æ± å¯åŠ¨å¤±è´¥ï¼ˆPDF ç”Ÿæˆå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼‰")

    # âœ… v7.120 P1ä¼˜åŒ–: é¢„åˆå§‹åŒ–è®¾å¤‡ä¼šè¯ç®¡ç†å™¨ï¼ˆæ¶ˆé™¤4.05så»¶è¿Ÿï¼‰
    try:
        from intelligent_project_analyzer.services.device_session_manager import get_device_manager

        device_manager = get_device_manager()
        await device_manager.initialize()
        print("âœ… è®¾å¤‡ä¼šè¯ç®¡ç†å™¨å·²é¢„åˆå§‹åŒ–ï¼ˆP1ä¼˜åŒ–: 4.05sâ†’0.05sï¼‰")
    except Exception as e:
        logger.warning(f"âš ï¸ è®¾å¤‡ä¼šè¯ç®¡ç†å™¨é¢„åˆå§‹åŒ–å¤±è´¥: {e}")
        print("âš ï¸ è®¾å¤‡ä¼šè¯ç®¡ç†å™¨é¢„åˆå§‹åŒ–å¤±è´¥ï¼ˆè®¾å¤‡æ£€æŸ¥å¯èƒ½è¾ƒæ…¢ï¼‰")

    print("âœ… æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ")
    print("ğŸ“ API æ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ“ å¥åº·æ£€æŸ¥: http://localhost:8000/health")
    print()

    # ğŸ”¥ v7.105: é¢„çƒ­ä¼šè¯ç¼“å­˜ï¼ˆæ¶ˆé™¤é¦–æ¬¡è¯·æ±‚å»¶è¿Ÿï¼‰
    try:
        import time

        logger.info("â³ é¢„çƒ­ä¼šè¯åˆ—è¡¨ç¼“å­˜...")
        start_time = time.time()
        sessions = await session_manager.get_all_sessions()
        elapsed = time.time() - start_time
        logger.info(f"âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ: {len(sessions)} ä¸ªä¼šè¯ ({elapsed:.1f}ç§’)")
    except Exception as e:
        logger.warning(f"âš ï¸ ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")

    # âœ… Fix 1.4: å¯åŠ¨æ—¶æ¸…ç†æ—§ä¼šè¯ï¼ˆ24å°æ—¶å‰çš„å·²å®Œæˆä¼šè¯ï¼‰
    try:
        logger.info("ğŸ§¹ æ¸…ç†æ—§ä¼šè¯...")
        cleaned = await session_manager.cleanup_old_sessions(max_age_hours=24)
        if cleaned > 0:
            logger.info(f"âœ… å¯åŠ¨æ¸…ç†å®Œæˆ: åˆ é™¤ {cleaned} ä¸ªæ—§ä¼šè¯")
        else:
            logger.info("âœ… å¯åŠ¨æ¸…ç†å®Œæˆ: æ— éœ€æ¸…ç†")
    except Exception as e:
        logger.warning(f"âš ï¸ å¯åŠ¨æ¸…ç†å¤±è´¥: {e}")

    yield

    # å…³é—­æ—¶
    print("\nğŸ‘‹ æœåŠ¡å™¨å…³é—­ä¸­...")

    # âœ… v7.1.2æ–°å¢: å…³é—­ Playwright æµè§ˆå™¨æ± 
    try:
        from intelligent_project_analyzer.api.html_pdf_generator import PlaywrightBrowserPool

        await PlaywrightBrowserPool.cleanup()
        print("âœ… Playwright æµè§ˆå™¨æ± å·²å…³é—­")
    except Exception as e:
        logger.warning(f"âš ï¸ Playwright æµè§ˆå™¨æ± å…³é—­å¤±è´¥: {e}")

    # âœ… å…³é—­ Redis Pub/Sub
    if redis_pubsub_task:
        redis_pubsub_task.cancel()
        try:
            await redis_pubsub_task
        except asyncio.CancelledError:
            pass

    if redis_pubsub_client:
        await redis_pubsub_client.close()

    # âœ… å…³é—­ Redis ä¼šè¯ç®¡ç†å™¨
    if session_manager:
        await session_manager.disconnect()

    # âœ… v3.6æ–°å¢: å…³é—­å½’æ¡£ç®¡ç†å™¨ï¼ˆå…³é—­æ•°æ®åº“è¿æ¥ï¼‰
    if archive_manager:
        # SessionArchiveManager ä½¿ç”¨ SQLAlchemyï¼Œå¼•æ“ä¼šè‡ªåŠ¨ç®¡ç†è¿æ¥æ± 
        # ä¸éœ€è¦æ˜¾å¼å…³é—­ï¼Œä½†è®°å½•æ—¥å¿—
        logger.info("ğŸ“¦ ä¼šè¯å½’æ¡£ç®¡ç†å™¨å·²å…³é—­")

    print("ğŸ‘‹ æœåŠ¡å™¨å·²å…³é—­")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="æ™ºèƒ½é¡¹ç›®åˆ†æç³»ç»Ÿ API", description="åŸºäº LangGraph çš„å¤šæ™ºèƒ½ä½“åä½œåˆ†æå¹³å°", version="2.0.0", lifespan=lifespan)

# ğŸ†• æ·»åŠ æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶
from intelligent_project_analyzer.api.performance_monitor import performance_monitoring_middleware

app.middleware("http")(performance_monitoring_middleware)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ”¥ æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•ï¼ˆç”¨äºä¸“å®¶ç”Ÿæˆçš„å›¾ç‰‡ï¼‰
try:
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    data_dir = Path(__file__).parent.parent.parent / "data"
    archived_images_dir = data_dir / "archived_images"
    uploads_dir = data_dir / "uploads"
    generated_images_dir = data_dir / "generated_images"  # ğŸ†• v7.108
    followup_images_dir = data_dir / "followup_images"  # ğŸ†• v7.108.2

    archived_images_dir.mkdir(parents=True, exist_ok=True)
    uploads_dir.mkdir(parents=True, exist_ok=True)
    generated_images_dir.mkdir(parents=True, exist_ok=True)  # ğŸ†• v7.108
    followup_images_dir.mkdir(parents=True, exist_ok=True)  # ğŸ†• v7.108.2

    # æŒ‚è½½é™æ€æ–‡ä»¶æœåŠ¡
    app.mount("/archived_images", StaticFiles(directory=str(archived_images_dir)), name="archived_images")
    app.mount("/uploads", StaticFiles(directory=str(uploads_dir)), name="uploads")
    app.mount(
        "/generated_images", StaticFiles(directory=str(generated_images_dir)), name="generated_images"
    )  # ğŸ†• v7.108
    app.mount("/followup_images", StaticFiles(directory=str(followup_images_dir)), name="followup_images")  # ğŸ†• v7.108.2

    logger.info(f"âœ… é™æ€æ–‡ä»¶æœåŠ¡å·²æŒ‚è½½: /archived_images -> {archived_images_dir}")
    logger.info(f"âœ… é™æ€æ–‡ä»¶æœåŠ¡å·²æŒ‚è½½: /uploads -> {uploads_dir}")
    logger.info(f"âœ… é™æ€æ–‡ä»¶æœåŠ¡å·²æŒ‚è½½: /generated_images -> {generated_images_dir}")  # ğŸ†• v7.108
    logger.info(f"âœ… é™æ€æ–‡ä»¶æœåŠ¡å·²æŒ‚è½½: /followup_images -> {followup_images_dir}")  # ğŸ†• v7.108.2
except Exception as e:
    logger.warning(f"âš ï¸ é™æ€æ–‡ä»¶æœåŠ¡æŒ‚è½½å¤±è´¥: {e}")

# âœ… v7.10æ–°å¢: æ³¨å†Œ WordPress JWT è®¤è¯è·¯ç”±
try:
    from intelligent_project_analyzer.api.auth_routes import router as auth_router

    app.include_router(auth_router)
    logger.info("âœ… WordPress JWT è®¤è¯è·¯ç”±å·²æ³¨å†Œ")
except Exception as e:
    logger.warning(f"âš ï¸ WordPress JWT è®¤è¯è·¯ç”±åŠ è½½å¤±è´¥: {e}")

# âœ… v7.10.1æ–°å¢: æ³¨å†Œ WPCOM Member ä¼šå‘˜ä¿¡æ¯è·¯ç”±
try:
    from intelligent_project_analyzer.api.member_routes import router as member_router

    app.include_router(member_router)
    logger.info("âœ… WPCOM Member ä¼šå‘˜ä¿¡æ¯è·¯ç”±å·²æ³¨å†Œ")
except Exception as e:
    logger.warning(f"âš ï¸ WPCOM Member ä¼šå‘˜ä¿¡æ¯è·¯ç”±åŠ è½½å¤±è´¥: {e}")

# âœ… v7.11æ–°å¢: æ³¨å†Œæ€§èƒ½å’Œå‘Šè­¦ç»Ÿè®¡APIè·¯ç”±
try:
    from intelligent_project_analyzer.api.metrics_routes import router as metrics_router

    app.include_router(metrics_router)
    logger.info("âœ… æ€§èƒ½å’Œå‘Šè­¦ç»Ÿè®¡APIè·¯ç”±å·²æ³¨å†Œ")
except Exception as e:
    logger.warning(f"âš ï¸ æ€§èƒ½å’Œå‘Šè­¦ç»Ÿè®¡APIè·¯ç”±åŠ è½½å¤±è´¥: {e}")

# ğŸ”¥ ç®¡ç†å‘˜åå°è·¯ç”±ï¼ˆä»…é™ç®¡ç†å‘˜è®¿é—®ï¼‰
try:
    from intelligent_project_analyzer.api.admin_routes import router as admin_router

    app.include_router(admin_router)
    logger.info("âœ… ç®¡ç†å‘˜åå°è·¯ç”±å·²æ³¨å†Œ")
except Exception as e:
    logger.warning(f"âš ï¸ ç®¡ç†å‘˜åå°è·¯ç”±åŠ è½½å¤±è´¥: {e}")

# âœ… v3.9æ–°å¢: æ³¨å†Œ Celery è·¯ç”±ï¼ˆå¯é€‰ï¼‰
try:
    from intelligent_project_analyzer.api.celery_routes import register_celery_routes

    register_celery_routes(app)
except ImportError as e:
    logger.warning(f"âš ï¸ Celery è·¯ç”±æœªåŠ è½½ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰: {e}")


# ==================== æ•°æ®æ¨¡å‹ ====================


class AnalysisRequest(BaseModel):
    """åˆ†æè¯·æ±‚"""

    # Backward compatible aliases:
    # - legacy clients use `requirement` instead of `user_input`
    # - some clients may send `username`/`userId` etc; we only normalize what we actually need
    model_config = ConfigDict(populate_by_name=True, coerce_numbers_to_str=True)

    user_input: str = Field(validation_alias=AliasChoices("user_input", "requirement"))
    user_id: str = Field(default="web_user", validation_alias=AliasChoices("user_id", "username"))  # ç”¨æˆ·ID
    # ğŸ†• v7.39: åˆ†ææ¨¡å¼ - normal(æ™®é€š) æˆ– deep_thinking(æ·±åº¦æ€è€ƒ)
    # æ·±åº¦æ€è€ƒæ¨¡å¼ä¼šä¸ºæ¯ä¸ªä¸“å®¶ç”Ÿæˆæ¦‚å¿µå›¾åƒ
    analysis_mode: str = Field(default="normal", validation_alias=AliasChoices("analysis_mode", "mode"))

    # Optional legacy field: accepted but currently not used by backend.
    domain: Optional[str] = None


class ResumeRequest(BaseModel):
    """æ¢å¤è¯·æ±‚"""

    model_config = ConfigDict(populate_by_name=True)

    session_id: str
    # Backward compatible alias: some older clients used `user_response`
    resume_value: Any = Field(validation_alias=AliasChoices("resume_value", "user_response"))


class FollowupRequest(BaseModel):
    """è¿½é—®è¯·æ±‚ï¼ˆç”¨äºå·²å®Œæˆçš„åˆ†ææŠ¥å‘Šï¼‰"""

    session_id: str
    question: str
    requires_analysis: bool = True  # æ˜¯å¦éœ€è¦é‡æ–°åˆ†æ


class SessionResponse(BaseModel):
    """ä¼šè¯å“åº”"""

    session_id: str
    status: str
    message: str


class AnalysisStatus(BaseModel):
    """åˆ†æçŠ¶æ€"""

    session_id: str
    status: str  # running, waiting_for_input, completed, failed, rejected
    current_stage: Optional[str] = None
    detail: Optional[str] = None  # ğŸ”¥ æ–°å¢ï¼šå½“å‰èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯
    progress: float = 0.0
    history: Optional[List[Dict[str, Any]]] = None  # ğŸ”¥ æ–°å¢ï¼šæ‰§è¡Œå†å²
    interrupt_data: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    traceback: Optional[str] = None  # æ·»åŠ tracebackå­—æ®µç”¨äºè°ƒè¯•
    rejection_message: Optional[str] = None  # ğŸ†• æ‹’ç»åŸå› æç¤º
    user_input: Optional[str] = None  # ğŸ”¥ v7.37.7: ç”¨æˆ·åŸå§‹è¾“å…¥


class AnalysisResult(BaseModel):
    """åˆ†æç»“æœ"""

    session_id: str
    status: str
    # ç°è¡Œå­—æ®µ
    results: Optional[Any] = None
    final_report: Optional[Any] = None

    # å…¼å®¹æ—§å­—æ®µï¼ˆtests/api/test_analysis_endpoints.py ä»åœ¨ä½¿ç”¨ï¼‰
    final_result: Optional[Any] = None
    agent_results: Optional[Any] = None


# ğŸ†• å¯¹è¯ç›¸å…³æ•°æ®æ¨¡å‹
class ConversationRequest(BaseModel):
    """å¯¹è¯è¯·æ±‚"""

    session_id: str
    question: str
    context_hint: Optional[str] = None  # å¯é€‰ï¼šç« èŠ‚æç¤º


class ConversationResponse(BaseModel):
    """å¯¹è¯å“åº”"""

    answer: str
    intent: str
    references: List[str]


# ==================== ç»“æ„åŒ–æŠ¥å‘Šç±»å‹ ====================


class ExecutiveSummaryResponse(BaseModel):
    """æ‰§è¡Œæ‘˜è¦å“åº”"""

    project_overview: str = Field(default="", description="é¡¹ç›®æ¦‚è¿°")
    key_findings: List[str] = Field(default_factory=list, description="å…³é”®å‘ç°åˆ—è¡¨")
    key_recommendations: List[str] = Field(default_factory=list, description="æ ¸å¿ƒå»ºè®®åˆ—è¡¨")
    success_factors: List[str] = Field(default_factory=list, description="æˆåŠŸè¦ç´ åˆ—è¡¨")


# ğŸ”¥ Phase 1.4+ P4: æ ¸å¿ƒç­”æ¡ˆå“åº”æ¨¡å‹ï¼ˆå‘åå…¼å®¹ç‰ˆï¼‰
class CoreAnswerResponse(BaseModel):
    """æ ¸å¿ƒç­”æ¡ˆå“åº”ï¼ˆå‘åå…¼å®¹ï¼‰"""

    question: str = Field(default="", description="ä»ç”¨æˆ·è¾“å…¥æå–çš„æ ¸å¿ƒé—®é¢˜")
    answer: str = Field(default="", description="ç›´æ¥æ˜äº†çš„æ ¸å¿ƒç­”æ¡ˆ")
    deliverables: List[str] = Field(default_factory=list, description="äº¤ä»˜ç‰©æ¸…å•")
    timeline: str = Field(default="", description="é¢„ä¼°æ—¶é—´çº¿")
    budget_range: str = Field(default="", description="é¢„ç®—ä¼°ç®—èŒƒå›´")


# ğŸ†• v7.0: å•ä¸ªäº¤ä»˜ç‰©çš„è´£ä»»è€…ç­”æ¡ˆå“åº”
class DeliverableAnswerResponse(BaseModel):
    """å•ä¸ªäº¤ä»˜ç‰©çš„è´£ä»»è€…ç­”æ¡ˆå“åº”"""

    deliverable_id: str = Field(default="", description="äº¤ä»˜ç‰©ID")
    deliverable_name: str = Field(default="", description="äº¤ä»˜ç‰©åç§°")
    deliverable_type: str = Field(default="unknown", description="äº¤ä»˜ç‰©ç±»å‹")
    owner_role: str = Field(default="", description="è´£ä»»è€…è§’è‰²ID")
    owner_answer: str = Field(default="", description="è´£ä»»è€…çš„æ ¸å¿ƒç­”æ¡ˆ")
    answer_summary: str = Field(default="", description="ç­”æ¡ˆæ‘˜è¦")
    supporters: List[str] = Field(default_factory=list, description="æ”¯æ’‘ä¸“å®¶åˆ—è¡¨")
    quality_score: Optional[float] = Field(default=None, description="è´¨é‡åˆ†æ•°")


# ğŸ†• v7.0: ä¸“å®¶æ”¯æ’‘é“¾å“åº”
class ExpertSupportChainResponse(BaseModel):
    """ä¸“å®¶æ”¯æ’‘é“¾å“åº”"""

    role_id: str = Field(default="", description="ä¸“å®¶è§’è‰²ID")
    role_name: str = Field(default="", description="ä¸“å®¶åç§°")
    contribution_type: str = Field(default="support", description="è´¡çŒ®ç±»å‹")
    contribution_summary: str = Field(default="", description="è´¡çŒ®æ‘˜è¦")
    related_deliverables: List[str] = Field(default_factory=list, description="å…³è”çš„äº¤ä»˜ç‰©ID")


# ğŸ†• v7.0: å¢å¼ºç‰ˆæ ¸å¿ƒç­”æ¡ˆå“åº”ï¼ˆæ”¯æŒå¤šäº¤ä»˜ç‰©ï¼‰
class CoreAnswerV7Response(BaseModel):
    """
    v7.0 å¢å¼ºç‰ˆæ ¸å¿ƒç­”æ¡ˆå“åº” - æ”¯æŒå¤šä¸ªäº¤ä»˜ç‰©

    æ ¸å¿ƒç†å¿µï¼š
    - æ ¸å¿ƒç­”æ¡ˆ = å„è´£ä»»è€…çš„æœ€ç»ˆäº¤ä»˜ï¼ˆä¸åšLLMç»¼åˆï¼‰
    - æ¯ä¸ªäº¤ä»˜ç‰©æœ‰ä¸€ä¸ª primary_ownerï¼Œå…¶è¾“å‡ºå³ä¸ºè¯¥äº¤ä»˜ç‰©çš„ç­”æ¡ˆ
    - ä¸“å®¶æ”¯æ’‘é“¾å±•ç¤ºé owner ä¸“å®¶çš„è´¡çŒ®
    """

    question: str = Field(default="", description="ä»ç”¨æˆ·è¾“å…¥æå–çš„æ ¸å¿ƒé—®é¢˜")
    deliverable_answers: List[DeliverableAnswerResponse] = Field(default_factory=list, description="å„äº¤ä»˜ç‰©çš„è´£ä»»è€…ç­”æ¡ˆåˆ—è¡¨")
    expert_support_chain: List[ExpertSupportChainResponse] = Field(default_factory=list, description="ä¸“å®¶æ”¯æ’‘é“¾")
    timeline: str = Field(default="å¾…å®š", description="é¢„ä¼°æ—¶é—´çº¿")
    budget_range: str = Field(default="å¾…å®š", description="é¢„ç®—ä¼°ç®—èŒƒå›´")

    # å‘åå…¼å®¹å­—æ®µ
    answer: str = Field(default="", description="ç»¼åˆæ‘˜è¦ï¼ˆå‘åå…¼å®¹ï¼‰")
    deliverables: List[str] = Field(default_factory=list, description="äº¤ä»˜ç‰©æ¸…å•ï¼ˆå‘åå…¼å®¹ï¼‰")


# ğŸ”¥ Phase 1.4+ v4.1: æ´å¯ŸåŒºå—å“åº”æ¨¡å‹
class InsightsSectionResponse(BaseModel):
    """æ´å¯ŸåŒºå—å“åº” - ä»éœ€æ±‚åˆ†æå¸ˆå’Œæ‰€æœ‰ä¸“å®¶ä¸­æç‚¼çš„å…³é”®æ´å¯Ÿ"""

    key_insights: List[str] = Field(default_factory=list, description="3-5æ¡æ ¸å¿ƒæ´å¯Ÿ")
    cross_domain_connections: List[str] = Field(default_factory=list, description="è·¨é¢†åŸŸå…³è”å‘ç°")
    user_needs_interpretation: str = Field(default="", description="å¯¹ç”¨æˆ·éœ€æ±‚çš„æ·±å±‚è§£è¯»")


# ğŸ”¥ Phase 1.4+ v4.1: æ¨æ•²è¿‡ç¨‹å“åº”æ¨¡å‹
class DeliberationProcessResponse(BaseModel):
    """æ¨æ•²è¿‡ç¨‹å“åº” - é¡¹ç›®æ€»ç›‘çš„æˆ˜ç•¥åˆ†æå’Œå†³ç­–æ€è·¯"""

    inquiry_architecture: str = Field(default="", description="é€‰æ‹©çš„æ¢è¯¢æ¶æ„ç±»å‹")
    reasoning: str = Field(default="", description="ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ¢è¯¢æ¶æ„")
    role_selection: List[str] = Field(default_factory=list, description="é€‰æ‹©çš„ä¸“å®¶è§’è‰²åŠç†ç”±")
    strategic_approach: str = Field(default="", description="æ•´ä½“æˆ˜ç•¥æ–¹å‘")


# ğŸ”¥ Phase 1.4+ v4.1: å»ºè®®åŒºå—å“åº”æ¨¡å‹
class RecommendationsSectionResponse(BaseModel):
    """å»ºè®®åŒºå—å“åº” - æ•´åˆæ‰€æœ‰ä¸“å®¶çš„å¯æ‰§è¡Œå»ºè®®"""

    immediate_actions: List[str] = Field(default_factory=list, description="ç«‹å³å¯æ‰§è¡Œçš„è¡ŒåŠ¨")
    short_term_priorities: List[str] = Field(default_factory=list, description="çŸ­æœŸä¼˜å…ˆçº§")
    long_term_strategy: List[str] = Field(default_factory=list, description="é•¿æœŸæˆ˜ç•¥æ–¹å‘")
    risk_mitigation: List[str] = Field(default_factory=list, description="é£é™©ç¼“è§£æªæ–½")


class ReportSectionResponse(BaseModel):
    """æŠ¥å‘Šç« èŠ‚å“åº”"""

    section_id: str = Field(default="", description="ç« èŠ‚ID")
    title: str = Field(default="", description="ç« èŠ‚æ ‡é¢˜")
    content: str = Field(default="", description="ç« èŠ‚å†…å®¹")
    confidence: float = Field(default=0.0, description="ç½®ä¿¡åº¦")


class ComprehensiveAnalysisResponse(BaseModel):
    """ç»¼åˆåˆ†æå“åº”"""

    cross_domain_insights: List[str] = Field(default_factory=list, description="è·¨é¢†åŸŸæ´å¯Ÿ")
    integrated_recommendations: List[str] = Field(default_factory=list, description="æ•´åˆå»ºè®®")
    risk_assessment: List[str] = Field(default_factory=list, description="é£é™©è¯„ä¼°")
    implementation_roadmap: List[str] = Field(default_factory=list, description="å®æ–½è·¯çº¿å›¾")


class ConclusionsResponse(BaseModel):
    """ç»“è®ºå“åº”"""

    project_analysis_summary: str = Field(default="", description="é¡¹ç›®åˆ†ææ€»ç»“")
    next_steps: List[str] = Field(default_factory=list, description="ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®")
    success_metrics: List[str] = Field(default_factory=list, description="æˆåŠŸæŒ‡æ ‡")


class ReviewFeedbackItemResponse(BaseModel):
    """å®¡æ ¸åé¦ˆé¡¹å“åº”"""

    issue_id: str = Field(default="", description="é—®é¢˜ID")
    reviewer: str = Field(default="", description="å®¡æ ¸ä¸“å®¶")
    issue_type: str = Field(default="", description="é—®é¢˜ç±»å‹")
    description: str = Field(default="", description="é—®é¢˜æè¿°")
    response: str = Field(default="", description="å“åº”æªæ–½")
    status: str = Field(default="", description="çŠ¶æ€")
    priority: str = Field(default="medium", description="ä¼˜å…ˆçº§")


class ReviewFeedbackResponse(BaseModel):
    """å®¡æ ¸åé¦ˆå“åº”"""

    red_team_challenges: List[ReviewFeedbackItemResponse] = Field(default_factory=list)
    blue_team_validations: List[ReviewFeedbackItemResponse] = Field(default_factory=list)
    judge_rulings: List[ReviewFeedbackItemResponse] = Field(default_factory=list)
    client_decisions: List[ReviewFeedbackItemResponse] = Field(default_factory=list)
    iteration_summary: str = Field(default="")


class ReviewRoundDataResponse(BaseModel):
    """å®¡æ ¸è½®æ¬¡æ•°æ®å“åº”"""

    round_number: int = Field(default=0)
    red_score: int = Field(default=0)
    blue_score: int = Field(default=0)
    judge_score: int = Field(default=0)
    issues_found: int = Field(default=0)
    issues_resolved: int = Field(default=0)
    timestamp: str = Field(default="")


class ReviewVisualizationResponse(BaseModel):
    """å®¡æ ¸å¯è§†åŒ–å“åº”"""

    rounds: List[ReviewRoundDataResponse] = Field(default_factory=list)
    final_decision: str = Field(default="")
    total_rounds: int = Field(default=0)
    improvement_rate: float = Field(default=0.0)


class ChallengeItemResponse(BaseModel):
    """å•ä¸ªæŒ‘æˆ˜é¡¹å“åº”"""

    expert_id: str = Field(default="", description="ä¸“å®¶ID")
    expert_name: str = Field(default="", description="ä¸“å®¶åç§°")
    challenged_item: str = Field(default="", description="è´¨ç–‘çš„äº‹é¡¹")
    challenge_type: str = Field(default="", description="æŒ‘æˆ˜ç±»å‹: reinterpret/flag_risk/escalate")
    severity: str = Field(default="should-fix", description="ä¸¥é‡ç¨‹åº¦: must-fix/should-fix")
    rationale: str = Field(default="", description="è´¨ç–‘ç†ç”±")
    proposed_alternative: str = Field(default="", description="å»ºè®®çš„æ›¿ä»£æ–¹æ¡ˆ")
    design_impact: str = Field(default="", description="å¯¹è®¾è®¡çš„å½±å“")
    decision: str = Field(default="", description="å¤„ç†å†³ç­–: accept/synthesize/escalate")


class ChallengeDetectionResponse(BaseModel):
    """æŒ‘æˆ˜æ£€æµ‹å“åº”"""

    has_challenges: bool = Field(default=False, description="æ˜¯å¦æœ‰æŒ‘æˆ˜")
    total_count: int = Field(default=0, description="æŒ‘æˆ˜æ€»æ•°")
    must_fix_count: int = Field(default=0, description="å¿…é¡»ä¿®å¤çš„é—®é¢˜æ•°")
    should_fix_count: int = Field(default=0, description="å»ºè®®ä¿®å¤çš„é—®é¢˜æ•°")
    challenges: List[ChallengeItemResponse] = Field(default_factory=list, description="æŒ‘æˆ˜åˆ—è¡¨")
    handling_summary: str = Field(default="", description="å¤„ç†æ‘˜è¦")


class QuestionnaireResponseItem(BaseModel):
    """å•ä¸ªé—®å·å›ç­”é¡¹"""

    question_id: str = Field(default="", description="é—®é¢˜ID")
    question: str = Field(default="", description="é—®é¢˜å†…å®¹")
    answer: str = Field(default="", description="ç”¨æˆ·å›ç­”")
    context: str = Field(default="", description="é—®é¢˜ä¸Šä¸‹æ–‡è¯´æ˜")


class QuestionnaireResponseData(BaseModel):
    """é—®å·å›ç­”æ•°æ®"""

    responses: List[QuestionnaireResponseItem] = Field(default_factory=list, description="é—®å·å›ç­”åˆ—è¡¨")
    timestamp: str = Field(default="", description="æäº¤æ—¶é—´")
    analysis_insights: str = Field(default="", description="ä»å›ç­”ä¸­æå–çš„å…³é”®æ´å¯Ÿ")


class RequirementsAnalysisResponse(BaseModel):
    """éœ€æ±‚åˆ†æç»“æœï¼ˆéœ€æ±‚åˆ†æå¸ˆåŸå§‹è¾“å‡º - èåˆç”¨æˆ·ä¿®æ”¹åçš„æœ€ç»ˆç‰ˆæœ¬ï¼‰"""

    project_overview: str = Field(default="", description="é¡¹ç›®æ¦‚è§ˆ")
    core_objectives: List[str] = Field(default_factory=list, description="æ ¸å¿ƒç›®æ ‡")
    project_tasks: List[str] = Field(default_factory=list, description="é¡¹ç›®ä»»åŠ¡")
    narrative_characters: List[str] = Field(default_factory=list, description="å™äº‹è§’è‰²")
    physical_contexts: List[str] = Field(default_factory=list, description="ç‰©ç†ç¯å¢ƒ")
    constraints_opportunities: Dict[str, Any] = Field(default_factory=dict, description="çº¦æŸä¸æœºé‡")


class StructuredReportResponse(BaseModel):
    """ç»“æ„åŒ–æŠ¥å‘Šå“åº”"""

    inquiry_architecture: str = Field(default="", description="æ¢è¯¢æ¶æ„ç±»å‹")
    # ğŸ”¥ Phase 1.4+ P4: æ ¸å¿ƒç­”æ¡ˆï¼ˆç”¨æˆ·æœ€å…³å¿ƒçš„TL;DRï¼‰
    # ğŸ†• v7.0: æ”¯æŒæ–°çš„å¤šäº¤ä»˜ç‰©æ ¼å¼å’Œæ—§æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
    # å¦‚æœæœ‰ deliverable_answers å­—æ®µï¼Œåˆ™æ˜¯ v7.0 æ ¼å¼
    # å¦åˆ™æ˜¯æ—§æ ¼å¼ï¼ˆåªæœ‰ answer å­—æ®µï¼‰
    core_answer: Optional[Dict[str, Any]] = Field(default=None, description="æ ¸å¿ƒç­”æ¡ˆï¼ˆæ”¯æŒv7.0å¤šäº¤ä»˜ç‰©æ ¼å¼å’Œæ—§æ ¼å¼ï¼‰")
    # ğŸ”¥ Phase 1.4+ v4.1: æ–°å¢æ´å¯Ÿã€æ¨æ•²è¿‡ç¨‹ã€å»ºè®®åŒºå—
    insights: Optional[InsightsSectionResponse] = Field(default=None, description="éœ€æ±‚æ´å¯Ÿï¼ˆLLMç»¼åˆï¼‰")
    requirements_analysis: Optional[RequirementsAnalysisResponse] = Field(default=None, description="éœ€æ±‚åˆ†æç»“æœï¼ˆéœ€æ±‚åˆ†æå¸ˆåŸå§‹è¾“å‡ºï¼‰")
    deliberation_process: Optional[DeliberationProcessResponse] = Field(default=None, description="æ¨æ•²è¿‡ç¨‹")
    recommendations: Optional[RecommendationsSectionResponse] = Field(default=None, description="å»ºè®®")
    executive_summary: ExecutiveSummaryResponse = Field(default_factory=ExecutiveSummaryResponse)
    sections: List[ReportSectionResponse] = Field(default_factory=list)
    comprehensive_analysis: ComprehensiveAnalysisResponse = Field(default_factory=ComprehensiveAnalysisResponse)
    conclusions: ConclusionsResponse = Field(default_factory=ConclusionsResponse)
    expert_reports: Dict[str, str] = Field(default_factory=dict, description="ä¸“å®¶åŸå§‹æŠ¥å‘Š")
    review_feedback: Optional[ReviewFeedbackResponse] = None
    questionnaire_responses: Optional[QuestionnaireResponseData] = Field(default=None, description="é—®å·å›ç­”æ•°æ®")
    review_visualization: Optional[ReviewVisualizationResponse] = None
    challenge_detection: Optional[ChallengeDetectionResponse] = Field(default=None, description="æŒ‘æˆ˜æ£€æµ‹ç»“æœ")
    # ğŸ†• v7.4: æ‰§è¡Œå…ƒæ•°æ®æ±‡æ€»
    execution_metadata: Optional[Dict[str, Any]] = Field(default=None, description="æ‰§è¡Œå…ƒæ•°æ®æ±‡æ€»")
    # ğŸ†• v3.0.26: æ€ç»´å¯¼å›¾å†…å®¹ç»“æ„ï¼ˆä»¥å†…å®¹ä¸ºä¸­å¿ƒï¼‰
    mindmap_content: Optional[Dict[str, Any]] = Field(default=None, description="æ€ç»´å¯¼å›¾å†…å®¹ç»“æ„")
    # ğŸ†• æ™®é€šæ¨¡å¼æ¦‚å¿µå›¾ï¼ˆé›†ä¸­ç”Ÿæˆï¼‰
    generated_images: Optional[List[str]] = Field(default=None, description="AI æ¦‚å¿µå›¾ï¼ˆæ™®é€šæ¨¡å¼ï¼‰")
    image_prompts: Optional[List[str]] = Field(default=None, description="AI æ¦‚å¿µå›¾æç¤ºè¯ï¼ˆæ™®é€šæ¨¡å¼ï¼‰")
    image_top_constraints: Optional[str] = Field(default=None, description="AI æ¦‚å¿µå›¾é¡¶å±‚çº¦æŸï¼ˆæ™®é€šæ¨¡å¼ï¼‰")
    # ğŸ†• v7.39: ä¸“å®¶æ¦‚å¿µå›¾ï¼ˆæ·±åº¦æ€è€ƒæ¨¡å¼ï¼‰
    generated_images_by_expert: Optional[Dict[str, Any]] = Field(default=None, description="ä¸“å®¶æ¦‚å¿µå›¾ï¼ˆæ·±åº¦æ€è€ƒæ¨¡å¼ï¼‰")


class ReportResponse(BaseModel):
    """æŠ¥å‘Šå“åº”ï¼ˆä¸“é—¨ç”¨äºå‰ç«¯è·å–æŠ¥å‘Šï¼‰"""

    session_id: str
    report_text: str
    report_pdf_path: Optional[str] = None
    created_at: str
    user_input: str = Field(default="", description="ç”¨æˆ·åŸå§‹è¾“å…¥")
    suggestions: List[str] = Field(default_factory=list)
    conversation_id: Optional[int] = None
    structured_report: Optional[StructuredReportResponse] = Field(default=None, description="ç»“æ„åŒ–æŠ¥å‘Šæ•°æ®")


# ==================== æŠ¥å‘Šæ•°æ®æ¸…æ´—è¾…åŠ©å‡½æ•° ====================


def _is_blank_section(section: ReportSectionResponse) -> bool:
    """åˆ¤æ–­ç« èŠ‚å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–ä»…åŒ…å«å ä½ç¬¦"""

    content = (section.content or "").strip()
    if not content:
        return True

    normalized = content.strip()
    if normalized in {"{}", "[]", '""'}:
        return True

    try:
        parsed = json.loads(normalized)
    except Exception:
        return False

    if isinstance(parsed, dict):
        return len(parsed) == 0
    if isinstance(parsed, list):
        return len(parsed) == 0
    return False


def _normalize_section_id(raw_identifier: Optional[str], fallback: str) -> str:
    """è§„èŒƒåŒ–ç« èŠ‚ IDï¼Œç¡®ä¿å¯ç”¨äºå­—å…¸é”®ä¸å‰ç«¯é”šç‚¹"""

    candidate = (raw_identifier or "").strip()
    if candidate:
        slug = re.sub(r"[^A-Za-z0-9]+", "_", candidate).strip("_").lower()
        if slug:
            return slug

    slug = re.sub(r"[^A-Za-z0-9]+", "_", fallback).strip("_").lower()
    if slug:
        return slug

    return f"section_{uuid.uuid4().hex[:8]}"


def _derive_section_identity(role_id: str, agent_result: Dict[str, Any]) -> Tuple[str, str]:
    """æ ¹æ®æ™ºèƒ½ä½“è¾“å‡ºæ¨æ–­ç« èŠ‚ ID ä¸æ ‡é¢˜ï¼Œæ”¯æŒåŠ¨æ€è§’è‰²"""

    metadata = agent_result.get("metadata") or {}

    candidate_ids = [
        metadata.get("section_id"),
        agent_result.get("section_id"),
        agent_result.get("report_section_id"),
    ]

    candidate_titles = [
        metadata.get("section_title"),
        agent_result.get("section_title"),
        agent_result.get("display_name"),
        agent_result.get("role_name"),
    ]

    if role_id == "requirements_analyst":
        candidate_ids.append("requirements_analysis")
        candidate_titles.append("éœ€æ±‚åˆ†æ")

    section_id = _normalize_section_id(next((cid for cid in candidate_ids if cid), None), role_id)
    section_title = next((title for title in candidate_titles if title), None) or role_id

    return section_id, section_title


def _sanitize_structured_data(data: Any) -> Tuple[Any, List[str]]:
    """æ¸…ç†ç»“æ„åŒ–æ•°æ®ï¼Œæ»¤é™¤ä¸ç¬¦åˆçº¦æŸçš„å‘½åé¡¹"""

    warnings: List[str] = []

    if not isinstance(data, dict):
        return data, warnings

    sanitized: Dict[str, Any] = {}

    for key, value in data.items():
        if key == "custom_analysis" and isinstance(value, dict):
            cleaned_custom, custom_warnings = _sanitize_custom_analysis(value)
            sanitized[key] = cleaned_custom
            warnings.extend(custom_warnings)
        elif isinstance(value, dict):
            cleaned_value, nested_warnings = _sanitize_structured_data(value)
            sanitized[key] = cleaned_value
            warnings.extend(nested_warnings)
        else:
            sanitized[key] = value

    return sanitized, warnings


def _sanitize_custom_analysis(data: Dict[str, Any]) -> Tuple[Dict[str, Any], List[str]]:
    """é’ˆå¯¹å®šåˆ¶åˆ†æéƒ¨åˆ†çš„å‘½åé•¿åº¦åšçº¦æŸè¿‡æ»¤"""

    sanitized: Dict[str, Any] = {}
    warnings: List[str] = []

    for key, value in data.items():
        if isinstance(value, list):
            valid_entries = []
            removed_entries = []

            for entry in value:
                if isinstance(entry, dict):
                    name = entry.get("å‘½åæœ¬èº«") or entry.get("å‘½å") or entry.get("åç§°")
                    name_str = name.strip() if isinstance(name, str) else ""
                    if name_str and len(name_str) == 4:
                        valid_entries.append(entry)
                    else:
                        removed_entries.append(name_str or "<æœªå‘½å>")
                else:
                    valid_entries.append(entry)

            if removed_entries:
                warnings.append(f"{key}: å·²ç§»é™¤{len(removed_entries)}ä¸ªæœªæ»¡è¶³å››å­—è¦æ±‚çš„å‘½å")

            sanitized[key] = valid_entries

        elif isinstance(value, dict):
            cleaned_value, nested_warnings = _sanitize_custom_analysis(value)
            sanitized[key] = cleaned_value
            warnings.extend(nested_warnings)
        else:
            sanitized[key] = value

    return sanitized, warnings


def _format_agent_payload(agent_result: Dict[str, Any]) -> Optional[OrderedDict]:
    """å°†æ™ºèƒ½ä½“è¾“å‡ºæ ¼å¼åŒ–ä¸ºç»“æ„åŒ–payload"""

    if not agent_result:
        return None

    structured_raw = agent_result.get("structured_data") or {}
    structured, validation_warnings = _sanitize_structured_data(structured_raw)
    content = agent_result.get("content")

    payload = OrderedDict()

    if structured:
        payload["structured_data"] = structured

    if isinstance(content, str) and content.strip():
        payload["narrative_summary"] = content.strip()

    if validation_warnings:
        payload["validation_warnings"] = validation_warnings

    return payload if payload else None


def _enrich_sections_with_agent_results(
    sections: List[ReportSectionResponse], session: Dict[str, Any]
) -> List[ReportSectionResponse]:
    """è¡¥å…¨æˆ–æ›¿æ¢ç¼ºå¤±çš„ç« èŠ‚å†…å®¹"""

    agent_results = session.get("agent_results") or {}
    if not agent_results:
        return sections

    active_agents = session.get("active_agents") or list(agent_results.keys())

    section_lookup: Dict[str, ReportSectionResponse] = {}
    unlabeled_sections: List[ReportSectionResponse] = []

    for sec in sections:
        if sec.section_id:
            section_lookup[sec.section_id] = sec
        else:
            unlabeled_sections.append(sec)

    # æ”¶é›†å„ç« èŠ‚çš„è¡¥å……æ•°æ®
    section_contributions: Dict[str, OrderedDict] = {}
    section_titles: Dict[str, str] = {}
    section_confidences: Dict[str, List[float]] = defaultdict(list)
    agent_section_sequence: List[str] = []

    for role_id in active_agents:
        agent_result = agent_results.get(role_id) or {}
        payload = _format_agent_payload(agent_result)
        if not payload:
            continue

        section_id, section_title = _derive_section_identity(role_id, agent_result)
        agent_section_sequence.append(section_id)

        source_name = agent_result.get("display_name") or agent_result.get("role_name") or role_id

        section_contributions.setdefault(section_id, OrderedDict())
        section_contributions[section_id][source_name] = payload

        if section_title:
            section_titles.setdefault(section_id, section_title)

        confidence = agent_result.get("confidence")
        try:
            if confidence is not None:
                section_confidences[section_id].append(float(confidence))
        except (TypeError, ValueError):
            pass

    if not section_contributions:
        return sections

    for section_id, payload in section_contributions.items():
        if not payload:
            continue

        section = section_lookup.get(section_id)
        if section is None:
            section = ReportSectionResponse(
                section_id=section_id,
                title=section_titles.get(section_id, section_id),
                content="",
                confidence=0.0,
            )
            section_lookup[section_id] = section

        if not section.title:
            section.title = section_titles.get(section_id, section_id)

        if _is_blank_section(section):
            section.content = json.dumps(payload, ensure_ascii=False, indent=2)

        # ğŸ”¥ Phase 1.4+: ä¿®å¤ç½®ä¿¡åº¦ä¸º0%çš„é—®é¢˜
        # æ— è®ºç« èŠ‚å†…å®¹æ˜¯å¦ä¸ºç©ºï¼Œéƒ½åº”è¯¥è¡¥å…¨confidenceå€¼
        confidence_values = section_confidences.get(section_id, [])
        if confidence_values:
            section.confidence = max(confidence_values)
        elif not section.confidence or section.confidence == 0.0:
            # å¦‚æœconfidenceä¸º0æˆ–æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼0.8
            section.confidence = 0.8

    ordered_sections: List[ReportSectionResponse] = []
    added_ids: Set[str] = set()

    for section in sections:
        section_id = section.section_id
        if section_id and section_id not in added_ids:
            ordered_sections.append(section)
            added_ids.add(section_id)

    for section_id in agent_section_sequence:
        section = section_lookup.get(section_id)
        if section and section.section_id not in added_ids:
            ordered_sections.append(section)
            added_ids.add(section.section_id)

    for section in section_lookup.values():
        if section.section_id not in added_ids:
            ordered_sections.append(section)
            added_ids.add(section.section_id)

    ordered_sections.extend(unlabeled_sections)

    return ordered_sections


# ==================== è¾…åŠ©å‡½æ•° ====================


async def subscribe_to_redis_pubsub():
    """
    è®¢é˜… Redis Pub/Sub é¢‘é“ï¼Œç”¨äºå¤šå®ä¾‹ WebSocket æ¶ˆæ¯å¹¿æ’­
    """
    if not redis_pubsub_client:
        return

    try:
        pubsub = redis_pubsub_client.pubsub()
        await pubsub.subscribe("workflow:broadcast")

        logger.info("ğŸ“¡ Redis Pub/Sub è®¢é˜…å·²å¯åŠ¨")

        async for message in pubsub.listen():
            if message["type"] == "message":
                try:
                    import json

                    data = json.loads(message["data"])
                    session_id = data.get("session_id")
                    payload = data.get("payload")

                    # æœ¬åœ°å¹¿æ’­åˆ° WebSocket
                    if session_id in websocket_connections:
                        connections = websocket_connections[session_id]
                        disconnected = []

                        for ws in connections:
                            try:
                                # âœ… Fix 1.1: Check WebSocket state before sending (matches local broadcast logic)
                                if ws.client_state.name != "CONNECTED":
                                    logger.debug(f"â­ï¸ è·³è¿‡éè¿æ¥çŠ¶æ€çš„WebSocket (state={ws.client_state.name})")
                                    disconnected.append(ws)
                                    continue

                                await ws.send_json(payload)
                            except Exception as e:
                                logger.warning(f"âš ï¸ WebSocket å‘é€å¤±è´¥: {e}")
                                disconnected.append(ws)

                        # æ¸…ç†æ–­å¼€çš„è¿æ¥
                        for ws in disconnected:
                            connections.remove(ws)

                except Exception as e:
                    logger.error(f"âŒ å¤„ç† Pub/Sub æ¶ˆæ¯å¤±è´¥: {e}")

    except asyncio.CancelledError:
        logger.info("ğŸ“¡ Redis Pub/Sub è®¢é˜…å·²åœæ­¢")
        await pubsub.unsubscribe("workflow:broadcast")
        await pubsub.close()
    except Exception as e:
        logger.error(f"âŒ Redis Pub/Sub è®¢é˜…å¤±è´¥: {e}")


def create_workflow() -> Optional[MainWorkflow]:
    """
    åˆ›å»ºå·¥ä½œæµå®ä¾‹ - ä½¿ç”¨ LLMFactoryï¼ˆæ”¯æŒè‡ªåŠ¨é™çº§ï¼‰

    âœ… ä½¿ç”¨ LLMFactory åˆ›å»º LLMï¼Œæ”¯æŒè¿è¡Œæ—¶é™çº§
    """
    try:
        from intelligent_project_analyzer.services.llm_factory import LLMFactory

        logger.info("ğŸ”§ ä½¿ç”¨ LLMFactory åˆ›å»º LLMï¼ˆæ”¯æŒè‡ªåŠ¨é™çº§ï¼‰")

        # âœ… ä½¿ç”¨ LLMFactory åˆ›å»º LLMï¼ˆè‡ªåŠ¨åº”ç”¨ .env é…ç½®å’Œé™çº§é“¾ï¼‰
        llm = LLMFactory.create_llm()

        # é»˜è®¤ä½¿ç”¨ Dynamic Mode
        config = {
            "mode": "dynamic",
            "enable_role_config": True,
            "post_completion_followup_enabled": settings.post_completion_followup_enabled,
        }

        workflow = MainWorkflow(llm, config)
        logger.info("âœ… å·¥ä½œæµåˆ›å»ºæˆåŠŸï¼ˆLLM é™çº§å·²å¯ç”¨ï¼‰")
        return workflow

    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºå·¥ä½œæµå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return None


async def broadcast_to_websockets(session_id: str, message: Dict[str, Any]):
    """
    å‘æ‰€æœ‰è¿æ¥åˆ°æŒ‡å®šä¼šè¯çš„ WebSocket å®¢æˆ·ç«¯å¹¿æ’­æ¶ˆæ¯
    âœ… ä½¿ç”¨ Redis Pub/Sub æ”¯æŒå¤šå®ä¾‹éƒ¨ç½²

    Args:
        session_id: ä¼šè¯ ID
        message: è¦å‘é€çš„æ¶ˆæ¯ï¼ˆå­—å…¸æ ¼å¼ï¼Œå°†è¢«è½¬æ¢ä¸º JSONï¼‰
    """
    # ğŸ”¥ Redis Pub/Sub æ¨¡å¼ï¼šå‘å¸ƒåˆ° Redisï¼Œæ‰€æœ‰å®ä¾‹ç›‘å¬
    if redis_pubsub_client:
        try:
            import json

            payload = {"session_id": session_id, "payload": message}
            await redis_pubsub_client.publish("workflow:broadcast", json.dumps(payload, ensure_ascii=False))
            return
        except Exception as e:
            logger.warning(f"âš ï¸ Redis Pub/Sub å‘å¸ƒå¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°å¹¿æ’­: {e}")

    # ğŸ”¥ æœ¬åœ°æ¨¡å¼ï¼šç›´æ¥å¹¿æ’­åˆ°æœ¬å®ä¾‹çš„ WebSocket è¿æ¥
    if session_id not in websocket_connections:
        return

    # è·å–è¯¥ä¼šè¯çš„æ‰€æœ‰è¿æ¥
    connections = websocket_connections[session_id]

    # å­˜å‚¨æ–­å¼€çš„è¿æ¥
    disconnected = []

    # å¹¿æ’­æ¶ˆæ¯åˆ°æ‰€æœ‰è¿æ¥
    for ws in connections:
        try:
            # âœ… P0ä¿®å¤: æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€
            if ws.client_state.name != "CONNECTED":
                logger.debug(f"âš ï¸ WebSocketæœªè¿æ¥ (çŠ¶æ€: {ws.client_state.name})ï¼Œæ ‡è®°ä¸ºæ–­å¼€")
                disconnected.append(ws)
                continue

            await ws.send_json(message)
        except Exception as e:
            logger.warning(f"âš ï¸ WebSocket å‘é€å¤±è´¥: {e}")
            disconnected.append(ws)

    # æ¸…ç†æ–­å¼€çš„è¿æ¥
    for ws in disconnected:
        connections.remove(ws)


async def run_workflow_async(session_id: str, user_input: str):
    """å¼‚æ­¥æ‰§è¡Œå·¥ä½œæµï¼ˆä»… Dynamic Modeï¼‰"""
    try:
        # ğŸ†• v7.39: ä» session è·å–åˆ†ææ¨¡å¼
        session_data = await session_manager.get(session_id)
        analysis_mode = session_data.get("analysis_mode", "normal") if session_data else "normal"
        user_id = session_data.get("user_id", "api_user") if session_data else "api_user"

        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ")
        print(f"Session ID: {session_id}")
        print(f"ç”¨æˆ·è¾“å…¥: {user_input[:100]}...")
        print(f"è¿è¡Œæ¨¡å¼: Dynamic Mode")
        print(f"åˆ†ææ¨¡å¼: {analysis_mode}")  # ğŸ†• v7.39
        print(f"{'='*60}\n")

        # âœ… æ›´æ–°ä¼šè¯çŠ¶æ€
        await session_manager.update(session_id, {"status": "running", "progress": 0.1})

        # ğŸ”¥ å¹¿æ’­çŠ¶æ€åˆ° WebSocket
        await broadcast_to_websockets(
            session_id, {"type": "status_update", "status": "running", "progress": 0.1, "message": "å·¥ä½œæµå¼€å§‹æ‰§è¡Œ"}
        )

        # åˆ›å»ºå·¥ä½œæµ
        print(f"ğŸ“¦ åˆ›å»ºå·¥ä½œæµ (Dynamic Mode)...")
        workflow = create_workflow()
        if not workflow:
            print(f"âŒ å·¥ä½œæµåˆ›å»ºå¤±è´¥")
            await session_manager.update(
                session_id, {"status": "failed", "error": "å·¥ä½œæµåˆ›å»ºå¤±è´¥", "traceback": "å·¥ä½œæµåˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®"}
            )
            return

        print(f"âœ… å·¥ä½œæµåˆ›å»ºæˆåŠŸ")
        workflows[session_id] = workflow

        # åˆ›å»ºåˆå§‹çŠ¶æ€ - ğŸ†• v7.39: ä¼ é€’ analysis_mode
        initial_state = StateManager.create_initial_state(
            user_input=user_input, session_id=session_id, user_id=user_id, analysis_mode=analysis_mode  # ğŸ†• v7.39
        )

        config = {"configurable": {"thread_id": session_id}, "recursion_limit": 100}  # å¢åŠ é€’å½’é™åˆ¶ï¼Œé»˜è®¤æ˜¯25

        # æµå¼æ‰§è¡Œå·¥ä½œæµ
        # ä¸æŒ‡å®š stream_modeï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼ä»¥æ­£ç¡®æ¥æ”¶ __interrupt__
        # ğŸ†• æ·»åŠ GraphRecursionErrorå¤„ç†
        from langgraph.errors import GraphRecursionError

        events = []
        try:
            async for chunk in workflow.graph.astream(initial_state, config):
                # ğŸ”§ è¯Šæ–­æ—¥å¿—ï¼šæ£€æŸ¥æ¯ä¸ª chunk çš„é”®
                logger.info(f"ğŸ” [STREAM] chunk keys: {list(chunk.keys())}")

                events.append(_serialize_for_json(chunk))

                # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æœ‰ interrupt - æå‰æ£€æµ‹ï¼ˆåœ¨å¤„ç†å…¶ä»–èŠ‚ç‚¹ä¹‹å‰ï¼‰
                if "__interrupt__" in chunk:
                    logger.info(f"ğŸ›‘ [INTERRUPT] Detected! chunk keys: {list(chunk.keys())}")
                    # æå– interrupt æ•°æ®
                    interrupt_tuple = chunk["__interrupt__"]
                    logger.info(f"ğŸ›‘ [INTERRUPT] tuple type: {type(interrupt_tuple)}, content: {interrupt_tuple}")

                    # interrupt_tuple æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ Interrupt å¯¹è±¡
                    if interrupt_tuple:
                        interrupt_obj = interrupt_tuple[0] if isinstance(interrupt_tuple, tuple) else interrupt_tuple
                        logger.info(f"ğŸ›‘ [INTERRUPT] obj type: {type(interrupt_obj)}")

                        # æå– interrupt çš„ value
                        interrupt_value = None
                        if hasattr(interrupt_obj, "value"):
                            interrupt_value = interrupt_obj.value
                            logger.info(f"ğŸ›‘ [INTERRUPT] Extracted value from .value attribute")
                        else:
                            interrupt_value = interrupt_obj
                            logger.info(f"ğŸ›‘ [INTERRUPT] Using obj directly as value")

                        logger.info(f"ğŸ›‘ [INTERRUPT] value type: {type(interrupt_value)}")

                        # âœ… v7.119: æ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼Œå¹¶è®°å½•æ—¶é—´æˆ³
                        import time

                        await session_manager.update(
                            session_id,
                            {
                                "status": "waiting_for_input",
                                "interrupt_data": interrupt_value,
                                "current_node": "interrupt",
                                "interrupt_timestamp": time.time(),  # è®°å½•è¿›å…¥waiting_for_inputçš„æ—¶é—´
                            },
                        )
                        logger.info(f"ğŸ›‘ [INTERRUPT] Session {session_id} updated to waiting_for_input")

                        # ğŸ”¥ å¹¿æ’­ interrupt åˆ° WebSocket
                        await broadcast_to_websockets(
                            session_id,
                            {"type": "interrupt", "status": "waiting_for_input", "interrupt_data": interrupt_value},
                        )
                        logger.info(f"ğŸ›‘ [INTERRUPT] Broadcasted to WebSocket")
                        return

                # ğŸ”¥ æ›´æ–°å½“å‰èŠ‚ç‚¹å’Œè¯¦ç»†ä¿¡æ¯ï¼ˆç”¨äºå‰ç«¯è¿›åº¦å±•ç¤ºï¼‰
                for node_name, node_output in chunk.items():
                    if node_name != "__interrupt__":
                        # æå–è¯¦ç»†ä¿¡æ¯
                        detail = ""
                        if isinstance(node_output, dict):
                            # âœ… ä¼˜å…ˆä½¿ç”¨ detail å­—æ®µï¼ˆèŠ‚ç‚¹è¿”å›çš„è¯¦ç»†æè¿°ï¼‰
                            if "detail" in node_output:
                                detail = node_output["detail"]
                            # å›é€€ï¼šä½¿ç”¨ current_stage
                            elif "current_stage" in node_output:
                                detail = node_output["current_stage"]
                            # æœ€åï¼šä½¿ç”¨ status
                            elif "status" in node_output:
                                detail = node_output["status"]

                        # âœ… æ›´æ–°å½“å‰èŠ‚ç‚¹ã€è¯¦æƒ…å’Œå†å²è®°å½•
                        # è·å–å½“å‰ä¼šè¯ä»¥è¿½åŠ å†å²
                        current_session = await session_manager.get(session_id)
                        history = current_session.get("history", []) if current_session else []

                        # æ·»åŠ æ–°è®°å½•
                        history.append(
                            {"node": node_name, "detail": detail, "time": datetime.now().strftime("%H:%M:%S")}
                        )

                        # ğŸ”¥ v7.120: æå–search_referencesï¼ˆå¦‚æœèŠ‚ç‚¹æ›´æ–°äº†æ­¤å­—æ®µï¼‰
                        update_data = {"current_node": node_name, "detail": detail, "history": history}

                        # æ£€æŸ¥å¹¶æå–search_references
                        if isinstance(node_output, dict) and "search_references" in node_output:
                            search_refs = node_output["search_references"]
                            if search_refs:  # åªæœ‰éç©ºæ‰æ›´æ–°
                                update_data["search_references"] = search_refs
                                logger.info(f"ğŸ” [v7.120] èŠ‚ç‚¹ {node_name} æ›´æ–°äº† {len(search_refs)} ä¸ªæœç´¢å¼•ç”¨")

                        await session_manager.update(session_id, update_data)
                        logger.debug(f"[PROGRESS] èŠ‚ç‚¹: {node_name}, è¯¦æƒ…: {detail}")

                        # ğŸ”§ è¯Šæ–­æ—¥å¿—ï¼ˆ2025-11-30ï¼‰ï¼šæ£€æŸ¥detailæå–å’Œå¹¿æ’­
                        if node_name == "agent_executor":
                            logger.info(f"ğŸ” [DIAGNOSTIC] agent_executor detail: '{detail}'")
                            logger.info(
                                f"ğŸ” [DIAGNOSTIC] node_output keys: {list(node_output.keys()) if isinstance(node_output, dict) else 'not dict'}"
                            )
                            if isinstance(node_output, dict) and "detail" in node_output:
                                logger.info(f"ğŸ” [DIAGNOSTIC] node_output['detail']: '{node_output['detail']}'")

                        # ğŸ”¥ å¹¿æ’­èŠ‚ç‚¹æ›´æ–°åˆ° WebSocket
                        await broadcast_to_websockets(
                            session_id,
                            {
                                "type": "node_update",
                                "current_node": node_name,
                                "detail": detail,
                                "timestamp": datetime.now().isoformat(),
                            },
                        )

                        # ğŸ”§ è¯Šæ–­æ—¥å¿—ï¼šç¡®è®¤å¹¿æ’­å†…å®¹
                        if node_name == "agent_executor":
                            logger.info(f"ğŸ” [DIAGNOSTIC] Broadcasted node_update with detail: '{detail}'")

                # ğŸ”¥ æ›´æ–°è¿›åº¦ï¼ˆä¼˜åŒ–ï¼šåŸºäºèŠ‚ç‚¹åç§°æ˜ å°„ï¼‰
                # âœ… è·å–å½“å‰ä¼šè¯æ•°æ®
                current_session = await session_manager.get(session_id)
                if not current_session:
                    continue

                current_node_name = current_session.get("current_node", "")

                # ğŸ¯ v7.21: å®šä¹‰èŠ‚ç‚¹åˆ°è¿›åº¦çš„æ˜ å°„ï¼ˆä¸ main_workflow.py å®é™…èŠ‚ç‚¹åç§°å¯¹é½ï¼‰
                node_progress_map = {
                    # è¾“å…¥éªŒè¯é˜¶æ®µ (0-15%)
                    "unified_input_validator_initial": 0.05,  # 5% - åˆå§‹è¾“å…¥éªŒè¯
                    "unified_input_validator_secondary": 0.10,  # 10% - äºŒæ¬¡éªŒè¯
                    # éœ€æ±‚åˆ†æé˜¶æ®µ (15-35%)
                    "requirements_analyst": 0.15,  # 15% - éœ€æ±‚åˆ†æ
                    "feasibility_analyst": 0.20,  # 20% - å¯è¡Œæ€§åˆ†æ
                    "calibration_questionnaire": 0.25,  # 25% - é—®å·
                    "requirements_confirmation": 0.35,  # 35% - éœ€æ±‚ç¡®è®¤
                    # é¡¹ç›®è§„åˆ’é˜¶æ®µ (35-55%)
                    "project_director": 0.40,  # 40% - é¡¹ç›®æ€»ç›‘
                    "role_task_unified_review": 0.45,  # 45% - è§’è‰²å®¡æ ¸
                    "quality_preflight": 0.50,  # 50% - è´¨é‡é¢„æ£€
                    # ä¸“å®¶æ‰§è¡Œé˜¶æ®µ (55-80%)
                    "batch_executor": 0.55,  # 55% - æ‰¹æ¬¡è°ƒåº¦
                    "agent_executor": 0.70,  # 70% - ä¸“å®¶æ‰§è¡Œ
                    "batch_aggregator": 0.75,  # 75% - æ‰¹æ¬¡èšåˆ
                    "batch_router": 0.76,  # 76% - æ‰¹æ¬¡è·¯ç”±
                    "batch_strategy_review": 0.78,  # 78% - ç­–ç•¥å®¡æ ¸
                    # å®¡æ ¸èšåˆé˜¶æ®µ (80-100%)
                    "detect_challenges": 0.80,  # 80% - æŒ‘æˆ˜æ£€æµ‹
                    "analysis_review": 0.85,  # 85% - åˆ†æå®¡æ ¸
                    "result_aggregator": 0.90,  # 90% - ç»“æœèšåˆ
                    "report_guard": 0.95,  # 95% - æŠ¥å‘Šå®¡æ ¸
                    "pdf_generator": 0.98,  # 98% - PDF ç”Ÿæˆ
                }

                # ä½¿ç”¨èŠ‚ç‚¹æ˜ å°„æˆ–å›é€€åˆ°è®¡æ•°
                new_progress = node_progress_map.get(current_node_name, min(0.9, len(events) * 0.1))

                # ğŸ”¥ é˜²æ­¢è¿›åº¦å›é€€ï¼šåªæœ‰æ–°è¿›åº¦ â‰¥ æ—§è¿›åº¦æ—¶æ‰æ›´æ–°
                old_progress = current_session.get("progress", 0)
                progress = max(new_progress, old_progress if isinstance(old_progress, (int, float)) else 0)

                if new_progress < old_progress:
                    logger.debug(f"âš ï¸ æ£€æµ‹åˆ°è¿›åº¦å›é€€: {old_progress:.0%} â†’ {new_progress:.0%}ï¼Œä½¿ç”¨æ—§è¿›åº¦ {progress:.0%}")

                # âœ… å•æ¬¡æ›´æ–° Redisï¼ˆé¿å…é‡å¤å†™å…¥å’Œç«æ€æ¡ä»¶ï¼‰
                await session_manager.update(
                    session_id,
                    {
                        "progress": progress,
                        "events": events,
                        "current_node": current_node_name,
                        "detail": current_session.get("detail"),
                        "status": current_session["status"],
                    },
                )

                # ğŸ”„ ç›´æ¥ä½¿ç”¨è®¡ç®—å€¼å¹¿æ’­åˆ° WebSocketï¼ˆé¿å… Redis è¯»å–ç«æ€ï¼‰
                # ğŸ”¥ v7.120: åŒ…å«search_references
                broadcast_data = {
                    "type": "status_update",
                    "status": current_session["status"],
                    "progress": progress,
                    "current_node": current_node_name,
                    "detail": current_session.get("detail"),
                }

                # æ·»åŠ search_referencesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                search_refs = current_session.get("search_references")
                if search_refs:
                    broadcast_data["search_references"] = search_refs

                await broadcast_to_websockets(session_id, broadcast_data)

            # æ£€æŸ¥æ˜¯å¦æœ‰èŠ‚ç‚¹é”™è¯¯æˆ–è¢«æ‹’ç»
            has_error = False
            error_message = None
            is_rejected = False
            rejection_message = None

            for event in events:
                for node_name, node_output in event.items():
                    if isinstance(node_output, dict):
                        # æ£€æŸ¥é”™è¯¯
                        if node_output.get("error") or node_output.get("status") == "error":
                            has_error = True
                            error_message = node_output.get("error", f"èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥")
                            break
                        # ğŸ†• æ£€æŸ¥è¢«æ‹’ç»
                        if (
                            node_output.get("final_status") == "rejected"
                            or node_output.get("current_stage") == "REJECTED"
                        ):
                            is_rejected = True
                            rejection_message = node_output.get("rejection_message", "è¾“å…¥ä¸ç¬¦åˆè¦æ±‚")
                            rejection_reason = node_output.get("rejection_reason", "unknown")  # è·å–æ‹’ç»åŸå› 
                            break
                if has_error or is_rejected:
                    break

            # æ ¹æ®çŠ¶æ€è®¾ç½®ä¼šè¯
            if is_rejected:
                await session_manager.update(
                    session_id,
                    {
                        "status": "rejected",
                        "rejection_message": rejection_message,
                        "rejection_reason": rejection_reason,  # ä¿å­˜æ‹’ç»åŸå› 
                        "progress": 1.0,
                    },
                )
                logger.info(f"âœ‹ è¾“å…¥è¢«æ‹’ç»: {rejection_message[:100]}...")

                # âœ… è·å–æœ€æ–°ä¼šè¯æ•°æ®ç”¨äºå¹¿æ’­
                updated_session = await session_manager.get(session_id)

                # ğŸ”¥ å¹¿æ’­æ‹’ç»çŠ¶æ€
                await broadcast_to_websockets(
                    session_id,
                    {
                        "type": "status_update",
                        "status": "rejected",
                        "progress": 1.0,
                        "rejection_message": rejection_message,
                        "rejection_reason": rejection_reason,  # å¹¿æ’­æ‹’ç»åŸå› 
                        "current_node": updated_session.get("current_node") if updated_session else None,
                        "detail": updated_session.get("detail") if updated_session else None,
                    },
                )
            elif has_error:
                await session_manager.update(session_id, {"status": "failed", "error": error_message})
                logger.error(f"å·¥ä½œæµå¤±è´¥: {error_message}")

                # âœ… è·å–æœ€æ–°ä¼šè¯æ•°æ®
                updated_session = await session_manager.get(session_id)

                # ğŸ”¥ å¹¿æ’­é”™è¯¯çŠ¶æ€
                await broadcast_to_websockets(
                    session_id,
                    {
                        "type": "status_update",
                        "status": "failed",
                        "error": error_message,
                        "current_node": updated_session.get("current_node") if updated_session else None,
                        "detail": updated_session.get("detail") if updated_session else None,
                        "progress": updated_session.get("progress") if updated_session else 0,
                    },
                )
            else:
                # æå–æœ€ç»ˆæŠ¥å‘Šå’ŒPDFè·¯å¾„
                final_report = None
                pdf_path = None

                for event in events:
                    for node_name, node_output in event.items():
                        if isinstance(node_output, dict):
                            # æå– final_report
                            if "final_report" in node_output:
                                final_report = node_output["final_report"]
                            # æå– pdf_pathï¼ˆç”± report_generator èŠ‚ç‚¹ç”Ÿæˆï¼‰
                            if "pdf_path" in node_output:
                                pdf_path = node_output["pdf_path"]
                                logger.info(f"ğŸ“„ æå–åˆ°æŠ¥å‘Šè·¯å¾„: {pdf_path}")

                # âœ… æ›´æ–°å®ŒæˆçŠ¶æ€
                await session_manager.update(
                    session_id,
                    {
                        "status": "completed",
                        "progress": 1.0,
                        "final_report": final_report or "åˆ†æå®Œæˆ",
                        "pdf_path": pdf_path,
                    },
                )

                # âœ… è·å–æœ€æ–°ä¼šè¯æ•°æ®
                updated_session = await session_manager.get(session_id)

                # ğŸ”¥ å¹¿æ’­å®ŒæˆçŠ¶æ€ï¼ˆv7.120: åŒ…å«search_referencesï¼‰
                completion_broadcast = {
                    "type": "status_update",
                    "status": "completed",
                    "progress": 1.0,
                    "final_report": final_report or "åˆ†æå®Œæˆ",
                    "current_node": updated_session.get("current_node") if updated_session else None,
                    "detail": updated_session.get("detail") if updated_session else None,
                }

                # æ·»åŠ search_referencesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if updated_session and updated_session.get("search_references"):
                    completion_broadcast["search_references"] = updated_session["search_references"]
                    logger.info(f"ğŸ“š [v7.120] å®Œæˆå¹¿æ’­åŒ…å« {len(updated_session['search_references'])} ä¸ªæœç´¢å¼•ç”¨")

                await broadcast_to_websockets(session_id, completion_broadcast)

                # ğŸ†• æå–æœ€ç»ˆçŠ¶æ€ä½œä¸ºç»“æ„åŒ–ç»“æœï¼ˆä¾›get_analysis_resultä½¿ç”¨ï¼‰
                final_state = None
                challenge_detection = None
                challenge_handling = None

                if events:
                    # æœ€åä¸€ä¸ªäº‹ä»¶å¯èƒ½åŒ…å«å®Œæ•´çŠ¶æ€
                    last_event = events[-1] if events else {}
                    # å°è¯•ä»å„ä¸ªèŠ‚ç‚¹æå–çŠ¶æ€
                    for node_name, node_output in last_event.items():
                        if isinstance(node_output, dict):
                            if "agent_results" in node_output:
                                final_state = node_output
                            # ğŸ†• æå–æŒ‘æˆ˜æ£€æµ‹æ•°æ®
                            if "challenge_detection" in node_output:
                                challenge_detection = node_output["challenge_detection"]
                            if "challenge_handling" in node_output:
                                challenge_handling = node_output["challenge_handling"]

                    # å¦‚æœæœ€åä¸€ä¸ªäº‹ä»¶æ²¡æœ‰ï¼Œéå†æ‰€æœ‰äº‹ä»¶æŸ¥æ‰¾
                    if not challenge_detection:
                        for event in events:
                            for node_name, node_output in event.items():
                                if isinstance(node_output, dict):
                                    if "challenge_detection" in node_output and node_output["challenge_detection"]:
                                        challenge_detection = node_output["challenge_detection"]
                                        challenge_handling = node_output.get("challenge_handling")
                                        logger.info(f"ğŸ” ä» {node_name} æå–åˆ°æŒ‘æˆ˜æ£€æµ‹æ•°æ®")
                                        break
                            if challenge_detection:
                                break

                # âœ… ä¿å­˜æœ€ç»ˆçŠ¶æ€å’Œäº‹ä»¶ï¼ˆåŒ…å«æŒ‘æˆ˜æ£€æµ‹ï¼‰
                update_data = {"final_state": final_state, "results": events}
                if challenge_detection:
                    update_data["challenge_detection"] = challenge_detection
                    update_data["challenge_handling"] = challenge_handling
                    logger.info(f"âœ… ä¿å­˜æŒ‘æˆ˜æ£€æµ‹æ•°æ®: has_challenges={challenge_detection.get('has_challenges')}")

                await session_manager.update(session_id, update_data)

                # ğŸ†• v3.6æ–°å¢: è‡ªåŠ¨å½’æ¡£å®Œæˆçš„ä¼šè¯ï¼ˆæ°¸ä¹…ä¿å­˜ï¼‰
                if archive_manager:
                    try:
                        # è·å–å®Œæ•´ä¼šè¯æ•°æ®
                        final_session = await session_manager.get(session_id)
                        if final_session:
                            await archive_manager.archive_session(
                                session_id=session_id, session_data=final_session, force=False  # ä»…å½’æ¡£completedçŠ¶æ€çš„ä¼šè¯
                            )
                            logger.info(f"ğŸ“¦ ä¼šè¯å·²è‡ªåŠ¨å½’æ¡£ï¼ˆæ°¸ä¹…ä¿å­˜ï¼‰: {session_id}")
                    except Exception as archive_error:
                        # å½’æ¡£å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
                        logger.warning(f"âš ï¸ è‡ªåŠ¨å½’æ¡£å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {archive_error}")

        # ğŸ†• å¤„ç†é€’å½’é™åˆ¶é”™è¯¯
        except GraphRecursionError as e:
            logger.warning(f"âš ï¸ è¾¾åˆ°é€’å½’é™åˆ¶ï¼ä¼šè¯: {session_id}")
            logger.info("ğŸ“¦ å°è¯•è·å–æœ€ä½³ç»“æœ...")

            # è·å–å½“å‰çŠ¶æ€
            try:
                current_state = workflow.graph.get_state(config)
                state_values = current_state.values

                # å°è¯•è·å–æœ€ä½³ç»“æœ
                best_result = state_values.get("best_result")
                if best_result:
                    logger.info(f"âœ… æ‰¾åˆ°æœ€ä½³ç»“æœï¼ˆè¯„åˆ†{state_values.get('best_score', 0):.1f}ï¼‰")
                    # ä½¿ç”¨æœ€ä½³ç»“æœæ›´æ–°agent_results
                    state_values["agent_results"] = best_result
                    state_values["metadata"]["forced_completion"] = True
                    state_values["metadata"]["completion_reason"] = "è¾¾åˆ°é€’å½’é™åˆ¶ï¼Œä½¿ç”¨æœ€ä½³å†å²ç»“æœ"
                else:
                    logger.warning("âš ï¸ æœªæ‰¾åˆ°æœ€ä½³ç»“æœï¼Œä½¿ç”¨å½“å‰ç»“æœ")
                    state_values["metadata"]["forced_completion"] = True
                    state_values["metadata"]["completion_reason"] = "è¾¾åˆ°é€’å½’é™åˆ¶"

                # âœ… æ›´æ–°ä¸ºå®ŒæˆçŠ¶æ€
                await session_manager.update(
                    session_id,
                    {
                        "status": "completed",
                        "progress": 1.0,
                        "results": events,
                        "final_report": "åˆ†æå·²å®Œæˆï¼ˆè¾¾åˆ°é€’å½’é™åˆ¶ï¼‰",
                        "metadata": state_values.get("metadata", {}),
                    },
                )

            except Exception as state_error:
                logger.error(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {state_error}")
                import traceback

                await session_manager.update(
                    session_id,
                    {"status": "failed", "error": f"è¾¾åˆ°é€’å½’é™åˆ¶ä¸”æ— æ³•è·å–çŠ¶æ€: {str(e)}", "traceback": traceback.format_exc()},
                )

    except Exception as e:
        import traceback

        await session_manager.update(
            session_id, {"status": "failed", "error": str(e), "traceback": traceback.format_exc()}
        )


# ==================== API ç«¯ç‚¹ ====================


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {"message": "æ™ºèƒ½é¡¹ç›®åˆ†æç³»ç»Ÿ API", "version": "2.0.0", "docs": "/docs"}


@app.get("/api/rate-limit/stats")
async def get_rate_limit_stats():
    """
    è·å– LLM API é™æµç»Ÿè®¡

    v3.9æ–°å¢ï¼šç›‘æ§ LLM API è°ƒç”¨é™æµçŠ¶æ€
    """
    try:
        from intelligent_project_analyzer.services.rate_limiter import rate_limit_manager

        return {"status": "ok", "stats": rate_limit_manager.get_all_stats()}
    except Exception as e:
        return {"status": "error", "error": str(e), "message": "é™æµæ¨¡å—æœªåˆå§‹åŒ–"}


@app.get("/api/keys/stats")
async def get_api_key_stats():
    """
    è·å– API Key è´Ÿè½½å‡è¡¡ç»Ÿè®¡

    v3.9æ–°å¢ï¼šç›‘æ§å¤š Key ä½¿ç”¨çŠ¶æ€
    """
    try:
        from intelligent_project_analyzer.services.key_balancer import key_balancer

        return {
            "status": "ok",
            "available_providers": key_balancer.available_providers,
            "stats": key_balancer.get_all_stats(),
        }
    except Exception as e:
        return {"status": "error", "error": str(e), "message": "Key è´Ÿè½½å‡è¡¡å™¨æœªåˆå§‹åŒ–"}


@app.get("/health")
async def health_check():
    """
    ğŸ†• P2ä¼˜åŒ–: å¢å¼ºå¥åº·æ£€æŸ¥ç«¯ç‚¹ - è¿”å›è¯¦ç»†ç»„ä»¶çŠ¶æ€

    ç”¨äºè´Ÿè½½å‡è¡¡å™¨å’Œç›‘æ§ç³»ç»Ÿå¿«é€Ÿæ£€æŸ¥æœåŠ¡çŠ¶æ€
    è¿”å›å„ç»„ä»¶ï¼ˆRedis/Playwright/LLMï¼‰çš„å¥åº·çŠ¶æ€
    """
    import time

    start_time = time.time()

    health_status = {"status": "healthy", "timestamp": datetime.now().isoformat(), "components": {}, "metrics": {}}

    try:
        # 1. æ£€æŸ¥Redisè¿æ¥
        redis_healthy = False
        redis_latency = 0
        try:
            redis_start = time.time()
            await session_manager.redis_client.ping()
            redis_latency = (time.time() - redis_start) * 1000
            redis_healthy = True
            health_status["components"]["redis"] = {
                "status": "up",
                "latency_ms": round(redis_latency, 2),
                "mode": "redis",
            }
        except Exception as redis_err:
            health_status["components"]["redis"] = {
                "status": "degraded",
                "mode": "memory_fallback",
                "error": str(redis_err),
            }

        # 2. æ£€æŸ¥Playwrightæµè§ˆå™¨æ± 
        playwright_healthy = False
        try:
            from intelligent_project_analyzer.api.html_pdf_generator import get_browser_pool

            browser_pool = get_browser_pool()
            if browser_pool._initialized and browser_pool._browser:
                playwright_healthy = browser_pool._browser.is_connected()
                health_status["components"]["playwright"] = {
                    "status": "up" if playwright_healthy else "down",
                    "initialized": browser_pool._initialized,
                    "connected": playwright_healthy,
                }
            else:
                health_status["components"]["playwright"] = {
                    "status": "not_initialized",
                    "pdf_generation": "unavailable",
                }
        except Exception as pw_err:
            health_status["components"]["playwright"] = {"status": "error", "error": str(pw_err)}

        # 3. æ£€æŸ¥LLMé…ç½®
        llm_configured = False
        try:
            from intelligent_project_analyzer.settings import settings as app_settings

            api_key = app_settings.openai_api_key
            if api_key and api_key != "your-api-key-here":
                llm_configured = True
                health_status["components"]["llm"] = {"status": "configured", "provider": "openai"}
            else:
                health_status["components"]["llm"] = {"status": "not_configured", "warning": "OPENAI_API_KEY not set"}
        except Exception as llm_err:
            health_status["components"]["llm"] = {"status": "error", "error": str(llm_err)}

        # 4. ä¼šè¯ç»Ÿè®¡
        try:
            active_sessions = await session_manager.list_all_sessions()
            health_status["metrics"]["active_sessions"] = len(active_sessions)
            health_status["metrics"]["active_websockets"] = sum(len(conns) for conns in websocket_connections.values())
        except Exception:
            health_status["metrics"]["active_sessions"] = 0
            health_status["metrics"]["active_websockets"] = 0

        # 5. æ€»ä½“å¥åº·åˆ¤æ–­
        if not redis_healthy and not health_status["components"]["redis"].get("mode") == "memory_fallback":
            health_status["status"] = "degraded"
        if not llm_configured:
            health_status["status"] = "degraded"

        health_status["response_time_ms"] = round((time.time() - start_time) * 1000, 2)

        return health_status

    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "status": "unhealthy",
            "timestamp": datetime.now().isoformat(),
            "error": str(e),
            "response_time_ms": round((time.time() - start_time) * 1000, 2),
        }


@app.get("/api/debug/redis-health")
async def redis_health_check():
    """
    Redis å¥åº·æ£€æŸ¥ç«¯ç‚¹ - ç”¨äºè¯Šæ–­ Redis æ€§èƒ½é—®é¢˜

    æ‰§è¡Œå®Œæ•´çš„ CRUD æ“ä½œå¹¶è¿”å›å»¶è¿Ÿæ—¶é—´
    """
    import time

    start = time.time()

    try:
        test_id = f"test-health-{int(time.time())}"

        # æµ‹è¯• Create
        create_start = time.time()
        await session_manager.create(test_id, {"test": "data", "timestamp": datetime.now().isoformat()})
        create_time = (time.time() - create_start) * 1000

        # æµ‹è¯• Read
        read_start = time.time()
        data = await session_manager.get(test_id)
        read_time = (time.time() - read_start) * 1000

        # æµ‹è¯• Update
        update_start = time.time()
        await session_manager.update(test_id, {"test": "updated"})
        update_time = (time.time() - update_start) * 1000

        # æµ‹è¯• Delete
        delete_start = time.time()
        await session_manager.delete(test_id)
        delete_time = (time.time() - delete_start) * 1000

        total_time = (time.time() - start) * 1000

        return {
            "status": "healthy",
            "total_latency_ms": int(total_time),
            "operations": {
                "create_ms": int(create_time),
                "read_ms": int(read_time),
                "update_ms": int(update_time),
                "delete_ms": int(delete_time),
            },
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        elapsed = (time.time() - start) * 1000
        logger.error(f"âŒ Rediså¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "elapsed_ms": int(elapsed),
            "timestamp": datetime.now().isoformat(),
        }


@app.get("/readiness")
async def readiness_check():
    """
    å°±ç»ªæ£€æŸ¥ç«¯ç‚¹ - æ£€æŸ¥æœåŠ¡æ˜¯å¦å‡†å¤‡å¥½æ¥æ”¶æµé‡

    æ£€æŸ¥é¡¹ï¼š
    1. Redisè¿æ¥çŠ¶æ€
    2. è…¾è®¯äº‘APIå¯è¾¾æ€§
    3. åŠ¨æ€è§„åˆ™åŠ è½½å™¨çŠ¶æ€
    4. ä¼šè¯ç®¡ç†å™¨çŠ¶æ€
    """
    checks = {}
    is_ready = True

    # 1. æ£€æŸ¥Redisè¿æ¥
    try:
        if session_manager:
            # å°è¯•ping Redis
            await session_manager.list_all_sessions()
            checks["redis"] = {"status": "ok", "message": "Redisè¿æ¥æ­£å¸¸"}
        else:
            checks["redis"] = {"status": "warning", "message": "ä¼šè¯ç®¡ç†å™¨æœªåˆå§‹åŒ–"}
            is_ready = False
    except Exception as e:
        checks["redis"] = {"status": "error", "message": f"Redisè¿æ¥å¤±è´¥: {str(e)}"}
        is_ready = False

    # 2. æ£€æŸ¥è…¾è®¯äº‘APIå¯è¾¾æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    try:
        if os.getenv("ENABLE_TENCENT_CONTENT_SAFETY") == "true":
            from intelligent_project_analyzer.security.tencent_content_safety import get_tencent_content_safety_client

            client = get_tencent_content_safety_client()
            if client:
                checks["tencent_api"] = {"status": "ok", "message": "è…¾è®¯äº‘APIå·²é…ç½®"}
            else:
                checks["tencent_api"] = {"status": "warning", "message": "è…¾è®¯äº‘APIæœªå¯ç”¨"}
        else:
            checks["tencent_api"] = {"status": "disabled", "message": "è…¾è®¯äº‘APIæœªå¯ç”¨"}
    except Exception as e:
        checks["tencent_api"] = {"status": "error", "message": f"è…¾è®¯äº‘APIæ£€æŸ¥å¤±è´¥: {str(e)}"}
        # è…¾è®¯äº‘APIå¤±è´¥ä¸å½±å“å°±ç»ªçŠ¶æ€ï¼ˆå¯ä»¥é™çº§åˆ°æœ¬åœ°æ£€æµ‹ï¼‰

    # 3. æ£€æŸ¥åŠ¨æ€è§„åˆ™åŠ è½½å™¨çŠ¶æ€
    try:
        from intelligent_project_analyzer.security.dynamic_rule_loader import get_rule_loader

        loader = get_rule_loader()
        if loader:
            stats = loader.get_stats()
            checks["dynamic_rules"] = {
                "status": "ok",
                "message": "åŠ¨æ€è§„åˆ™åŠ è½½å™¨æ­£å¸¸",
                "version": stats.get("version", "unknown"),
                "categories": stats["keywords"]["total_categories"],
            }
        else:
            checks["dynamic_rules"] = {"status": "warning", "message": "åŠ¨æ€è§„åˆ™åŠ è½½å™¨æœªåˆå§‹åŒ–"}
    except Exception as e:
        checks["dynamic_rules"] = {"status": "error", "message": f"åŠ¨æ€è§„åˆ™æ£€æŸ¥å¤±è´¥: {str(e)}"}
        # åŠ¨æ€è§„åˆ™å¤±è´¥ä¸å½±å“å°±ç»ªçŠ¶æ€ï¼ˆå¯ä»¥å›é€€åˆ°é™æ€è§„åˆ™ï¼‰

    # 4. æ£€æŸ¥ä¼šè¯ç®¡ç†å™¨çŠ¶æ€
    try:
        if session_manager:
            checks["session_manager"] = {"status": "ok", "message": "ä¼šè¯ç®¡ç†å™¨æ­£å¸¸"}
        else:
            checks["session_manager"] = {"status": "error", "message": "ä¼šè¯ç®¡ç†å™¨æœªåˆå§‹åŒ–"}
            is_ready = False
    except Exception as e:
        checks["session_manager"] = {"status": "error", "message": f"ä¼šè¯ç®¡ç†å™¨æ£€æŸ¥å¤±è´¥: {str(e)}"}
        is_ready = False

    # 5. æ£€æŸ¥æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
    try:
        if file_processor:
            checks["file_processor"] = {"status": "ok", "message": "æ–‡ä»¶å¤„ç†å™¨æ­£å¸¸"}
        else:
            checks["file_processor"] = {"status": "warning", "message": "æ–‡ä»¶å¤„ç†å™¨æœªåˆå§‹åŒ–"}
    except Exception as e:
        checks["file_processor"] = {"status": "warning", "message": f"æ–‡ä»¶å¤„ç†å™¨æ£€æŸ¥å¤±è´¥: {str(e)}"}

    # æ„å»ºå“åº”
    response = {
        "status": "ready" if is_ready else "not_ready",
        "timestamp": datetime.now().isoformat(),
        "checks": checks,
    }

    # å¦‚æœä¸å°±ç»ªï¼Œè¿”å›503çŠ¶æ€ç 
    if not is_ready:
        return Response(
            content=json.dumps(response, ensure_ascii=False, indent=2), status_code=503, media_type="application/json"
        )

    return response


# ==================== ç”¨æˆ·éš”ç¦» API ====================


@app.get("/api/user/{user_id}/sessions")
async def get_user_sessions(user_id: str, limit: int = 10):
    """
    è·å–ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯

    v3.9æ–°å¢ï¼šç”¨æˆ·ä¼šè¯éš”ç¦»
    """
    try:
        from intelligent_project_analyzer.services.user_session_manager import get_user_session_manager

        manager = await get_user_session_manager()
        sessions = await manager.get_user_sessions(user_id, limit)
        return {"user_id": user_id, "sessions": sessions, "count": len(sessions)}
    except Exception as e:
        return {"error": str(e), "sessions": []}


@app.get("/api/user/{user_id}/progress")
async def get_user_all_progress(user_id: str):
    """
    è·å–ç”¨æˆ·æ‰€æœ‰ä¼šè¯çš„è¿›åº¦

    v3.9æ–°å¢ï¼šç”¨æˆ·ç‹¬ç«‹è¿›åº¦
    """
    try:
        from intelligent_project_analyzer.services.user_session_manager import get_user_session_manager

        manager = await get_user_session_manager()
        progress_list = await manager.get_all_user_progress(user_id)
        return {"user_id": user_id, "progress": progress_list}
    except Exception as e:
        return {"error": str(e), "progress": []}


@app.get("/api/user/{user_id}/quota")
async def get_user_quota(user_id: str):
    """
    è·å–ç”¨æˆ·é…é¢ä¿¡æ¯

    v3.9æ–°å¢ï¼šç”¨æˆ·é…é¢ç®¡ç†
    """
    try:
        from intelligent_project_analyzer.services.user_session_manager import get_user_session_manager

        manager = await get_user_session_manager()
        quota = await manager.check_user_quota(user_id)
        usage = await manager.get_user_usage(user_id)
        return {**quota, **usage}
    except Exception as e:
        return {"error": str(e)}


@app.get("/api/user/{user_id}/active")
async def get_user_active_session(user_id: str):
    """
    è·å–ç”¨æˆ·å½“å‰æ´»è·ƒä¼šè¯

    v3.9æ–°å¢ï¼šå¿«é€Ÿè·å–ç”¨æˆ·æ­£åœ¨è¿›è¡Œçš„åˆ†æ
    """
    try:
        from intelligent_project_analyzer.services.user_session_manager import get_user_session_manager

        manager = await get_user_session_manager()
        active_session_id = await manager.get_user_active_session(user_id)

        if active_session_id:
            progress = await manager.get_progress(user_id, active_session_id)
            return {
                "user_id": user_id,
                "active_session_id": active_session_id,
                "progress": progress.to_dict() if progress else None,
            }

        return {"user_id": user_id, "active_session_id": None, "message": "æ²¡æœ‰æ´»è·ƒä¼šè¯"}
    except Exception as e:
        return {"error": str(e)}


@app.get("/api/debug/sessions")
async def debug_sessions():
    """è°ƒè¯•ï¼šåˆ—å‡ºæ‰€æœ‰æ´»è·ƒä¼šè¯"""
    all_sessions = await session_manager.get_all_sessions()
    return {
        "active_sessions": [s["session_id"] for s in all_sessions],
        "session_details": {
            s["session_id"]: {
                "status": s.get("status"),
                "current_node": s.get("current_node"),
                "has_interrupt": s.get("interrupt_data") is not None,
            }
            for s in all_sessions
        },
    }


@app.get("/api/debug/redis")
async def check_redis_status():
    """
    è°ƒè¯•ï¼šæ£€æŸ¥Redisè¿æ¥çŠ¶æ€å’Œé…ç½®

    v3.6æ–°å¢ï¼šç”¨äºè¯Šæ–­ä¼šè¯å†å²ä¸ç¨³å®šé—®é¢˜
    """
    try:
        if session_manager._memory_mode:
            return {
                "mode": "memory",
                "status": "fallback",
                "warning": "Redisä¸å¯ç”¨ï¼Œä½¿ç”¨å†…å­˜æ¨¡å¼ï¼ˆæ•°æ®ä¸æŒä¹…åŒ–ï¼‰",
                "sessions_in_memory": len(session_manager._memory_sessions),
                "redis_url": session_manager.redis_url,
                "ttl": session_manager.SESSION_TTL,
            }

        # æµ‹è¯•Redisè¿æ¥
        await session_manager.redis_client.ping()
        session_keys = await session_manager.list_all_sessions()

        # è·å–Redisé…ç½®
        redis_info = await session_manager.redis_client.info("persistence")

        return {
            "mode": "redis",
            "status": "connected",
            "redis_url": session_manager.redis_url,
            "session_count": len(session_keys),
            "session_ttl": f"{session_manager.SESSION_TTL}ç§’ ({session_manager.SESSION_TTL // 3600}å°æ—¶)",
            "persistence": {
                "rdb_enabled": redis_info.get("rdb_bgsave_in_progress", "unknown"),
                "aof_enabled": redis_info.get("aof_enabled", "unknown"),
                "last_save_time": redis_info.get("rdb_last_save_time", "unknown"),
            },
            "recommendation": "âœ… Rediså·²è¿æ¥ï¼Œä¼šè¯æ•°æ®æŒä¹…åŒ–å­˜å‚¨"
            if redis_info.get("aof_enabled") == "1"
            else "âš ï¸ å»ºè®®å¯ç”¨AOFæŒä¹…åŒ–ä»¥é˜²æ­¢æ•°æ®ä¸¢å¤±",
        }
    except Exception as e:
        return {"mode": "error", "status": "failed", "error": str(e), "recommendation": "âŒ Redisè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥RedisæœåŠ¡æ˜¯å¦è¿è¡Œ"}


@app.post("/api/analysis/start", response_model=SessionResponse)
async def start_analysis(
    request: Request,  # ğŸŒ ç”¨äºIPé‡‡é›†
    analysis_request: AnalysisRequest,
    background_tasks: BackgroundTasks,
    current_user: Optional[dict] = Depends(optional_auth),  # ğŸ†• å¯é€‰JWTè®¤è¯
):
    """
    å¼€å§‹åˆ†æï¼ˆä»… Dynamic Modeï¼‰

    åˆ›å»ºæ–°çš„åˆ†æä¼šè¯å¹¶åœ¨åå°æ‰§è¡Œå·¥ä½œæµ

    ğŸ†• v7.39: æ”¯æŒ analysis_mode å‚æ•°
    - normal: æ™®é€šæ¨¡å¼ï¼Œé›†ä¸­ç”Ÿæˆ2-3å¼ æ¦‚å¿µå›¾
    - deep_thinking: æ·±åº¦æ€è€ƒæ¨¡å¼ï¼Œæ¯ä¸ªä¸“å®¶éƒ½ç”Ÿæˆå¯¹åº”çš„æ¦‚å¿µå›¾

    ğŸ†• v7.130: æ”¯æŒJWTè®¤è¯è·å–çœŸå®WordPressç”¨æˆ·ä¿¡æ¯
    """
    print(f"\nğŸ“¥ æ”¶åˆ°åˆ†æè¯·æ±‚")
    print(f"ç”¨æˆ·è¾“å…¥: {analysis_request.user_input[:100]}...")
    print(f"åˆ†ææ¨¡å¼: {analysis_request.analysis_mode}")  # ğŸ†• v7.39

    # ğŸ†• v7.131: å®Œå…¨ä¾èµ–JWTè®¤è¯ï¼Œå¿½ç•¥å‰ç«¯ä¼ å…¥çš„user_id
    # è¿™æ ·å¯ä»¥é˜²æ­¢å‰ç«¯ä¼ªé€ ç”¨æˆ·èº«ä»½ï¼Œç¡®ä¿ä¼šè¯ç®¡ç†æ˜¾ç¤ºæ­£ç¡®çš„ç”¨æˆ·
    actual_user_id = "guest"  # é»˜è®¤æœªè®¤è¯ç”¨æˆ·
    username = None
    display_name = None

    # ğŸŒ é‡‡é›†IPåœ°å€å’Œåœ°ç†ä½ç½®
    geoip_service = get_geoip_service()
    client_ip = geoip_service.get_client_ip(request)
    location_info = geoip_service.get_location(client_ip)

    logger.info(f"ğŸŒ å®¢æˆ·ç«¯IP: {client_ip} -> {location_info.get('country')}/{location_info.get('city')}")

    if current_user:
        # ç”¨æˆ·å·²é€šè¿‡JWTè®¤è¯ï¼Œä½¿ç”¨JWTä¸­çš„ç”¨æˆ·ä¿¡æ¯ï¼ˆä¼˜å…ˆ sub ä½œä¸ºç”¨æˆ·åï¼‰
        resolved_username = current_user.get("sub") or current_user.get("username")
        actual_user_id = resolved_username or str(current_user.get("user_id", "guest"))
        username = resolved_username
        display_name = current_user.get("name") or current_user.get("display_name") or username
        logger.info(f"âœ… JWTè®¤è¯ç”¨æˆ·: {username} ({display_name})")
    else:
        # æœªè®¤è¯ç”¨æˆ·ï¼Œä½¿ç”¨guestæ ‡è¯†
        logger.info(f"â„¹ï¸ æœªè®¤è¯è®¿å®¢ç”¨æˆ·ï¼Œä½¿ç”¨ID: guest")

    # ğŸ“Š v7.110: æ·»åŠ æ¨¡å¼ä½¿ç”¨ç»Ÿè®¡æ—¥å¿—
    logger.info(f"ğŸ“Š [æ¨¡å¼ç»Ÿè®¡] ç”¨æˆ· {actual_user_id} " f"é€‰æ‹© {analysis_request.analysis_mode} æ¨¡å¼")

    print(f"è¿è¡Œæ¨¡å¼: Dynamic Mode")

    # è¾“å…¥å®ˆå«ï¼šç©ºå­—ç¬¦ä¸²ç›´æ¥æ‹’ç»ï¼ˆé¿å…åˆ›å»ºæ— æ„ä¹‰ä¼šè¯ï¼‰
    if not analysis_request.user_input or not analysis_request.user_input.strip():
        raise HTTPException(status_code=400, detail="requirement/user_input ä¸èƒ½ä¸ºç©º")

    sm = await _get_session_manager()

    # ç”Ÿæˆä¼šè¯ IDï¼ˆä½¿ç”¨çœŸå®ç”¨æˆ·æ ‡è¯†ï¼‰
    session_id = f"{actual_user_id}-{datetime.now().strftime('%Y%m%d%H%M%S')}-{uuid.uuid4().hex[:8]}"
    print(f"ç”Ÿæˆ Session ID: {session_id}")

    # âœ… ä½¿ç”¨ Redis åˆ›å»ºä¼šè¯
    session_data = {
        "session_id": session_id,
        "user_id": actual_user_id,  # ğŸ†• v7.130: çœŸå®ç”¨æˆ·ID
        "user_input": analysis_request.user_input,
        "mode": "dynamic",
        "analysis_mode": analysis_request.analysis_mode,  # ğŸ†• v7.39: åˆ†ææ¨¡å¼
        "status": "initializing",
        "progress": 0.0,
        "events": [],
        "interrupt_data": None,
        "current_node": None,
        "error": None,
        "created_at": datetime.now().isoformat(),
        "metadata": {  # ğŸŒ æ·»åŠ å…ƒæ•°æ®
            "client_ip": client_ip,
            "location": location_info.get("city", "æœªçŸ¥"),
            "geo_info": location_info,
            "user_agent": request.headers.get("User-Agent", ""),
        },
    }

    # ğŸ†• v7.130: æ·»åŠ ç”¨æˆ·è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰JWTè®¤è¯ï¼‰
    if username:
        session_data["username"] = username
    if display_name:
        session_data["display_name"] = display_name

    await sm.create(session_id, session_data)

    # ğŸ”¥ v7.120 P1: ä½¿ç¼“å­˜å¤±æ•ˆ
    sessions_cache.invalidate(f"sessions:{actual_user_id}")

    print(f"âœ… ä¼šè¯çŠ¶æ€å·²åˆå§‹åŒ–ï¼ˆRedisï¼‰")

    # åœ¨åå°æ‰§è¡Œå·¥ä½œæµ
    print(f"ğŸ“¤ æ·»åŠ åå°ä»»åŠ¡...")
    background_tasks.add_task(run_workflow_async, session_id, analysis_request.user_input)

    print(f"âœ… åå°ä»»åŠ¡å·²æ·»åŠ ï¼Œè¿”å›å“åº”\n")

    return SessionResponse(session_id=session_id, status="pending", message="åˆ†æå·²å¼€å§‹ï¼Œè¯·ä½¿ç”¨ session_id æŸ¥è¯¢çŠ¶æ€")


@app.post("/api/analysis/start-with-files", response_model=SessionResponse)
async def start_analysis_with_files(
    background_tasks: BackgroundTasks,  # ğŸ”¥ ä¿®å¤ï¼šç§»åˆ°å‰é¢ï¼Œç§»é™¤é»˜è®¤å€¼
    user_input: str = Form(default=""),
    requirement: str = Form(default=""),  # å…¼å®¹æ—§å‰ç«¯å­—æ®µå
    user_id: str = Form(default="web_user"),
    analysis_mode: str = Form(default="normal"),  # ğŸ†• v7.39: åˆ†ææ¨¡å¼
    files: List[UploadFile] = File(default=[]),
    current_user: Optional[dict] = Depends(optional_auth),  # ğŸ†• v7.130: å¯é€‰JWTè®¤è¯
):
    """
    ğŸ†• v3.7: æ”¯æŒå¤šæ¨¡æ€è¾“å…¥çš„åˆ†ææ¥å£

    æ¥å—æ–‡æœ¬ + å¤šä¸ªæ–‡ä»¶ï¼ˆPDF, TXT, å›¾ç‰‡ï¼‰

    ğŸ†• v7.39: æ”¯æŒ analysis_mode å‚æ•°
    - normal: æ™®é€šæ¨¡å¼ï¼Œé›†ä¸­ç”Ÿæˆ2-3å¼ æ¦‚å¿µå›¾
    - deep_thinking: æ·±åº¦æ€è€ƒæ¨¡å¼ï¼Œæ¯ä¸ªä¸“å®¶éƒ½ç”Ÿæˆå¯¹åº”çš„æ¦‚å¿µå›¾

    Args:
        user_input: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬æè¿°
        user_id: ç”¨æˆ·ID
        analysis_mode: åˆ†ææ¨¡å¼ (normal/deep_thinking)
        files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
        background_tasks: åå°ä»»åŠ¡ç®¡ç†å™¨

    Returns:
        ä¼šè¯å“åº”
    """
    logger.info(f"\nğŸ“¥ æ”¶åˆ°å¤šæ¨¡æ€åˆ†æè¯·æ±‚")
    logger.info(f"ç”¨æˆ·è¾“å…¥: {user_input[:100] if user_input else '(æ— æ–‡æœ¬)'}...")
    logger.info(f"åˆ†ææ¨¡å¼: {analysis_mode}")  # ğŸ†• v7.39
    logger.info(f"æ–‡ä»¶æ•°é‡: {len(files)}")

    # ğŸ†• v7.131: å®Œå…¨ä¾èµ–JWTè®¤è¯ï¼Œå¿½ç•¥å‰ç«¯ä¼ å…¥çš„user_id
    actual_user_id = "guest"  # é»˜è®¤æœªè®¤è¯ç”¨æˆ·
    username = None
    display_name = None

    if current_user:
        resolved_username = current_user.get("sub") or current_user.get("username")
        actual_user_id = resolved_username or str(current_user.get("user_id", "guest"))
        username = resolved_username
        display_name = current_user.get("name") or current_user.get("display_name") or username
        logger.info(f"âœ… JWTè®¤è¯ç”¨æˆ·: {username} ({display_name})")
    else:
        logger.info(f"â„¹ï¸ æœªè®¤è¯è®¿å®¢ç”¨æˆ·ï¼Œä½¿ç”¨ID: guest")

    # 1. éªŒè¯è¾“å…¥
    if not user_input.strip() and not files:
        raise HTTPException(status_code=400, detail="è¯·æä¾›æ–‡æœ¬è¾“å…¥æˆ–ä¸Šä¼ æ–‡ä»¶")

    # 2. ç”Ÿæˆä¼šè¯ IDï¼ˆä½¿ç”¨çœŸå®ç”¨æˆ·æ ‡è¯†ï¼‰
    session_id = f"{actual_user_id}-{datetime.now().strftime('%Y%m%d%H%M%S')}-{uuid.uuid4().hex[:8]}"
    logger.info(f"ç”Ÿæˆ Session ID: {session_id}")

    # 3. ä¿å­˜å¹¶å¤„ç†æ–‡ä»¶
    file_contents = []
    attachment_metadata = []

    for file in files:
        try:
            # éªŒè¯æ–‡ä»¶å¤§å° (10MBé™åˆ¶)
            content = await file.read()
            file_size = len(content)

            if file_size > 10 * 1024 * 1024:
                logger.warning(f"âš ï¸ æ–‡ä»¶è¿‡å¤§ï¼Œè·³è¿‡: {file.filename} ({file_size} bytes)")
                continue

            # ä¿å­˜æ–‡ä»¶
            file_path = await file_processor.save_file(
                file_content=content, filename=file.filename, session_id=session_id
            )

            # æå–å†…å®¹
            extracted_content = await file_processor.extract_content(
                file_path=file_path, content_type=file.content_type
            )
            file_contents.append(extracted_content)

            # ä¿å­˜å…ƒæ•°æ®
            attachment_metadata.append(
                {
                    "filename": file.filename,
                    "content_type": file.content_type,
                    "size": file_size,
                    "path": str(file_path),
                    "extracted_summary": extracted_content.get("summary", ""),
                    "extraction_error": extracted_content.get("error", None),
                }
            )

            logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {file.filename} - {extracted_content.get('summary', '')}")

        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {file.filename} - {str(e)}")
            attachment_metadata.append({"filename": file.filename, "content_type": file.content_type, "error": str(e)})

    # 4. åˆå¹¶ç”¨æˆ·è¾“å…¥å’Œæ–‡ä»¶å†…å®¹
    # å…¼å®¹ï¼šå¦‚æœå‰ç«¯ä¼ çš„æ˜¯ requirement å­—æ®µï¼Œåˆ™æ˜ å°„åˆ° user_input
    effective_user_input = user_input or requirement
    if not effective_user_input and not files:
        raise HTTPException(status_code=400, detail="user_input/requirement æˆ– files è‡³å°‘æä¾›ä¸€ä¸ª")

    combined_input = build_combined_input(effective_user_input, file_contents)

    logger.info(f"âœ… å†…å®¹åˆå¹¶å®Œæˆ: æœ€ç»ˆè¾“å…¥é•¿åº¦ {len(combined_input)} å­—ç¬¦")

    # 5. åˆ›å»ºä¼šè¯ï¼ˆå¢å¼ºçŠ¶æ€ï¼‰
    sm = await _get_session_manager()
    session_data = {
        "session_id": session_id,
        "user_id": actual_user_id,  # ğŸ†• v7.130: çœŸå®ç”¨æˆ·ID
        "user_input": effective_user_input,  # åŸå§‹æ–‡æœ¬
        "combined_input": combined_input,  # ğŸ”¥ åˆå¹¶åçš„è¾“å…¥
        "attachments": attachment_metadata,  # ğŸ”¥ é™„ä»¶å…ƒæ•°æ®
        "mode": "dynamic",
        "analysis_mode": analysis_mode,  # ğŸ†• v7.39: åˆ†ææ¨¡å¼
        "status": "initializing",
        "progress": 0.0,
        "events": [],
        "interrupt_data": None,
        "current_node": None,
        "error": None,
        "created_at": datetime.now().isoformat(),
    }

    # ğŸ†• v7.130: æ·»åŠ ç”¨æˆ·è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰JWTè®¤è¯ï¼‰
    if username:
        session_data["username"] = username
    if display_name:
        session_data["display_name"] = display_name

    await sm.create(session_id, session_data)

    logger.info(f"âœ… ä¼šè¯çŠ¶æ€å·²åˆå§‹åŒ–ï¼ˆRedis + æ–‡ä»¶ï¼‰")

    # 6. å¯åŠ¨å·¥ä½œæµï¼ˆä¼ å…¥ combined_inputï¼‰
    background_tasks.add_task(run_workflow_async, session_id, combined_input)  # ğŸ”¥ ä½¿ç”¨å¢å¼ºåçš„è¾“å…¥

    logger.info(f"âœ… åå°ä»»åŠ¡å·²æ·»åŠ \n")

    return SessionResponse(session_id=session_id, status="pending", message=f"åˆ†æå·²å¼€å§‹ï¼Œå·²æ¥æ”¶ {len(files)} ä¸ªæ–‡ä»¶")


@app.get("/api/analysis/status/{session_id}", response_model=AnalysisStatus)
async def get_analysis_status(
    session_id: str,
    extend_ttl: bool = False,
    include_history: bool = Query(False, description="æ˜¯å¦åŒ…å«å®Œæ•´historyï¼ˆå½±å“æ€§èƒ½ï¼‰"),  # ğŸ”¥ v7.120 P1
):
    """
    è·å–åˆ†æçŠ¶æ€

    æŸ¥è¯¢æŒ‡å®šä¼šè¯çš„å½“å‰çŠ¶æ€å’Œè¿›åº¦

    Args:
        session_id: ä¼šè¯ID
        extend_ttl: æ˜¯å¦å»¶é•¿TTLï¼ˆé»˜è®¤Falseï¼Œé¿å…é¢‘ç¹è½®è¯¢æ—¶è¿‡åº¦ç»­æœŸï¼‰
        include_history: æ˜¯å¦åŒ…å«å®Œæ•´historyï¼ˆé»˜è®¤Falseï¼Œå‡å°‘åºåˆ—åŒ–å¼€é”€ï¼‰ğŸ”¥ v7.120 P1ä¼˜åŒ–

    ğŸ”¥ v7.120 P1ä¼˜åŒ–: é»˜è®¤ä¸è¿”å›historyå­—æ®µï¼Œé¢„æœŸæ€§èƒ½æå‡: 2.03sâ†’0.5s
    """
    # âœ… ä½¿ç”¨ Redis è¯»å–ä¼šè¯
    sm = await _get_session_manager()
    session = await sm.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    # âœ… Fix 2.5: ä»…åœ¨æ˜ç¡®è¯·æ±‚æ—¶æ‰ç»­æœŸTTLï¼ˆå‡å°‘95% Redisè´Ÿè½½ï¼‰
    if extend_ttl:
        await sm.extend_ttl(session_id)

    # ğŸ†• v7.119: æ£€æŸ¥ waiting_for_input çŠ¶æ€çš„è¶…æ—¶
    if session["status"] == "waiting_for_input":
        import time

        interrupt_timestamp = session.get("interrupt_timestamp")
        if interrupt_timestamp:
            elapsed_minutes = (time.time() - interrupt_timestamp) / 60

            # è¶…è¿‡15åˆ†é’Ÿå‘é€WebSocketæé†’
            if elapsed_minutes > 15 and not session.get("timeout_reminder_sent"):
                logger.warning(f"â° Session {session_id} ç­‰å¾…ç”¨æˆ·è¾“å…¥å·²è¶…è¿‡15åˆ†é’Ÿ")
                await broadcast_to_websockets(
                    session_id,
                    {
                        "type": "status_update",
                        "status": "waiting_for_input",
                        "message": "âš ï¸ ç³»ç»Ÿå·²ç­‰å¾…æ‚¨çš„ç¡®è®¤è¶…è¿‡15åˆ†é’Ÿï¼Œè¯·åŠæ—¶å“åº”",
                        "detail": "è¶…æ—¶æé†’",
                    },
                )
                await sm.update(session_id, {"timeout_reminder_sent": True})

            # è¶…è¿‡30åˆ†é’Ÿè‡ªåŠ¨æ ‡è®°ä¸ºtimeout
            if elapsed_minutes > 30:
                logger.error(f"âŒ Session {session_id} ç­‰å¾…ç”¨æˆ·è¾“å…¥è¶…æ—¶ï¼ˆ30åˆ†é’Ÿï¼‰")
                await sm.update(session_id, {"status": "timeout", "error": "ç”¨æˆ·æœªåœ¨30åˆ†é’Ÿå†…å“åº”ï¼Œä¼šè¯å·²è¶…æ—¶", "detail": "ä¼šè¯è¶…æ—¶"})
                session["status"] = "timeout"
                session["error"] = "ç”¨æˆ·æœªåœ¨30åˆ†é’Ÿå†…å“åº”ï¼Œä¼šè¯å·²è¶…æ—¶"

    return AnalysisStatus(
        session_id=session_id,
        status=session["status"],
        current_stage=session.get("current_node"),
        detail=session.get("detail"),  # ğŸ”¥ æ–°å¢ï¼šè¿”å›è¯¦ç»†ä¿¡æ¯
        progress=session["progress"],
        history=session.get("history", []) if include_history else [],  # ğŸ”¥ v7.120 P1: æŒ‰éœ€è¿”å›
        interrupt_data=session.get("interrupt_data"),
        error=session.get("error"),
        traceback=session.get("traceback"),  # è¿”å›tracebackç”¨äºè°ƒè¯•
        rejection_message=session.get("rejection_message"),  # ğŸ†• è¿”å›æ‹’ç»æç¤º
        user_input=session.get("user_input"),  # ğŸ”¥ v7.37.7: è¿”å›ç”¨æˆ·åŸå§‹è¾“å…¥
    )


@app.post("/api/analysis/resume", response_model=SessionResponse)
async def resume_analysis(request: ResumeRequest, background_tasks: BackgroundTasks):
    """
    æ¢å¤åˆ†æ

    åœ¨ interrupt åæä¾›ç”¨æˆ·è¾“å…¥å¹¶ç»§ç»­æ‰§è¡Œ
    """
    session_id = request.session_id

    sm = await _get_session_manager()

    # âœ… è·å–æ´»è·ƒä¼šè¯åˆ—è¡¨
    active_sessions = await sm.list_all_sessions()

    logger.info(f"ğŸ“¨ æ”¶åˆ° resume è¯·æ±‚: session_id={session_id}")
    logger.info(f"   resume_value: {request.resume_value}")
    logger.info(f"   å½“å‰æ´»è·ƒä¼šè¯: {active_sessions}")

    # âœ… æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
    session = await sm.get(session_id)
    if not session:
        logger.error(f"âŒ ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        logger.error(f"   å¯ç”¨ä¼šè¯: {active_sessions}")
        raise HTTPException(status_code=404, detail=f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")

    # å…¼å®¹ï¼šå†å²æ•°æ®/æ—§å®ç°å¯èƒ½ä½¿ç”¨ interrupted è¡¨ç¤ºç­‰å¾…ç”¨æˆ·è¾“å…¥
    if session.get("status") not in {"waiting_for_input", "interrupted"}:
        raise HTTPException(status_code=400, detail=f"ä¼šè¯çŠ¶æ€ä¸æ­£ç¡®: {session.get('status')}")

    # è·å–å·¥ä½œæµ
    workflow = workflows.get(session_id)
    if not workflow:
        logger.error(f"âŒ å·¥ä½œæµå®ä¾‹ä¸å­˜åœ¨: {session_id}")
        logger.error(f"   è¿™é€šå¸¸å‘ç”Ÿåœ¨æœåŠ¡å™¨é‡å¯åï¼Œå·¥ä½œæµæ— æ³•ç»§ç»­")
        logger.error(f"   å»ºè®®ï¼šä½¿ç”¨æŒä¹…åŒ–çš„æ£€æŸ¥ç‚¹å­˜å‚¨ï¼ˆå¦‚SqliteSaverï¼‰è€ŒéMemorySaver")

        # ğŸ”§ DEV_MODEï¼šæµ‹è¯•/æœ¬åœ°è°ƒè¯•æ—¶ï¼Œä¸ç”¨ 410 ç›´æ¥é˜»å¡ï¼ˆå•æµ‹åªå…³æ³¨ API æ˜¯å¦å¯ç”¨ï¼‰
        if DEV_MODE:
            # DEV_MODE ä¸‹å°½é‡ä¸ä¾èµ– Redis åˆ†å¸ƒå¼é”æ›´æ–°ï¼ˆæµ‹è¯•ç¯å¢ƒ mock redis_client ä¸ä¸€å®šæ”¯æŒ Lockï¼‰
            try:
                await sm.update(session_id, {"status": "running", "interrupt_data": None})
            except Exception:
                pass
            return SessionResponse(
                session_id=session_id, status="processing", message="æ¢å¤è¯·æ±‚å·²æ¥æ”¶ï¼ˆDEV_MODE ä¸‹è·³è¿‡ workflow å®ä¾‹æ ¡éªŒï¼‰"
            )

        raise HTTPException(
            status_code=410, detail="å·¥ä½œæµå·²å¤±æ•ˆï¼Œè¯·é‡æ–°å¼€å§‹åˆ†æã€‚å¦‚æœé—®é¢˜æŒç»­å‡ºç°ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚"  # 410 Gone - resource no longer available
        )

    # æ›´æ–°çŠ¶æ€
    logger.debug(f"[DEBUG] Resume request for session {session_id}")
    logger.debug(f"[DEBUG] resume_value type: {type(request.resume_value)}")
    logger.debug(f"[DEBUG] resume_value content: {request.resume_value}")

    # ğŸ”¥ v7.119: ç«‹å³æ›´æ–° Redis çŠ¶æ€ä¸º runningï¼Œæ¸…é™¤è¶…æ—¶ç›¸å…³å­—æ®µ
    await sm.update(
        session_id,
        {
            "status": "running",
            "interrupt_data": None,
            "interrupt_timestamp": None,  # æ¸…é™¤è¶…æ—¶æ—¶é—´æˆ³
            "timeout_reminder_sent": None,  # æ¸…é™¤æé†’æ ‡è®°
        },
    )

    # æ›´æ–°æœ¬åœ° session å¯¹è±¡ï¼ˆè™½ç„¶ continue_workflow ä½¿ç”¨çš„æ˜¯é—­åŒ…ä¸­çš„ sessionï¼Œä½†ä¸ºäº†ä¿é™©èµ·è§ï¼‰
    session["status"] = "running"
    session["interrupt_data"] = None

    # ç»§ç»­æ‰§è¡Œå·¥ä½œæµ
    async def continue_workflow():
        # ğŸ†• å¯¼å…¥GraphRecursionError
        from langgraph.errors import GraphRecursionError

        try:
            config = {"configurable": {"thread_id": session_id}, "recursion_limit": 100}  # å¢åŠ é€’å½’é™åˆ¶ï¼Œé»˜è®¤æ˜¯25

            logger.info(f"[DEBUG] Resuming workflow with Command(resume={request.resume_value})")

            # ä½¿ç”¨ Command(resume) ç»§ç»­æ‰§è¡Œ
            # ä¸æŒ‡å®š stream_modeï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼ä»¥æ­£ç¡®æ¥æ”¶ __interrupt__
            async for chunk in workflow.graph.astream(Command(resume=request.resume_value), config):
                logger.debug(f"[DEBUG] Resume stream chunk keys: {chunk.keys()}")

                # ğŸ”¥ æ›´æ–°å½“å‰èŠ‚ç‚¹å’Œè¯¦ç»†ä¿¡æ¯
                for node_name, node_output in chunk.items():
                    if node_name != "__interrupt__":
                        session["current_node"] = node_name
                        detail = ""
                        if isinstance(node_output, dict):
                            if "current_stage" in node_output:
                                detail = node_output["current_stage"]
                            elif "status" in node_output:
                                detail = node_output["status"]
                        session["detail"] = detail
                        logger.debug(f"[PROGRESS] èŠ‚ç‚¹: {node_name}, è¯¦æƒ…: {detail}")

                session["events"].append(chunk)
                # ğŸ¯ v7.21: èŠ‚ç‚¹æ˜ å°„ä¸ main_workflow.py å¯¹é½
                current_node = session.get("current_node", "")
                node_progress_map = {
                    "unified_input_validator_initial": 0.05,
                    "unified_input_validator_secondary": 0.10,
                    "requirements_analyst": 0.15,
                    "feasibility_analyst": 0.20,
                    "calibration_questionnaire": 0.25,
                    "requirements_confirmation": 0.35,
                    "project_director": 0.40,
                    "role_task_unified_review": 0.45,
                    "quality_preflight": 0.50,
                    "batch_executor": 0.55,
                    "agent_executor": 0.70,
                    "batch_aggregator": 0.75,
                    "batch_router": 0.76,
                    "batch_strategy_review": 0.78,
                    "detect_challenges": 0.80,
                    "analysis_review": 0.85,
                    "result_aggregator": 0.90,
                    "report_guard": 0.95,
                    "pdf_generator": 0.98,
                }
                session["progress"] = node_progress_map.get(current_node, min(0.9, len(session["events"]) * 0.1))

                # ğŸ”„ ç¡®ä¿ Redis å’Œ WebSocket åŸå­æ€§åŒæ­¥
                # 1. å…ˆæ›´æ–° Redis
                await session_manager.update(
                    session_id,
                    {
                        "status": session["status"],
                        "progress": session["progress"],
                        "current_node": current_node,
                        "detail": session.get("detail"),
                        "events": session["events"],
                    },
                )

                # 2. åŸºäºæœ€æ–° Redis æ•°æ®å¹¿æ’­ WebSocket
                updated_session = await session_manager.get(session_id)
                if updated_session:
                    await broadcast_to_websockets(
                        request.session_id,
                        {
                            "type": "status_update",
                            "status": updated_session["status"],
                            "progress": updated_session["progress"],
                            "current_node": updated_session.get("current_node"),
                            "detail": updated_session.get("detail"),
                        },
                    )

                # æ£€æŸ¥æ˜¯å¦åˆæœ‰ interrupt - interrupt ä½œä¸ºç‹¬ç«‹çš„ chunk è¿”å›
                if "__interrupt__" in chunk:
                    # æå– interrupt æ•°æ®
                    interrupt_tuple = chunk["__interrupt__"]
                    # interrupt_tuple æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ Interrupt å¯¹è±¡
                    if interrupt_tuple:
                        interrupt_obj = interrupt_tuple[0] if isinstance(interrupt_tuple, tuple) else interrupt_tuple

                        # æå– interrupt çš„ value
                        interrupt_value = None
                        if hasattr(interrupt_obj, "value"):
                            interrupt_value = interrupt_obj.value
                        else:
                            interrupt_value = interrupt_obj

                        session["status"] = "waiting_for_input"
                        session["interrupt_data"] = interrupt_value
                        session["current_node"] = "interrupt"

                        # ğŸ”¥ å¹¿æ’­ interrupt åˆ° WebSocket
                        await broadcast_to_websockets(
                            request.session_id,
                            {"type": "interrupt", "status": "waiting_for_input", "interrupt_data": interrupt_value},
                        )

                        # ğŸ”¥ æ›´æ–° Redis ä¸­çš„ interrupt çŠ¶æ€
                        await session_manager.update(
                            session_id,
                            {
                                "status": "waiting_for_input",
                                "interrupt_data": interrupt_value,
                                "current_node": "interrupt",
                            },
                        )

                        logger.info(
                            f"ğŸ“¡ å·²å¹¿æ’­ç¬¬äºŒä¸ª interrupt åˆ° WebSocket: {interrupt_value.get('interaction_type', 'unknown') if isinstance(interrupt_value, dict) else type(interrupt_value)}"
                        )
                        return

            # æ£€æŸ¥æ˜¯å¦æœ‰èŠ‚ç‚¹é”™è¯¯
            has_error = False
            error_message = None
            for event in session["events"]:
                for node_name, node_output in event.items():
                    if isinstance(node_output, dict):
                        if node_output.get("error") or node_output.get("status") == "error":
                            has_error = True
                            error_message = node_output.get("error", f"èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥")
                            break
                if has_error:
                    break

            # æ ¹æ®æ˜¯å¦æœ‰é”™è¯¯è®¾ç½®çŠ¶æ€
            if has_error:
                session["status"] = "failed"
                session["error"] = error_message
                logger.error(f"å·¥ä½œæµå¤±è´¥: {error_message}")

                # ğŸ”¥ å¹¿æ’­å¤±è´¥çŠ¶æ€åˆ° WebSocket
                await broadcast_to_websockets(
                    request.session_id, {"type": "status", "status": "failed", "message": error_message}
                )

                # ğŸ”¥ æ›´æ–° Redis å¤±è´¥çŠ¶æ€
                await session_manager.update(session_id, {"status": "failed", "error": error_message})
            else:
                session["status"] = "completed"
                session["progress"] = 1.0

                # æå–æœ€ç»ˆæŠ¥å‘Š
                final_report = None
                for event in session["events"]:
                    for node_name, node_output in event.items():
                        if isinstance(node_output, dict) and "final_report" in node_output:
                            final_report = node_output["final_report"]
                            break

                session["final_report"] = final_report or "åˆ†æå®Œæˆ"

                # ğŸ”¥ å¹¿æ’­å®ŒæˆçŠ¶æ€åˆ° WebSocket
                await broadcast_to_websockets(
                    request.session_id,
                    {
                        "type": "status",
                        "status": "completed",
                        "progress": 1.0,
                        "message": "åˆ†æå®Œæˆ",
                        "final_report": session.get("final_report"),
                    },
                )

                # ğŸ”¥ æ›´æ–° Redis å®ŒæˆçŠ¶æ€
                await session_manager.update(
                    session_id, {"status": "completed", "progress": 1.0, "final_report": session.get("final_report")}
                )

                # ğŸ†• v3.6æ–°å¢: è‡ªåŠ¨å½’æ¡£å®Œæˆçš„ä¼šè¯ï¼ˆæ°¸ä¹…ä¿å­˜ï¼‰
                if archive_manager:
                    try:
                        # è·å–å®Œæ•´ä¼šè¯æ•°æ®
                        final_session = await session_manager.get(session_id)
                        if final_session:
                            await archive_manager.archive_session(
                                session_id=session_id, session_data=final_session, force=False
                            )
                            logger.info(f"ğŸ“¦ ä¼šè¯å·²è‡ªåŠ¨å½’æ¡£ï¼ˆæ°¸ä¹…ä¿å­˜ï¼‰: {session_id}")
                    except Exception as archive_error:
                        logger.warning(f"âš ï¸ è‡ªåŠ¨å½’æ¡£å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {archive_error}")

                logger.info(f"ğŸ“¡ å·²å¹¿æ’­å®ŒæˆçŠ¶æ€åˆ° WebSocket: {request.session_id}")

        # ğŸ†• å¤„ç†é€’å½’é™åˆ¶é”™è¯¯
        except GraphRecursionError as e:
            logger.warning(f"âš ï¸ Resumeæ—¶è¾¾åˆ°é€’å½’é™åˆ¶ï¼ä¼šè¯: {session_id}")
            logger.info("ğŸ“¦ å°è¯•è·å–æœ€ä½³ç»“æœ...")

            try:
                current_state = workflow.graph.get_state(config)
                state_values = current_state.values

                best_result = state_values.get("best_result")
                if best_result:
                    logger.info(f"âœ… æ‰¾åˆ°æœ€ä½³ç»“æœï¼ˆè¯„åˆ†{state_values.get('best_score', 0):.1f}ï¼‰")
                    state_values["agent_results"] = best_result
                else:
                    logger.warning("âš ï¸ æœªæ‰¾åˆ°æœ€ä½³ç»“æœï¼Œä½¿ç”¨å½“å‰ç»“æœ")

                session["status"] = "completed"
                session["progress"] = 1.0
                session["final_report"] = "åˆ†æå·²å®Œæˆï¼ˆè¾¾åˆ°é€’å½’é™åˆ¶ï¼‰"

                # ğŸ”¥ å¹¿æ’­å®ŒæˆçŠ¶æ€åˆ° WebSocket
                await broadcast_to_websockets(
                    session_id, {"type": "status", "status": "completed", "progress": 1.0, "message": "åˆ†æå·²å®Œæˆï¼ˆè¾¾åˆ°é€’å½’é™åˆ¶ï¼‰"}
                )
                logger.info(f"ğŸ“¡ å·²å¹¿æ’­å®ŒæˆçŠ¶æ€åˆ° WebSocket (é€’å½’é™åˆ¶): {session_id}")
                session["metadata"] = {"forced_completion": True, "best_score": state_values.get("best_score", 0)}

            except Exception as state_error:
                logger.error(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {state_error}")
                session["status"] = "failed"
                session["error"] = f"è¾¾åˆ°é€’å½’é™åˆ¶: {str(e)}"

        except Exception as e:
            session["status"] = "failed"
            session["error"] = str(e)
            import traceback

            session["traceback"] = traceback.format_exc()
            logger.error(f"[ERROR] Resume workflow failed: {e}")
            logger.error(f"[ERROR] Traceback:\n{traceback.format_exc()}")

    background_tasks.add_task(continue_workflow)

    return SessionResponse(session_id=session_id, status="resumed", message="åˆ†æå·²æ¢å¤")


@app.post("/api/analysis/followup", response_model=SessionResponse)
async def submit_followup_question(
    session_id: str = Form(...),
    question: str = Form(...),
    requires_analysis: bool = Form(True),
    image: Optional[UploadFile] = File(None),
    background_tasks: BackgroundTasks = BackgroundTasks(),
):
    """
    æäº¤è¿½é—®ï¼ˆæ”¯æŒæŒç»­å¯¹è¯ + å›¾ç‰‡ä¸Šä¼ ï¼‰

    ğŸ”¥ v3.11 é‡å¤§æ”¹é€ ï¼š
    - ä¸å†åˆ›å»ºæ–°ä¼šè¯ï¼Œåœ¨åŸä¼šè¯ä¸Šè¿½åŠ å¯¹è¯å†å²
    - æ”¯æŒæ— é™è½®æ¬¡çš„è¿ç»­è¿½é—®
    - æ”¯æŒ"è®°å¿†å…¨éƒ¨"æ¨¡å¼ï¼ˆæ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†ï¼‰
    - å¯¹è¯å†å²æŒä¹…åŒ–åˆ°Redis

    ğŸ”¥ v7.108 æ–°å¢ï¼š
    - æ”¯æŒå›¾ç‰‡ä¸Šä¼ ï¼ˆmultipart/form-dataï¼‰
    - å›¾ç‰‡æ°¸ä¹…ä¿å­˜åˆ° data/followup_images/{session_id}/
    - è‡ªåŠ¨ç”Ÿæˆç¼©ç•¥å›¾ï¼ˆ400pxï¼‰
    - é›†æˆ Vision API åˆ†æå›¾ç‰‡å†…å®¹

    ä¸ /api/analysis/resume çš„åŒºåˆ«:
    - resume: ç”¨äº waiting_for_input çŠ¶æ€çš„ä¸­æ–­æ¢å¤
    - followup: ç”¨äº completed çŠ¶æ€çš„åç»­è¿½é—®
    """
    logger.info(f"ğŸ“¨ æ”¶åˆ°è¿½é—®è¯·æ±‚: session_id={session_id}")
    logger.info(f"   é—®é¢˜: {question}")
    logger.info(f"   éœ€è¦åˆ†æ: {requires_analysis}")
    logger.info(f"   åŒ…å«å›¾ç‰‡: {image is not None}")

    # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
    session = await session_manager.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail=f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")

    # å…è®¸ completed çŠ¶æ€çš„ä¼šè¯è¿›è¡Œè¿½é—®
    if session["status"] not in ["completed", "waiting_for_input"]:
        raise HTTPException(status_code=400, detail=f"æ— æ³•è¿½é—®ï¼Œä¼šè¯çŠ¶æ€: {session['status']}ï¼ˆåªèƒ½å¯¹å·²å®Œæˆæˆ–ç­‰å¾…è¾“å…¥çš„ä¼šè¯è¿½é—®ï¼‰")

    # ğŸ”¥ å…³é”®æ”¹å˜ï¼šä¸åˆ›å»ºæ–°ä¼šè¯ï¼Œç›´æ¥åœ¨åŸä¼šè¯ä¸Šè¿½é—®
    logger.info(f"ğŸ”¥ åœ¨åŸä¼šè¯ä¸Šè¿½é—®ï¼ˆä¸åˆ›å»ºæ–°ä¼šè¯ï¼‰")

    # ğŸ”¥ ä½¿ç”¨åå°ä»»åŠ¡å¤„ç†è¿½é—®
    async def handle_followup():
        try:
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            await session_manager.update(session_id, {"status": "processing_followup", "detail": "æ­£åœ¨æ€è€ƒå›ç­”..."})

            # ğŸ”¥ è·å–è¿½é—®å†å²
            history_data = await followup_history_manager.get_history(session_id, limit=None)  # è·å–å…¨éƒ¨
            next_turn_id = len(history_data) + 1
            logger.info(f"ğŸ“š å½“å‰å¯¹è¯å†å²: {len(history_data)} è½®")

            # ğŸ”¥ v7.108: å¤„ç†å›¾ç‰‡ä¸Šä¼ ï¼ˆå¦‚æœæœ‰ï¼‰
            image_metadata = None
            enhanced_question = question

            if image is not None:
                try:
                    from pathlib import Path

                    from intelligent_project_analyzer.services.file_processor import FileProcessor
                    from intelligent_project_analyzer.services.followup_image_storage_manager import (
                        FollowupImageStorageManager,
                    )

                    logger.info(f"ğŸ“· å¼€å§‹å¤„ç†å›¾ç‰‡: {image.filename}")

                    # ä¿å­˜å›¾ç‰‡ï¼ˆåŸå›¾ + ç¼©ç•¥å›¾ï¼‰
                    image_metadata = await FollowupImageStorageManager.save_image(
                        image_file=image, session_id=session_id, turn_id=next_turn_id
                    )
                    logger.info(f"âœ… å›¾ç‰‡å·²ä¿å­˜: {image_metadata['stored_filename']}")

                    # Vision API åˆ†æï¼ˆä½¿ç”¨ FileProcessorï¼‰
                    try:
                        file_processor = FileProcessor(enable_vision_api=True)
                        image_path = Path(f"data/followup_images/{session_id}/{image_metadata['stored_filename']}")

                        vision_result = await file_processor._extract_image(image_path)
                        vision_analysis = (
                            vision_result.get("text", "").split("## AIè§†è§‰åˆ†æ")[-1].strip()
                            if "## AIè§†è§‰åˆ†æ" in vision_result.get("text", "")
                            else ""
                        )

                        image_metadata["vision_analysis"] = vision_analysis
                        logger.info(f"âœ… Vision API åˆ†æå®Œæˆ: {len(vision_analysis)} å­—ç¬¦")

                    except Exception as e:
                        logger.warning(f"âš ï¸ Vision API åˆ†æå¤±è´¥: {e}")
                        image_metadata["vision_analysis"] = ""

                    # å¢å¼ºé—®é¢˜æ–‡æœ¬ï¼ˆæ‹¼æ¥ Vision åˆ†æï¼‰
                    if image_metadata.get("vision_analysis"):
                        enhanced_question = f"""{question}

[å›¾ç‰‡: {image_metadata['original_filename']}]
AIåˆ†æ: {image_metadata['vision_analysis']}
"""

                except Exception as e:
                    logger.error(f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: {e}")
                    import traceback

                    traceback.print_exc()
                    # ä¸é˜»å¡è¿½é—®ï¼Œç»§ç»­å¤„ç†

            # ğŸ”¥ v7.15: ä½¿ç”¨ FollowupAgent (LangGraph)
            agent = FollowupAgent()

            # æ„å»ºä¸Šä¸‹æ–‡
            parent_session = await session_manager.get(session_id)
            aggregated_results = parent_session.get("aggregated_results", {})
            agent_results = parent_session.get("agent_results", {})
            structured_requirements = parent_session.get("structured_requirements", {})
            original_input = parent_session.get("user_input", "")

            # å¦‚æœæ²¡æœ‰ç»“æ„åŒ–æ•°æ®ï¼Œå°è¯•ä» final_report è§£æ
            final_report = parent_session.get("final_report")
            if isinstance(final_report, dict) and not aggregated_results:
                aggregated_results = final_report

            # ğŸ”¥ v7.15: æ„å»º report_context (æ–°æ ¼å¼)
            report_context = {
                "final_report": aggregated_results if isinstance(aggregated_results, dict) else {},
                "agent_results": agent_results if isinstance(agent_results, dict) else {},
                "requirements": structured_requirements if isinstance(structured_requirements, dict) else {},
                "user_input": original_input,
            }

            # ğŸ”¥ v7.15: è°ƒç”¨ FollowupAgentï¼ˆä½¿ç”¨å¢å¼ºåçš„é—®é¢˜ï¼‰
            logger.info(f"ğŸ¤– è°ƒç”¨ FollowupAgent (LangGraph)ï¼ˆå†å²è½®æ¬¡: {len(history_data)}ï¼‰")
            result = await agent.answer_question_async(
                question=enhanced_question, report_context=report_context, conversation_history=history_data
            )

            answer = result.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚")

            # ğŸ”¥ v7.60.5: ç´¯åŠ è¿½é—®Tokenåˆ°ä¼šè¯metadata
            from intelligent_project_analyzer.utils.token_utils import extract_tokens_from_result, update_session_tokens

            token_data = extract_tokens_from_result(result)
            if token_data:
                success = await update_session_tokens(session_manager, session_id, token_data, agent_name="followup_qa")
                if success:
                    logger.info(f"âœ… [è¿½é—®Token] å·²ç´¯åŠ åˆ°ä¼šè¯ {session_id}")

            # ğŸ”¥ ä¿å­˜åˆ°è¿½é—®å†å²ï¼ˆåŒ…å«é™„ä»¶ï¼‰
            attachments = []
            if image_metadata:
                attachments.append({"type": "image", **image_metadata})

            await followup_history_manager.add_turn(
                session_id=session_id,
                question=question,
                answer=answer,
                intent=result.get("intent", "general"),
                referenced_sections=result.get("references", []),
                attachments=attachments,
            )

            # æ›´æ–°ä¼šè¯çŠ¶æ€ï¼ˆä¿æŒcompletedçŠ¶æ€ï¼‰
            await session_manager.update(
                session_id, {"status": "completed", "detail": "è¿½é—®å›ç­”å®Œæˆ", "last_followup_at": datetime.now().isoformat()}
            )

            # ğŸ”¥ é€šè¿‡WebSocketå¹¿æ’­æ›´æ–°ï¼ˆå‰ç«¯å®æ—¶æ˜¾ç¤ºï¼‰
            await broadcast_to_websockets(
                session_id,
                {
                    "type": "followup_answer",
                    "turn_id": next_turn_id,
                    "question": question,
                    "answer": answer,
                    "intent": result.get("intent", "general"),
                    "referenced_sections": result.get("references", []),
                    "attachments": attachments,
                    "timestamp": datetime.now().isoformat(),
                },
            )

            logger.info(f"âœ… è¿½é—®å®Œæˆ: {session_id}, è½®æ¬¡={next_turn_id}")

        except Exception as e:
            logger.error(f"âŒ è¿½é—®å¤„ç†å¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            await session_manager.update(
                session_id, {"status": "completed", "detail": f"è¿½é—®å¤±è´¥: {str(e)}"}  # å›åˆ°completedçŠ¶æ€
            )

            # å¹¿æ’­é”™è¯¯
            await broadcast_to_websockets(session_id, {"type": "followup_error", "error": str(e)})

    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(handle_followup)

    return SessionResponse(session_id=session_id, status="processing", message="è¿½é—®å·²æäº¤ï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”...")  # ğŸ”¥ è¿”å›åŸä¼šè¯IDï¼Œä¸æ˜¯æ–°ä¼šè¯


@app.get("/api/analysis/result/{session_id}", response_model=AnalysisResult)
async def get_analysis_result(session_id: str):
    """
    è·å–åˆ†æç»“æœ

    è·å–å·²å®Œæˆåˆ†æçš„å®Œæ•´ç»“æœ
    """
    # âœ… ä½¿ç”¨ Redis è·å–ä¼šè¯
    sm = await _get_session_manager()
    session = await sm.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    if session["status"] != "completed":
        raise HTTPException(status_code=400, detail=f"åˆ†æå°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {session['status']}")

    # å…¼å®¹ï¼šä¸åŒç‰ˆæœ¬çš„ä¼šè¯ç»“æ„å­—æ®µåå¯èƒ½ä¸åŒ
    results = session.get("results")
    agent_results = session.get("agent_results")
    final_report = session.get("final_report")
    final_result = session.get("final_result")

    return AnalysisResult(
        session_id=session_id,
        status=session["status"],
        results=results if results is not None else agent_results,
        final_report=final_report if final_report is not None else final_result,
        final_result=final_result,
        agent_results=agent_results,
    )


@app.get("/api/analysis/report/{session_id}", response_model=ReportResponse)
async def get_analysis_report(session_id: str):
    """
    è·å–åˆ†ææŠ¥å‘Šï¼ˆä¸“é—¨ä¸ºå‰ç«¯è®¾è®¡çš„ç«¯ç‚¹ï¼‰

    è¿”å›æ ¼å¼åŒ–çš„æŠ¥å‘Šå†…å®¹ï¼Œé€‚é…å‰ç«¯ AnalysisReport ç±»å‹
    """
    # âœ… ä½¿ç”¨ Redis è·å–ä¼šè¯
    sm = await _get_session_manager()
    session = await sm.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    if session["status"] != "completed":
        raise HTTPException(status_code=400, detail=f"åˆ†æå°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {session['status']}")

    # è·å–æŠ¥å‘Šæ–‡æœ¬è·¯å¾„
    pdf_path = session.get("pdf_path")
    report_text = ""

    # å¦‚æœæœ‰ PDF è·¯å¾„ï¼Œå°è¯•è¯»å–å¯¹åº”çš„ txt æ–‡ä»¶
    if pdf_path and os.path.exists(pdf_path):
        try:
            with open(pdf_path, "r", encoding="utf-8") as f:
                report_text = f.read()
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•è¯»å–æŠ¥å‘Šæ–‡ä»¶: {e}")
            # ğŸ”¥ v7.52.5: é™çº§æ–¹æ¡ˆ - ä¸ä½¿ç”¨json.dumpsï¼Œè®©FastAPIè‡ªåŠ¨åºåˆ—åŒ–
            # report_text ä»…ç”¨äºç®€çŸ­æç¤ºï¼Œå®é™…æ•°æ®åœ¨ structured_report ä¸­
            report_text = "æŠ¥å‘Šæ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè¯·æŸ¥çœ‹ç»“æ„åŒ–æ•°æ®"
    else:
        # ğŸ”¥ v7.52.5: æ²¡æœ‰æ–‡ä»¶è·¯å¾„æ—¶ï¼Œè¿”å›ç®€çŸ­æç¤º
        # structured_report å­—æ®µä¼šåŒ…å«å®Œæ•´æ•°æ®ï¼Œä¸éœ€è¦json.dumps
        report_text = "è¯·æŸ¥çœ‹ç»“æ„åŒ–æŠ¥å‘Šå†…å®¹"

    # âœ… è§£æç»“æ„åŒ–æŠ¥å‘Šæ•°æ®
    structured_report = None
    final_report = session.get("final_report", {})

    if isinstance(final_report, dict) and final_report:
        try:
            # ğŸ”¥ Phase 1.4+ P4 & v7.0: è§£æ core_answerï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼ï¼‰
            core_answer_data = None
            ca_raw = final_report.get("core_answer")
            if ca_raw and isinstance(ca_raw, dict):
                # æ£€æµ‹æ˜¯å¦æ˜¯ v7.0 æ ¼å¼ï¼ˆæœ‰ deliverable_answers å­—æ®µï¼‰
                if "deliverable_answers" in ca_raw:
                    # ğŸ†• v7.0 æ ¼å¼ï¼šç›´æ¥ä¼ é€’æ•´ä¸ªç»“æ„
                    core_answer_data = ca_raw
                    deliverable_count = len(ca_raw.get("deliverable_answers", []))
                    logger.info(f"ğŸ¯ [v7.0] è§£æåˆ°å¤šäº¤ä»˜ç‰©æ ¸å¿ƒç­”æ¡ˆ: {deliverable_count} ä¸ªäº¤ä»˜ç‰©")
                else:
                    # æ—§æ ¼å¼ï¼šè½¬æ¢ä¸ºå­—å…¸ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
                    core_answer_data = {
                        "question": ca_raw.get("question", ""),
                        "answer": ca_raw.get("answer", ""),
                        "deliverables": ca_raw.get("deliverables", []),
                        "timeline": ca_raw.get("timeline", ""),
                        "budget_range": ca_raw.get("budget_range", ""),
                        # v7.0 å‘åå…¼å®¹å­—æ®µï¼ˆä¸ºç©ºï¼‰
                        "deliverable_answers": [],
                        "expert_support_chain": [],
                    }
                    logger.info(f"ğŸ¯ è§£æåˆ°æ ¸å¿ƒç­”æ¡ˆï¼ˆæ—§æ ¼å¼ï¼‰: {ca_raw.get('answer', '')[:50]}...")

            # è§£æ executive_summary
            exec_summary_data = final_report.get("executive_summary", {})
            exec_summary = ExecutiveSummaryResponse(
                project_overview=exec_summary_data.get("project_overview", ""),
                key_findings=exec_summary_data.get("key_findings", []),
                key_recommendations=exec_summary_data.get("key_recommendations", []),
                success_factors=exec_summary_data.get("success_factors", []),
            )

            # è§£æ sectionsï¼ˆæ”¯æŒæ•°ç»„å’Œå­—å…¸ä¸¤ç§æ ¼å¼ï¼‰
            sections_data = final_report.get("sections", {})
            sections = []

            # ğŸ”¥ ä¿®å¤ï¼šsectionså¯èƒ½æ˜¯dictï¼ˆkey=section_idï¼‰æˆ–listæ ¼å¼
            if isinstance(sections_data, dict):
                # å­—å…¸æ ¼å¼ï¼š{"requirements_analysis": {...}, "design_research": {...}}
                for section_id, section_content in sections_data.items():
                    if isinstance(section_content, dict):
                        # ğŸ”¥ v7.52.5: contentå¯èƒ½æ˜¯dictæˆ–string
                        # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–ä¸»è¦æ–‡æœ¬å†…å®¹ï¼Œä¸ä½¿ç”¨json.dumps
                        content_val = section_content.get("content", "")
                        if isinstance(content_val, dict):
                            # å°è¯•æå–ä¸»è¦æ–‡æœ¬å­—æ®µï¼Œè€Œä¸æ˜¯JSONå­—ç¬¦ä¸²
                            if "text" in content_val:
                                content_val = content_val["text"]
                            elif "content" in content_val:
                                content_val = content_val["content"]
                            else:
                                # å¦‚æœå®åœ¨éœ€è¦å±•ç¤ºç»“æ„åŒ–å†…å®¹ï¼Œç”¨ç®€çŸ­æè¿°
                                content_val = f"[ç»“æ„åŒ–å†…å®¹: {len(content_val)} ä¸ªå­—æ®µ]"

                        raw_confidence = section_content.get("confidence", 0.0)
                        try:
                            confidence_value = float(raw_confidence)
                        except (TypeError, ValueError):
                            confidence_value = 0.0

                        sections.append(
                            ReportSectionResponse(
                                section_id=section_id,
                                title=section_content.get("title", section_id),
                                content=str(content_val) if content_val else "",
                                confidence=confidence_value,
                            )
                        )
            elif isinstance(sections_data, list):
                # æ•°ç»„æ ¼å¼ï¼š[{section_id, title, content, confidence}, ...]
                for s in sections_data:
                    if isinstance(s, dict):
                        # ğŸ”¥ v7.52.5: contentå¯èƒ½æ˜¯dictæˆ–string
                        # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–ä¸»è¦æ–‡æœ¬å†…å®¹ï¼Œä¸ä½¿ç”¨json.dumps
                        content_val = s.get("content", "")
                        if isinstance(content_val, dict):
                            # å°è¯•æå–ä¸»è¦æ–‡æœ¬å­—æ®µï¼Œè€Œä¸æ˜¯JSONå­—ç¬¦ä¸²
                            if "text" in content_val:
                                content_val = content_val["text"]
                            elif "content" in content_val:
                                content_val = content_val["content"]
                            else:
                                # å¦‚æœå®åœ¨éœ€è¦å±•ç¤ºç»“æ„åŒ–å†…å®¹ï¼Œç”¨ç®€çŸ­æè¿°
                                content_val = f"[ç»“æ„åŒ–å†…å®¹: {len(content_val)} ä¸ªå­—æ®µ]"

                        raw_confidence = s.get("confidence", 0.0)
                        try:
                            confidence_value = float(raw_confidence)
                        except (TypeError, ValueError):
                            confidence_value = 0.0

                        sections.append(
                            ReportSectionResponse(
                                section_id=s.get("section_id", ""),
                                title=s.get("title", ""),
                                content=str(content_val) if content_val else "",
                                confidence=confidence_value,
                            )
                        )

            # ä½¿ç”¨æ™ºèƒ½ä½“åŸå§‹è¾“å‡ºè¡¥å…¨ç« èŠ‚
            sections = _enrich_sections_with_agent_results(sections, session)

            # è§£æ comprehensive_analysisï¼ˆå…¼å®¹å­—æ®µåå·®å¼‚ï¼‰
            comp_data = final_report.get("comprehensive_analysis", {})
            comp_analysis = ComprehensiveAnalysisResponse(
                cross_domain_insights=comp_data.get("cross_domain_insights", []),
                integrated_recommendations=comp_data.get("integrated_recommendations")
                or comp_data.get("integration_recommendations", []),
                risk_assessment=comp_data.get("risk_assessment", []),
                implementation_roadmap=comp_data.get("implementation_roadmap", []),
            )

            # è§£æ conclusionsï¼ˆå…¼å®¹ summary å’Œ project_analysis_summaryï¼‰
            concl_data = final_report.get("conclusions", {})
            conclusions = ConclusionsResponse(
                project_analysis_summary=concl_data.get("project_analysis_summary") or concl_data.get("summary", ""),
                next_steps=concl_data.get("next_steps", []),
                success_metrics=concl_data.get("success_metrics", []),
            )

            # è§£æ review_feedback
            review_feedback = None
            rf_data = final_report.get("review_feedback")
            if rf_data and isinstance(rf_data, dict):

                def parse_feedback_items(items_data):
                    items = []
                    for item in items_data or []:
                        if isinstance(item, dict):
                            items.append(
                                ReviewFeedbackItemResponse(
                                    issue_id=item.get("issue_id", ""),
                                    reviewer=item.get("reviewer", ""),
                                    issue_type=item.get("issue_type", ""),
                                    description=item.get("description", ""),
                                    response=item.get("response", ""),
                                    status=item.get("status", ""),
                                    priority=str(item.get("priority", "medium")),
                                )
                            )
                    return items

                review_feedback = ReviewFeedbackResponse(
                    red_team_challenges=parse_feedback_items(rf_data.get("red_team_challenges")),
                    blue_team_validations=parse_feedback_items(rf_data.get("blue_team_validations")),
                    judge_rulings=parse_feedback_items(rf_data.get("judge_rulings")),
                    client_decisions=parse_feedback_items(rf_data.get("client_decisions")),
                    iteration_summary=rf_data.get("iteration_summary", ""),
                )

            # è§£æ review_visualization
            review_viz = None
            rv_data = final_report.get("review_visualization")
            if rv_data and isinstance(rv_data, dict):
                rounds = []
                for rd in rv_data.get("rounds", []):
                    if isinstance(rd, dict):
                        rounds.append(
                            ReviewRoundDataResponse(
                                round_number=rd.get("round_number", 0),
                                red_score=rd.get("red_score", 0),
                                blue_score=rd.get("blue_score", 0),
                                judge_score=rd.get("judge_score", 0),
                                issues_found=rd.get("issues_found", 0),
                                issues_resolved=rd.get("issues_resolved", 0),
                                timestamp=rd.get("timestamp", ""),
                            )
                        )
                review_viz = ReviewVisualizationResponse(
                    rounds=rounds,
                    final_decision=rv_data.get("final_decision", ""),
                    total_rounds=rv_data.get("total_rounds", 0),
                    improvement_rate=float(rv_data.get("improvement_rate", 0.0)),
                )

            # ğŸ†• è§£æ challenge_detectionï¼ˆä» session state ä¸­è·å–ï¼‰
            challenge_detection = None
            cd_data = session.get("challenge_detection")
            if cd_data and isinstance(cd_data, dict):
                challenges_list = []
                raw_challenges = cd_data.get("challenges", [])
                must_fix_count = 0
                should_fix_count = 0

                for ch in raw_challenges:
                    if isinstance(ch, dict):
                        severity = ch.get("severity", "should-fix")
                        if severity == "must-fix":
                            must_fix_count += 1
                        else:
                            should_fix_count += 1

                        challenges_list.append(
                            ChallengeItemResponse(
                                expert_id=ch.get("expert_id", ""),
                                expert_name=ch.get("expert_name", ch.get("expert_id", "")),
                                challenged_item=ch.get("challenged_item", ""),
                                challenge_type=ch.get("challenge_type", ""),
                                severity=severity,
                                rationale=ch.get("rationale", ""),
                                proposed_alternative=ch.get("proposed_alternative", ""),
                                design_impact=ch.get("design_impact", ""),
                                decision=ch.get("decision", ""),
                            )
                        )

                # è·å–å¤„ç†æ‘˜è¦
                handling_data = session.get("challenge_handling", {})
                handling_summary = handling_data.get("summary", "") if isinstance(handling_data, dict) else ""

                challenge_detection = ChallengeDetectionResponse(
                    has_challenges=cd_data.get("has_challenges", False),
                    total_count=len(challenges_list),
                    must_fix_count=must_fix_count,
                    should_fix_count=should_fix_count,
                    challenges=challenges_list,
                    handling_summary=handling_summary,
                )

                if challenges_list:
                    logger.info(f"ğŸ” æŒ‘æˆ˜æ£€æµ‹: {must_fix_count} must-fix, {should_fix_count} should-fix")

            # ğŸ”¥ ä¿®å¤ï¼šä» session.agent_results æå– expert_reportsï¼ˆå¦‚æœ final_report é‡Œæ²¡æœ‰ï¼‰
            expert_reports_data = final_report.get("expert_reports", {})
            if not expert_reports_data:
                # ä» agent_results æå–ä¸“å®¶æŠ¥å‘Š
                agent_results = session.get("agent_results", {})
                active_agents = session.get("active_agents", [])
                expert_reports_data = {}

                for role_id in active_agents:
                    # è·³è¿‡éœ€æ±‚åˆ†æå¸ˆå’Œé¡¹ç›®æ€»ç›‘
                    if role_id in ["requirements_analyst", "project_director"]:
                        continue
                    # åªæå– V2-V6 ä¸“å®¶çš„æŠ¥å‘Š
                    if not any(role_id.startswith(prefix) for prefix in ["V2_", "V3_", "V4_", "V5_", "V6_"]):
                        continue

                    agent_result = agent_results.get(role_id, {})
                    if agent_result:
                        structured_raw = agent_result.get("structured_data", {})
                        structured_data, validation_warnings = _sanitize_structured_data(structured_raw)
                        content = agent_result.get("content", "")

                        if structured_data and content:
                            payload = OrderedDict()
                            payload["structured_data"] = structured_data
                            payload["narrative_summary"] = content
                            if validation_warnings:
                                payload["validation_warnings"] = validation_warnings
                            expert_reports_data[role_id] = json.dumps(payload, ensure_ascii=False, indent=2)
                        elif structured_data:
                            if validation_warnings:
                                payload = OrderedDict()
                                payload["structured_data"] = structured_data
                                payload["validation_warnings"] = validation_warnings
                                expert_reports_data[role_id] = json.dumps(payload, ensure_ascii=False, indent=2)
                            else:
                                expert_reports_data[role_id] = json.dumps(structured_data, ensure_ascii=False, indent=2)
                        elif content:
                            if validation_warnings:
                                payload = OrderedDict()
                                payload["narrative_summary"] = content
                                payload["validation_warnings"] = validation_warnings
                                expert_reports_data[role_id] = json.dumps(payload, ensure_ascii=False, indent=2)
                            else:
                                expert_reports_data[role_id] = content
                        elif validation_warnings:
                            payload = OrderedDict()
                            payload["validation_warnings"] = validation_warnings
                            expert_reports_data[role_id] = json.dumps(payload, ensure_ascii=False, indent=2)

                if expert_reports_data:
                    logger.info(f"ğŸ“Š ä»agent_resultsæå–äº† {len(expert_reports_data)} ä¸ªä¸“å®¶æŠ¥å‘Š")

            # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœsectionsä»ä¸ºç©ºï¼Œä»agent_resultsåŠ¨æ€å¡«å……
            if not sections:
                agent_results = session.get("agent_results") or {}
                if agent_results:
                    active_agents = session.get("active_agents") or list(agent_results.keys())

                    section_contributions: Dict[str, OrderedDict] = {}
                    section_titles: Dict[str, str] = {}
                    section_confidences: Dict[str, List[float]] = defaultdict(list)
                    section_sequence: List[str] = []

                    for role_id in active_agents:
                        if role_id in ["requirements_analyst", "project_director"]:
                            continue

                        agent_result = agent_results.get(role_id) or {}
                        payload = _format_agent_payload(agent_result)
                        if not payload:
                            continue

                        section_id, section_title = _derive_section_identity(role_id, agent_result)
                        source_name = agent_result.get("display_name") or agent_result.get("role_name") or role_id

                        section_contributions.setdefault(section_id, OrderedDict())
                        section_contributions[section_id][source_name] = payload

                        if section_title:
                            section_titles.setdefault(section_id, section_title)

                        if section_id not in section_sequence:
                            section_sequence.append(section_id)

                        raw_confidence = agent_result.get("confidence")
                        try:
                            if raw_confidence is not None:
                                section_confidences[section_id].append(float(raw_confidence))
                        except (TypeError, ValueError):
                            logger.debug(f"âš ï¸ æ— æ³•è§£æ {role_id} çš„ç½®ä¿¡åº¦: {raw_confidence}")

                    for section_id in section_sequence:
                        payload = section_contributions.get(section_id)
                        if not payload:
                            continue

                        confidence_values = section_confidences.get(section_id, [])
                        if confidence_values:
                            confidence = max(confidence_values)
                        else:
                            confidence = 0.8

                        section_content = json.dumps(payload, ensure_ascii=False, indent=2)
                        sections.append(
                            ReportSectionResponse(
                                section_id=section_id,
                                title=section_titles.get(section_id, section_id),
                                content=section_content,
                                confidence=confidence,
                            )
                        )

                    if sections:
                        logger.info(f"ğŸ“Š ä»agent_resultsåŠ¨æ€å¡«å……äº† {len(sections)} ä¸ªç« èŠ‚")

            # ğŸ”¥ Phase 1.4+ P3: è§£æé—®å·å›ç­”æ•°æ®
            questionnaire_data = None
            qr_raw = final_report.get("questionnaire_responses")
            if qr_raw and isinstance(qr_raw, dict):
                responses_list = []
                for resp_item in qr_raw.get("responses", []):
                    if isinstance(resp_item, dict):
                        responses_list.append(
                            QuestionnaireResponseItem(
                                question_id=resp_item.get("question_id", ""),
                                question=resp_item.get("question", ""),
                                answer=resp_item.get("answer", ""),
                                context=resp_item.get("context", ""),
                            )
                        )

                if responses_list:
                    questionnaire_data = QuestionnaireResponseData(
                        responses=responses_list,
                        timestamp=qr_raw.get("timestamp", ""),
                        analysis_insights=qr_raw.get("analysis_insights", ""),
                    )
                    logger.info(f"ğŸ“ è§£æåˆ° {len(responses_list)} æ¡é—®å·å›ç­”")

            # ğŸ”¥ Phase 1.4+ v4.1: è§£ææ´å¯ŸåŒºå— - å·²åºŸå¼ƒï¼ˆæ”¹ç”¨éœ€æ±‚åˆ†æå¸ˆçš„åŸå§‹è¾“å‡ºï¼‰
            insights_data = None
            # insights_raw = final_report.get("insights")
            # if insights_raw:
            #     # æ”¯æŒ Pydantic å¯¹è±¡å’Œ dict ä¸¤ç§æ ¼å¼
            #     if hasattr(insights_raw, 'model_dump'):
            #         insights_dict = insights_raw.model_dump()
            #     elif isinstance(insights_raw, dict):
            #         insights_dict = insights_raw
            #     else:
            #         insights_dict = {}
            #
            #     if insights_dict:
            #         insights_data = InsightsSectionResponse(
            #             key_insights=insights_dict.get("key_insights", []),
            #             cross_domain_connections=insights_dict.get("cross_domain_connections", []),
            #             user_needs_interpretation=insights_dict.get("user_needs_interpretation", "")
            #         )
            #         logger.info(f"ğŸ’¡ è§£æåˆ°æ´å¯ŸåŒºå—: {len(insights_data.key_insights)} æ¡å…³é”®æ´å¯Ÿ")

            # ğŸ”¥ Phase 1.4+ v4.1: è§£ææ¨æ•²è¿‡ç¨‹
            deliberation_data = None
            deliberation_raw = final_report.get("deliberation_process")
            if deliberation_raw:
                if hasattr(deliberation_raw, "model_dump"):
                    deliberation_dict = deliberation_raw.model_dump()
                elif isinstance(deliberation_raw, dict):
                    deliberation_dict = deliberation_raw
                else:
                    deliberation_dict = {}

                if deliberation_dict:
                    deliberation_data = DeliberationProcessResponse(
                        inquiry_architecture=deliberation_dict.get("inquiry_architecture", ""),
                        reasoning=deliberation_dict.get("reasoning", ""),
                        role_selection=deliberation_dict.get("role_selection", []),
                        strategic_approach=deliberation_dict.get("strategic_approach", ""),
                    )
                    logger.info(f"ğŸ§  è§£æåˆ°æ¨æ•²è¿‡ç¨‹: æ¶æ„={deliberation_data.inquiry_architecture}")

            # ğŸ”¥ Phase 1.4+ v4.1: è§£æå»ºè®®åŒºå—
            recommendations_data = None
            recommendations_raw = final_report.get("recommendations")
            if recommendations_raw:
                if hasattr(recommendations_raw, "model_dump"):
                    recommendations_dict = recommendations_raw.model_dump()
                elif isinstance(recommendations_raw, dict):
                    recommendations_dict = recommendations_raw
                else:
                    recommendations_dict = {}

                if recommendations_dict:
                    recommendations_data = RecommendationsSectionResponse(
                        immediate_actions=recommendations_dict.get("immediate_actions", []),
                        short_term_priorities=recommendations_dict.get("short_term_priorities", []),
                        long_term_strategy=recommendations_dict.get("long_term_strategy", []),
                        risk_mitigation=recommendations_dict.get("risk_mitigation", []),
                    )
                    logger.info(f"ğŸ“‹ è§£æåˆ°å»ºè®®åŒºå—: {len(recommendations_data.immediate_actions)} æ¡ç«‹å³è¡ŒåŠ¨")

            # ğŸ†• è§£æéœ€æ±‚åˆ†æç»“æœï¼ˆéœ€æ±‚åˆ†æå¸ˆåŸå§‹è¾“å‡ºï¼‰
            # ğŸ”¥ ä¿®å¤ï¼šåº”ä» final_report è¯»å–ï¼Œè€Œä¸æ˜¯ä» session.structured_requirements
            requirements_analysis_data = None
            requirements_analysis_raw = final_report.get("requirements_analysis")

            # å°è¯•ä» final_report é¡¶å±‚è·å–
            if requirements_analysis_raw and isinstance(requirements_analysis_raw, dict):
                requirements_analysis_data = RequirementsAnalysisResponse(
                    project_overview=requirements_analysis_raw.get("project_overview", ""),
                    core_objectives=requirements_analysis_raw.get("core_objectives", []),
                    project_tasks=requirements_analysis_raw.get("project_tasks", []),
                    narrative_characters=requirements_analysis_raw.get("narrative_characters", []),
                    physical_contexts=requirements_analysis_raw.get("physical_contexts", []),
                    constraints_opportunities=requirements_analysis_raw.get("constraints_opportunities", {}),
                    # ğŸ†• ä¼ é€’ç”¨æˆ·ä¿®æ”¹æ ‡è¯†
                    has_user_modifications=session.get("has_user_modifications", False),
                    user_modification_summary=session.get("user_modification_summary"),
                )
                logger.info(f"ğŸ“Š è§£æåˆ°éœ€æ±‚åˆ†æç»“æœï¼ˆä» final_reportï¼‰: {len(requirements_analysis_data.core_objectives)} ä¸ªæ ¸å¿ƒç›®æ ‡")
            else:
                # ğŸ”¥ å¤‡ç”¨æ–¹æ¡ˆ1ï¼šä» sections æ•°ç»„ä¸­æŸ¥æ‰¾ï¼ˆé’ˆå¯¹å·²æœ‰ä¼šè¯ï¼‰
                sections_data = final_report.get("sections", [])
                logger.debug(
                    f"ğŸ” [DEBUG] sections_data type: {type(sections_data)}, length: {len(sections_data) if isinstance(sections_data, list) else 'N/A'}"
                )

                if isinstance(sections_data, list):
                    for section in sections_data:
                        if isinstance(section, dict):
                            section_id = section.get("section_id", "")
                            logger.debug(f"ğŸ” [DEBUG] Checking section: {section_id}")

                            if section_id == "requirements_analysis":
                                content_str = section.get("content", "")
                                logger.info(
                                    f"ğŸ¯ Found requirements_analysis in sections, content length: {len(content_str)}"
                                )

                                if content_str:
                                    try:
                                        # è§£æ JSON å­—ç¬¦ä¸²
                                        req_data = (
                                            json.loads(content_str) if isinstance(content_str, str) else content_str
                                        )

                                        # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®æ˜ å°„ requirements_analyst çš„å®é™…è¾“å‡ºå­—æ®µ
                                        # requirements_analyst è¾“å‡ºçš„æ˜¯å®Œæ•´çš„ç»“æ„åŒ–æ•°æ®ï¼ŒåŒ…å«å¤šä¸ªå­—æ®µ
                                        logger.debug(f"ğŸ” [FIELD MAPPING] req_data keys: {list(req_data.keys())}")
                                        logger.debug(
                                            f"ğŸ” [FIELD MAPPING] project_task: '{req_data.get('project_task', '')}' (len={len(req_data.get('project_task', ''))})"
                                        )
                                        logger.debug(
                                            f"ğŸ” [FIELD MAPPING] character_narrative: (len={len(req_data.get('character_narrative', ''))})"
                                        )
                                        logger.debug(
                                            f"ğŸ” [FIELD MAPPING] physical_context: (len={len(req_data.get('physical_context', ''))})"
                                        )

                                        requirements_analysis_data = RequirementsAnalysisResponse(
                                            project_overview=req_data.get("project_overview")
                                            or req_data.get("project_task", ""),
                                            core_objectives=req_data.get("core_objectives", []),
                                            project_tasks=[req_data.get("project_task", "")]
                                            if req_data.get("project_task")
                                            else [],
                                            narrative_characters=[req_data.get("character_narrative", "")]
                                            if req_data.get("character_narrative")
                                            else [],
                                            physical_contexts=[req_data.get("physical_context", "")]
                                            if req_data.get("physical_context")
                                            else [],
                                            constraints_opportunities={
                                                "resource_constraints": req_data.get("resource_constraints", ""),
                                                "regulatory_requirements": req_data.get("regulatory_requirements", ""),
                                                "space_constraints": req_data.get("space_constraints", ""),
                                                "core_tension": req_data.get("core_tension", ""),
                                                "design_challenge": req_data.get("design_challenge", ""),
                                            },
                                            # ğŸ†• ä¼ é€’ç”¨æˆ·ä¿®æ”¹æ ‡è¯†
                                            has_user_modifications=session.get("has_user_modifications", False),
                                            user_modification_summary=session.get("user_modification_summary"),
                                        )
                                        logger.info(
                                            f"ğŸ“Š è§£æåˆ°éœ€æ±‚åˆ†æç»“æœï¼ˆä» sectionsï¼‰: {len(requirements_analysis_data.core_objectives)} ä¸ªæ ¸å¿ƒç›®æ ‡"
                                        )
                                        logger.debug(
                                            f"ğŸ” [FIELD MAPPING] project_tasks after mapping: {len(requirements_analysis_data.project_tasks)} items"
                                        )
                                        logger.debug(
                                            f"ğŸ” [FIELD MAPPING] narrative_characters after mapping: {len(requirements_analysis_data.narrative_characters)} items"
                                        )
                                        logger.debug(
                                            f"ğŸ” [FIELD MAPPING] physical_contexts after mapping: {len(requirements_analysis_data.physical_contexts)} items"
                                        )
                                        break
                                    except (json.JSONDecodeError, TypeError) as e:
                                        logger.warning(f"âš ï¸ è§£æ sections ä¸­çš„ requirements_analysis å¤±è´¥: {e}")
                else:
                    logger.debug(f"ğŸ” [DEBUG] sections_data is not a list, type: {type(sections_data)}")

                # ğŸ”¥ å¤‡ç”¨æ–¹æ¡ˆ2ï¼šå¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œå°è¯•ä» session.structured_requirements è¯»å–ï¼ˆå‘åå…¼å®¹ï¼‰
                if not requirements_analysis_data:
                    structured_req = session.get("structured_requirements")
                    if structured_req and isinstance(structured_req, dict):
                        requirements_analysis_data = RequirementsAnalysisResponse(
                            project_overview=structured_req.get("project_overview", ""),
                            core_objectives=structured_req.get("core_objectives", []),
                            project_tasks=structured_req.get("project_tasks", []),
                            narrative_characters=structured_req.get("narrative_characters", []),
                            physical_contexts=structured_req.get("physical_contexts", []),
                            constraints_opportunities=structured_req.get("constraints_opportunities", {}),
                            # ğŸ†• ä¼ é€’ç”¨æˆ·ä¿®æ”¹æ ‡è¯†
                            has_user_modifications=session.get("has_user_modifications", False),
                            user_modification_summary=session.get("user_modification_summary"),
                        )
                        logger.info(
                            f"ğŸ“Š è§£æåˆ°éœ€æ±‚åˆ†æç»“æœï¼ˆä» session.structured_requirements å¤‡ç”¨ï¼‰: {len(requirements_analysis_data.core_objectives)} ä¸ªæ ¸å¿ƒç›®æ ‡"
                        )

            structured_report = StructuredReportResponse(
                inquiry_architecture=final_report.get("inquiry_architecture", ""),
                core_answer=core_answer_data,  # ğŸ”¥ æ·»åŠ æ ¸å¿ƒç­”æ¡ˆ
                insights=None,  # ğŸ”¥ å·²åºŸå¼ƒï¼šä¸å†ä½¿ç”¨LLMç»¼åˆæ´å¯Ÿ
                requirements_analysis=requirements_analysis_data,  # ğŸ†• æ·»åŠ éœ€æ±‚åˆ†æç»“æœï¼ˆéœ€æ±‚åˆ†æå¸ˆåŸå§‹è¾“å‡ºï¼‰
                deliberation_process=deliberation_data,  # ğŸ”¥ Phase 1.4+ v4.1: æ·»åŠ æ¨æ•²è¿‡ç¨‹
                recommendations=recommendations_data,  # ğŸ”¥ Phase 1.4+ v4.1: æ·»åŠ å»ºè®®
                executive_summary=exec_summary,
                sections=sections,
                comprehensive_analysis=comp_analysis,
                conclusions=conclusions,
                expert_reports=expert_reports_data,
                review_feedback=review_feedback,
                questionnaire_responses=questionnaire_data,  # ğŸ”¥ æ·»åŠ é—®å·æ•°æ®
                review_visualization=review_viz,
                challenge_detection=challenge_detection,
                # ğŸ†• v7.4: æ·»åŠ æ‰§è¡Œå…ƒæ•°æ®æ±‡æ€»
                execution_metadata=final_report.get("metadata"),
                # ğŸ†• v3.0.26: æ·»åŠ æ€ç»´å¯¼å›¾å†…å®¹ç»“æ„
                mindmap_content=final_report.get("mindmap_content"),
                # æ™®é€šæ¨¡å¼æ¦‚å¿µå›¾ï¼ˆé›†ä¸­ç”Ÿæˆï¼‰
                generated_images=final_report.get("generated_images"),
                image_prompts=final_report.get("image_prompts"),
                image_top_constraints=final_report.get("image_top_constraints"),
                # ğŸ†• v7.39: æ·»åŠ ä¸“å®¶æ¦‚å¿µå›¾ï¼ˆæ·±åº¦æ€è€ƒæ¨¡å¼ï¼‰
                generated_images_by_expert=final_report.get("generated_images_by_expert"),
            )

            logger.info(f"âœ… æˆåŠŸè§£æç»“æ„åŒ–æŠ¥å‘Šï¼ŒåŒ…å« {len(sections)} ä¸ªç« èŠ‚")

        except Exception as e:
            logger.warning(f"âš ï¸ è§£æç»“æ„åŒ–æŠ¥å‘Šå¤±è´¥: {e}ï¼Œå°†è¿”å› None")
            structured_report = None

    # è·å–ç”¨æˆ·åŸå§‹è¾“å…¥
    user_input = session.get("user_input", "")

    return ReportResponse(
        session_id=session_id,
        report_text=report_text,
        report_pdf_path=pdf_path,
        created_at=session.get("created_at", datetime.now().isoformat()),
        user_input=user_input,
        structured_report=structured_report,
    )


# ========== PDF ä¸‹è½½ç«¯ç‚¹ ==========


class PDFGenerator(FPDF):
    """æ”¯æŒä¸­æ–‡çš„ PDF ç”Ÿæˆå™¨"""

    def __init__(self):
        super().__init__()
        self.chinese_font_loaded = False
        # è®¾ç½®é¡µé¢è¾¹è·ï¼ˆå·¦ã€ä¸Šã€å³ï¼‰- å…ˆè®¾ç½®è¾¹è·
        self.set_margins(left=25, top=25, right=25)
        self.set_auto_page_break(auto=True, margin=30)
        # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
        self._load_chinese_font()

    def _load_chinese_font(self):
        """åŠ è½½ä¸­æ–‡å­—ä½“"""
        # å°è¯•å¤šä¸ªå¸¸è§çš„ä¸­æ–‡å­—ä½“è·¯å¾„
        font_paths = [
            "C:/Windows/Fonts/msyh.ttc",  # å¾®è½¯é›…é»‘
            "C:/Windows/Fonts/simsun.ttc",  # å®‹ä½“
            "C:/Windows/Fonts/simhei.ttf",  # é»‘ä½“
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",  # Linux
            "/System/Library/Fonts/PingFang.ttc",  # macOS
        ]

        for font_path in font_paths:
            if os.path.exists(font_path):
                try:
                    self.add_font("Chinese", "", font_path, uni=True)
                    self.add_font("Chinese", "B", font_path, uni=True)
                    self.chinese_font_loaded = True
                    logger.info(f"âœ… æˆåŠŸåŠ è½½ä¸­æ–‡å­—ä½“: {font_path}")
                    return
                except Exception as e:
                    logger.warning(f"âš ï¸ åŠ è½½å­—ä½“å¤±è´¥ {font_path}: {e}")
                    continue

        logger.warning("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨å†…ç½®å­—ä½“")

    def _set_font_safe(self, style: str = "", size: int = 10):
        """å®‰å…¨è®¾ç½®å­—ä½“"""
        if self.chinese_font_loaded:
            self.set_font("Chinese", style, size)
        else:
            self.set_font("Arial", style, size)

    def header(self):
        """é¡µçœ‰ï¼ˆç•™ç©ºï¼‰"""
        pass

    def footer(self):
        """é¡µè„šï¼ˆå·²ç§»é™¤ï¼‰"""
        pass

    def add_cover_page(self, title: str = "é¡¹ç›®åˆ†ææŠ¥å‘Š"):
        """æ·»åŠ å°é¢é¡µ

        ğŸ”¥ v7.26 æ•´æ”¹:
        - ä¸­è‹±æ–‡é è¿‘ï¼ˆä¸è¦ç©ºè¡Œï¼‰
        - ç”Ÿæˆæ—¶é—´å‰åŠ "æè‡´æ¦‚å¿µ"
        - ä¸è¦ç”Ÿæˆæ—¶é—´å’Œå†’å·
        - ä¸è¦ç‰ˆæœ¬
        """
        self.add_page()

        # å°é¢æ ‡é¢˜ - å±…ä¸­æ˜¾ç¤ºåœ¨é¡µé¢ä¸­éƒ¨åä¸Š
        self.set_y(80)
        self._set_font_safe("B", 28)
        self.set_text_color(26, 26, 26)
        self.cell(0, 20, title, ln=True, align="C")

        # å‰¯æ ‡é¢˜ - ğŸ”¥ v7.26: ä¸­è‹±æ–‡é è¿‘ï¼ˆln(10) â†’ ln(3)ï¼‰
        self.ln(3)
        self._set_font_safe("", 14)
        self.set_text_color(100, 100, 100)
        self.cell(0, 10, "Intelligent Project Analyzer", ln=True, align="C")

        # ğŸ”¥ v7.26: "æè‡´æ¦‚å¿µ" + æ—¥æœŸï¼ˆæ— å†’å·ï¼Œæ— ç‰ˆæœ¬ï¼‰
        self.ln(40)
        self._set_font_safe("", 11)
        self.set_text_color(128, 128, 128)
        self.cell(0, 8, f"æè‡´æ¦‚å¿µ {datetime.now().strftime('%Y-%m-%d')}", ln=True, align="C")

    def add_table_of_contents(self, chapters: list):
        """æ·»åŠ ç›®å½•é¡µ

        Args:
            chapters: ç« èŠ‚åˆ—è¡¨ï¼Œæ¯é¡¹ä¸º {"title": str, "page": int}
        """
        self.add_page()

        # ç›®å½•æ ‡é¢˜
        self._set_font_safe("B", 18)
        self.set_text_color(26, 26, 26)
        self.cell(0, 15, "ç›® å½•", ln=True, align="C")
        self.ln(15)

        # ç›®å½•é¡¹
        self._set_font_safe("", 12)
        self.set_text_color(51, 51, 51)

        for i, chapter in enumerate(chapters, 1):
            title = chapter.get("title", "")
            page = chapter.get("page", "")

            # ç« èŠ‚ç¼–å·å’Œæ ‡é¢˜
            chapter_text = f"ç¬¬{i}ç«   {title}"

            # è®¡ç®—ç‚¹çº¿å¡«å……
            self.set_x(self.l_margin)
            title_width = self.get_string_width(chapter_text)
            page_width = self.get_string_width(str(page))
            available_width = self.w - self.l_margin - self.r_margin - title_width - page_width - 10
            dots = "." * int(available_width / self.get_string_width("."))

            # è¾“å‡ºç›®å½•è¡Œ
            self.cell(title_width + 5, 10, chapter_text, ln=False)
            self.set_text_color(180, 180, 180)
            self.cell(available_width, 10, dots, ln=False)
            self.set_text_color(51, 51, 51)
            self.cell(page_width + 5, 10, str(page), ln=True, align="R")
            self.ln(2)

    def chapter_title(self, title: str, level: int = 1):
        """æ·»åŠ æ ‡é¢˜ - æ™ºèƒ½å¤„ç†æ¢è¡Œ"""
        if not title:
            return
        sizes = {1: 16, 2: 13, 3: 11, 4: 10}
        size = sizes.get(level, 10)
        self._set_font_safe("B", size)
        self.set_text_color(26, 26, 26)
        self.ln(4 if level > 1 else 0)
        # é‡ç½® X åˆ°å·¦è¾¹è·
        self.set_x(self.l_margin)
        # ä½¿ç”¨ wrapmode=WrapMode.CHAR é¿å…è‹±æ–‡å•è¯è¢«æ‹†åˆ†æ¢è¡Œ
        from fpdf.enums import WrapMode

        self.multi_cell(w=0, h=7, text=str(title), wrapmode=WrapMode.CHAR)
        self.set_x(self.l_margin)  # multi_cell åé‡ç½®
        self.ln(2)

    def body_text(self, text: str):
        """æ·»åŠ æ­£æ–‡ - æ™ºèƒ½å¤„ç†æ¢è¡Œå’ŒMarkdownæ ¼å¼

        ğŸ”¥ v7.26.3: æ”¯æŒMarkdownæ ¼å¼è§£æ
        - ### æ ‡é¢˜ â†’ å°èŠ‚æ ‡é¢˜
        - **åŠ ç²—** â†’ å»é™¤æ˜Ÿå·æ˜¾ç¤º
        - - åˆ—è¡¨é¡¹ â†’ bulletåˆ—è¡¨
        """
        if not text:
            return

        # æ¸…ç†æ–‡æœ¬ï¼Œç¡®ä¿å­—ç¬¦ä¸²æ ¼å¼
        clean_text = str(text).strip()
        if not clean_text:
            return

        import re

        from fpdf.enums import WrapMode

        # ğŸ”¥ v7.26.3: æŒ‰è¡Œå¤„ç†ï¼Œè¯†åˆ«Markdownæ ¼å¼
        lines = clean_text.split("\n")

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # 1. å¤„ç† Markdown æ ‡é¢˜ (### æˆ– ## æˆ– #)
            header_match = re.match(r"^(#{1,4})\s+(.+)$", line)
            if header_match:
                level = len(header_match.group(1)) + 2  # # -> level 3, ## -> level 4
                title_text = header_match.group(2).strip()
                # æ¸…ç†æ ‡é¢˜ä¸­çš„Markdownæ ¼å¼
                title_text = re.sub(r"\*\*(.+?)\*\*", r"\1", title_text)
                title_text = re.sub(r"\*(.+?)\*", r"\1", title_text)
                self.chapter_title(title_text, min(level, 4))
                continue

            # 2. å¤„ç† Markdown æ— åºåˆ—è¡¨ (- æˆ– *)
            list_match = re.match(r"^[-*]\s+(.+)$", line)
            if list_match:
                item_text = list_match.group(1).strip()
                # æ¸…ç†åˆ—è¡¨é¡¹ä¸­çš„Markdownæ ¼å¼
                item_text = re.sub(r"\*\*(.+?)\*\*", r"\1", item_text)
                item_text = re.sub(r"\*(.+?)\*", r"\1", item_text)
                self.list_item(item_text)
                continue

            # 3. æ™®é€šæ–‡æœ¬ï¼šæ¸…ç†Markdownæ ¼å¼åè¾“å‡º
            # å»é™¤ **åŠ ç²—** å’Œ *æ–œä½“* æ ‡è®°
            clean_line = re.sub(r"\*\*(.+?)\*\*", r"\1", line)
            clean_line = re.sub(r"\*(.+?)\*", r"\1", clean_line)

            # è®¾ç½®å­—ä½“å’Œé¢œè‰²
            self._set_font_safe("", 10)
            self.set_text_color(51, 51, 51)
            self.set_x(self.l_margin)

            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç¼–å·åˆ—è¡¨
            if any(f"{i}." in clean_line or f"{i}ã€" in clean_line for i in range(1, 10)):
                formatted_text = _format_numbered_list(clean_line)
                sub_lines = formatted_text.split("\n")
                for sub_line in sub_lines:
                    sub_line = sub_line.strip()
                    if sub_line:
                        self.multi_cell(w=0, h=5, text=sub_line, wrapmode=WrapMode.CHAR)
                        self.set_x(self.l_margin)
            else:
                self.multi_cell(w=0, h=5, text=clean_line, wrapmode=WrapMode.CHAR)
                self.set_x(self.l_margin)

        self.ln(2)

    def list_item(self, text: str, numbered: bool = False, index: int = 0):
        """æ·»åŠ åˆ—è¡¨é¡¹ - æ™ºèƒ½å¤„ç†æ¢è¡Œ"""
        if not text:
            return
        self._set_font_safe("", 10)
        self.set_text_color(51, 51, 51)
        prefix = f"{index + 1}. " if numbered else "â€¢ "
        clean_text = str(text).strip()
        if clean_text:
            self.set_x(self.l_margin)  # é‡ç½® X åˆ°å·¦è¾¹è·
            # ä½¿ç”¨ wrapmode=WrapMode.CHAR é¿å…è‹±æ–‡å•è¯è¢«æ‹†åˆ†æ¢è¡Œ
            from fpdf.enums import WrapMode

            self.multi_cell(w=0, h=5, text=prefix + clean_text, wrapmode=WrapMode.CHAR)
            self.set_x(self.l_margin)  # multi_cell åé‡ç½®

    def add_divider(self):
        """æ·»åŠ åˆ†éš”çº¿"""
        self.ln(3)
        self.set_draw_color(229, 231, 235)
        # ä½¿ç”¨é¡µé¢å®½åº¦è®¡ç®—
        page_width = self.w - self.l_margin - self.r_margin
        self.line(self.l_margin, self.get_y(), self.l_margin + page_width, self.get_y())
        self.ln(4)

    def highlighted_box(self, text: str):
        """æ·»åŠ é«˜äº®æ¡†ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰"""
        if not text:
            return

        clean_text = str(text).strip()
        if not clean_text:
            return

        self.set_fill_color(248, 249, 250)
        self.set_draw_color(59, 130, 246)
        self._set_font_safe("", 10)
        self.set_text_color(51, 51, 51)

        # è®¡ç®—å¯ç”¨å®½åº¦
        available_width = self.w - self.l_margin - self.r_margin
        box_width = available_width - 10  # ç•™ä¸€ç‚¹è¾¹è·

        # å…ˆç»˜åˆ¶å·¦ä¾§è“è‰²è¾¹çº¿
        x = self.l_margin + 5
        y = self.get_y()

        # å­˜å‚¨å½“å‰ä½ç½®
        start_y = y

        # ç»˜åˆ¶èƒŒæ™¯å’Œæ–‡æœ¬ - ä½¿ç”¨å­—ç¬¦çº§æ¢è¡Œ
        self.set_x(x + 5)
        from fpdf.enums import WrapMode

        self.multi_cell(w=box_width - 10, h=5, text=clean_text, fill=True, wrapmode=WrapMode.CHAR)

        # ç»˜åˆ¶å·¦ä¾§è“è‰²è¾¹çº¿
        end_y = self.get_y()
        self.set_line_width(0.8)
        self.set_draw_color(59, 130, 246)
        self.line(x, start_y, x, end_y)

        # é‡ç½® X ä½ç½®
        self.set_x(self.l_margin)
        self.ln(4)


def generate_report_pdf(report_data: dict, user_input: str = "") -> bytes:
    """
    ğŸ”¥ v7.24 åˆå¹¶ä¼˜åŒ–ï¼šç”Ÿæˆå®Œæ•´æŠ¥å‘Š PDFï¼ˆå«ä¸“å®¶æŠ¥å‘Šï¼‰

    PDF ç»“æ„å¯¹é½å‰ç«¯æ˜¾ç¤ºï¼ŒåŒ…å« 6 ä¸ªæ ¸å¿ƒç« èŠ‚ï¼š
    1. ç”¨æˆ·åŸå§‹éœ€æ±‚
    2. æ ¡å‡†é—®å·å›é¡¾ï¼ˆè¿‡æ»¤"æœªå›ç­”"ï¼‰
    3. éœ€æ±‚æ´å¯Ÿ
    4. æ ¸å¿ƒç­”æ¡ˆï¼ˆæ”¯æŒ v7.0 å¤šäº¤ä»˜ç‰©æ ¼å¼ï¼‰
    5. ä¸“å®¶æŠ¥å‘Šé™„å½•ï¼ˆğŸ†• v7.24: åˆå¹¶åŸç‹¬ç«‹ä¸‹è½½ï¼‰
    6. æ‰§è¡Œå…ƒæ•°æ®
    """
    pdf = PDFGenerator()

    # ========== å°é¢é¡µ ==========
    pdf.add_cover_page("é¡¹ç›®åˆ†ææŠ¥å‘Š")

    # ========== ç›®å½•é¡µï¼ˆç®€åŒ–ç‰ˆï¼Œæ— é¡µç ï¼‰ ==========
    # ğŸ”¥ v7.26: æ·»åŠ "æŠ¥å‘Šï¼ˆæè‡´æ¦‚å¿µï¼‰"æ¡ç›®
    chapters = [
        {"title": "æŠ¥å‘Šï¼ˆæè‡´æ¦‚å¿µï¼‰", "page": ""},
        {"title": "ç”¨æˆ·åŸå§‹éœ€æ±‚", "page": ""},
        {"title": "æ ¡å‡†é—®å·å›é¡¾", "page": ""},
        {"title": "éœ€æ±‚æ´å¯Ÿ", "page": ""},
        {"title": "æ ¸å¿ƒç­”æ¡ˆ", "page": ""},
        {"title": "ä¸“å®¶æŠ¥å‘Šé™„å½•", "page": ""},
        {"title": "æ‰§è¡Œå…ƒæ•°æ®", "page": ""},
    ]
    pdf.add_table_of_contents(chapters)

    # ========== ç¬¬ä¸€ç« ï¼šæŠ¥å‘Šï¼ˆæè‡´æ¦‚å¿µï¼‰ ==========
    # ğŸ”¥ v7.26: æ–°å¢ç« èŠ‚ - æŠ¥å‘Šæ¦‚è¿°
    pdf.add_page()  # ç›®å½•åçš„ç¬¬ä¸€ç« éœ€è¦æ–°é¡µ
    pdf.chapter_title("ç¬¬ä¸€ç«   æŠ¥å‘Šï¼ˆæè‡´æ¦‚å¿µï¼‰", 1)
    pdf.body_text("æœ¬æŠ¥å‘Šç”±æè‡´æ¦‚å¿µæ™ºèƒ½åˆ†æç³»ç»Ÿç”Ÿæˆï¼ŒåŸºäºå¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶ï¼Œä¸ºæ‚¨çš„é¡¹ç›®éœ€æ±‚æä¾›å…¨æ–¹ä½çš„ä¸“ä¸šåˆ†æä¸å»ºè®®ã€‚")
    pdf.ln(5)

    # æŠ¥å‘Šæ¦‚è¿°ä¿¡æ¯
    expert_reports = report_data.get("expert_reports", {})
    expert_count = len(expert_reports) if isinstance(expert_reports, dict) else 0
    if expert_count > 0:
        pdf.chapter_title("åˆ†ææ¦‚è¿°", 2)
        pdf.body_text(f"â€¢ å‚ä¸ä¸“å®¶æ•°é‡ï¼š{expert_count} ä½")
        pdf.body_text(f"â€¢ ç”Ÿæˆæ—¥æœŸï¼š{datetime.now().strftime('%Y-%m-%d')}")

    pdf.add_divider()

    # ========== ç¬¬äºŒç« ï¼šç”¨æˆ·åŸå§‹éœ€æ±‚ ==========
    # ğŸ”¥ v7.26: ç©ºä¸¤è¡Œè¿ç»­è¾“å‡ºï¼Œä¸è¦æ¯ä¸ªç« èŠ‚åˆ†é¡µ
    pdf.ln(15)
    pdf.chapter_title("ç¬¬äºŒç«   ç”¨æˆ·åŸå§‹éœ€æ±‚", 1)
    if user_input:
        pdf.highlighted_box(user_input)
    else:
        pdf.body_text("ï¼ˆæ— ç”¨æˆ·è¾“å…¥ï¼‰")
    pdf.add_divider()

    # ========== ç¬¬ä¸‰ç« ï¼šæ ¡å‡†é—®å·å›é¡¾ ==========
    # ğŸ”¥ v7.26: ç©ºä¸¤è¡Œè¿ç»­è¾“å‡º
    pdf.ln(15)
    pdf.chapter_title("ç¬¬ä¸‰ç«   æ ¡å‡†é—®å·å›é¡¾", 1)

    questionnaire = report_data.get("questionnaire_responses", {})
    if questionnaire and isinstance(questionnaire, dict):
        responses = questionnaire.get("responses", [])
        # ğŸ”¥ è¿‡æ»¤ï¼šåªæ˜¾ç¤ºæœ‰æ•ˆå›ç­”ï¼ˆæ’é™¤"æœªå›ç­”"å’Œç©ºç­”æ¡ˆï¼‰
        valid_responses = [
            r for r in responses if isinstance(r, dict) and r.get("answer") and r.get("answer") not in ["æœªå›ç­”", ""]
        ]

        if valid_responses:
            pdf.body_text(f"å…±æ”¶é›† {len(valid_responses)} æ¡æœ‰æ•ˆå›ç­”ï¼š")
            pdf.ln(3)

            for idx, resp in enumerate(valid_responses, 1):
                question = resp.get("question", "")
                answer = resp.get("answer", "")
                context = resp.get("context", "")

                # é—®é¢˜æ ‡é¢˜
                pdf.chapter_title(f"Q{idx}. {question}", 3)

                # å›ç­”å†…å®¹
                pdf._set_font_safe("", 10)
                pdf.set_text_color(51, 51, 51)
                pdf.body_text(f"å›ç­”ï¼š{answer}")

                # é—®é¢˜èƒŒæ™¯ï¼ˆå¦‚æœæœ‰ï¼‰
                if context:
                    pdf._set_font_safe("", 9)
                    pdf.set_text_color(128, 128, 128)
                    pdf.body_text(f"èƒŒæ™¯ï¼š{context}")

                pdf.ln(2)

            # åˆ†ææ´å¯Ÿï¼ˆå¦‚æœæœ‰ï¼‰
            analysis_insights = questionnaire.get("analysis_insights", "")
            if analysis_insights:
                pdf.add_divider()
                pdf.chapter_title("éœ€æ±‚åˆ†æ", 3)
                pdf.body_text(analysis_insights)
        else:
            pdf.body_text("ç”¨æˆ·è·³è¿‡äº†æ ¡å‡†é—®å·ï¼Œæˆ–æ‰€æœ‰é—®é¢˜å‡æœªå›ç­”ã€‚")
    else:
        pdf.body_text("ç”¨æˆ·è·³è¿‡äº†æ ¡å‡†é—®å·ã€‚")

    pdf.add_divider()

    # ========== ç¬¬å››ç« ï¼šéœ€æ±‚æ´å¯Ÿ ==========
    # ğŸ”¥ v7.26: ç©ºä¸¤è¡Œè¿ç»­è¾“å‡º
    pdf.ln(15)
    pdf.chapter_title("ç¬¬å››ç«   éœ€æ±‚æ´å¯Ÿ", 1)

    insights = report_data.get("insights", {})

    # ğŸ”¥ v7.26.2: å…œåº•é€»è¾‘ - å¦‚æœ insights ä¸ºç©ºï¼Œä» requirements_analysis æå–
    if not insights or not isinstance(insights, dict):
        requirements_analysis = report_data.get("requirements_analysis", {})
        if requirements_analysis and isinstance(requirements_analysis, dict):
            logger.info("ğŸ”§ [PDF] insights ä¸ºç©ºï¼Œä» requirements_analysis æå–å…œåº•æ•°æ®")
            insights = {
                "key_insights": [
                    requirements_analysis.get("project_overview", ""),
                    requirements_analysis.get("project_task", ""),
                ],
                "cross_domain_connections": requirements_analysis.get("core_objectives", []),
                "user_needs_interpretation": requirements_analysis.get("character_narrative", ""),
            }
            # è¿‡æ»¤ç©ºå€¼
            insights["key_insights"] = [i for i in insights["key_insights"] if i]
            if not insights["key_insights"]:
                insights = {}

    if insights and isinstance(insights, dict):
        # æ ¸å¿ƒæ´å¯Ÿ
        key_insights = insights.get("key_insights", [])
        if key_insights:
            pdf.chapter_title("æ ¸å¿ƒæ´å¯Ÿ", 2)
            for idx, insight in enumerate(key_insights, 1):
                pdf.list_item(f"{insight}", numbered=True, index=idx - 1)
            pdf.ln(3)

        # è·¨é¢†åŸŸå…³è”
        cross_domain = insights.get("cross_domain_connections", [])
        if cross_domain:
            pdf.chapter_title("è·¨é¢†åŸŸå…³è”", 2)
            for item in cross_domain:
                pdf.list_item(item)
            pdf.ln(3)

        # ç”¨æˆ·éœ€æ±‚æ·±å±‚è§£è¯»
        interpretation = insights.get("user_needs_interpretation", "")
        if interpretation:
            pdf.chapter_title("ç”¨æˆ·éœ€æ±‚æ·±å±‚è§£è¯»", 2)
            pdf.body_text(interpretation)
    else:
        pdf.body_text("ï¼ˆæš‚æ— éœ€æ±‚æ´å¯Ÿæ•°æ®ï¼‰")

    pdf.add_divider()

    # ========== ç¬¬äº”ç« ï¼šæ ¸å¿ƒç­”æ¡ˆ ==========
    # ğŸ”¥ v7.26: ç©ºä¸¤è¡Œè¿ç»­è¾“å‡º
    pdf.ln(15)
    pdf.chapter_title("ç¬¬äº”ç«   æ ¸å¿ƒç­”æ¡ˆ", 1)

    core_answer = report_data.get("core_answer", {})

    # ğŸ”¥ v7.26.2: å…œåº•é€»è¾‘ - å¦‚æœ core_answer ä¸ºç©ºï¼Œä» expert_reports æå–äº¤ä»˜ç‰©ä¿¡æ¯
    if not core_answer or not isinstance(core_answer, dict):
        logger.info("ğŸ”§ [PDF] core_answer ä¸ºç©ºï¼Œä» expert_reports æå–å…œåº•æ•°æ®")
        # ä»ä¸“å®¶æŠ¥å‘Šä¸­æå–äº¤ä»˜ç‰©åç§°
        deliverable_names = []
        expert_reports_raw = report_data.get("expert_reports", {})
        if isinstance(expert_reports_raw, dict):
            for expert_name, content in expert_reports_raw.items():
                if isinstance(content, str):
                    try:
                        content_dict = json.loads(content) if content.strip().startswith("{") else {}
                        ter = content_dict.get("task_execution_report", content_dict)
                        if isinstance(ter, dict):
                            outputs = ter.get("deliverable_outputs", [])
                            for output in outputs:
                                if isinstance(output, dict):
                                    name = output.get("deliverable_name", output.get("name", ""))
                                    if name and name not in deliverable_names:
                                        deliverable_names.append(name)
                    except (json.JSONDecodeError, AttributeError):
                        pass

        if deliverable_names:
            requirements = report_data.get("requirements_analysis", {})
            core_answer = {
                "question": user_input[:100] + "..." if len(user_input) > 100 else user_input,
                "answer": requirements.get("project_overview", "è¯·æŸ¥çœ‹å„ä¸“å®¶çš„è¯¦ç»†åˆ†ææŠ¥å‘Š"),
                "deliverables": deliverable_names[:5],
                "timeline": "è¯·å‚è€ƒå·¥ç¨‹å¸ˆä¸“å®¶çš„å®æ–½è§„åˆ’",
                "budget_range": "è¯·å‚è€ƒå·¥ç¨‹å¸ˆä¸“å®¶çš„æˆæœ¬ä¼°ç®—",
            }

    if core_answer and isinstance(core_answer, dict):
        # æ£€æµ‹æ˜¯å¦æ˜¯ v7.0 å¤šäº¤ä»˜ç‰©æ ¼å¼
        deliverable_answers = core_answer.get("deliverable_answers", [])

        if deliverable_answers:
            # ğŸ†• v7.0 å¤šäº¤ä»˜ç‰©æ ¼å¼
            pdf.body_text(f"æœ¬é¡¹ç›®åŒ…å« {len(deliverable_answers)} ä¸ªæ ¸å¿ƒäº¤ä»˜ç‰©ï¼š")
            pdf.ln(5)

            for da in deliverable_answers:
                if not isinstance(da, dict):
                    continue

                deliverable_id = da.get("deliverable_id", "")
                deliverable_name = da.get("deliverable_name", "")
                owner_role = da.get("owner_role", "")
                answer_summary = da.get("answer_summary", "")
                owner_answer = da.get("owner_answer", "")
                supporters = da.get("supporters", [])
                quality_score = da.get("quality_score")

                # äº¤ä»˜ç‰©æ ‡é¢˜
                pdf.chapter_title(f"ã€{deliverable_id}ã€‘{deliverable_name}", 2)

                # è´£ä»»è€…ä¿¡æ¯
                pdf._set_font_safe("", 10)
                pdf.set_text_color(100, 100, 100)
                role_display = _get_role_display_name(owner_role)
                pdf.body_text(f"è´£ä»»ä¸“å®¶: {role_display}")

                if quality_score:
                    pdf.body_text(f"å®Œæˆåº¦: {int(quality_score)}%")

                # ç­”æ¡ˆæ‘˜è¦
                if answer_summary:
                    pdf.chapter_title("ç­”æ¡ˆæ‘˜è¦", 3)
                    pdf.body_text(answer_summary)

                # å®Œæ•´è¾“å‡º
                if owner_answer:
                    pdf.chapter_title("è´£ä»»è€…è¾“å‡º", 3)
                    pdf.body_text(owner_answer)

                # æ”¯æ’‘ä¸“å®¶
                if supporters:
                    pdf.chapter_title("æ”¯æ’‘ä¸“å®¶", 3)
                    supporter_names = [_get_role_display_name(s) for s in supporters]
                    pdf.body_text("ã€".join(supporter_names))

                pdf.ln(5)
        else:
            # æ—§æ ¼å¼ï¼ˆå•ä¸€ç­”æ¡ˆï¼‰
            question = core_answer.get("question", "")
            answer = core_answer.get("answer", "")
            deliverables = core_answer.get("deliverables", [])
            timeline = core_answer.get("timeline", "")
            budget_range = core_answer.get("budget_range", "")

            if question:
                pdf.chapter_title("æ ¸å¿ƒé—®é¢˜", 2)
                pdf.body_text(question)

            if answer:
                pdf.chapter_title("ç»¼åˆç­”æ¡ˆ", 2)
                pdf.body_text(answer)

            if deliverables:
                pdf.chapter_title("äº¤ä»˜ç‰©æ¸…å•", 2)
                for idx, d in enumerate(deliverables, 1):
                    pdf.list_item(d, numbered=True, index=idx - 1)
                pdf.ln(3)

            if timeline:
                pdf.chapter_title("æ—¶é—´è§„åˆ’", 2)
                pdf.body_text(timeline)

            if budget_range:
                pdf.chapter_title("é¢„ç®—èŒƒå›´", 2)
                pdf.body_text(budget_range)
    else:
        pdf.body_text("ï¼ˆæš‚æ— æ ¸å¿ƒç­”æ¡ˆæ•°æ®ï¼‰")

    pdf.add_divider()

    # ========== ç¬¬å…­ç« ï¼šä¸“å®¶æŠ¥å‘Šé™„å½• ğŸ†• v7.24 ==========
    expert_reports = report_data.get("expert_reports", {})
    if expert_reports and isinstance(expert_reports, dict) and len(expert_reports) > 0:
        # ğŸ”¥ v7.26: ç©ºä¸¤è¡Œè¿ç»­è¾“å‡ºï¼Œä¸è¦åˆ†é¡µ
        pdf.ln(15)
        pdf.chapter_title("ç¬¬å…­ç«   ä¸“å®¶æŠ¥å‘Šé™„å½•", 1)
        pdf.body_text(f"æœ¬ç« åŒ…å« {len(expert_reports)} ä½ä¸“å®¶çš„è¯¦ç»†åˆ†ææŠ¥å‘Šã€‚")
        pdf.ln(5)

        # ä¸“å®¶ç›®å½•
        pdf.chapter_title("ä¸“å®¶åˆ—è¡¨", 2)
        for i, expert_name in enumerate(expert_reports.keys(), 1):
            pdf.list_item(f"{i}. {expert_name}", numbered=False)
        pdf.ln(5)

        # é€ä¸ªä¸“å®¶æŠ¥å‘Š - ğŸ”¥ v7.26: ä¸åˆ†é¡µï¼Œç©ºè¡Œåˆ†éš”
        for expert_name, content in expert_reports.items():
            pdf.ln(10)
            pdf.chapter_title(expert_name, 2)
            format_expert_content_for_pdf(pdf, content)

    pdf.add_divider()

    # ========== ç¬¬ä¸ƒç« ï¼šæ‰§è¡Œå…ƒæ•°æ® ==========
    # ğŸ”¥ v7.26: ç©ºä¸¤è¡Œè¿ç»­è¾“å‡ºï¼Œä¸è¦åˆ†é¡µ
    pdf.ln(15)
    pdf.chapter_title("ç¬¬ä¸ƒç«   æ‰§è¡Œå…ƒæ•°æ®", 1)

    # ä» report_data ä¸­æ”¶é›†å…ƒæ•°æ®
    inquiry_architecture = report_data.get("inquiry_architecture", "")
    expert_reports = report_data.get("expert_reports", {})
    expert_count = len(expert_reports) if isinstance(expert_reports, dict) else 0

    # ä¸“å®¶æ•°é‡
    pdf.chapter_title("ä¸“å®¶æ•°é‡", 2)
    pdf.body_text(f"{expert_count} ä½ä¸“å®¶å‚ä¸åˆ†æ")

    # æ¢è¯¢æ¶æ„
    if inquiry_architecture:
        pdf.chapter_title("æ¢è¯¢æ¶æ„", 2)
        pdf.body_text(inquiry_architecture)

    # ç”Ÿæˆæ—¶é—´
    pdf.chapter_title("æŠ¥å‘Šç”Ÿæˆæ—¶é—´", 2)
    pdf.body_text(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

    return bytes(pdf.output())


def _get_role_display_name(role_id: str) -> str:
    """æå–è§’è‰²æ˜¾ç¤ºåç§°"""
    role_map = {
        "V2_è®¾è®¡æ€»ç›‘": "è®¾è®¡æ€»ç›‘",
        "V3_å™äº‹ä¸ä½“éªŒä¸“å®¶": "å™äº‹ä¸ä½“éªŒä¸“å®¶",
        "V3_äººç‰©åŠå™äº‹ä¸“å®¶": "äººç‰©åŠå™äº‹ä¸“å®¶",
        "V4_è®¾è®¡ç ”ç©¶ä¸“å‘˜": "è®¾è®¡ç ”ç©¶ä¸“å‘˜",
        "V4_è®¾è®¡ç ”ç©¶å‘˜": "è®¾è®¡ç ”ç©¶å‘˜",
        "V5_åœºæ™¯ç­–åˆ’å¸ˆ": "åœºæ™¯ç­–åˆ’å¸ˆ",
        "V5_åœºæ™¯ä¸ç”¨æˆ·ç”Ÿæ€ä¸“å®¶": "åœºæ™¯ä¸ç”¨æˆ·ç”Ÿæ€ä¸“å®¶",
        "V6_ä¸“ä¸šæ€»å·¥ç¨‹å¸ˆ": "ä¸“ä¸šæ€»å·¥ç¨‹å¸ˆ",
        "V6_å·¥ç¨‹å¸ˆ": "å·¥ç¨‹å¸ˆ",
    }

    for prefix, name in role_map.items():
        if role_id.startswith(prefix):
            return name
    return role_id


# å­—æ®µä¸­æ–‡æ ‡ç­¾æ˜ å°„ï¼ˆä¸å‰ç«¯ä¿æŒä¸€è‡´ï¼‰
FIELD_LABELS = {
    # é€šç”¨å­—æ®µ
    "executive_summary": "æ‰§è¡Œæ‘˜è¦",
    "project_overview": "é¡¹ç›®æ¦‚è¿°",
    "key_findings": "å…³é”®å‘ç°",
    "key_recommendations": "æ ¸å¿ƒå»ºè®®",
    "success_factors": "æˆåŠŸè¦ç´ ",
    "core_analysis": "æ ¸å¿ƒåˆ†æ",
    "professional_opinion": "ä¸“ä¸šæ„è§",
    "design_recommendations": "è®¾è®¡å»ºè®®",
    "implementation_guidance": "å®æ–½æŒ‡å¯¼",
    "analysis": "åˆ†æ",
    "recommendations": "å»ºè®®",
    "conclusion": "ç»“è®º",
    "summary": "æ€»ç»“",
    "overview": "æ¦‚è¿°",
    "details": "è¯¦æƒ…",
    "description": "æè¿°",
    "assessment": "è¯„ä¼°",
    "evaluation": "è¯„ä»·",
    "findings": "å‘ç°",
    "insights": "æ´å¯Ÿ",
    "observations": "è§‚å¯Ÿ",
    "considerations": "è€ƒè™‘å› ç´ ",
    "factors": "å› ç´ ",
    "challenges": "æŒ‘æˆ˜",
    "opportunities": "æœºé‡",
    "risks": "é£é™©",
    "benefits": "ä¼˜åŠ¿",
    "limitations": "å±€é™",
    "requirements": "éœ€æ±‚",
    "objectives": "ç›®æ ‡",
    "goals": "ç›®æ ‡",
    "strategy": "ç­–ç•¥",
    "approach": "æ–¹æ³•",
    "methodology": "æ–¹æ³•è®º",
    "framework": "æ¡†æ¶",
    "principles": "åŸåˆ™",
    "guidelines": "æŒ‡å¯¼æ–¹é’ˆ",
    "standards": "æ ‡å‡†",
    "criteria": "æ ‡å‡†",
    "metrics": "æŒ‡æ ‡",
    "indicators": "æŒ‡æ ‡",
    "performance": "æ€§èƒ½",
    "quality": "è´¨é‡",
    "efficiency": "æ•ˆç‡",
    "effectiveness": "æœ‰æ•ˆæ€§",
    "impact": "å½±å“",
    "outcome": "ç»“æœ",
    "output": "äº§å‡º",
    "input": "è¾“å…¥",
    "process": "æµç¨‹",
    "procedure": "ç¨‹åº",
    "steps": "æ­¥éª¤",
    "phases": "é˜¶æ®µ",
    "stages": "é˜¶æ®µ",
    "timeline": "æ—¶é—´çº¿",
    "schedule": "è®¡åˆ’",
    "budget": "é¢„ç®—",
    "cost": "æˆæœ¬",
    "resources": "èµ„æº",
    "materials": "ææ–™",
    "equipment": "è®¾å¤‡",
    "tools": "å·¥å…·",
    "technologies": "æŠ€æœ¯",
    "methods": "æ–¹æ³•",
    "techniques": "æŠ€æœ¯",
    "solutions": "è§£å†³æ–¹æ¡ˆ",
    "alternatives": "æ›¿ä»£æ–¹æ¡ˆ",
    "options": "é€‰é¡¹",
    "choices": "é€‰æ‹©",
    "preferences": "åå¥½",
    "priorities": "ä¼˜å…ˆçº§",
    "concerns": "å…³æ³¨ç‚¹",
    "issues": "é—®é¢˜",
    "problems": "é—®é¢˜",
    "actions": "è¡ŒåŠ¨",
    "tasks": "ä»»åŠ¡",
    "activities": "æ´»åŠ¨",
    "deliverables": "äº¤ä»˜ç‰©",
    "milestones": "é‡Œç¨‹ç¢‘",
    "achievements": "æˆå°±",
    "results": "ç»“æœ",
    "confidence": "ç½®ä¿¡åº¦",
    "custom_analysis": "å®šåˆ¶åˆ†æ",
    "expert_handoff_response": "ä¸“å®¶äº¤æ¥å“åº”",
    "critical_questions_responses": "å…³é”®é—®é¢˜å“åº”",
    "missing_inputs_warning": "ç¼ºå¤±è¾“å…¥è­¦å‘Š",
    # è®¾è®¡ç›¸å…³å­—æ®µ
    "project_vision_summary": "é¡¹ç›®æ„¿æ™¯æ¦‚è¿°",
    "decision_rationale": "å†³ç­–ä¾æ®",
    "spatial_concept": "ç©ºé—´æ¦‚å¿µ",
    "customer_journey_design": "å®¢æˆ·æ—…ç¨‹è®¾è®¡",
    "visual_merchandising_strategy": "è§†è§‰è¥é”€ç­–ç•¥",
    "brand_identity_integration": "å“ç‰Œè¯†åˆ«æ•´åˆ",
    "space_planning": "ç©ºé—´è§„åˆ’",
    "material_selection": "ææ–™é€‰æ‹©",
    "lighting_design": "ç…§æ˜è®¾è®¡",
    "color_scheme": "é…è‰²æ–¹æ¡ˆ",
    "furniture_layout": "å®¶å…·å¸ƒå±€",
    "user_experience": "ç”¨æˆ·ä½“éªŒ",
    "functional_requirements": "åŠŸèƒ½éœ€æ±‚",
    "aesthetic_considerations": "ç¾å­¦è€ƒé‡",
    "sustainability": "å¯æŒç»­æ€§",
    "accessibility": "æ— éšœç¢è®¾è®¡",
    "safety": "å®‰å…¨æ€§",
    "maintenance": "ç»´æŠ¤",
    "durability": "è€ä¹…æ€§",
    # æ¡ˆä¾‹ç ”ç©¶ç›¸å…³
    "case_studies_deep_dive": "æ·±åº¦æ¡ˆä¾‹ç ”ç©¶",
    "competitive_analysis": "ç«å“åˆ†æ",
    "reusable_design_patterns": "å¯å¤ç”¨è®¾è®¡æ¨¡å¼",
    "key_success_factors": "å…³é”®æˆåŠŸå› ç´ ",
    "application_guidelines_for_team": "å›¢é˜Ÿåº”ç”¨æŒ‡å—",
    "key_takeaways": "å…³é”®è¦ç‚¹",
    "name": "åç§°",
    "brand": "å“ç‰Œ",
    "strengths": "ä¼˜åŠ¿",
    "weaknesses": "åŠ£åŠ¿",
    "pattern_name": "æ¨¡å¼åç§°",
    "pattern name": "æ¨¡å¼åç§°",
    # è¿è¥ç›¸å…³
    "business_goal_analysis": "å•†ä¸šç›®æ ‡åˆ†æ",
    "operational_blueprint": "è¿è¥è“å›¾",
    "key_performance_indicators": "å…³é”®ç»©æ•ˆæŒ‡æ ‡",
    "design_challenges_for_v2": "ç»™è®¾è®¡æ€»ç›‘çš„æŒ‘æˆ˜",
    "journey_maps": "æ—…ç¨‹åœ°å›¾",
    "healing_environment_kpis": "ç–—æ„ˆç¯å¢ƒKPI",
    "technical_requirements_for_v6": "ç»™æŠ€æœ¯ä¸“å®¶çš„éœ€æ±‚",
    "metric": "æŒ‡æ ‡",
    "target": "ç›®æ ‡å€¼",
    "spatial_strategy": "ç©ºé—´ç­–ç•¥",
    # ç”¨æˆ·ç ”ç©¶ç›¸å…³
    "pain_points": "ç—›ç‚¹",
    "Pain Points": "ç—›ç‚¹",
    "persona": "ç”¨æˆ·ç”»åƒ",
    "Persona": "ç”¨æˆ·ç”»åƒ",
    "user_needs": "ç”¨æˆ·éœ€æ±‚",
    "user_goals": "ç”¨æˆ·ç›®æ ‡",
    "user_journey": "ç”¨æˆ·æ—…ç¨‹",
    "touchpoints": "è§¦ç‚¹",
    "empathy_map": "å…±æƒ…åœ°å›¾",
    # æŠ€æœ¯ç›¸å…³
    "mep_overall_strategy": "æœºç”µæ•´ä½“ç­–ç•¥",
    "system_solutions": "ç³»ç»Ÿè§£å†³æ–¹æ¡ˆ",
    "smart_building_scenarios": "æ™ºèƒ½å»ºç­‘åœºæ™¯",
    "coordination_and_clash_points": "åè°ƒä¸å†²çªç‚¹",
    "sustainability_and_energy_saving": "å¯æŒç»­ä¸èŠ‚èƒ½",
    # ææ–™ä¸å·¥è‰º
    "craftsmanship_strategy": "å·¥è‰ºç­–ç•¥",
    "key_material_specifications": "å…³é”®ææ–™è§„æ ¼",
    "critical_node_details": "å…³é”®èŠ‚ç‚¹è¯¦å›¾",
    "quality_control_and_mockup": "è´¨é‡æ§åˆ¶ä¸æ ·æ¿",
    "risk_analysis": "é£é™©åˆ†æ",
    "design_rationale": "è®¾è®¡ä¾æ®",
    # æŒ‘æˆ˜ç›¸å…³
    "challenge": "æŒ‘æˆ˜",
    "context": "èƒŒæ™¯",
    "constraints": "çº¦æŸæ¡ä»¶",
    "challenge_flags": "æŒ‘æˆ˜æ ‡è®°",
    # ç­¾åæ–¹æ³•/åº”ç”¨ç›¸å…³
    "signature_methods": "æ ‡å¿—æ€§æ–¹æ³•",
    "application_to_project": "é¡¹ç›®åº”ç”¨",
    "initial_key_scenario": "åˆå§‹å…³é”®åœºæ™¯",
    # è®¾è®¡ç«‹åœºç›¸å…³
    "pole_a_resolve": "ç«‹åœºAè§£å†³æ–¹æ¡ˆ",
    "pole_b_resolve": "ç«‹åœºBè§£å†³æ–¹æ¡ˆ",
    "chosen_design_stance": "é€‰å®šçš„è®¾è®¡ç«‹åœº",
    # å¤§å¸ˆæ¡ˆä¾‹ç ”ç©¶ç›¸å…³
    "master_work_deconstruction_nendo": "å¤§å¸ˆä½œå“è§£æ„ï¼šNendo",
    "master_work_deconstruction": "å¤§å¸ˆä½œå“è§£æ„",
    "master": "å¤§å¸ˆ",
    "philosophy": "è®¾è®¡å“²å­¦",
    "missing_inspiration_warning": "ç¼ºå¤±çµæ„Ÿè­¦å‘Š",
    "desc": "è¯´æ˜",
    # å…¶ä»–å¸¸è§å­—æ®µ
    "q1": "é—®é¢˜1",
    "q2": "é—®é¢˜2",
    "q3": "é—®é¢˜3",
    # ============ ä»»åŠ¡å¯¼å‘æ¨¡å‹å­—æ®µ (task_oriented_models.py) ============
    # DeliverableOutput äº¤ä»˜ç‰©è¾“å‡º
    "deliverable_name": "äº¤ä»˜ç‰©åç§°",
    "deliverable_outputs": "äº¤ä»˜ç‰©è¾“å‡º",
    "content": "å†…å®¹",
    "completion_status": "å®ŒæˆçŠ¶æ€",
    "completion_rate": "å®Œæˆåº¦",
    "notes": "å¤‡æ³¨",
    "quality_self_assessment": "è´¨é‡è‡ªè¯„",
    # TaskExecutionReport ä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Š
    "task_execution_report": "ä»»åŠ¡æ‰§è¡ŒæŠ¥å‘Š",
    "task_completion_summary": "ä»»åŠ¡å®Œæˆæ€»ç»“",
    "additional_insights": "é¢å¤–æ´å¯Ÿ",
    "execution_challenges": "æ‰§è¡ŒæŒ‘æˆ˜",
    # ProtocolExecutionReport åè®®æ‰§è¡ŒæŠ¥å‘Š
    "protocol_execution": "åè®®æ‰§è¡ŒæŠ¥å‘Š",
    "protocol_status": "åè®®çŠ¶æ€",
    "compliance_confirmation": "åˆè§„ç¡®è®¤",
    "challenge_details": "æŒ‘æˆ˜è¯¦æƒ…",
    "reinterpretation": "é‡æ–°è¯ é‡Š",
    # ChallengeFlag æŒ‘æˆ˜æ ‡è®°
    "challenged_item": "è¢«æŒ‘æˆ˜å†…å®¹",
    "challenge_reason": "æŒ‘æˆ˜ç†ç”±",
    "alternative_proposal": "æ›¿ä»£æ–¹æ¡ˆ",
    # ReinterpretationDetail é‡æ–°è¯ é‡Šè¯¦æƒ…
    "original_interpretation": "åŸå§‹è¯ é‡Š",
    "new_interpretation": "æ–°è¯ é‡Š",
    "reinterpretation_rationale": "è¯ é‡Šä¾æ®",
    "impact_on_approach": "æ–¹æ³•è®ºå½±å“",
    # ExecutionMetadata æ‰§è¡Œå…ƒæ•°æ®
    "execution_metadata": "æ‰§è¡Œå…ƒæ•°æ®",
    "execution_time_estimate": "æ‰§è¡Œæ—¶é—´ä¼°ç®—",
    "execution_notes": "æ‰§è¡Œå¤‡æ³¨",
    "dependencies_satisfied": "ä¾èµ–æ»¡è¶³",
    # TaskInstruction ä»»åŠ¡æŒ‡ä»¤
    "objective": "æ ¸å¿ƒç›®æ ‡",
    "success_criteria": "æˆåŠŸæ ‡å‡†",
    "context_requirements": "ä¸Šä¸‹æ–‡éœ€æ±‚",
    # DeliverableSpec äº¤ä»˜ç‰©è§„æ ¼
    "format": "æ ¼å¼",
    "priority": "ä¼˜å…ˆçº§",
    # åè®®çŠ¶æ€æšä¸¾å€¼
    "complied": "å·²éµç…§",
    "challenged": "å·²æŒ‘æˆ˜",
    "reinterpreted": "å·²é‡æ–°è¯ é‡Š",
    # å®ŒæˆçŠ¶æ€æšä¸¾å€¼
    "completed": "å·²å®Œæˆ",
    "partial": "éƒ¨åˆ†å®Œæˆ",
    "unable": "æ— æ³•å®Œæˆ",
    # ============ V2-V6 FlexibleOutput ä¸“å®¶æ¨¡å‹å­—æ®µ ============
    # é€šç”¨å­—æ®µ
    "output_mode": "è¾“å‡ºæ¨¡å¼",
    "user_question_focus": "é—®é¢˜èšç„¦",
    "design_rationale": "è®¾è®¡ä¾æ®",
    "decision_rationale": "å†³ç­–ä¾æ®",
    "targeted_analysis": "é’ˆå¯¹æ€§åˆ†æ",
    "supplementary_insights": "è¡¥å……æ´å¯Ÿ",
    # V6-1 ç»“æ„ä¸å¹•å¢™å·¥ç¨‹å¸ˆ
    "feasibility_assessment": "å¯è¡Œæ€§è¯„ä¼°",
    "structural_system_options": "ç»“æ„ä½“ç³»é€‰é¡¹",
    "facade_system_options": "å¹•å¢™ä½“ç³»é€‰é¡¹",
    "key_technical_nodes": "å…³é”®æŠ€æœ¯èŠ‚ç‚¹",
    "risk_analysis_and_recommendations": "é£é™©åˆ†æä¸å»ºè®®",
    "option_name": "æ–¹æ¡ˆåç§°",
    "advantages": "ä¼˜åŠ¿",
    "disadvantages": "åŠ£åŠ¿",
    "estimated_cost_level": "é¢„ä¼°é€ ä»·ç­‰çº§",
    "node_name": "èŠ‚ç‚¹åç§°",
    "proposed_solution": "å»ºè®®æ–¹æ¡ˆ",
    # V6-2 æœºç”µä¸æ™ºèƒ½åŒ–å·¥ç¨‹å¸ˆ
    "mep_overall_strategy": "æœºç”µæ•´ä½“ç­–ç•¥",
    "system_solutions": "ç³»ç»Ÿè§£å†³æ–¹æ¡ˆ",
    "smart_building_scenarios": "æ™ºèƒ½å»ºç­‘åœºæ™¯",
    "coordination_and_clash_points": "åè°ƒä¸å†²çªç‚¹",
    "sustainability_and_energy_saving": "å¯æŒç»­ä¸èŠ‚èƒ½",
    "system_name": "ç³»ç»Ÿåç§°",
    "recommended_solution": "æ¨èæ–¹æ¡ˆ",
    "reasoning": "ç†ç”±",
    "impact_on_architecture": "å¯¹å»ºç­‘çš„å½±å“",
    "scenario_name": "åœºæ™¯åç§°",
    "triggered_systems": "è”åŠ¨ç³»ç»Ÿ",
    # V6-3 å®¤å†…å·¥è‰ºä¸ææ–™ä¸“å®¶
    "craftsmanship_strategy": "å·¥è‰ºç­–ç•¥",
    "key_material_specifications": "å…³é”®ææ–™è§„æ ¼",
    "critical_node_details": "å…³é”®èŠ‚ç‚¹è¯¦å›¾",
    "quality_control_and_mockup": "è´¨é‡æ§åˆ¶ä¸æ ·æ¿",
    "material_name": "ææ–™åç§°",
    "application_area": "åº”ç”¨åŒºåŸŸ",
    "key_specifications": "å…³é”®è§„æ ¼",
    # V6-4 æˆæœ¬ä¸ä»·å€¼å·¥ç¨‹å¸ˆ
    "cost_estimation_summary": "æˆæœ¬ä¼°ç®—æ‘˜è¦",
    "cost_breakdown_analysis": "æˆæœ¬æ„æˆåˆ†æ",
    "value_engineering_options": "ä»·å€¼å·¥ç¨‹é€‰é¡¹",
    "budget_control_strategy": "é¢„ç®—æ§åˆ¶ç­–ç•¥",
    "cost_overrun_risk_analysis": "æˆæœ¬è¶…æ”¯é£é™©åˆ†æ",
    "category": "ç±»åˆ«",
    "percentage": "ç™¾åˆ†æ¯”",
    "cost_drivers": "æˆæœ¬é©±åŠ¨å› ç´ ",
    "original_scheme": "åŸæ–¹æ¡ˆ",
    "proposed_option": "ä¼˜åŒ–æ–¹æ¡ˆ",
    "impact_analysis": "å½±å“åˆ†æ",
    # V5-1 å±…ä½åœºæ™¯ä¸ç”Ÿæ´»æ–¹å¼ä¸“å®¶
    "family_profile_and_needs": "å®¶åº­æˆå‘˜ç”»åƒä¸éœ€æ±‚",
    "operational_blueprint": "è¿è¥è“å›¾",
    "design_challenges_for_v2": "ç»™è®¾è®¡æ€»ç›‘çš„æŒ‘æˆ˜",
    "member": "æˆå‘˜",
    "daily_routine": "æ—¥å¸¸ä½œæ¯",
    "spatial_needs": "ç©ºé—´éœ€æ±‚",
    "storage_needs": "æ”¶çº³éœ€æ±‚",
    # V5-2 å•†ä¸šé›¶å”®è¿è¥ä¸“å®¶
    "business_goal_analysis": "å•†ä¸šç›®æ ‡åˆ†æ",
    "spatial_strategy": "ç©ºé—´ç­–ç•¥",
    # V5-3 ä¼ä¸šåŠå…¬ç­–ç•¥ä¸“å®¶
    "organizational_analysis": "ç»„ç»‡åˆ†æ",
    "collaboration_model": "åä½œæ¨¡å¼",
    "workspace_strategy": "å·¥ä½œç©ºé—´ç­–ç•¥",
    # V5-4 é…’åº—é¤é¥®è¿è¥ä¸“å®¶
    "service_process_analysis": "æœåŠ¡æµç¨‹åˆ†æ",
    "operational_efficiency": "è¿è¥æ•ˆç‡",
    "guest_experience_blueprint": "å®¾å®¢ä½“éªŒè“å›¾",
    # V5-5 æ–‡åŒ–æ•™è‚²åœºæ™¯ä¸“å®¶
    "visitor_journey_analysis": "è®¿å®¢æ—…ç¨‹åˆ†æ",
    "educational_model": "æ•™è‚²æ¨¡å¼",
    "public_service_strategy": "å…¬å…±æœåŠ¡ç­–ç•¥",
    # V5-6 åŒ»ç–—åº·å…»åœºæ™¯ä¸“å®¶
    "healthcare_process_analysis": "åŒ»ç–—æµç¨‹åˆ†æ",
    "patient_experience_blueprint": "æ‚£è€…ä½“éªŒè“å›¾",
    "wellness_strategy": "åº·å…»ç­–ç•¥",
    # V2ç³»åˆ— è®¾è®¡æ€»ç›‘
    "project_vision_summary": "é¡¹ç›®æ„¿æ™¯æ¦‚è¿°",
    "spatial_concept": "ç©ºé—´æ¦‚å¿µ",
    "customer_journey_design": "å®¢æˆ·æ—…ç¨‹è®¾è®¡",
    "visual_merchandising_strategy": "è§†è§‰è¥é”€ç­–ç•¥",
    "brand_identity_integration": "å“ç‰Œè¯†åˆ«æ•´åˆ",
    "implementation_guidance": "å®æ–½æŒ‡å¯¼",
    "architectural_concept": "å»ºç­‘æ¦‚å¿µ",
    "facade_and_envelope": "ç«‹é¢ä¸å›´æŠ¤",
    "landscape_integration": "æ™¯è§‚æ•´åˆ",
    "indoor_outdoor_relationship": "å®¤å†…å¤–å…³ç³»",
    "public_vision": "å…¬å…±æ„¿æ™¯",
    "spatial_accessibility": "ç©ºé—´å¯è¾¾æ€§",
    "community_engagement": "ç¤¾åŒºå‚ä¸",
    "cultural_expression": "æ–‡åŒ–è¡¨è¾¾",
    # V3ç³»åˆ— å™äº‹ä¸ä½“éªŒä¸“å®¶
    "narrative_framework": "å™äº‹æ¡†æ¶",
    "emotional_journey": "æƒ…æ„Ÿæ—…ç¨‹",
    "touchpoint_design": "è§¦ç‚¹è®¾è®¡",
    # V4ç³»åˆ— è®¾è®¡ç ”ç©¶ä¸“å‘˜
    "case_studies_deep_dive": "æ·±åº¦æ¡ˆä¾‹ç ”ç©¶",
    "reusable_design_patterns": "å¯å¤ç”¨è®¾è®¡æ¨¡å¼",
    "key_success_factors": "å…³é”®æˆåŠŸå› ç´ ",
    "application_guidelines_for_team": "å›¢é˜Ÿåº”ç”¨æŒ‡å—",
    "trend_analysis": "è¶‹åŠ¿åˆ†æ",
    "future_scenarios": "æœªæ¥åœºæ™¯",
    "opportunity_identification": "æœºä¼šè¯†åˆ«",
    "design_implications": "è®¾è®¡å¯ç¤º",
}


def format_expert_content_for_pdf(pdf: "PDFGenerator", content: str, depth: int = 0):
    """
    æ ¼å¼åŒ–ä¸“å®¶æŠ¥å‘Šå†…å®¹å¹¶å†™å…¥ PDF

    æ”¯æŒè§£æ JSON ç»“æ„åŒ–æ•°æ®ï¼Œé€’å½’å¤„ç†åµŒå¥—å¯¹è±¡å’Œæ•°ç»„
    """
    import json

    if not content:
        pdf.body_text("ï¼ˆæ— å†…å®¹ï¼‰")
        return

    # å°è¯•è§£æ JSON
    try:
        parsed = json.loads(content)
        if isinstance(parsed, dict):
            _format_dict_to_pdf(pdf, parsed, depth)
        elif isinstance(parsed, list):
            for item in parsed:
                if isinstance(item, dict):
                    _format_dict_to_pdf(pdf, item, depth)
                else:
                    pdf.list_item(str(item))
        else:
            pdf.body_text(str(parsed))
    except (json.JSONDecodeError, TypeError):
        # ä¸æ˜¯ JSONï¼Œç›´æ¥è¾“å‡ºåŸå§‹æ–‡æœ¬
        pdf.body_text(content)


def _get_field_label(key: str) -> str:
    """è·å–å­—æ®µçš„ä¸­æ–‡æ ‡ç­¾"""
    import re

    lower_key = key.lower().strip()

    # ç²¾ç¡®åŒ¹é…ï¼ˆåŒ…æ‹¬å¸¦ç©ºæ ¼çš„keyï¼‰
    if lower_key in FIELD_LABELS:
        return FIELD_LABELS[lower_key]

    # å°è¯•æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿ååŒ¹é…
    normalized_key = lower_key.replace(" ", "_").replace("-", "_")
    if normalized_key in FIELD_LABELS:
        return FIELD_LABELS[normalized_key]

    # å¤„ç†ç‰¹æ®Šæ ¼å¼ï¼šå¦‚ "Q1 ç©ºé—´è¦å¼ºåŒ–..." è¿™ç§é—®é¢˜+å†…å®¹æ··åˆæ ¼å¼
    # åªç¿»è¯‘ Q1/Q2/Q3 éƒ¨åˆ†
    import re as regex

    q_match = regex.match(r"^(q\d+)\s*(.*)$", lower_key, regex.IGNORECASE)
    if q_match:
        q_num = q_match.group(1).upper()
        rest = q_match.group(2).strip()
        q_label = {"Q1": "é—®é¢˜1", "Q2": "é—®é¢˜2", "Q3": "é—®é¢˜3", "Q4": "é—®é¢˜4", "Q5": "é—®é¢˜5"}.get(q_num, q_num)
        if rest:
            return f"{q_label} {rest}"
        return q_label

    # å¸¸è§è‹±æ–‡è¯æ±‡åˆ°ä¸­æ–‡çš„æ˜ å°„
    common_words = {
        # åŠŸèƒ½è¯
        "for": "",
        "the": "",
        "of": "",
        "and": "ä¸",
        "to": "åˆ°",
        "in": "åœ¨",
        "on": "ä¸Š",
        "a": "",
        "an": "",
        "is": "",
        "are": "",
        "be": "",
        # è§’è‰²
        "v2": "è®¾è®¡æ€»ç›‘",
        "v3": "ä¸“å®¶",
        "v4": "ç ”ç©¶å‘˜",
        "v5": "åˆ›æ–°ä¸“å®¶",
        "v6": "æŠ€æœ¯ä¸“å®¶",
        # å¸¸è§æœ¯è¯­
        "kpi": "KPI",
        "kpis": "KPIæŒ‡æ ‡",
        "deep": "æ·±åº¦",
        "dive": "ç ”ç©¶",
        "how": "å¦‚ä½•",
        "might": "å¯èƒ½",
        "we": "æˆ‘ä»¬",
        "pattern": "æ¨¡å¼",
        "name": "åç§°",
        "signature": "æ ‡å¿—æ€§",
        "methods": "æ–¹æ³•",
        "application": "åº”ç”¨",
        "project": "é¡¹ç›®",
        "initial": "åˆå§‹",
        "key": "å…³é”®",
        "scenario": "åœºæ™¯",
        "pole": "ç«‹åœº",
        "resolve": "è§£å†³æ–¹æ¡ˆ",
        "chosen": "é€‰å®šçš„",
        "design": "è®¾è®¡",
        "stance": "ç«‹åœº",
        "q1": "é—®é¢˜1",
        "q2": "é—®é¢˜2",
        "q3": "é—®é¢˜3",
        "brand": "å“ç‰Œ",
        "identity": "è¯†åˆ«",
        "integration": "æ•´åˆ",
        "space": "ç©ºé—´",
        "spatial": "ç©ºé—´",
        "concept": "æ¦‚å¿µ",
        "customer": "å®¢æˆ·",
        "journey": "æ—…ç¨‹",
        "visual": "è§†è§‰",
        "merchandising": "è¥é”€",
        "strategy": "ç­–ç•¥",
        "summary": "æ¦‚è¿°",
        "vision": "æ„¿æ™¯",
        "rationale": "ä¾æ®",
        "decision": "å†³ç­–",
        "guidance": "æŒ‡å¯¼",
        "implementation": "å®æ–½",
        "custom": "å®šåˆ¶",
        "analysis": "åˆ†æ",
        "confidence": "ç½®ä¿¡åº¦",
        "expert": "ä¸“å®¶",
        "handoff": "äº¤æ¥",
        "response": "å“åº”",
        "critical": "å…³é”®",
        "questions": "é—®é¢˜",
        "responses": "å“åº”",
        "missing": "ç¼ºå¤±",
        "inputs": "è¾“å…¥",
        "warning": "è­¦å‘Š",
        "challenges": "æŒ‘æˆ˜",
        "flags": "æ ‡è®°",
        # å¤§å¸ˆ/æ¡ˆä¾‹ç›¸å…³
        "master": "å¤§å¸ˆ",
        "work": "ä½œå“",
        "deconstruction": "è§£æ„",
        "nendo": "Nendo",
        "philosophy": "è®¾è®¡å“²å­¦",
        "inspiration": "çµæ„Ÿ",
        "desc": "è¯´æ˜",
    }

    # å°è¯•éƒ¨åˆ†åŒ¹é…ï¼ˆå°† snake_case åˆ†è§£åç¿»è¯‘ï¼‰
    parts = normalized_key.split("_")
    translated_parts = []
    has_untranslated = False

    for part in parts:
        if not part:
            continue
        if part in FIELD_LABELS:
            translated_parts.append(FIELD_LABELS[part])
        elif part in common_words:
            if common_words[part]:
                translated_parts.append(common_words[part])
        elif part.isdigit():
            translated_parts.append(part)
        else:
            has_untranslated = True
            translated_parts.append(part)

    # å¦‚æœæœ‰æœªç¿»è¯‘çš„éƒ¨åˆ†ï¼Œè¿”å›æ ¼å¼åŒ–çš„åŸå§‹æ ‡ç­¾
    if has_untranslated:
        label = key.replace("_", " ").replace("-", " ")
        label = regex.sub(r"([a-z])([A-Z])", r"\1 \2", label)
        return label.title()

    return "".join(translated_parts) if translated_parts else key


# éœ€è¦è·³è¿‡çš„é‡å¤/å†…éƒ¨å­—æ®µ
# ğŸ”¥ v7.9.2: æ‰©å±•é»‘åå•,è¿‡æ»¤å…ƒæ•°æ®å­—æ®µ(ä¸å‰ç«¯ExpertReportAccordion.tsxä¿æŒä¸€è‡´)
# ğŸ”¥ v7.26.1: ç§»é™¤ content å­—æ®µï¼Œäº¤ç»™é€’å½’å‡½æ•°ç‰¹æ®Šå¤„ç†ï¼ˆå…è®¸åµŒå¥—å¯¹è±¡çš„ contentï¼‰
SKIP_FIELDS = {
    # åŸæœ‰å­—æ®µ - ğŸ”¥ v7.26.1: ç§»é™¤ 'content'ï¼Œäº¤ç»™é€’å½’å‡½æ•°å¤„ç†
    "raw_content",
    "raw_response",
    "original_content",
    # ğŸ”¥ v7.9.2: ä»»åŠ¡å¯¼å‘è¾“å‡ºå…ƒæ•°æ®(é¿å…æ˜¾ç¤ºæŠ€æœ¯å­—æ®µ)
    "task_execution_report",  # å·²è¢«æå–,ä¸å†éœ€è¦æ˜¾ç¤º
    "protocol_execution",
    "protocolæ‰§è¡Œ",
    "protocol_status",
    "protocolçŠ¶æ€",
    "execution_metadata",
    "executionmetadata",
    "compliance_confirmation",
    "complianceconfirmation",
    # æŠ€æœ¯å­—æ®µ
    "confidence",
    "ç½®ä¿¡åº¦",
    "completion_status",
    "completionè®°å½•",
    "completion_ratio",
    "completion_rate",
    "quality_self_assessment",
    "dependencies_satisfied",
    "notes",  # é€šå¸¸æ˜¯æŠ€æœ¯å¤‡æ³¨
    # ğŸ”¥ v7.10.1: è¿‡æ»¤æ— æ„ä¹‰çš„å›¾ç‰‡å ä½ç¬¦å­—æ®µ
    "image",
    "images",
    "å›¾ç‰‡",
    "illustration",
    "illustrations",
    "image_1_url",
    "image_2_url",
    "image_3_url",
    "image_4_url",
    "image_5_url",
    "image_6_url",
    "image_url",
    "image_urls",
    "å›¾ç‰‡é“¾æ¥",
}

# ğŸ”¥ v7.26.1: é¡¶å±‚ä¸“ç”¨é»‘åå•ï¼ˆåªåœ¨ depth=0 æ—¶è·³è¿‡ï¼‰
TOP_LEVEL_SKIP_FIELDS = {
    "content",  # é¡¶å±‚ content å¯èƒ½ä¸ structured_data é‡å¤
}

# ============ å†…å®¹ç¿»è¯‘å‡½æ•°ï¼ˆå¤„ç† LLM è¾“å‡ºä¸­çš„è‹±æ–‡çŸ­è¯­ï¼‰ ============
CONTENT_TRANSLATIONS = {
    # è®¾è®¡æ€ç»´æ¡†æ¶çŸ­è¯­
    "How might we": "æˆ‘ä»¬å¦‚ä½•èƒ½å¤Ÿ",
    "How Might We": "æˆ‘ä»¬å¦‚ä½•èƒ½å¤Ÿ",
    "HMW": "å¦‚ä½•",
    # Pain Points å„ç§å˜ä½“
    "Pain Points": "ç—›ç‚¹",
    "Pain points": "ç—›ç‚¹",
    "pain points": "ç—›ç‚¹",
    "Pain Point": "ç—›ç‚¹",
    "pain point": "ç—›ç‚¹",
    # Persona å„ç§å˜ä½“ï¼ˆä¿ç•™å†’å·åçš„ç©ºæ ¼ï¼‰
    "Persona: ": "ç”¨æˆ·ç”»åƒ: ",
    "Persona:": "ç”¨æˆ·ç”»åƒ:",
    "persona: ": "ç”¨æˆ·ç”»åƒ: ",
    "persona:": "ç”¨æˆ·ç”»åƒ:",
    # å€¼ç¿»è¯‘ï¼ˆLLM å¯èƒ½è¾“å‡ºçš„è‹±æ–‡å€¼ï¼‰
    "pole_a_resolve": "ç«‹åœºAè§£å†³æ–¹æ¡ˆ",
    "pole_b_resolve": "ç«‹åœºBè§£å†³æ–¹æ¡ˆ",
    "pole_a": "ç«‹åœºA",
    "pole_b": "ç«‹åœºB",
    "Pole A": "ç«‹åœºA",
    "Pole B": "ç«‹åœºB",
    # æ—…ç¨‹åœ°å›¾ç›¸å…³
    "Journey Map": "æ—…ç¨‹åœ°å›¾",
    "journey map": "æ—…ç¨‹åœ°å›¾",
    "User Journey": "ç”¨æˆ·æ—…ç¨‹",
    "Customer Journey": "å®¢æˆ·æ—…ç¨‹",
    "Touchpoint": "è§¦ç‚¹",
    "touchpoint": "è§¦ç‚¹",
    # å¸¸è§è®¾è®¡æœ¯è¯­
    "Key Takeaways": "å…³é”®è¦ç‚¹",
    "Key takeaways": "å…³é”®è¦ç‚¹",
    "Best Practices": "æœ€ä½³å®è·µ",
    "best practices": "æœ€ä½³å®è·µ",
    "Case Study": "æ¡ˆä¾‹ç ”ç©¶",
    "case study": "æ¡ˆä¾‹ç ”ç©¶",
    "Deep Dive": "æ·±åº¦ç ”ç©¶",
    "deep dive": "æ·±åº¦ç ”ç©¶",
    "Next Steps": "ä¸‹ä¸€æ­¥",
    "next steps": "ä¸‹ä¸€æ­¥",
    "Action Items": "è¡ŒåŠ¨é¡¹",
    "action items": "è¡ŒåŠ¨é¡¹",
    "Trade-offs": "æƒè¡¡",
    "trade-offs": "æƒè¡¡",
    "Pros and Cons": "ä¼˜ç¼ºç‚¹",
    "pros and cons": "ä¼˜ç¼ºç‚¹",
}


def _translate_content(text: str) -> str:
    """ç¿»è¯‘å†…å®¹ä¸­çš„è‹±æ–‡çŸ­è¯­ä¸ºä¸­æ–‡"""
    if not text or not isinstance(text, str):
        return text

    result = text
    for eng, chn in CONTENT_TRANSLATIONS.items():
        result = result.replace(eng, chn)

    return result


def _clean_markdown_inline(text: str) -> str:
    """ğŸ”¥ v7.26.3: æ¸…ç†è¡Œå†…Markdownæ ¼å¼ï¼ˆç”¨äºçŸ­æ–‡æœ¬ï¼‰

    å»é™¤ **åŠ ç²—** å’Œ *æ–œä½“* æ ‡è®°ï¼Œä¿ç•™æ–‡æœ¬å†…å®¹
    """
    if not text or not isinstance(text, str):
        return text

    import re

    # å»é™¤ **åŠ ç²—**
    result = re.sub(r"\*\*(.+?)\*\*", r"\1", text)
    # å»é™¤ *æ–œä½“*
    result = re.sub(r"\*(.+?)\*", r"\1", result)
    return result


def _format_numbered_list(text: str) -> str:
    """å°†è¿ç»­çš„ç¼–å·åˆ—è¡¨æ‹†åˆ†æˆç‹¬ç«‹è¡Œ

    ä¾‹å¦‚: "1. xxx 2. yyy 3. zzz" -> "1. xxx\n2. yyy\n3. zzz"
    """
    if not text or not isinstance(text, str):
        return text

    import re

    # åŒ¹é… "æ•°å­—. " æˆ– "æ•°å­—ã€" æˆ– "æ•°å­—ï¼‰" å‰é¢æœ‰å†…å®¹çš„æƒ…å†µ
    # åœ¨ç¼–å·å‰æ’å…¥æ¢è¡Œï¼ˆä½†ä¸æ˜¯å¼€å¤´çš„ç¼–å·ï¼‰
    result = re.sub(r"([ã€‚ï¼›ï¼Œã€\.\)ï¼‰])\s*(\d+[\.\ã€\)ï¼‰]\s*)", r"\1\n\2", text)

    return result


def _format_dict_to_pdf(pdf: "PDFGenerator", data: dict, depth: int = 0):
    """é€’å½’æ ¼å¼åŒ–å­—å…¸æ•°æ®åˆ° PDF

    å¢å¼ºç‰ˆï¼š
    - depth=0 (é¡¶çº§) æ—¶æ·»åŠ åˆ†éš”çº¿
    - æ”¹è¿›åˆ—è¡¨å’ŒåµŒå¥—ç»“æ„çš„é—´è·
    - ğŸ”¥ v7.26.1: é¡¶å±‚è·³è¿‡ contentï¼ŒåµŒå¥—å±‚å…è®¸
    """
    is_top_level = depth == 0
    item_count = 0

    for key, value in data.items():
        # è·³è¿‡é‡å¤å†…å®¹å­—æ®µ
        if key.lower() in SKIP_FIELDS:
            continue

        # ğŸ”¥ v7.26.1: é¡¶å±‚æ—¶é¢å¤–è·³è¿‡ contentï¼ˆå¯èƒ½ä¸ structured_data é‡å¤ï¼‰
        if is_top_level and key.lower() in TOP_LEVEL_SKIP_FIELDS:
            continue

        label = _get_field_label(key)

        if value is None or (isinstance(value, str) and not value.strip()):
            continue

        # é¡¶çº§å­—æ®µä¹‹é—´æ·»åŠ åˆ†éš”çº¿ï¼ˆé™¤äº†ç¬¬ä¸€ä¸ªï¼‰
        if is_top_level and item_count > 0:
            pdf.add_divider()
        item_count += 1

        if isinstance(value, list):
            if not value:
                continue
            # åˆ—è¡¨æ ‡é¢˜
            level = min(depth + 2, 4) if is_top_level else min(depth + 3, 4)
            pdf.chapter_title(label, level)

            for idx, item in enumerate(value):
                if isinstance(item, dict):
                    # äº¤ä»˜ç‰©åˆ—è¡¨é¡¹ä¹‹é—´æ·»åŠ å°é—´è·
                    if idx > 0:
                        pdf.ln(3)
                    _format_dict_to_pdf(pdf, item, depth + 1)
                else:
                    # ğŸ”¥ v7.26.3: æ¸…ç†åˆ—è¡¨é¡¹ä¸­çš„Markdownæ ¼å¼
                    item_str = _translate_content(str(item).strip())
                    item_str = _clean_markdown_inline(item_str)
                    if item_str:
                        pdf.list_item(item_str)
            pdf.ln(3)

        elif isinstance(value, dict):
            if not value:
                continue
            level = min(depth + 2, 4) if is_top_level else min(depth + 3, 4)
            pdf.chapter_title(label, level)
            _format_dict_to_pdf(pdf, value, depth + 1)

        else:
            # ğŸ”¥ v7.26.3: å…ˆç¿»è¯‘ï¼Œå†æ¸…ç†Markdownæ ¼å¼
            value_str = _translate_content(str(value).strip())
            value_str = _clean_markdown_inline(value_str)
            if not value_str:
                continue

            # è®¡ç®—æ ‡ç­¾å’Œå€¼çš„å®é™…æ˜¾ç¤ºå®½åº¦
            pdf._set_font_safe("B", 10)
            label_text = f"{label}: "
            label_width = pdf.get_string_width(label_text) + 2

            pdf._set_font_safe("", 10)
            value_width = pdf.get_string_width(value_str)

            # é¡µé¢å¯ç”¨å®½åº¦
            page_width = pdf.w - pdf.l_margin - pdf.r_margin

            # å†³å®šæ˜¾ç¤ºæ–¹å¼ï¼š
            # 1. å¦‚æœæ ‡ç­¾+å€¼èƒ½åœ¨ä¸€è¡Œæ˜¾ç¤º â†’ åŒè¡Œ
            # 2. å¦‚æœå€¼æœ¬èº«è¶…è¿‡é¡µé¢å®½åº¦çš„80% â†’ ä½œä¸ºæ®µè½ï¼ˆæ ‡ç­¾å•ç‹¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜ï¼‰
            # 3. å¦åˆ™ â†’ æ ‡ç­¾: æ¢è¡Œæ˜¾ç¤ºå€¼

            if label_width + value_width <= page_width - 5:
                # æƒ…å†µ1: èƒ½åœ¨ä¸€è¡Œæ˜¾ç¤º
                pdf.set_text_color(51, 51, 51)
                pdf.set_x(pdf.l_margin)
                pdf._set_font_safe("B", 10)
                pdf.cell(label_width, 6, label_text, ln=False)
                pdf._set_font_safe("", 10)
                pdf.set_text_color(0, 0, 0)
                pdf.cell(0, 6, value_str, ln=True)
                pdf.set_x(pdf.l_margin)
                pdf.ln(2)
            elif value_width > page_width * 0.8:
                # æƒ…å†µ2: é•¿æ–‡æœ¬ï¼Œä½œä¸ºæ®µè½æ˜¾ç¤º
                level = min(depth + 2, 4) if is_top_level else min(depth + 3, 4)
                pdf.chapter_title(label, level)
                pdf.body_text(value_str)
            else:
                # æƒ…å†µ3: ä¸­ç­‰é•¿åº¦ï¼Œæ ‡ç­¾åæ¢è¡Œæ˜¾ç¤ºå€¼
                pdf.set_text_color(51, 51, 51)
                pdf.set_x(pdf.l_margin)
                pdf._set_font_safe("B", 10)
                pdf.cell(0, 6, label_text, ln=True)
                pdf._set_font_safe("", 10)
                pdf.set_text_color(0, 0, 0)
                pdf.set_x(pdf.l_margin)
                from fpdf.enums import WrapMode

                pdf.multi_cell(w=0, h=5, text=value_str, wrapmode=WrapMode.CHAR)
                pdf.set_x(pdf.l_margin)
                pdf.ln(2)


@app.get("/api/analysis/report/{session_id}/download-pdf")
async def download_report_pdf(session_id: str):
    """
    ä¸‹è½½åˆ†ææŠ¥å‘Š PDFï¼ˆv7.0 é‡æ„ç‰ˆï¼‰

    ç”Ÿæˆå¯ç¼–è¾‘çš„ PDF æ–‡ä»¶ï¼ˆæ–‡æœ¬å¯é€‰ä¸­å¤åˆ¶ï¼‰

    åŒ…å« 5 ä¸ªæ ¸å¿ƒç« èŠ‚ï¼š
    1. ç”¨æˆ·åŸå§‹éœ€æ±‚
    2. æ ¡å‡†é—®å·å›é¡¾ï¼ˆè¿‡æ»¤"æœªå›ç­”"ï¼‰
    3. éœ€æ±‚æ´å¯Ÿ
    4. æ ¸å¿ƒç­”æ¡ˆï¼ˆæ”¯æŒ v7.0 å¤šäº¤ä»˜ç‰©æ ¼å¼ï¼‰
    5. æ‰§è¡Œå…ƒæ•°æ®

    ä¸åŒ…å«ä¸“å®¶æŠ¥å‘Šï¼ˆä¸“å®¶æŠ¥å‘Šæœ‰ç‹¬ç«‹ä¸‹è½½å…¥å£ï¼‰
    """
    session = await session_manager.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    if session["status"] != "completed":
        raise HTTPException(status_code=400, detail=f"åˆ†æå°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {session['status']}")

    # è·å–æŠ¥å‘Šæ•°æ®
    final_report = session.get("final_report", {})
    user_input = session.get("user_input", "")

    if not isinstance(final_report, dict) or not final_report:
        raise HTTPException(status_code=400, detail="æŠ¥å‘Šæ•°æ®ä¸å¯ç”¨")

    try:
        pdf_bytes = generate_report_pdf(final_report, user_input)

        return Response(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={"Content-Disposition": f"attachment; filename=project_report_{session_id}.pdf"},
        )
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆ PDF å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"PDF ç”Ÿæˆå¤±è´¥: {str(e)}")


async def generate_all_experts_pdf_async(expert_reports: Dict[str, str], user_input: str = "") -> bytes:
    """å¼‚æ­¥ç”Ÿæˆæ‰€æœ‰ä¸“å®¶æŠ¥å‘Šçš„åˆå¹¶ PDFï¼ˆä½¿ç”¨ HTML + Playwright æ–¹æ¡ˆï¼‰

    v7.1.2 æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨å¼‚æ­¥ç‰ˆæœ¬ï¼Œå……åˆ†åˆ©ç”¨æµè§ˆå™¨æ± 
    """
    import json

    # è½¬æ¢ä¸“å®¶æ•°æ®æ ¼å¼
    experts = []
    for expert_name, expert_content in expert_reports.items():
        # è§£æå†…å®¹
        content = expert_content
        if isinstance(expert_content, str):
            try:
                content = json.loads(expert_content)
            except json.JSONDecodeError:
                content = {"åˆ†æå†…å®¹": expert_content}

        experts.append({"expert_name": expert_name, "content": content})

    # ä½¿ç”¨å¼‚æ­¥ HTML PDF ç”Ÿæˆå™¨
    generator = HTMLPDFGenerator()
    pdf_bytes = await generator.generate_pdf_async(
        experts=experts,
        title="ä¸“å®¶æŠ¥å‘Šåˆé›†",
        subtitle=user_input[:100] + "..." if len(user_input) > 100 else user_input if user_input else None,
        session_id=None,
    )

    return pdf_bytes


def generate_all_experts_pdf(expert_reports: Dict[str, str], user_input: str = "") -> bytes:
    """ç”Ÿæˆæ‰€æœ‰ä¸“å®¶æŠ¥å‘Šçš„åˆå¹¶ PDFï¼ˆä½¿ç”¨ HTML + Playwright æ–¹æ¡ˆï¼‰

    æ³¨æ„ï¼šæ­¤ä¸ºåŒæ­¥ç‰ˆæœ¬ï¼Œåœ¨ FastAPI å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­æ¨èä½¿ç”¨ generate_all_experts_pdf_async
    """
    import json

    # è½¬æ¢ä¸“å®¶æ•°æ®æ ¼å¼
    experts = []
    for expert_name, expert_content in expert_reports.items():
        # è§£æå†…å®¹
        content = expert_content
        if isinstance(expert_content, str):
            try:
                content = json.loads(expert_content)
            except json.JSONDecodeError:
                content = {"åˆ†æå†…å®¹": expert_content}

        experts.append({"expert_name": expert_name, "content": content})

    # ä½¿ç”¨æ–°çš„ HTML PDF ç”Ÿæˆå™¨
    pdf_bytes = generate_html_pdf(
        experts=experts,
        title="ä¸“å®¶æŠ¥å‘Šåˆé›†",
        subtitle=user_input[:100] + "..." if len(user_input) > 100 else user_input if user_input else None,
        session_id=None,
    )

    return pdf_bytes


def generate_all_experts_pdf_fast(expert_reports: Dict[str, str], user_input: str = "") -> bytes:
    """
    ğŸ”¥ v7.1.3: å¿«é€Ÿç”Ÿæˆæ‰€æœ‰ä¸“å®¶æŠ¥å‘Š PDF (ä½¿ç”¨ FPDF)

    æ›¿ä»£ Playwright æ–¹æ¡ˆï¼Œæä¾›æé€Ÿç”Ÿæˆä½“éªŒã€‚
    """
    pdf = PDFGenerator()

    # å°é¢
    pdf.add_cover_page("ä¸“å®¶æŠ¥å‘Šæ±‡æ€»")

    # ç›®å½•
    pdf.add_page()
    pdf._set_font_safe("B", 18)
    pdf.set_text_color(26, 26, 26)
    pdf.cell(0, 15, "ä¸“å®¶åˆ—è¡¨", ln=True, align="C")
    pdf.ln(10)
    pdf._set_font_safe("", 12)
    pdf.set_text_color(51, 51, 51)

    # æ”¶é›†ä¸“å®¶åˆ—è¡¨ç”¨äºç›®å½•
    expert_names = list(expert_reports.keys())
    for i, name in enumerate(expert_names, 1):
        pdf.cell(0, 10, f"{i}. {name}", ln=True)

    # ç”¨æˆ·è¾“å…¥
    if user_input:
        pdf.add_page()
        pdf.chapter_title("ç”¨æˆ·åŸå§‹éœ€æ±‚", level=1)
        pdf.body_text(user_input)

    # ä¸“å®¶å†…å®¹
    for expert_name, content in expert_reports.items():
        pdf.add_page()
        pdf.chapter_title(expert_name, level=1)
        format_expert_content_for_pdf(pdf, content)

    return bytes(pdf.output())


@app.get("/api/analysis/report/{session_id}/download-all-experts-pdf")
async def download_all_experts_pdf(session_id: str):
    """
    ä¸‹è½½æ‰€æœ‰ä¸“å®¶æŠ¥å‘Šçš„åˆå¹¶ PDF

    v7.1.3 å‡çº§ï¼š
    - åˆ‡æ¢ä¸º FPDF åŸç”Ÿç”Ÿæˆå¼•æ“ (generate_all_experts_pdf_fast)
    - é€Ÿåº¦æå‡ 10x (10s -> <1s)
    - ç§»é™¤ Playwright ä¾èµ–ï¼Œæ›´ç¨³å®š
    """
    # ğŸš€ ç¼“å­˜æ£€æŸ¥ - ç¼“å­˜å‘½ä¸­ç›´æ¥è¿”å›
    cache_key = f"all_experts_pdf_fast_{session_id}"
    if cache_key in pdf_cache:
        logger.info(f"ğŸ“¦ PDF ç¼“å­˜å‘½ä¸­: {session_id}")
        pdf_bytes = pdf_cache[cache_key]
        from urllib.parse import quote

        safe_filename = quote(f"all_expert_reports_{session_id}.pdf", safe="")
        return Response(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={"Content-Disposition": f"attachment; filename*=UTF-8''{safe_filename}"},
        )

    session = await session_manager.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    if session["status"] != "completed":
        raise HTTPException(status_code=400, detail=f"åˆ†æå°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {session['status']}")

    # è·å–ä¸“å®¶æŠ¥å‘Š
    final_report = session.get("final_report", {})
    expert_reports = final_report.get("expert_reports", {}) if isinstance(final_report, dict) else {}

    if not expert_reports:
        raise HTTPException(status_code=400, detail="æ— ä¸“å®¶æŠ¥å‘Šæ•°æ®")

    user_input = session.get("user_input", "")

    try:
        logger.info(f"âš¡ å¿«é€Ÿç”Ÿæˆ PDF (FPDF): {session_id}")
        # ä½¿ç”¨æ–°çš„å¿«é€Ÿç”Ÿæˆå‡½æ•°
        pdf_bytes = generate_all_experts_pdf_fast(expert_reports, user_input)

        # ğŸš€ ç¼“å­˜ PDF
        pdf_cache[cache_key] = pdf_bytes
        logger.info(f"ğŸ’¾ PDF å·²ç¼“å­˜: {session_id} ({len(pdf_bytes)} bytes)")

        # ä½¿ç”¨ URL ç¼–ç å¤„ç†ä¸­æ–‡æ–‡ä»¶å
        from urllib.parse import quote

        safe_filename = quote(f"all_expert_reports_{session_id}.pdf", safe="")

        return Response(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={"Content-Disposition": f"attachment; filename*=UTF-8''{safe_filename}"},
        )
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆæ‰€æœ‰ä¸“å®¶æŠ¥å‘Š PDF å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"PDF ç”Ÿæˆå¤±è´¥: {str(e)}")


# ğŸ†• v7.40.1: å›¾åƒé‡æ–°ç”Ÿæˆ API
# ğŸ”¥ v7.41: æ‰©å±•æ”¯æŒå¤šå›¾ã€å‚æ•°æ§åˆ¶ã€ä¿å­˜å‰¯æœ¬
class RegenerateImageRequest(BaseModel):
    expert_name: str
    new_prompt: str
    # ğŸ”¥ v7.41: æ–°å¢å­—æ®µ
    save_as_copy: bool = False  # æ˜¯å¦ä¿å­˜ä¸ºå‰¯æœ¬ï¼ˆé»˜è®¤è¦†ç›–ï¼‰
    image_id: Optional[str] = None  # è¦æ›¿æ¢çš„å›¾åƒIDï¼ˆå¤šå›¾æ¨¡å¼ï¼‰
    aspect_ratio: Optional[str] = "16:9"  # å®½é«˜æ¯”
    style_type: Optional[str] = None  # é£æ ¼ç±»å‹


class AddImageRequest(BaseModel):
    """ğŸ”¥ v7.41: æ–°å¢æ¦‚å¿µå›¾è¯·æ±‚"""

    expert_name: str
    prompt: str
    aspect_ratio: Optional[str] = "16:9"
    style_type: Optional[str] = None


class DeleteImageRequest(BaseModel):
    """ğŸ”¥ v7.41: åˆ é™¤æ¦‚å¿µå›¾è¯·æ±‚"""

    expert_name: str
    image_id: Optional[str] = None  # å¦‚æœä¸ºç©ºï¼Œåˆ é™¤è¯¥ä¸“å®¶çš„æ‰€æœ‰å›¾åƒ


@app.post("/api/analysis/regenerate-image/{session_id}")
async def regenerate_expert_image(session_id: str, request: RegenerateImageRequest):
    """
    é‡æ–°ç”Ÿæˆä¸“å®¶æ¦‚å¿µå›¾åƒ

    ğŸ”¥ v7.40.1: å…è®¸ç”¨æˆ·ç¼–è¾‘æç¤ºè¯åé‡æ–°ç”Ÿæˆå›¾åƒ
    ğŸ”¥ v7.41: æ”¯æŒä¿å­˜ä¸ºå‰¯æœ¬ã€å‚æ•°æ§åˆ¶
    """
    try:
        # è·å–ä¼šè¯
        session = await session_manager.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        logger.info(f"ğŸ”„ å¼€å§‹é‡æ–°ç”Ÿæˆå›¾åƒ: session={session_id}, expert={request.expert_name}")
        logger.info(f"ğŸ“ æ–°æç¤ºè¯: {request.new_prompt[:100]}...")
        logger.info(
            f"âš™ï¸ å‚æ•°: aspect_ratio={request.aspect_ratio}, style_type={request.style_type}, save_as_copy={request.save_as_copy}"
        )

        # æ£€æŸ¥å›¾åƒç”Ÿæˆæ˜¯å¦å¯ç”¨
        if not settings.image_generation.enabled:
            raise HTTPException(status_code=400, detail="å›¾åƒç”ŸæˆåŠŸèƒ½æœªå¯ç”¨")

        # å¯¼å…¥å›¾åƒç”ŸæˆæœåŠ¡
        from intelligent_project_analyzer.services.image_generator import ImageGeneratorService

        image_service = ImageGeneratorService()

        # ğŸ”¥ v7.60.4: ä¿®å¤å‚æ•°åç§°å’Œç±»å‹ï¼ˆstyle_typeâ†’style, stringâ†’enumï¼‰
        result = await image_service.generate_image(
            prompt=request.new_prompt, aspect_ratio=_parse_aspect_ratio(request.aspect_ratio), style=request.style_type
        )

        if not result.success:
            logger.error(f"âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {result.error}")
            return {"success": False, "error": result.error or "å›¾åƒç”Ÿæˆå¤±è´¥"}

        # ğŸ”¥ v7.60.5: ç´¯åŠ å›¾åƒç”ŸæˆTokenåˆ°ä¼šè¯metadata
        if result.total_tokens > 0:
            from intelligent_project_analyzer.utils.token_utils import update_session_tokens

            token_data = {
                "prompt_tokens": result.prompt_tokens,
                "completion_tokens": result.completion_tokens,
                "total_tokens": result.total_tokens,
            }
            success = await update_session_tokens(
                session_manager, session_id, token_data, agent_name="image_generation"
            )
            if success:
                logger.info(f"âœ… [å›¾åƒToken] å·²ç´¯åŠ  {result.total_tokens} tokens åˆ°ä¼šè¯ {session_id}")

        logger.info(f"âœ… å›¾åƒé‡æ–°ç”ŸæˆæˆåŠŸ: expert={request.expert_name}")

        # ğŸ”¥ v7.41: ç”Ÿæˆå”¯ä¸€ID
        import uuid

        new_image_id = str(uuid.uuid4())[:8]

        new_image_data = {
            "expert_name": request.expert_name,
            "image_url": result.image_url,
            "prompt": request.new_prompt,
            "id": new_image_id,
            "aspect_ratio": request.aspect_ratio,
            "style_type": request.style_type,
            "created_at": datetime.now().isoformat(),
        }

        # æ›´æ–°ä¼šè¯ä¸­çš„å›¾åƒæ•°æ®
        final_report = session.get("final_report", {})
        if isinstance(final_report, dict):
            generated_images_by_expert = final_report.get("generated_images_by_expert", {})

            # ğŸ”¥ v7.41: å¤šå›¾æ”¯æŒ
            if request.expert_name in generated_images_by_expert:
                existing = generated_images_by_expert[request.expert_name]

                # å…¼å®¹æ—§æ ¼å¼ï¼ˆå•å›¾å¯¹è±¡ -> æ•°ç»„ï¼‰
                if isinstance(existing, dict) and "images" not in existing:
                    existing = {"expert_name": request.expert_name, "images": [existing]}
                elif isinstance(existing, dict) and "images" in existing:
                    pass  # å·²ç»æ˜¯æ–°æ ¼å¼
                else:
                    existing = {"expert_name": request.expert_name, "images": []}

                images = existing.get("images", [])

                if request.save_as_copy:
                    # ä¿å­˜ä¸ºå‰¯æœ¬ï¼ˆæœ€å¤š3å¼ ï¼‰
                    if len(images) >= 3:
                        logger.warning(f"âš ï¸ ä¸“å®¶ {request.expert_name} å·²æœ‰3å¼ å›¾åƒï¼Œæ— æ³•æ·»åŠ æ›´å¤š")
                        return {"success": False, "error": "å·²è¾¾åˆ°æœ€å¤§å›¾åƒæ•°é‡ï¼ˆ3å¼ ï¼‰"}
                    images.append(new_image_data)
                else:
                    # è¦†ç›–ï¼šæ›¿æ¢æŒ‡å®šå›¾åƒæˆ–ç¬¬ä¸€å¼ 
                    if request.image_id:
                        for i, img in enumerate(images):
                            if img.get("id") == request.image_id:
                                images[i] = new_image_data
                                break
                        else:
                            # æœªæ‰¾åˆ°æŒ‡å®šIDï¼Œè¿½åŠ 
                            if len(images) < 3:
                                images.append(new_image_data)
                    elif images:
                        images[0] = new_image_data
                    else:
                        images.append(new_image_data)

                existing["images"] = images
                generated_images_by_expert[request.expert_name] = existing
            else:
                # æ–°ä¸“å®¶ï¼Œåˆ›å»ºæ–°æ¡ç›®
                generated_images_by_expert[request.expert_name] = {
                    "expert_name": request.expert_name,
                    "images": [new_image_data],
                }

            final_report["generated_images_by_expert"] = generated_images_by_expert
            session["final_report"] = final_report
            await session_manager.update(session_id, session)
            logger.info(f"ğŸ’¾ å·²æ›´æ–°ä¼šè¯ä¸­çš„å›¾åƒæ•°æ®")

        return {
            "success": True,
            "image_url": result.image_url,
            "prompt": request.new_prompt,
            "expert_name": request.expert_name,
            "image_id": new_image_id,
            "aspect_ratio": request.aspect_ratio,
            "style_type": request.style_type,
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ é‡æ–°ç”Ÿæˆå›¾åƒå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return {"success": False, "error": str(e)}


# ğŸ”¥ v7.41: æ–°å¢æ¦‚å¿µå›¾ API
@app.post("/api/analysis/add-image/{session_id}")
async def add_expert_image(session_id: str, request: AddImageRequest):
    """
    ä¸ºä¸“å®¶æ–°å¢æ¦‚å¿µå›¾ï¼ˆæœ€å¤š3å¼ ï¼‰
    """
    try:
        session = await session_manager.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        logger.info(f"â• æ–°å¢æ¦‚å¿µå›¾: session={session_id}, expert={request.expert_name}")

        if not settings.image_generation.enabled:
            raise HTTPException(status_code=400, detail="å›¾åƒç”ŸæˆåŠŸèƒ½æœªå¯ç”¨")

        # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°ä¸Šé™
        final_report = session.get("final_report", {})
        generated_images_by_expert = final_report.get("generated_images_by_expert", {})

        if request.expert_name in generated_images_by_expert:
            existing = generated_images_by_expert[request.expert_name]
            # å…¼å®¹æ—§æ ¼å¼
            if isinstance(existing, dict) and "images" not in existing:
                images = [existing]
            elif isinstance(existing, dict) and "images" in existing:
                images = existing.get("images", [])
            else:
                images = []

            if len(images) >= 3:
                return {"success": False, "error": "å·²è¾¾åˆ°æœ€å¤§å›¾åƒæ•°é‡ï¼ˆ3å¼ ï¼‰"}

        from intelligent_project_analyzer.services.image_generator import ImageGeneratorService

        image_service = ImageGeneratorService()
        # ğŸ”¥ v7.60.4: ä¿®å¤å‚æ•°åç§°å’Œç±»å‹ï¼ˆstyle_typeâ†’style, stringâ†’enumï¼‰
        result = await image_service.generate_image(
            prompt=request.prompt, aspect_ratio=_parse_aspect_ratio(request.aspect_ratio), style=request.style_type
        )

        if not result.success:
            return {"success": False, "error": result.error or "å›¾åƒç”Ÿæˆå¤±è´¥"}

        # ğŸ”¥ v7.60.5: ç´¯åŠ å›¾åƒç”ŸæˆTokenåˆ°ä¼šè¯metadata
        if result.total_tokens > 0:
            from intelligent_project_analyzer.utils.token_utils import update_session_tokens

            token_data = {
                "prompt_tokens": result.prompt_tokens,
                "completion_tokens": result.completion_tokens,
                "total_tokens": result.total_tokens,
            }
            success = await update_session_tokens(
                session_manager, session_id, token_data, agent_name="image_generation"
            )
            if success:
                logger.info(f"âœ… [å›¾åƒToken] å·²ç´¯åŠ  {result.total_tokens} tokens åˆ°ä¼šè¯ {session_id}")

        import uuid

        new_image_id = str(uuid.uuid4())[:8]

        new_image_data = {
            "expert_name": request.expert_name,
            "image_url": result.image_url,
            "prompt": request.prompt,
            "id": new_image_id,
            "aspect_ratio": request.aspect_ratio,
            "style_type": request.style_type,
            "created_at": datetime.now().isoformat(),
        }

        # æ›´æ–°ä¼šè¯
        if request.expert_name in generated_images_by_expert:
            existing = generated_images_by_expert[request.expert_name]
            if isinstance(existing, dict) and "images" not in existing:
                existing = {"expert_name": request.expert_name, "images": [existing]}
            existing["images"].append(new_image_data)
            generated_images_by_expert[request.expert_name] = existing
        else:
            generated_images_by_expert[request.expert_name] = {
                "expert_name": request.expert_name,
                "images": [new_image_data],
            }

        final_report["generated_images_by_expert"] = generated_images_by_expert
        session["final_report"] = final_report
        await session_manager.update(session_id, session)

        logger.info(f"âœ… æ–°å¢æ¦‚å¿µå›¾æˆåŠŸ: id={new_image_id}")

        return {"success": True, "image": new_image_data}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ–°å¢æ¦‚å¿µå›¾å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}


# ğŸ”¥ v7.41: åˆ é™¤æ¦‚å¿µå›¾ API
@app.delete("/api/analysis/delete-image/{session_id}")
async def delete_expert_image(session_id: str, request: DeleteImageRequest):
    """
    åˆ é™¤ä¸“å®¶æ¦‚å¿µå›¾
    """
    try:
        session = await session_manager.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ¦‚å¿µå›¾: session={session_id}, expert={request.expert_name}, image_id={request.image_id}")

        final_report = session.get("final_report", {})
        generated_images_by_expert = final_report.get("generated_images_by_expert", {})

        if request.expert_name not in generated_images_by_expert:
            return {"success": False, "error": "æœªæ‰¾åˆ°è¯¥ä¸“å®¶çš„æ¦‚å¿µå›¾"}

        existing = generated_images_by_expert[request.expert_name]

        if request.image_id:
            # åˆ é™¤æŒ‡å®šå›¾åƒ
            if isinstance(existing, dict) and "images" in existing:
                images = existing.get("images", [])
                images = [img for img in images if img.get("id") != request.image_id]
                if images:
                    existing["images"] = images
                    generated_images_by_expert[request.expert_name] = existing
                else:
                    del generated_images_by_expert[request.expert_name]
            else:
                # æ—§æ ¼å¼å•å›¾ï¼Œç›´æ¥åˆ é™¤
                del generated_images_by_expert[request.expert_name]
        else:
            # åˆ é™¤è¯¥ä¸“å®¶çš„æ‰€æœ‰å›¾åƒ
            del generated_images_by_expert[request.expert_name]

        final_report["generated_images_by_expert"] = generated_images_by_expert
        session["final_report"] = final_report
        await session_manager.update(session_id, session)

        logger.info(f"âœ… åˆ é™¤æ¦‚å¿µå›¾æˆåŠŸ")

        return {"success": True}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤æ¦‚å¿µå›¾å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}


# ğŸ”¥ v7.41: æ™ºèƒ½æ¨èæç¤ºè¯ API
@app.get("/api/analysis/suggest-prompts/{session_id}/{expert_name}")
async def suggest_image_prompts(session_id: str, expert_name: str):
    """
    åŸºäºä¸“å®¶æŠ¥å‘Šå…³é”®è¯ç”Ÿæˆ3ä¸ªæ¨èæç¤ºè¯

    ç­–ç•¥ï¼šä»ä¸“å®¶æŠ¥å‘Šä¸­æå–å…³é”®æ¦‚å¿µï¼Œç»„åˆæˆå¯è§†åŒ–æç¤ºè¯
    """
    try:
        session = await session_manager.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        logger.info(f"ğŸ’¡ ç”Ÿæˆæ¨èæç¤ºè¯: session={session_id}, expert={expert_name}")

        final_report = session.get("final_report", {})
        expert_reports = final_report.get("expert_reports", {})

        # æŸ¥æ‰¾ä¸“å®¶æŠ¥å‘Š
        expert_content = None
        expert_dynamic_name = expert_name

        for key, value in expert_reports.items():
            # åŒ¹é…ä¸“å®¶åç§°ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
            if expert_name in key or key in expert_name:
                expert_content = value
                expert_dynamic_name = key
                break

        if not expert_content:
            # å°è¯•ä» agent_results è·å–
            agent_results = session.get("agent_results", {})
            for key, value in agent_results.items():
                if expert_name in key or key in expert_name:
                    if isinstance(value, dict):
                        expert_content = value.get("content", "")
                    else:
                        expert_content = str(value)
                    break

        if not expert_content:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä¸“å®¶æŠ¥å‘Š: {expert_name}")
            # è¿”å›é»˜è®¤æ¨è
            return {
                "success": True,
                "suggestions": [
                    {
                        "label": "ç°ä»£å®¤å†…è®¾è®¡",
                        "prompt": f"A modern interior design concept for {expert_name}, featuring clean lines and warm lighting",
                        "keywords": ["modern", "interior", "design"],
                        "confidence": 0.6,
                    },
                    {
                        "label": "ç©ºé—´æè´¨å¯è§†åŒ–",
                        "prompt": f"An architectural visualization showing spatial arrangement and material textures",
                        "keywords": ["architecture", "spatial", "materials"],
                        "confidence": 0.5,
                    },
                    {
                        "label": "æ¦‚å¿µé£æ ¼å±•æ¿",
                        "prompt": f"A conceptual design mood board with color palette and style references",
                        "keywords": ["concept", "mood board", "style"],
                        "confidence": 0.5,
                    },
                ],
            }

        # ä»ä¸“å®¶æŠ¥å‘Šä¸­æå–å…³é”®è¯
        import re

        import jieba

        # æ¸…ç†å†…å®¹
        if isinstance(expert_content, dict):
            content_text = json.dumps(expert_content, ensure_ascii=False)
        else:
            content_text = str(expert_content)

        # æå–ä¸­æ–‡å…³é”®è¯
        words = list(jieba.cut(content_text))

        # è¿‡æ»¤å¸¸è§è¯å’ŒçŸ­è¯
        stop_words = {
            "çš„",
            "æ˜¯",
            "åœ¨",
            "å’Œ",
            "ä¸",
            "äº†",
            "å°†",
            "å¯¹",
            "ä¸º",
            "ç­‰",
            "ä¸­",
            "ä»¥",
            "åŠ",
            "åˆ°",
            "ä»",
            "æœ‰",
            "è¿™",
            "ä¸ª",
            "äºº",
            "æˆ‘",
            "ä»¬",
            "ä½ ",
            "ä»–",
            "å¥¹",
            "å®ƒ",
        }
        keywords = [w for w in words if len(w) >= 2 and w not in stop_words]

        # ç»Ÿè®¡è¯é¢‘
        from collections import Counter

        word_freq = Counter(keywords)
        top_keywords = [word for word, _ in word_freq.most_common(30)]

        # æå–è®¾è®¡ç›¸å…³å…³é”®è¯
        design_keywords = []
        design_patterns = [
            r"(ç©ºé—´|å¸ƒå±€|é£æ ¼|æè´¨|è‰²å½©|ç¯å…‰|å®¶å…·|è£…é¥°|åŠŸèƒ½åŒº|åŠ¨çº¿)",
            r"(ç°ä»£|ç®€çº¦|å¥¢å|è‡ªç„¶|å·¥ä¸š|åŒ—æ¬§|æ—¥å¼|ä¸­å¼|ç¾å¼)",
            r"(å®¢å…|å§å®¤|å¨æˆ¿|ä¹¦æˆ¿|é˜³å°|ç„å…³|é¤å…|å«ç”Ÿé—´)",
            r"(æœ¨è´¨|çŸ³æ|é‡‘å±|ç»ç’ƒ|çš®é©|ç»‡ç‰©|å¤§ç†çŸ³)",
            r"(æ¸©é¦¨|èˆ’é€‚|æ˜äº®|å¼€æ”¾|ç§å¯†|å±‚æ¬¡|å¯¹æ¯”)",
        ]

        for pattern in design_patterns:
            matches = re.findall(pattern, content_text)
            design_keywords.extend(matches)

        # åˆå¹¶å…³é”®è¯
        all_keywords = list(set(design_keywords + top_keywords[:15]))[:20]

        # ç”Ÿæˆæ¨èæç¤ºè¯
        suggestions = []

        # æç¤ºè¯æ¨¡æ¿ï¼ˆåŒ…å«ä¸­æ–‡æ ‡ç­¾ï¼‰
        templates = [
            {
                "label": "ç©ºé—´æ°›å›´æ¸²æŸ“",
                "template": "A {style} interior design concept featuring {material} elements, {lighting} lighting, and {mood} atmosphere, professional architectural visualization, 8K",
                "defaults": {
                    "style": "modern minimalist",
                    "material": "natural wood and marble",
                    "lighting": "warm ambient",
                    "mood": "serene and inviting",
                },
            },
            {
                "label": "åŠŸèƒ½åŒºè§„åˆ’",
                "template": "Spatial visualization of {space} with {feature} design, {color} color palette, {style} aesthetic, photorealistic rendering",
                "defaults": {
                    "space": "open living area",
                    "feature": "flowing",
                    "color": "neutral earth tone",
                    "style": "contemporary",
                },
            },
            {
                "label": "è®¾è®¡æ¦‚å¿µå›¾",
                "template": "Conceptual design for {function} space, emphasizing {quality} and {element}, {style} style, architectural photography",
                "defaults": {
                    "function": "multi-functional",
                    "quality": "natural light flow",
                    "element": "spatial hierarchy",
                    "style": "Scandinavian",
                },
            },
        ]

        # æ ¹æ®å…³é”®è¯å¡«å……æ¨¡æ¿
        for i, template_info in enumerate(templates):
            template = template_info["template"]
            defaults = template_info["defaults"]

            # å°è¯•ç”¨æå–çš„å…³é”®è¯æ›¿æ¢é»˜è®¤å€¼
            filled = template
            used_keywords = []

            for key, default_value in defaults.items():
                # æŸ¥æ‰¾ç›¸å…³å…³é”®è¯
                relevant = [kw for kw in all_keywords if kw not in used_keywords]
                if relevant and i < len(all_keywords):
                    # é€‰æ‹©ä¸€ä¸ªå…³é”®è¯
                    keyword = relevant[i % len(relevant)]
                    used_keywords.append(keyword)
                    filled = filled.replace(
                        f"{{{key}}}",
                        f"{keyword} {default_value.split()[0]}" if len(default_value.split()) > 1 else keyword,
                    )
                else:
                    filled = filled.replace(f"{{{key}}}", default_value)

            suggestions.append(
                {
                    "label": template_info["label"],
                    "prompt": filled,
                    "keywords": used_keywords[:5] if used_keywords else list(defaults.values())[:3],
                    "confidence": 0.8 - (i * 0.1),
                }
            )

        logger.info(f"âœ… ç”Ÿæˆäº† {len(suggestions)} ä¸ªæ¨èæç¤ºè¯")

        return {"success": True, "suggestions": suggestions, "extracted_keywords": all_keywords[:10]}

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆæ¨èæç¤ºè¯å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return {"success": False, "error": str(e), "suggestions": []}


# ============================================================================
# ğŸ”¥ v7.48: å›¾åƒå¯¹è¯å†å² APIï¼ˆGoogle AI Studio é£æ ¼ï¼‰
# ============================================================================


class ImageChatTurnModel(BaseModel):
    """å•è½®å¯¹è¯æ¨¡å‹"""

    turn_id: str
    type: str  # 'user' | 'assistant'
    timestamp: str
    prompt: Optional[str] = None
    aspect_ratio: Optional[str] = None
    style_type: Optional[str] = None
    reference_image_url: Optional[str] = None
    image: Optional[Dict[str, Any]] = None  # ExpertGeneratedImage
    error: Optional[str] = None


class ImageChatHistoryRequest(BaseModel):
    """ä¿å­˜å¯¹è¯å†å²è¯·æ±‚"""

    turns: List[ImageChatTurnModel]


class RegenerateImageWithContextRequest(BaseModel):
    """å¸¦ä¸Šä¸‹æ–‡çš„å›¾åƒç”Ÿæˆè¯·æ±‚"""

    expert_name: str
    prompt: str
    aspect_ratio: Optional[str] = "16:9"
    style_type: Optional[str] = None
    reference_image: Optional[str] = None
    context: Optional[str] = None  # å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡
    # ğŸ”¥ v7.61: Vision åˆ†æå‚æ•°
    use_vision_analysis: Optional[bool] = True
    vision_focus: Optional[str] = "comprehensive"
    # ğŸ”¥ v7.62: Inpainting å›¾åƒç¼–è¾‘å‚æ•°
    mask_image: Optional[str] = None  # Mask å›¾åƒ Base64ï¼ˆé»‘è‰²=ä¿ç•™ï¼Œé€æ˜=ç¼–è¾‘ï¼‰
    edit_mode: Optional[bool] = False  # æ˜¯å¦ä¸ºç¼–è¾‘æ¨¡å¼ï¼ˆæœ‰maskæ—¶è‡ªåŠ¨ä¸ºTrueï¼‰


@app.get("/api/analysis/image-chat-history/{session_id}/{expert_name}")
async def get_image_chat_history(session_id: str, expert_name: str):
    """
    è·å–ä¸“å®¶çš„å›¾åƒå¯¹è¯å†å²

    ğŸ”¥ v7.48: æ”¯æŒ Google AI Studio é£æ ¼çš„å›¾åƒç”Ÿæˆå¯¹è¯
    """
    try:
        session = await session_manager.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        logger.info(f"ğŸ“– è·å–å›¾åƒå¯¹è¯å†å²: session={session_id}, expert={expert_name}")

        # ä» session ä¸­è·å–å¯¹è¯å†å²
        image_chat_histories = session.get("image_chat_histories", {})
        expert_history = image_chat_histories.get(expert_name, {})

        if not expert_history:
            # è¿”å›ç©ºå†å²
            return {
                "success": True,
                "history": {
                    "expert_name": expert_name,
                    "session_id": session_id,
                    "turns": [],
                    "created_at": datetime.now().isoformat(),
                    "updated_at": datetime.now().isoformat(),
                },
            }

        return {"success": True, "history": expert_history}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å›¾åƒå¯¹è¯å†å²å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}


@app.post("/api/analysis/image-chat-history/{session_id}/{expert_name}")
async def save_image_chat_history(session_id: str, expert_name: str, request: ImageChatHistoryRequest):
    """
    ä¿å­˜ä¸“å®¶çš„å›¾åƒå¯¹è¯å†å²

    ğŸ”¥ v7.48: å¯¹è¯å†å²æŒä¹…åŒ–ï¼Œæ”¯æŒåˆ é™¤æ•´æ¡å¯¹è¯è®°å½•
    """
    try:
        session = await session_manager.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        logger.info(f"ğŸ’¾ ä¿å­˜å›¾åƒå¯¹è¯å†å²: session={session_id}, expert={expert_name}, turns={len(request.turns)}")

        # è·å–æˆ–åˆå§‹åŒ–å¯¹è¯å†å²å­˜å‚¨
        if "image_chat_histories" not in session:
            session["image_chat_histories"] = {}

        # è½¬æ¢ turns ä¸ºå­—å…¸æ ¼å¼å­˜å‚¨
        turns_data = [turn.dict() for turn in request.turns]

        # ä¿å­˜å¯¹è¯å†å²
        session["image_chat_histories"][expert_name] = {
            "expert_name": expert_name,
            "session_id": session_id,
            "turns": turns_data,
            "created_at": session["image_chat_histories"]
            .get(expert_name, {})
            .get("created_at", datetime.now().isoformat()),
            "updated_at": datetime.now().isoformat(),
        }

        await session_manager.update(session_id, session)

        logger.info(f"âœ… å›¾åƒå¯¹è¯å†å²å·²ä¿å­˜")

        return {"success": True}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜å›¾åƒå¯¹è¯å†å²å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}


@app.post("/api/analysis/regenerate-image-with-context/{session_id}")
async def regenerate_image_with_context(session_id: str, request: RegenerateImageWithContextRequest):
    """
    å¸¦å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡çš„å›¾åƒç”Ÿæˆ

    ğŸ”¥ v7.48: æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ä¼ é€’ç»™ LLMï¼Œå®ç°æ›´è¿è´¯çš„å›¾åƒç”Ÿæˆ

    ä¸Šä¸‹æ–‡æ ¼å¼ï¼šå°†ä¹‹å‰çš„ prompts æ‹¼æ¥ä¸ºå­—ç¬¦ä¸²ï¼Œå¸®åŠ© LLM ç†è§£ç”¨æˆ·æ„å›¾æ¼”å˜
    """
    try:
        session = await session_manager.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        logger.info(f"ğŸ¨ å¸¦ä¸Šä¸‹æ–‡ç”Ÿæˆå›¾åƒ: session={session_id}, expert={request.expert_name}")
        logger.info(f"   æç¤ºè¯: {request.prompt[:100]}...")
        if request.context:
            logger.info(f"   ä¸Šä¸‹æ–‡: {request.context[:200]}...")

        if not settings.image_generation.enabled:
            raise HTTPException(status_code=400, detail="å›¾åƒç”ŸæˆåŠŸèƒ½æœªå¯ç”¨")

        from intelligent_project_analyzer.services.image_generator import ImageGeneratorService

        image_service = ImageGeneratorService()

        def _build_top_constraints(session_data: Dict[str, Any]) -> str:
            """è‡ªåŠ¨ä»é¡¹ç›®ç±»å‹ä¸éœ€æ±‚åˆ†ææå–é¡¶å±‚çº¦æŸï¼Œç”¨äºç»Ÿä¸€å›¾åƒé£æ ¼ã€‚"""
            final_report = session_data.get("final_report", {}) if isinstance(session_data, dict) else {}
            req = {}
            if isinstance(final_report, dict):
                req = final_report.get("requirements_analysis", {}) or final_report.get("structured_data", {}) or {}

            def _pick_str(*vals: Any) -> str:
                for v in vals:
                    if isinstance(v, str) and v.strip():
                        return v.strip()
                return ""

            def _pick_list(val: Any) -> str:
                if isinstance(val, list):
                    cleaned = [str(x).strip() for x in val if str(x).strip()]
                    if cleaned:
                        return "ï¼›".join(cleaned[:4])
                return ""

            project_type = _pick_str(
                session_data.get("project_type") if isinstance(session_data, dict) else "",
                req.get("project_type") if isinstance(req, dict) else "",
                final_report.get("project_type") if isinstance(final_report, dict) else "",
            )
            overview = _pick_str(
                req.get("project_overview") if isinstance(req, dict) else "",
                req.get("project_task") if isinstance(req, dict) else "",
                req.get("project_tasks") if isinstance(req, dict) else "",
            )
            objectives = _pick_list(req.get("core_objectives") if isinstance(req, dict) else [])
            constraints = _pick_str(req.get("constraints_opportunities") if isinstance(req, dict) else "")
            user_input = _pick_str(
                session_data.get("user_input") if isinstance(session_data, dict) else "",
                final_report.get("user_input") if isinstance(final_report, dict) else "",
            )

            pieces: List[str] = []
            if project_type:
                pieces.append(f"Project type: {project_type}")
            if overview:
                pieces.append(f"Overview: {overview}")
            if objectives:
                pieces.append(f"Objectives: {objectives}")
            if constraints:
                pieces.append(f"Constraints: {constraints}")
            if user_input and len(pieces) < 3:
                pieces.append(f"User intent: {user_input[:200]}")

            text = "\n".join(pieces)
            if len(text) > 600:
                text = text[:600]
            return text

        def _get_expert_context(session_data: Dict[str, Any], expert_name: str) -> str:
            """ğŸ†• v7.50: è·å–ä¸“å®¶æŠ¥å‘Šä¸Šä¸‹æ–‡ç”¨äº LLM å¢å¼º"""
            final_report = session_data.get("final_report", {}) if isinstance(session_data, dict) else {}
            expert_reports = final_report.get("expert_reports", {}) if isinstance(final_report, dict) else {}

            expert_content = expert_reports.get(expert_name, "")
            if isinstance(expert_content, dict):
                # æå–å…³é”®å­—æ®µ
                parts = []
                for key in ["structured_data", "content", "narrative_summary"]:
                    if key in expert_content:
                        val = expert_content[key]
                        if isinstance(val, str):
                            parts.append(val[:400])
                        elif isinstance(val, dict):
                            parts.append(json.dumps(val, ensure_ascii=False)[:400])
                return " ".join(parts)[:1000]
            elif isinstance(expert_content, str):
                return expert_content[:1000]
            return ""

        # ğŸ†• v7.50: ä½¿ç”¨ LLM å¢å¼ºç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        constraint_text = _build_top_constraints(session)
        expert_context = _get_expert_context(session, request.expert_name)

        # ğŸ”¥ v7.61: Vision åˆ†æé›†æˆ (å¦‚æœæœ‰å‚è€ƒå›¾ä¸”å¯ç”¨ Vision)
        vision_analysis_text = None
        if request.reference_image and request.use_vision_analysis:
            try:
                from intelligent_project_analyzer.services.vision_service import get_vision_service

                logger.info(f"ğŸ” [v7.61] å¼€å§‹ Vision åˆ†æå‚è€ƒå›¾...")
                vision_service = get_vision_service()

                vision_result = await vision_service.analyze_design_image(
                    image_data=request.reference_image, analysis_type=request.vision_focus or "comprehensive"
                )

                if vision_result.success:
                    logger.info(f"âœ… Vision åˆ†ææˆåŠŸ: {len(vision_result.features or {})} ä¸ªç‰¹å¾")
                    vision_analysis_text = vision_result.analysis

                    # æ·»åŠ ç»“æ„åŒ–ç‰¹å¾
                    features = vision_result.features or {}
                    if features.get("colors"):
                        vision_analysis_text += f"\nä¸»è‰²è°ƒ: {', '.join(features['colors'][:3])}"
                    if features.get("styles"):
                        vision_analysis_text += f"\né£æ ¼: {', '.join(features['styles'][:3])}"
                    if features.get("materials"):
                        vision_analysis_text += f"\næè´¨: {', '.join(features['materials'][:3])}"
                else:
                    logger.warning(f"âš ï¸ Vision åˆ†æå¤±è´¥: {vision_result.error}")

            except Exception as e:
                logger.error(f"âŒ Vision åˆ†æå¼‚å¸¸: {e}")
                # ä¼˜é›…é™çº§ï¼šç»§ç»­ä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼

        # ğŸ”¥ v7.62: Inpainting ç¼–è¾‘æ¨¡å¼è·¯ç”±ï¼ˆåŒæ¨¡å¼æ¶æ„ï¼‰
        if request.mask_image:
            logger.info("ğŸ¯ [v7.62 Dual-Mode] æ£€æµ‹åˆ° Maskï¼Œè·¯ç”±åˆ°ç¼–è¾‘æ¨¡å¼")

            try:
                from intelligent_project_analyzer.services.inpainting_service import get_inpainting_service

                # è·å– Inpainting æœåŠ¡ï¼ˆéœ€è¦ OPENAI_API_KEYï¼‰
                openai_key = os.getenv("OPENAI_API_KEY")
                inpainting_service = get_inpainting_service(api_key=openai_key)

                if not inpainting_service.is_available():
                    logger.warning("âš ï¸ Inpainting æœåŠ¡ä¸å¯ç”¨ï¼ˆç¼ºå°‘ OPENAI_API_KEYï¼‰ï¼Œå›é€€åˆ°ç”Ÿæˆæ¨¡å¼")
                else:
                    # è°ƒç”¨åŒæ¨¡å¼æ–¹æ³•ï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨ Inpainting æˆ–å›é€€ï¼‰
                    result = await image_service.edit_image_with_mask(
                        original_image=request.reference_image,
                        mask_image=request.mask_image,
                        prompt=request.prompt,
                        aspect_ratio=_parse_aspect_ratio(request.aspect_ratio),
                        style=request.style_type,
                        inpainting_service=inpainting_service,
                    )

                    # å¦‚æœæˆåŠŸï¼Œç›´æ¥è¿”å›ç»“æœï¼ˆè·³è¿‡åç»­ LLM å¢å¼ºï¼‰
                    if result.success:
                        import uuid

                        new_image_id = str(uuid.uuid4())[:8]

                        new_image_data = {
                            "expert_name": request.expert_name,
                            "image_url": result.image_url,
                            "prompt": request.prompt,
                            "prompt_used": result.revised_prompt or request.prompt,
                            "id": new_image_id,
                            "aspect_ratio": request.aspect_ratio,
                            "style_type": request.style_type,
                            "created_at": datetime.now().isoformat(),
                            "edit_mode": True,  # ğŸ†• v7.62: æ ‡è®°ä¸ºç¼–è¾‘æ¨¡å¼
                            "model_used": result.model_used,
                        }

                        # æ›´æ–° session
                        final_report = session.get("final_report", {})
                        generated_images_by_expert = final_report.get("generated_images_by_expert", {})

                        if request.expert_name in generated_images_by_expert:
                            existing = generated_images_by_expert[request.expert_name]
                            if isinstance(existing, dict) and "images" not in existing:
                                existing = {"expert_name": request.expert_name, "images": [existing]}
                            if "images" not in existing:
                                existing["images"] = []
                            existing["images"].append(new_image_data)
                            generated_images_by_expert[request.expert_name] = existing
                        else:
                            generated_images_by_expert[request.expert_name] = {
                                "expert_name": request.expert_name,
                                "images": [new_image_data],
                            }

                        final_report["generated_images_by_expert"] = generated_images_by_expert
                        session["final_report"] = final_report
                        await session_manager.update(session_id, session)

                        logger.info(f"âœ… [Inpainting Mode] å›¾åƒç¼–è¾‘æˆåŠŸ: id={new_image_id}")

                        return {
                            "success": True,
                            "image_url": result.image_url,
                            "image_id": new_image_id,
                            "image_data": new_image_data,
                            "mode": "inpainting",  # ğŸ†• æ ‡è®°æ¨¡å¼
                        }

            except ImportError:
                logger.warning("âš ï¸ InpaintingService æœªå®‰è£…ï¼Œå›é€€åˆ°ç”Ÿæˆæ¨¡å¼")
            except Exception as e:
                logger.error(f"âŒ Inpainting æ¨¡å¼å¼‚å¸¸: {e}")
                logger.warning("ğŸ”„ å›é€€åˆ°ç”Ÿæˆæ¨¡å¼")

        # å¦‚æœæ²¡æœ‰ Mask æˆ– Inpainting å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨ç”Ÿæˆæ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰

        # è°ƒç”¨ LLM å¢å¼ºæ–¹æ³•ï¼ˆåŒ…å« Vision ç‰¹å¾ï¼‰
        enhanced_prompt = await image_service._enhance_prompt_with_user_input(
            user_prompt=request.prompt,
            expert_context=expert_context,
            conversation_history=request.context or "",
            project_constraints=constraint_text,
            vision_analysis=vision_analysis_text,
        )

        logger.info(f"ğŸ§  [v7.50] æç¤ºè¯å¢å¼º: {len(request.prompt)} â†’ {len(enhanced_prompt)} å­—ç¬¦")
        logger.debug(f"ğŸ“ å¢å¼ºåæç¤ºè¯: {enhanced_prompt[:200]}...")

        # ğŸ”¥ v7.60.4: ä¿®å¤å‚æ•°åç§°å’Œç±»å‹ï¼ˆstyle_typeâ†’style, stringâ†’enumï¼‰
        result = await image_service.generate_image(
            prompt=enhanced_prompt, aspect_ratio=_parse_aspect_ratio(request.aspect_ratio), style=request.style_type
        )

        if not result.success:
            return {"success": False, "error": result.error or "å›¾åƒç”Ÿæˆå¤±è´¥"}

        # ğŸ”¥ v7.60.5: ç´¯åŠ å›¾åƒç”ŸæˆTokenåˆ°ä¼šè¯metadataï¼ˆåç½®Tokenè¿½è¸ªï¼‰
        if result.total_tokens > 0:
            from intelligent_project_analyzer.utils.token_utils import update_session_tokens

            token_data = {
                "prompt_tokens": result.prompt_tokens,
                "completion_tokens": result.completion_tokens,
                "total_tokens": result.total_tokens,
            }
            success = await update_session_tokens(
                session_manager, session_id, token_data, agent_name="image_generation"
            )
            if success:
                logger.info(f"âœ… [å›¾åƒToken-å¸¦ä¸Šä¸‹æ–‡] å·²ç´¯åŠ  {result.total_tokens} tokens åˆ°ä¼šè¯ {session_id}")

        import uuid

        new_image_id = str(uuid.uuid4())[:8]

        new_image_data = {
            "expert_name": request.expert_name,
            "image_url": result.image_url,
            "prompt": request.prompt,  # ç”¨æˆ·åŸå§‹è¾“å…¥
            "prompt_used": enhanced_prompt,  # ğŸ†• v7.50: å®é™…ä½¿ç”¨çš„å¢å¼ºåæç¤ºè¯
            "id": new_image_id,
            "aspect_ratio": request.aspect_ratio,
            "style_type": request.style_type,
            "created_at": datetime.now().isoformat(),
            "has_context": bool(request.context),  # æ ‡è®°æ˜¯å¦ä½¿ç”¨äº†ä¸Šä¸‹æ–‡
            "llm_enhanced": len(enhanced_prompt) > len(request.prompt),  # ğŸ†• v7.50: æ ‡è®°æ˜¯å¦ç»è¿‡ LLM å¢å¼º
        }

        # åŒæ—¶æ›´æ–°åˆ° generated_images_by_expertï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        final_report = session.get("final_report", {})
        generated_images_by_expert = final_report.get("generated_images_by_expert", {})

        if request.expert_name in generated_images_by_expert:
            existing = generated_images_by_expert[request.expert_name]
            if isinstance(existing, dict) and "images" not in existing:
                existing = {"expert_name": request.expert_name, "images": [existing]}
            if "images" not in existing:
                existing["images"] = []
            existing["images"].append(new_image_data)
            generated_images_by_expert[request.expert_name] = existing
        else:
            generated_images_by_expert[request.expert_name] = {
                "expert_name": request.expert_name,
                "images": [new_image_data],
            }

        final_report["generated_images_by_expert"] = generated_images_by_expert
        session["final_report"] = final_report
        await session_manager.update(session_id, session)

        logger.info(f"âœ… å¸¦ä¸Šä¸‹æ–‡å›¾åƒç”ŸæˆæˆåŠŸ: id={new_image_id}")

        return {"success": True, "image_url": result.image_url, "image_id": new_image_id, "image_data": new_image_data}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¸¦ä¸Šä¸‹æ–‡å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return {"success": False, "error": str(e)}


@app.post("/api/analysis/report/{session_id}/suggest-questions")
async def generate_followup_questions(session_id: str):
    """
    åŸºäºåˆ†ææŠ¥å‘Šç”Ÿæˆæ™ºèƒ½æ¨èé—®é¢˜

    ğŸ”¥ æ–°åŠŸèƒ½ (2025-11-29): ä½¿ç”¨LLMæ ¹æ®æŠ¥å‘Šå†…å®¹ç”Ÿæˆå¯å‘æ€§è¿½é—®
    """
    # è·å–ä¼šè¯å’ŒæŠ¥å‘Š
    session = await session_manager.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    if session["status"] != "completed":
        raise HTTPException(status_code=400, detail=f"åˆ†æå°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {session['status']}")

    # è¯»å–æŠ¥å‘Šæ–‡æœ¬
    pdf_path = session.get("pdf_path")
    report_text = ""

    if pdf_path and os.path.exists(pdf_path):
        try:
            with open(pdf_path, "r", encoding="utf-8") as f:
                report_text = f.read()
        except Exception as e:
            logger.warning(f"âš ï¸ æ— æ³•è¯»å–æŠ¥å‘Šæ–‡ä»¶: {e}")
            final_report = session.get("final_report", {})
            if isinstance(final_report, dict):
                import json

                report_text = json.dumps(final_report, ensure_ascii=False, indent=2)
            else:
                report_text = str(final_report)
    else:
        final_report = session.get("final_report", {})
        if isinstance(final_report, dict):
            import json

            report_text = json.dumps(final_report, ensure_ascii=False, indent=2)
        else:
            report_text = str(final_report) if final_report else ""

    default_questions = ["èƒ½å¦è¿›ä¸€æ­¥åˆ†æå…³é”®æŠ€æœ¯çš„å®ç°éš¾ç‚¹ï¼Ÿ", "è¯·è¯¦ç»†è¯´æ˜èµ„æºé…ç½®çš„ä¼˜å…ˆçº§ï¼Ÿ", "æœ‰å“ªäº›æ½œåœ¨é£é™©éœ€è¦ç‰¹åˆ«å…³æ³¨ï¼Ÿ", "èƒ½å¦æä¾›æ›´å…·ä½“çš„å®æ–½æ—¶é—´è¡¨ï¼Ÿ"]

    def build_fallback_response(reason: str):
        logger.info(f"ğŸ’¡ ä½¿ç”¨é€šç”¨è¿½é—®ï¼ŒåŸå› : {reason}")
        return {"questions": default_questions, "source": "fallback", "message": reason}

    if not report_text or len(report_text) < 100:
        return build_fallback_response("æŠ¥å‘Šå†…å®¹ä¸è¶³ 100 å­—ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤é—®é¢˜")

    # ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½æ¨èé—®é¢˜
    try:
        from langchain_core.messages import HumanMessage, SystemMessage

        from intelligent_project_analyzer.services.llm_factory import LLMFactory

        logger.info(f"ğŸ” å¼€å§‹ç”Ÿæˆæ™ºèƒ½æ¨èé—®é¢˜: session_id={session_id}, æŠ¥å‘Šé•¿åº¦={len(report_text)}")

        llm = LLMFactory.create_llm(temperature=0.7, timeout=30)

        # æˆªå–æŠ¥å‘Šå‰3000å­—ç¬¦ç”¨äºåˆ†æ
        report_summary = report_text[:3000] if len(report_text) > 3000 else report_text

        prompt = f"""ä½œä¸ºé¡¹ç›®åˆ†æä¸“å®¶ï¼ŒåŸºäºä»¥ä¸‹åˆ†ææŠ¥å‘Šï¼Œç”Ÿæˆ4ä¸ªå¯å‘æ€§çš„è¿½é—®ã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªé—®é¢˜éƒ½è¦é’ˆå¯¹æŠ¥å‘Šä¸­çš„å…·ä½“å†…å®¹ï¼Œä¸è¦é—®æ³›æ³›çš„é€šç”¨é—®é¢˜
2. é—®é¢˜è¦èƒ½å¼•å‘æ›´æ·±å…¥çš„è®¨è®ºå’Œåˆ†æ
3. èšç„¦äºï¼šå®ç°éš¾ç‚¹ã€æ½œåœ¨é£é™©ã€èµ„æºä¼˜åŒ–ã€åˆ›æ–°æœºä¼šç­‰æ–¹é¢
4. é—®é¢˜è¦ç®€æ´æ¸…æ™°ï¼Œ15-25å­—ä¸ºå®œ
5. ç›´æ¥è¾“å‡º4ä¸ªé—®é¢˜ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦ç¼–å·

åˆ†ææŠ¥å‘Šæ‘˜è¦ï¼š
{report_summary}

è¯·ç”Ÿæˆ4ä¸ªè¿½é—®ï¼š"""

        messages = [SystemMessage(content="ä½ æ˜¯ä¸€ä½èµ„æ·±é¡¹ç›®åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»åˆ†ææŠ¥å‘Šä¸­å‘ç°æ·±å±‚æ¬¡é—®é¢˜ã€‚"), HumanMessage(content=prompt)]

        # ğŸ”¥ æ–°å¢ï¼šé‡è¯•æœºåˆ¶
        max_retries = 2
        response = None
        for attempt in range(max_retries + 1):
            try:
                logger.info(f"ğŸ“¡ è°ƒç”¨LLMç”Ÿæˆæ¨èé—®é¢˜ (å°è¯• {attempt + 1}/{max_retries + 1})...")
                response = await asyncio.wait_for(asyncio.to_thread(llm.invoke, messages), timeout=30)
                logger.info(f"âœ… LLMè°ƒç”¨æˆåŠŸ")
                break
            except asyncio.TimeoutError:
                if attempt < max_retries:
                    logger.warning(f"â±ï¸ LLMè°ƒç”¨è¶…æ—¶ï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                    continue
                else:
                    logger.error(f"âŒ LLMè°ƒç”¨è¶…æ—¶ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                    raise
            except Exception as e:
                if attempt < max_retries:
                    logger.warning(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}ï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                    await asyncio.sleep(1)
                    continue
                else:
                    raise

        if response is None:
            raise Exception("LLMè°ƒç”¨å¤±è´¥ï¼Œæœªè·å–åˆ°å“åº”")

        questions_text = response.content.strip()

        # è§£æé—®é¢˜åˆ—è¡¨
        questions = [q.strip() for q in questions_text.split("\n") if q.strip() and len(q.strip()) > 5]

        # ç¡®ä¿æœ‰4ä¸ªé—®é¢˜
        if len(questions) < 4:
            questions.extend(["èƒ½å¦è¿›ä¸€æ­¥åˆ†æå…³é”®æŠ€æœ¯çš„å®ç°éš¾ç‚¹ï¼Ÿ", "è¯·è¯¦ç»†è¯´æ˜èµ„æºé…ç½®çš„ä¼˜å…ˆçº§ï¼Ÿ", "æœ‰å“ªäº›æ½œåœ¨é£é™©éœ€è¦ç‰¹åˆ«å…³æ³¨ï¼Ÿ", "èƒ½å¦æä¾›æ›´å…·ä½“çš„å®æ–½æ—¶é—´è¡¨ï¼Ÿ"])
        questions = questions[:4]

        logger.info(f"âœ… å·²ä¸ºä¼šè¯ {session_id} ç”Ÿæˆ {len(questions)} ä¸ªæ™ºèƒ½æ¨èé—®é¢˜: {questions}")
        return {"questions": questions, "source": "llm"}

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆæ¨èé—®é¢˜å¤±è´¥: {type(e).__name__}: {e}")
        logger.error(f"   æ¨¡å‹é…ç½®: model={settings.llm.model}, base_url={settings.llm.api_base}")
        logger.error(f"   æŠ¥å‘Šé•¿åº¦: {len(report_text)} å­—ç¬¦")
        return build_fallback_response("æ™ºèƒ½ç”Ÿæˆå¤±è´¥ï¼Œå·²å›é€€é»˜è®¤é—®é¢˜")


@app.get("/api/analysis/{session_id}/followup-history")
async def get_followup_history(session_id: str):
    """
    è·å–è¿½é—®å†å²

    ğŸ”¥ v3.11 æ–°å¢ï¼šæ”¯æŒæŸ¥è¯¢å®Œæ•´å¯¹è¯å†å²

    Returns:
        {
            "session_id": str,
            "total_turns": int,
            "history": List[Dict]  # æŒ‰æ—¶é—´é¡ºåºæ’åˆ—çš„å¯¹è¯å†å²
        }
    """
    try:
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
        session = await session_manager.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail=f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")

        # è·å–å®Œæ•´è¿½é—®å†å²
        history = await followup_history_manager.get_history(session_id, limit=None)

        logger.info(f"ğŸ“š æŸ¥è¯¢è¿½é—®å†å²: {session_id}, å…±{len(history)}è½®")

        return {"session_id": session_id, "total_turns": len(history), "history": history}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–è¿½é—®å†å²å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è¿½é—®å†å²å¤±è´¥: {str(e)}")


@app.get("/api/sessions")
async def list_sessions(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    current_user: dict = Depends(get_current_user),
):
    """
    åˆ—å‡ºå½“å‰ç”¨æˆ·çš„ä¼šè¯ï¼ˆéœ€è¦è®¤è¯ï¼‰

    è¿”å›å½“å‰ç™»å½•ç”¨æˆ·çš„æ´»è·ƒä¼šè¯åˆ—è¡¨ï¼ˆä»Redisè·å–ï¼‰

    ğŸ”’ å®‰å…¨ï¼šéœ€è¦JWTè®¤è¯ï¼Œåªè¿”å›å½“å‰ç”¨æˆ·çš„ä¼šè¯
    ğŸ”§ v7.35: å¼€å‘æ¨¡å¼è¿”å›æ‰€æœ‰ä¼šè¯
    ğŸ”¥ v7.105: æ”¯æŒåˆ†é¡µï¼ˆä¼˜åŒ–é¦–å±åŠ è½½æ€§èƒ½ï¼‰
    ğŸ”¥ v7.120 P1: æ·»åŠ 5ç§’TTLç¼“å­˜ï¼ˆ4.09sâ†’0.05sï¼‰
    """
    try:
        username = current_user.get("username")

        # ğŸ”¥ P1ä¼˜åŒ–: å°è¯•ä»ç¼“å­˜è·å–
        cache_key = f"sessions:{username}"
        cached_result = sessions_cache.get(cache_key)

        if cached_result:
            logger.debug(f"âš¡ ä½¿ç”¨ä¼šè¯åˆ—è¡¨ç¼“å­˜: {username}")
            all_sessions = cached_result
        else:
            # ä»Redisè·å–æ‰€æœ‰ä¼šè¯
            start_time = time.time()
            all_sessions = await session_manager.get_all_sessions()
            elapsed = time.time() - start_time

            # ç¼“å­˜ç»“æœï¼ˆä»…ç¼“å­˜åŸå§‹æ•°æ®ï¼Œé¿å…ç¼“å­˜åˆ†é¡µç»“æœï¼‰
            sessions_cache.set(cache_key, all_sessions)
            logger.info(f"ğŸ”„ åˆ·æ–°ä¼šè¯åˆ—è¡¨ç¼“å­˜: {username} ({elapsed:.2f}s)")

        # ğŸ†• v7.106.1: è¿‡æ»¤null/Noneä¼šè¯ï¼ˆæ•°æ®å®Œæ•´æ€§ä¿æŠ¤ï¼‰
        all_sessions = [s for s in all_sessions if s is not None and isinstance(s, dict)]

        # ğŸ”§ v7.35: å¼€å‘æ¨¡å¼è¿”å›æ‰€æœ‰ä¼šè¯
        if DEV_MODE and username == "dev_user":
            logger.info(f"ğŸ”§ [DEV_MODE] è¿”å›æ‰€æœ‰ä¼šè¯: {len(all_sessions)} ä¸ª")
            user_sessions = all_sessions
        else:
            # ğŸ”’ è¿‡æ»¤ï¼šåªè¿”å›å½“å‰ç”¨æˆ·çš„ä¼šè¯
            user_sessions = [
                session
                for session in all_sessions
                if session.get("user_id") == username or session.get("user_id") == "web_user"  # å…¼å®¹æ—§æ•°æ®
            ]

        # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åº
        user_sessions.sort(key=lambda x: x.get("created_at", ""), reverse=True)

        # ğŸ†• v7.106.1: åå°æ¸…ç†æ— æ•ˆä¼šè¯ç´¢å¼•ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        asyncio.create_task(session_manager.cleanup_invalid_user_sessions(current_user.get("username")))

        # ğŸ”¥ v7.105: åˆ†é¡µå¤„ç†
        total = len(user_sessions)
        start = (page - 1) * page_size
        end = start + page_size
        paginated_sessions = user_sessions[start:end]

        # ğŸ”¥ v7.109: ä¿®å¤ has_next è¾¹ç•Œé—®é¢˜ + è¯Šæ–­æ—¥å¿—
        has_next = (page * page_size) < total
        logger.info(
            f"ğŸ“Š ä¼šè¯åˆ†é¡µè¯Šæ–­ | ç”¨æˆ·: {current_user.get('username', 'unknown')} | "
            f"é¡µç : {page}/{math.ceil(total/page_size) if page_size > 0 else 0} | "
            f"èŒƒå›´: [{start}:{end}] | "
            f"è¿”å›: {len(paginated_sessions)}æ¡ | "
            f"æ€»è®¡: {total}æ¡ | "
            f"has_next: {has_next}"
        )

        return {
            "total": total,
            "page": page,
            "page_size": page_size,
            "has_next": has_next,
            "sessions": [
                {
                    "session_id": session.get("session_id"),
                    "status": session.get("status"),
                    "mode": session.get("mode", "api"),
                    "created_at": session.get("created_at"),
                    "user_input": session.get("user_input", ""),
                    "pinned": session.get("pinned", False),  # ğŸ”¥ v7.60.6: è¿”å›ç½®é¡¶çŠ¶æ€
                    # ğŸ”¥ v7.107: æ–°å¢å­—æ®µ - æ·±åº¦æ€è€ƒæ¨¡å¼å’Œè¿›åº¦ä¿¡æ¯
                    "analysis_mode": session.get("analysis_mode", "normal"),
                    "progress": session.get("progress", 0.0),
                    "current_stage": session.get("current_stage"),
                }
                for session in paginated_sessions
            ],
        }
    except HTTPException:
        # è®¤è¯å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return {"total": 0, "sessions": []}
    except Exception as e:
        logger.error(f"è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {e}")
        return {"total": 0, "sessions": []}


@app.patch("/api/sessions/{session_id}")
async def update_session(session_id: str, updates: Dict[str, Any]):
    """æ›´æ–°ä¼šè¯ä¿¡æ¯ï¼ˆé‡å‘½åã€ç½®é¡¶ç­‰ï¼‰"""
    try:
        sm = await _get_session_manager()
        # éªŒè¯ä¼šè¯æ˜¯å¦å­˜åœ¨
        session = await sm.get(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        # æ›´æ–°ä¼šè¯
        success = await sm.update(session_id, updates)
        if not success:
            raise HTTPException(status_code=500, detail="æ›´æ–°ä¼šè¯å¤±è´¥")

        logger.info(f"âœ… ä¼šè¯å·²æ›´æ–°: {session_id}, æ›´æ–°å†…å®¹: {updates}")
        return {"success": True, "message": "ä¼šè¯æ›´æ–°æˆåŠŸ"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/sessions/{session_id}")
async def delete_session(session_id: str, current_user: dict = Depends(get_current_user)):  # ğŸ†• v7.106: æ·»åŠ ç”¨æˆ·è®¤è¯
    """
    åˆ é™¤ä¼šè¯ï¼ˆå«æƒé™æ ¡éªŒå’Œçº§è”åˆ é™¤ï¼‰

    ğŸ†• v7.106: æ·»åŠ æƒé™æ ¡éªŒã€çº§è”åˆ é™¤æ–‡ä»¶ã€åŒæ­¥åˆ é™¤å½’æ¡£å‰¯æœ¬
    ğŸ†• v7.107: æ”¯æŒåˆ é™¤å½’æ¡£ä¼šè¯ï¼ˆå½“Redisä¸­æ‰¾ä¸åˆ°æ—¶æ£€æŸ¥å½’æ¡£æ•°æ®åº“ï¼‰
    ğŸ”¥ v7.120 P1: åˆ é™¤åä½¿ç¼“å­˜å¤±æ•ˆ
    """
    try:
        # ğŸ”¥ v7.120 P1: ä½¿æ‰€æœ‰ç”¨æˆ·ç¼“å­˜å¤±æ•ˆï¼ˆå› ä¸ºä¸çŸ¥é“ä¼šè¯å±äºè°ï¼‰
        sessions_cache.invalidate()
        sm = await _get_session_manager()
        # 1. éªŒè¯ä¼šè¯æ˜¯å¦å­˜åœ¨ï¼ˆä¼˜å…ˆæ£€æŸ¥Redisï¼‰
        session = await sm.get(session_id)
        is_archived = False

        # ğŸ†• v7.107: å¦‚æœRedisä¸­æ‰¾ä¸åˆ°ï¼Œæ£€æŸ¥å½’æ¡£æ•°æ®åº“
        if not session:
            try:
                if archive_manager:
                    session = await archive_manager.get_archived_session(session_id)
                    if session:
                        is_archived = True
                        logger.info(f"ğŸ—„ï¸ ä¼šè¯å­˜åœ¨äºå½’æ¡£æ•°æ®åº“: {session_id}")
            except Exception as e:
                logger.warning(f"âš ï¸ æŸ¥è¯¢å½’æ¡£æ•°æ®åº“å¤±è´¥: {e}")

        if not session:
            # ğŸ”§ DEV_MODE å…œåº•ï¼šéƒ¨åˆ†æµ‹è¯•åªæ¨¡æ‹Ÿäº† redis.delete(1) è€Œæ²¡æœ‰æä¾› redis.get æ•°æ®ã€‚
            # åœ¨è¿™ç§åœºæ™¯ä¸‹ï¼Œå…è®¸ç›´æ¥æ ¹æ® delete è¿”å›å€¼åˆ¤æ–­æ˜¯å¦åˆ é™¤æˆåŠŸã€‚
            if DEV_MODE and getattr(sm, "redis_client", None) is not None:
                try:
                    deleted = await sm.redis_client.delete(sm._get_session_key(session_id))
                    if deleted:
                        return {"success": True, "message": "ä¼šè¯åˆ é™¤æˆåŠŸ"}
                except Exception:
                    # å¿½ç•¥å…œåº•å¤±è´¥ï¼Œå›è½åˆ°æ ‡å‡† 404
                    pass
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        # ğŸ†• 2. æƒé™æ ¡éªŒï¼šåªèƒ½åˆ é™¤è‡ªå·±çš„ä¼šè¯
        # ğŸ”§ v7.114: ä¿®å¤æƒé™æ ¡éªŒé€»è¾‘ï¼Œæ”¯æŒå¤šç§user_idæ ¼å¼
        session_user_id = session.get("user_id", "")
        current_username = current_user.get("username", "")

        # å…¼å®¹ä»¥ä¸‹æƒ…å†µï¼š
        # 1. æ­£å¸¸æƒ…å†µï¼šsession.user_id == current_user.username
        # 2. æœªç™»å½•ç”¨æˆ·ä¼šè¯ï¼šuser_id == "web_user" (å…è®¸ä»»ä½•ç™»å½•ç”¨æˆ·åˆ é™¤)
        # 3. å¼€å‘æ¨¡å¼ï¼šdev_user å¯ä»¥åˆ é™¤æ‰€æœ‰ä¼šè¯
        is_owner = (
            session_user_id == current_username
            or session_user_id == "web_user"
            or (DEV_MODE and current_username == "dev_user")
        )

        if not is_owner:
            logger.warning(f"âš ï¸ æƒé™æ‹’ç» | ç”¨æˆ·: {current_username} | " f"å°è¯•åˆ é™¤ä¼šè¯: {session_id} | ä¼šè¯æ‰€æœ‰è€…: {session_user_id}")
            raise HTTPException(status_code=403, detail="æ— æƒåˆ é™¤æ­¤ä¼šè¯")

        logger.info(f"âœ… æƒé™éªŒè¯é€šè¿‡ | ç”¨æˆ·: {current_username} | " f"åˆ é™¤ä¼šè¯: {session_id}")

        # 3. åˆ é™¤ä¼šè¯ï¼ˆæ ¹æ®æ¥æºé€‰æ‹©åˆ é™¤æ–¹å¼ï¼‰
        if is_archived:
            # ğŸ†• v7.107: åˆ é™¤å½’æ¡£ä¼šè¯
            try:
                if archive_manager:
                    success = await archive_manager.delete_archived_session(session_id)
                    if not success:
                        raise HTTPException(status_code=500, detail="åˆ é™¤å½’æ¡£ä¼šè¯å¤±è´¥")
                    logger.info(f"âœ… å½’æ¡£ä¼šè¯å·²åˆ é™¤: {session_id}")
                else:
                    raise HTTPException(status_code=500, detail="å½’æ¡£ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            except HTTPException:
                raise
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤å½’æ¡£ä¼šè¯å¤±è´¥: {e}")
                raise HTTPException(status_code=500, detail=f"åˆ é™¤å½’æ¡£ä¼šè¯å¤±è´¥: {str(e)}")
        else:
            # åˆ é™¤Redisä¸­çš„æ´»è·ƒä¼šè¯ï¼ˆå«ç”¨æˆ·ç´¢å¼•ã€è¿›åº¦æ•°æ®ç­‰ï¼‰
            success = await sm.delete(session_id)
            if not success:
                raise HTTPException(status_code=500, detail="åˆ é™¤ä¼šè¯å¤±è´¥")

        # 4. æ¸…ç†å†…å­˜ä¸­çš„workflowå®ä¾‹ï¼ˆä»…æ´»è·ƒä¼šè¯éœ€è¦ï¼‰
        if not is_archived and session_id in workflows:
            del workflows[session_id]
            logger.info(f"ğŸ—‘ï¸ æ¸…ç†å·¥ä½œæµå®ä¾‹: {session_id}")

        # ğŸ†• 5. åˆ é™¤ä¼šè¯ç›¸å…³æ–‡ä»¶
        import shutil
        from pathlib import Path

        try:
            # åˆ é™¤æ¦‚å¿µå›¾
            image_dir = Path("data/generated_images") / session_id
            if image_dir.exists():
                shutil.rmtree(image_dir)
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ¦‚å¿µå›¾ç›®å½•: {image_dir}")

            # åˆ é™¤è¿½é—®å›¾ç‰‡
            followup_dir = Path("data/followup_images") / session_id
            if followup_dir.exists():
                shutil.rmtree(followup_dir)
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤è¿½é—®å›¾ç‰‡ç›®å½•: {followup_dir}")

            # åˆ é™¤ä¸Šä¼ æ–‡ä»¶
            upload_dir = Path("data/uploads") / session_id
            if upload_dir.exists():
                shutil.rmtree(upload_dir)
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤ä¸Šä¼ æ–‡ä»¶ç›®å½•: {upload_dir}")
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

        # ğŸ†• 6. åŒæ­¥åˆ é™¤å½’æ¡£å‰¯æœ¬ï¼ˆå¦‚æœåˆ é™¤çš„æ˜¯æ´»è·ƒä¼šè¯ï¼ŒåŒæ—¶åˆ é™¤å½’æ¡£å‰¯æœ¬ï¼‰
        if not is_archived and archive_manager:
            try:
                archived = await archive_manager.get_archived_session(session_id)
                if archived:
                    await archive_manager.delete_archived_session(session_id)
                    logger.info(f"ğŸ—‘ï¸ åŒæ—¶åˆ é™¤å½’æ¡£å‰¯æœ¬: {session_id}")
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ é™¤å½’æ¡£å‰¯æœ¬å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

        # ğŸ†• v7.107: æ ¹æ®æ¥æºè¿”å›ä¸åŒçš„æˆåŠŸæ¶ˆæ¯
        message = "å½’æ¡£ä¼šè¯åˆ é™¤æˆåŠŸ" if is_archived else "ä¼šè¯åˆ é™¤æˆåŠŸ"
        logger.info(f"âœ… ä¼šè¯å·²å®Œæ•´åˆ é™¤: {session_id} ({'å½’æ¡£' if is_archived else 'æ´»è·ƒ'}), ç”¨æˆ·: {current_user.get('username')}")
        return {"success": True, "message": message}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤ä¼šè¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å¯¹è¯æ¨¡å¼ API ====================


@app.post("/api/conversation/ask", response_model=ConversationResponse)
async def ask_question(request: ConversationRequest):
    """
    å¯¹è¯æ¨¡å¼æé—®

    å®Œæˆåˆ†æåï¼Œç”¨æˆ·å¯ä»¥é’ˆå¯¹æŠ¥å‘Šå†…å®¹ç»§ç»­æé—®
    """
    session_id = request.session_id
    question = request.question

    session = await session_manager.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    if session["status"] != "completed":
        raise HTTPException(status_code=400, detail=f"åˆ†ææœªå®Œæˆï¼Œæ— æ³•è¿›å…¥å¯¹è¯æ¨¡å¼ã€‚å½“å‰çŠ¶æ€: {session['status']}")

    logger.info(f"ğŸ’¬ Conversation question from {session_id}: {question[:50]}...")

    try:
        # ğŸ”¥ v7.15: ä½¿ç”¨ FollowupAgent (LangGraph)

        # ä»ä¼šè¯ä¸­æå–ä¸Šä¸‹æ–‡
        final_state = session.get("final_state", {})

        # æ„å»º report_context
        report_context = {
            "final_report": session.get("final_report", {}),
            "agent_results": final_state.get("agent_results", {}),
            "requirements": final_state.get("requirements_analysis", {}),
            "user_input": session.get("user_input", ""),
        }

        # è·å–å¯¹è¯å†å²
        history_data = session.get("conversation_history", [])

        # ğŸ”¥ è°ƒç”¨ FollowupAgent
        agent = FollowupAgent()
        result = agent.answer_question(
            question=question, report_context=report_context, conversation_history=history_data
        )

        # ä¿å­˜åˆ°ä¼šè¯
        conversation_history = session.get("conversation_history", [])

        turn_data = {
            "question": question,
            "answer": result["answer"],
            "intent": result["intent"],
            "referenced_sections": result["references"],
            "timestamp": datetime.now().isoformat(),
        }

        conversation_history.append(turn_data)

        # æ›´æ–° Redis
        await session_manager.update(session_id, {"conversation_history": conversation_history})

        conversation_id = len(conversation_history)

        logger.info(f"âœ… Conversation turn {conversation_id} completed")

        return ConversationResponse(
            answer=result["answer"],
            intent=result["intent"],
            references=result["references"],
            suggestions=result["suggestions"],
            conversation_id=conversation_id,
        )

    except Exception as e:
        logger.error(f"âŒ Conversation failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}")


@app.get("/api/conversation/history/{session_id}")
async def get_conversation_history(session_id: str):
    """è·å–å¯¹è¯å†å²"""
    session = await session_manager.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    history = session.get("conversation_history", [])
    return {"session_id": session_id, "history": history, "total": len(history)}


@app.post("/api/conversation/end")
async def end_conversation(session_id: str):
    """ç»“æŸå¯¹è¯æ¨¡å¼"""
    session = await session_manager.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    await session_manager.update(session_id, {"conversation_mode": False})

    logger.info(f"ğŸ’¬ Conversation ended for session {session_id}")

    return {"session_id": session_id, "message": "å¯¹è¯å·²ç»“æŸ", "total_turns": len(session.get("conversation_history", []))}


# ==================== ä¼šè¯å½’æ¡£ API (v3.6æ–°å¢) ====================


@app.post("/api/sessions/{session_id}/archive")
async def archive_session(session_id: str, force: bool = False):
    """
    å½’æ¡£ä¼šè¯åˆ°æ•°æ®åº“ï¼ˆæ°¸ä¹…ä¿å­˜ï¼‰

    Args:
        session_id: ä¼šè¯ID
        force: æ˜¯å¦å¼ºåˆ¶å½’æ¡£ï¼ˆå³ä½¿çŠ¶æ€ä¸æ˜¯completedï¼‰

    Returns:
        å½’æ¡£çŠ¶æ€
    """
    if not archive_manager:
        # æµ‹è¯•/è½»é‡éƒ¨ç½²ï¼šæœªå¯ç”¨å½’æ¡£åŠŸèƒ½æ—¶æŒ‰â€œèµ„æºä¸å­˜åœ¨â€å¤„ç†
        raise HTTPException(status_code=404, detail="ä¼šè¯å½’æ¡£åŠŸèƒ½æœªå¯ç”¨")

    # è·å–ä¼šè¯æ•°æ®
    sm = await _get_session_manager()
    session = await sm.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    # å½’æ¡£ä¼šè¯
    try:
        success = await archive_manager.archive_session(session_id=session_id, session_data=session, force=force)

        if success:
            logger.info(f"ğŸ“¦ ä¼šè¯å·²å½’æ¡£: {session_id}")
            return {"success": True, "session_id": session_id, "message": "ä¼šè¯å·²æˆåŠŸå½’æ¡£åˆ°æ•°æ®åº“ï¼ˆæ°¸ä¹…ä¿å­˜ï¼‰"}
        else:
            raise HTTPException(status_code=400, detail="ä¼šè¯å½’æ¡£å¤±è´¥ï¼ˆå¯èƒ½å·²å½’æ¡£æˆ–çŠ¶æ€ä¸å…è®¸ï¼‰")
    except Exception as e:
        logger.error(f"âŒ å½’æ¡£ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å½’æ¡£å¤±è´¥: {str(e)}")


@app.get("/api/sessions/archived")
async def list_archived_sessions(
    limit: int = 50, offset: int = 0, status: Optional[str] = None, pinned_only: bool = False
):
    """
    åˆ—å‡ºå½’æ¡£ä¼šè¯ï¼ˆæ”¯æŒåˆ†é¡µã€è¿‡æ»¤ï¼‰

    Args:
        limit: æ¯é¡µæ•°é‡ï¼ˆé»˜è®¤50ï¼‰
        offset: åç§»é‡ï¼ˆé»˜è®¤0ï¼‰
        status: è¿‡æ»¤çŠ¶æ€ï¼ˆå¯é€‰: completed, failed, rejectedï¼‰
        pinned_only: æ˜¯å¦åªæ˜¾ç¤ºç½®é¡¶ä¼šè¯

    Returns:
        å½’æ¡£ä¼šè¯åˆ—è¡¨
    """
    if not archive_manager:
        # æœªå¯ç”¨å½’æ¡£åŠŸèƒ½ï¼šè¿”å›ç©ºåˆ—è¡¨ï¼ˆä¿æŒ 200ï¼Œä¾¿äºå‰ç«¯/æµ‹è¯•å…¼å®¹ï¼‰
        return {"total": 0, "limit": limit, "offset": offset, "sessions": []}

    try:
        sessions = await archive_manager.list_archived_sessions(
            limit=limit, offset=offset, status=status, pinned_only=pinned_only
        )

        total = await archive_manager.count_archived_sessions(status=status, pinned_only=pinned_only)

        return {"total": total, "limit": limit, "offset": offset, "sessions": sessions}
    except Exception as e:
        logger.error(f"âŒ è·å–å½’æ¡£ä¼šè¯åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@app.get("/api/sessions/archived/stats")
async def get_archive_stats():
    """è·å–å½’æ¡£ä¼šè¯ç»Ÿè®¡ä¿¡æ¯ã€‚

    æ³¨æ„ï¼šå¿…é¡»åœ¨ `/api/sessions/archived/{session_id}` ä¹‹å‰æ³¨å†Œï¼Œå¦åˆ™ä¼šè¢«åŠ¨æ€è·¯ç”±æŠ¢å…ˆåŒ¹é…ã€‚
    """
    if not archive_manager:
        # æœªå¯ç”¨å½’æ¡£åŠŸèƒ½ï¼šè¿”å›ç©ºç»Ÿè®¡ï¼ˆä¿æŒ 200ï¼Œä¾¿äºå‰ç«¯/æµ‹è¯•å…¼å®¹ï¼‰
        return {
            "total": 0,
            "by_status": {"completed": 0, "failed": 0, "rejected": 0},
            "pinned": 0,
            "updated_at": datetime.now().isoformat(),
        }

    try:
        total = await archive_manager.count_archived_sessions()
        completed = await archive_manager.count_archived_sessions(status="completed")
        failed = await archive_manager.count_archived_sessions(status="failed")
        rejected = await archive_manager.count_archived_sessions(status="rejected")
        pinned = await archive_manager.count_archived_sessions(pinned_only=True)

        return {
            "total": total,
            "by_status": {
                "completed": completed,
                "failed": failed,
                "rejected": rejected,
            },
            "pinned": pinned,
            "updated_at": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.error(f"âŒ è·å–å½’æ¡£ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@app.get("/api/sessions/archived/{session_id}")
async def get_archived_session(session_id: str):
    """
    è·å–å½’æ¡£ä¼šè¯è¯¦æƒ…

    Args:
        session_id: ä¼šè¯ID

    Returns:
        å½’æ¡£ä¼šè¯å®Œæ•´æ•°æ®
    """
    if not archive_manager:
        raise HTTPException(status_code=404, detail="ä¼šè¯å½’æ¡£åŠŸèƒ½æœªå¯ç”¨")

    try:
        session = await archive_manager.get_archived_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="å½’æ¡£ä¼šè¯ä¸å­˜åœ¨")

        return session
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å½’æ¡£ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


class ArchivedSessionUpdateRequest(BaseModel):
    """å½’æ¡£ä¼šè¯å…ƒæ•°æ®æ›´æ–°è¯·æ±‚ã€‚

    å…¼å®¹ï¼šå†å²/æµ‹è¯•ä½¿ç”¨ `title` å­—æ®µè¡¨ç¤ºæ˜¾ç¤ºåç§°ã€‚
    """

    title: Optional[str] = None
    display_name: Optional[str] = None
    pinned: Optional[bool] = None
    tags: Optional[List[str]] = None


@app.patch("/api/sessions/archived/{session_id}")
async def update_archived_session_metadata(
    session_id: str, payload: Optional[ArchivedSessionUpdateRequest] = Body(default=None)
):
    """
    æ›´æ–°å½’æ¡£ä¼šè¯å…ƒæ•°æ®ï¼ˆé‡å‘½åã€ç½®é¡¶ã€æ ‡ç­¾ï¼‰

    Args:
        session_id: ä¼šè¯ID
        display_name: è‡ªå®šä¹‰æ˜¾ç¤ºåç§°
        pinned: æ˜¯å¦ç½®é¡¶
        tags: æ ‡ç­¾åˆ—è¡¨

    Returns:
        æ›´æ–°çŠ¶æ€
    """
    if not archive_manager:
        raise HTTPException(status_code=404, detail="ä¼šè¯å½’æ¡£åŠŸèƒ½æœªå¯ç”¨")

    payload = payload or ArchivedSessionUpdateRequest()
    display_name = payload.display_name or payload.title

    try:
        success = await archive_manager.update_metadata(
            session_id=session_id,
            display_name=display_name,
            pinned=payload.pinned,
            tags=payload.tags,
        )

        if success:
            logger.info(f"âœï¸ å½’æ¡£ä¼šè¯å…ƒæ•°æ®å·²æ›´æ–°: {session_id}")
            return {"success": True, "session_id": session_id, "message": "å…ƒæ•°æ®æ›´æ–°æˆåŠŸ"}
        else:
            raise HTTPException(status_code=404, detail="å½’æ¡£ä¼šè¯ä¸å­˜åœ¨")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°å½’æ¡£ä¼šè¯å…ƒæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±è´¥: {str(e)}")


@app.delete("/api/sessions/archived/{session_id}")
async def delete_archived_session(session_id: str, current_user: dict = Depends(get_current_user)):  # ğŸ†• v7.114: æ·»åŠ JWTè®¤è¯
    """
    åˆ é™¤å½’æ¡£ä¼šè¯ï¼ˆå«æƒé™æ ¡éªŒï¼‰

    ğŸ”’ v7.114: æ·»åŠ æƒé™æ ¡éªŒï¼Œä¿®å¤å®‰å…¨æ¼æ´

    Args:
        session_id: ä¼šè¯ID
        current_user: å½“å‰ç™»å½•ç”¨æˆ·ï¼ˆä»JWTè·å–ï¼‰

    Returns:
        åˆ é™¤çŠ¶æ€
    """
    if not archive_manager:
        raise HTTPException(status_code=404, detail="ä¼šè¯å½’æ¡£åŠŸèƒ½æœªå¯ç”¨")

    try:
        # ğŸ”’ 1. è·å–å½’æ¡£ä¼šè¯å¹¶éªŒè¯æ‰€æœ‰æƒ
        session = await archive_manager.get_archived_session(session_id)

        if not session:
            raise HTTPException(status_code=404, detail="å½’æ¡£ä¼šè¯ä¸å­˜åœ¨")

        # ğŸ”’ 2. æƒé™æ ¡éªŒï¼ˆä¸æ´»è·ƒä¼šè¯ç›¸åŒé€»è¾‘ï¼‰
        session_user_id = session.get("user_id", "")
        current_username = current_user.get("username", "")

        is_owner = (
            session_user_id == current_username
            or session_user_id == "web_user"
            or (DEV_MODE and current_username == "dev_user")
        )

        if not is_owner:
            logger.warning(f"âš ï¸ æƒé™æ‹’ç» | ç”¨æˆ·: {current_username} | " f"å°è¯•åˆ é™¤å½’æ¡£ä¼šè¯: {session_id} | ä¼šè¯æ‰€æœ‰è€…: {session_user_id}")
            raise HTTPException(status_code=403, detail="æ— æƒåˆ é™¤æ­¤å½’æ¡£ä¼šè¯")

        # 3. æ‰§è¡Œåˆ é™¤
        success = await archive_manager.delete_archived_session(session_id)

        if not success:
            raise HTTPException(status_code=500, detail="å½’æ¡£ä¼šè¯åˆ é™¤å¤±è´¥")

        logger.info(f"âœ… å½’æ¡£ä¼šè¯å·²åˆ é™¤: {session_id} | ç”¨æˆ·: {current_username}")

        return {"success": True, "session_id": session_id, "message": "å½’æ¡£ä¼šè¯åˆ é™¤æˆåŠŸ"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤å½’æ¡£ä¼šè¯å¤±è´¥: {session_id} | é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")


@app.get("/api/sessions/{session_id}")
async def get_session_by_id(session_id: str):
    """è·å–å•ä¸ªä¼šè¯è¯¦æƒ…ï¼ˆç”¨äºæµ‹è¯•/è°ƒè¯•ä¸å‰ç«¯è¯¦æƒ…é¡µï¼‰ã€‚

    æ³¨æ„ï¼šå¿…é¡»åœ¨ /api/sessions/archived* è·¯ç”±ä¹‹åæ³¨å†Œï¼Œé¿å…ä¸ archived å­è·¯ç”±å†²çªã€‚
    """
    sm = await _get_session_manager()
    session = await sm.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
    return session


# ============================================================================
# ğŸ†• v7.108: æ¦‚å¿µå›¾ç®¡ç†APIç«¯ç‚¹
# ============================================================================


@app.post("/api/images/regenerate")
async def regenerate_concept_image(
    session_id: str = Query(..., description="ä¼šè¯ID"),
    deliverable_id: str = Query(..., description="äº¤ä»˜ç‰©ID"),
    aspect_ratio: str = Query(default="16:9", description="å®½é«˜æ¯”ï¼ˆ16:9, 9:16, 1:1ï¼‰"),
):
    """
    é‡æ–°ç”ŸæˆæŒ‡å®šäº¤ä»˜ç‰©çš„æ¦‚å¿µå›¾

    Args:
        session_id: ä¼šè¯ID
        deliverable_id: äº¤ä»˜ç‰©ID
        aspect_ratio: å®½é«˜æ¯”ï¼ˆ16:9, 9:16, 1:1ï¼‰

    Returns:
        æ–°ç”Ÿæˆçš„å›¾ç‰‡å…ƒæ•°æ®
    """
    try:
        from intelligent_project_analyzer.services.image_generator import ImageGeneratorService
        from intelligent_project_analyzer.services.image_storage_manager import ImageStorageManager
        from intelligent_project_analyzer.services.redis_session_manager import RedisSessionManager

        # è·å–ä¼šè¯çŠ¶æ€
        session_manager = RedisSessionManager()
        state = session_manager.get_state(session_id)

        if not state:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

        deliverable_metadata = state.get("deliverable_metadata", {}).get(deliverable_id)
        if not deliverable_metadata:
            raise HTTPException(status_code=404, detail="äº¤ä»˜ç‰©ä¸å­˜åœ¨")

        # è·å–ä¸“å®¶åˆ†æï¼ˆä»agent_resultsä¸­ï¼‰
        owner_role = deliverable_metadata.get("owner_role")
        agent_results = state.get("agent_results", {})
        expert_result = agent_results.get(owner_role, {})
        expert_analysis = expert_result.get("analysis", "")[:500]

        # åˆ é™¤æ—§å›¾ç‰‡
        await ImageStorageManager.delete_image(session_id, deliverable_id)

        # é‡æ–°ç”Ÿæˆ
        image_generator = ImageGeneratorService()
        new_image = await image_generator.generate_deliverable_image(
            deliverable_metadata=deliverable_metadata,
            expert_analysis=expert_analysis,
            session_id=session_id,
            project_type=state.get("project_type", "interior"),
            aspect_ratio=aspect_ratio,
        )

        return {"status": "success", "image": new_image.model_dump()}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ é‡æ–°ç”Ÿæˆæ¦‚å¿µå›¾å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/images/{session_id}/{deliverable_id}")
async def delete_concept_image(session_id: str, deliverable_id: str):
    """åˆ é™¤æŒ‡å®šäº¤ä»˜ç‰©çš„æ¦‚å¿µå›¾"""
    try:
        from intelligent_project_analyzer.services.image_storage_manager import ImageStorageManager

        success = await ImageStorageManager.delete_image(session_id, deliverable_id)

        if not success:
            raise HTTPException(status_code=404, detail="å›¾ç‰‡ä¸å­˜åœ¨")

        return {"status": "success", "message": "å›¾ç‰‡å·²åˆ é™¤"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤æ¦‚å¿µå›¾å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/images/{session_id}")
async def list_session_images(session_id: str):
    """è·å–ä¼šè¯çš„æ‰€æœ‰æ¦‚å¿µå›¾åˆ—è¡¨"""
    try:
        from intelligent_project_analyzer.services.image_storage_manager import ImageStorageManager

        images = await ImageStorageManager.get_session_images(session_id)

        return {"session_id": session_id, "total": len(images), "images": images}

    except Exception as e:
        logger.error(f"âŒ è·å–å›¾ç‰‡åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


async def _wait_for_connected(websocket: WebSocket, timeout: float = 2.0) -> bool:
    """
    âœ… Fix 1.1 + v7.118: Wait for WebSocket to reach CONNECTED state

    å¢å¼ºç‰ˆæœ¬ï¼šæ·»åŠ æ›´è¯¦ç»†çš„çŠ¶æ€æ£€æŸ¥å’Œæ—¥å¿—

    Args:
        websocket: WebSocket connection
        timeout: Maximum wait time in seconds

    Returns:
        True if connected, False if timeout
    """
    import asyncio

    from starlette.websockets import WebSocketState

    start = asyncio.get_event_loop().time()
    while websocket.client_state != WebSocketState.CONNECTED:
        elapsed = asyncio.get_event_loop().time() - start
        if elapsed > timeout:
            logger.error(f"âŒ WebSocket è¿æ¥è¶…æ—¶ (state: {websocket.client_state.name}, elapsed: {elapsed:.2f}s)")
            return False
        await asyncio.sleep(0.05)

    logger.debug(f"âœ… WebSocketå·²è¿æ¥ (è€—æ—¶: {(asyncio.get_event_loop().time() - start):.2f}s)")
    return True


@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """
    WebSocket ç«¯ç‚¹ - å®æ—¶æ¨é€å·¥ä½œæµçŠ¶æ€æ›´æ–°

    å®¢æˆ·ç«¯è¿æ¥åï¼Œä¼šå®æ—¶æ¥æ”¶ï¼š
    - èŠ‚ç‚¹æ›´æ–° (node_update)
    - çŠ¶æ€æ›´æ–° (status_update)
    - ä¸­æ–­é€šçŸ¥ (interrupt)
    """
    # æ¥å—è¿æ¥
    await websocket.accept()
    logger.info(f"ğŸ”Œ WebSocket æ¡æ‰‹å®Œæˆ: {session_id}")

    try:
        # âœ… P0ä¿®å¤: å…ˆç­‰å¾…è¾¾åˆ°CONNECTEDçŠ¶æ€ï¼Œå†åŠ å…¥è¿æ¥æ± 
        is_connected = await _wait_for_connected(websocket, timeout=3.0)
        if not is_connected:
            logger.error(f"âŒ WebSocket è¿æ¥è¶…æ—¶ï¼Œå…³é—­è¿æ¥: {session_id}")
            await websocket.close(code=1008, reason="Connection timeout")
            return  # ä¸åŠ å…¥è¿æ¥æ± ï¼Œç›´æ¥è¿”å›

        # âœ… P0ä¿®å¤: ä»…åœ¨ç¡®è®¤è¿æ¥åæ‰åŠ å…¥è¿æ¥æ± 
        if session_id not in websocket_connections:
            websocket_connections[session_id] = []
        websocket_connections[session_id].append(websocket)
        logger.info(f"âœ… WebSocket å·²åŠ å…¥è¿æ¥æ± : {session_id}")

        # å‘é€åˆå§‹çŠ¶æ€ï¼ˆç®€åŒ–é‡è¯•é€»è¾‘ï¼‰
        if session_manager:
            session = await session_manager.get(session_id)
            if session:
                # âœ… P0ä¿®å¤: è¿æ¥å·²ç¡®è®¤ï¼Œç›´æ¥å‘é€åˆå§‹çŠ¶æ€ï¼ˆæ— éœ€é‡è¯•ï¼‰
                await websocket.send_json(
                    {
                        "type": "initial_status",
                        "status": session.get("status", "pending"),
                        "progress": session.get("progress", 0),
                        "current_node": session.get("current_node"),
                        "detail": session.get("detail"),
                    }
                )
                logger.debug(f"âœ… WebSocket åˆå§‹çŠ¶æ€å·²å‘é€: {session_id}")

        # ä¿æŒè¿æ¥å¹¶æ¥æ”¶å®¢æˆ·ç«¯å¿ƒè·³
        while True:
            try:
                # æ¥æ”¶å®¢æˆ·ç«¯æ¶ˆæ¯ï¼ˆä¸»è¦ç”¨äºå¿ƒè·³æ£€æµ‹ï¼‰
                data = await asyncio.wait_for(websocket.receive_text(), timeout=60.0)

                # å¯é€‰ï¼šå¤„ç†å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
                if data == "ping":
                    # âœ… P0ä¿®å¤: å‘é€pongå‰æ£€æŸ¥è¿æ¥çŠ¶æ€
                    if websocket.client_state.name == "CONNECTED":
                        await websocket.send_json({"type": "pong"})

            except asyncio.TimeoutError:
                # 60ç§’æ— å¿ƒè·³ï¼Œå‘é€ ping æ£€æŸ¥è¿æ¥
                # âœ… P0ä¿®å¤: å‘é€pingå‰æ£€æŸ¥è¿æ¥çŠ¶æ€
                if websocket.client_state.name == "CONNECTED":
                    await websocket.send_json({"type": "ping"})

    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ WebSocket æ–­å¼€: {session_id}")
    except Exception as e:
        # âœ… v7.118: æ”¹è¿›é”™è¯¯å¤„ç†ï¼Œå¿½ç•¥å¸¸è§çš„è¿æ¥å…³é—­é”™è¯¯
        error_str = str(e)
        if any(keyword in error_str for keyword in ["Cannot call", "send", "close message", "not connected"]):
            logger.debug(f"ğŸ”Œ WebSocket è¿æ¥å·²å…³é—­: {session_id} ({type(e).__name__})")
        else:
            logger.error(f"âŒ WebSocket é”™è¯¯: {session_id}, {type(e).__name__}: {e}", exc_info=True)
    finally:
        # ä»è¿æ¥æ± ç§»é™¤
        if session_id in websocket_connections:
            if websocket in websocket_connections[session_id]:
                websocket_connections[session_id].remove(websocket)
            # å¦‚æœæ²¡æœ‰è¿æ¥äº†ï¼Œæ¸…ç†å­—å…¸
            if not websocket_connections[session_id]:
                del websocket_connections[session_id]


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000, reload=False, log_level="info")
