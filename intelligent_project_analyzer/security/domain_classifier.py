"""
é¢†åŸŸåˆ†ç±»å™¨ - åˆ¤æ–­æ˜¯å¦å±äºç©ºé—´è®¾è®¡é¢†åŸŸ
"""

import re
import json
from typing import Dict, Any, List, Optional
from loguru import logger


class DomainClassifier:
    """é¢†åŸŸåˆ†ç±»å™¨ - åˆ¤æ–­è¾“å…¥æ˜¯å¦å±äºç©ºé—´è®¾è®¡é¢†åŸŸ"""
    
    # è®¾è®¡é¢†åŸŸå…³é”®è¯
    DESIGN_KEYWORDS = {
        "ç©ºé—´è®¾è®¡": ["ç©ºé—´", "å®¤å†…", "å»ºç­‘", "æ™¯è§‚", "å±•å…", "åŠå…¬å®¤", "ä½å®…", "å•†ä¸šç©ºé—´", "åº—é“º", "é¤å…", "é…’åº—", "åŒ…æˆ¿"],  # ğŸ†• æ·»åŠ "åŒ…æˆ¿"
        "è®¾è®¡å…ƒç´ ": ["å¸ƒå±€", "åŠ¨çº¿", "æè´¨", "è‰²å½©", "ç…§æ˜", "å®¶å…·", "è£…é¥°", "è½¯è£…", "ç¡¬è£…", "åŠé¡¶", "åœ°é¢"],
        "è®¾è®¡é£æ ¼": ["ç°ä»£", "ç®€çº¦", "å·¥ä¸šé£", "æ–°ä¸­å¼", "åŒ—æ¬§", "è½»å¥¢", "æç®€", "å¤å¤", "æ—¥å¼", "æ¬§å¼"],
        "è®¾è®¡é˜¶æ®µ": ["æ–¹æ¡ˆè®¾è®¡", "æ¦‚å¿µè®¾è®¡", "æ–½å·¥å›¾", "æ•ˆæœå›¾", "æ·±åŒ–è®¾è®¡", "è½¯è£…è®¾è®¡", "å¹³é¢å›¾"],
        "ç©ºé—´ç±»å‹": ["åŠå…¬ç©ºé—´", "é›¶å”®ç©ºé—´", "å±•è§ˆç©ºé—´", "é¤é¥®ç©ºé—´", "é…’åº—ç©ºé—´", "ä¼šæ‰€", "å…¬å…±ç©ºé—´", "å’–å•¡å…", "å’–å•¡é¦†", "å®¢å…"],
        "è®¾è®¡éœ€æ±‚": ["è£…ä¿®", "æ”¹é€ ", "ç¿»æ–°", "è®¾è®¡æ–¹æ¡ˆ", "ç©ºé—´è§„åˆ’", "åŠŸèƒ½åˆ†åŒº", "æ°›å›´è¥é€ ", "è®¾è®¡", "å‘½å", "èµ·å", "å–å"],  # ğŸ†• æ·»åŠ å‘½åç±»
        "æŠ€æœ¯è¦ç´ ": ["ç»“æ„", "æœºç”µ", "æš–é€š", "æ™ºèƒ½åŒ–", "å¯æŒç»­", "BIM", "èŠ‚èƒ½", "ç¯ä¿"],
        "ç”¨æˆ·ä½“éªŒ": ["ç”¨æˆ·ä½“éªŒ", "äº¤äº’", "åŠ¨çº¿è®¾è®¡", "æ°›å›´", "èˆ’é€‚åº¦", "è§†è§‰æ•ˆæœ"],
        "å•†ä¸šè¦ç´ ": ["æˆæœ¬", "é¢„ç®—", "ROI", "æ‹›å•†", "è¿è¥", "å“ç‰Œ", "å®šä½"],
        "å®æ–½è¦ç´ ": ["æ–½å·¥", "å·¥æœŸ", "é‡‡è´­", "éªŒæ”¶", "äº¤ä»˜", "ææ–™", "å·¥è‰º"]
    }
    
    # éè®¾è®¡é¢†åŸŸå…³é”®è¯
    NON_DESIGN_KEYWORDS = {
        "ç¼–ç¨‹å¼€å‘": ["python", "ä»£ç ", "ç¼–ç¨‹", "ç®—æ³•", "æ•°æ®åº“", "api", "å‰ç«¯", "åç«¯", "java", "c++", "çˆ¬è™«", "ç¨‹åº", "å­˜å‚¨"],
        "åŒ»ç–—å¥åº·": ["ç–¾ç—…", "è¯ç‰©", "æ²»ç–—", "åŒ»é™¢", "æ‰‹æœ¯", "ç—…äºº", "åŒ»ç”Ÿ", "è¯Šæ–­"],
        "æ³•å¾‹é‡‘è": ["æ³•å¾‹", "åˆåŒ", "è¯‰è®¼", "è‚¡ç¥¨", "æŠ•èµ„", "è´·æ¬¾", "è¯åˆ¸", "ç†è´¢"],
        "å­¦æœ¯æ•™è‚²": ["è®ºæ–‡", "è€ƒè¯•", "è¯¾ç¨‹", "ä½œä¸š", "æ¯•ä¸š", "å­¦ä½", "æ•™æ"],
        "å¨±ä¹æ¸¸æˆ": ["æ¸¸æˆ", "ç”µå½±", "å°è¯´", "æ¼«ç”»", "åŠ¨ç”»", "å¨±ä¹"],
        "ç”µå•†è´­ç‰©": ["æ·˜å®", "äº¬ä¸œ", "è´­ç‰©", "å¿«é€’", "ç‰©æµ", "ä¸‹å•"],
        "ç¤¾äº¤åª’ä½“": ["å¾®ä¿¡", "æŠ–éŸ³", "å¾®åš", "æœ‹å‹åœˆ", "ç‚¹èµ", "è½¬å‘"]
    }
    
    def __init__(self, llm_model=None):
        """
        åˆå§‹åŒ–é¢†åŸŸåˆ†ç±»å™¨
        
        Args:
            llm_model: LLMæ¨¡å‹å®ä¾‹ï¼ˆç”¨äºè¾…åŠ©åˆ¤æ–­ï¼‰
        """
        self.llm_model = llm_model
    
    def classify(self, user_input: str) -> Dict[str, Any]:
        """
        åˆ†ç±»ç”¨æˆ·è¾“å…¥
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            
        Returns:
            {
                "is_design_related": bool | "unclear",
                "confidence": float,  # 0-1
                "matched_categories": List[str],
                "rejection_reason": str,  # å¦‚æœæ‹’ç»
                "clarification_needed": bool,
                "suggested_questions": List[str]
            }
        """
        normalized_input = user_input.lower()

        # 1. å…³é”®è¯åŒ¹é…
        design_stats = self._analyze_keywords(normalized_input, self.DESIGN_KEYWORDS)
        non_design_stats = self._analyze_keywords(normalized_input, self.NON_DESIGN_KEYWORDS)

        design_strength = design_stats["strength"]
        non_design_strength = non_design_stats["strength"]

        logger.info(
            "ğŸ“Š å…³é”®è¯å‘½ä¸­: è®¾è®¡=%s (hits=%s, categories=%s), éè®¾è®¡=%s (hits=%s, categories=%s)",
            design_strength,
            design_stats["hits"],
            design_stats["categories"],
            non_design_strength,
            non_design_stats["hits"],
            non_design_stats["categories"]
        )
        
        # 2. LLMè¾…åŠ©åˆ¤æ–­
        llm_result = {"is_design": True, "confidence": 0.5, "categories": []}
        if self.llm_model:
            try:
                llm_result = self._llm_classify(user_input)
                logger.info(f"ğŸ¤– LLMåˆ¤æ–­: is_design={llm_result['is_design']}, confidence={llm_result.get('confidence', 0):.2f}")
            except Exception as e:
                logger.warning(f"âš ï¸ LLMåˆ†ç±»å¤±è´¥: {e}")
        
        def _design_response(confidence: Optional[float] = None) -> Dict[str, Any]:
            final_conf = confidence if confidence is not None else self._compute_confidence(design_stats)
            matched_categories = list({*design_stats["categories"], *llm_result.get("categories", [])})
            return {
                "is_design_related": True,
                "confidence": round(final_conf, 2),
                "matched_categories": matched_categories
            }

        def _non_design_response(confidence: Optional[float] = None, reason: str = "è¾“å…¥å†…å®¹ä¸å±äºç©ºé—´è®¾è®¡é¢†åŸŸ") -> Dict[str, Any]:
            final_conf = confidence if confidence is not None else self._compute_confidence(non_design_stats)
            return {
                "is_design_related": False,
                "confidence": round(final_conf, 2),
                "rejection_reason": reason,
                "matched_categories": non_design_stats["categories"],
                "detected_domain": non_design_stats["categories"][0] if non_design_stats["categories"] else "æœªçŸ¥é¢†åŸŸ"
            }

        # 3. ç»¼åˆå†³ç­–
        # ğŸ†• è§„åˆ™0: ä¼˜å…ˆæ£€æŸ¥å‘½åä»»åŠ¡ï¼ˆä¸ä¾èµ–LLMç½®ä¿¡åº¦ï¼‰
        # âš ï¸ å‘½åç±»ä»»åŠ¡è§†ä¸ºè®¾è®¡ç›¸å…³ï¼ˆç©ºé—´å‘½åã€å“ç‰Œå‘½åç­‰ï¼‰
        is_naming_task = any(kw in normalized_input for kw in ["å‘½å", "èµ·å", "å–å", "åå­—", "å«ä»€ä¹ˆ"])

        if is_naming_task and design_strength >= 1:
            logger.info("ğŸ·ï¸ æ£€æµ‹åˆ°å‘½åä»»åŠ¡+è®¾è®¡å…³é”®è¯ï¼Œæ”¾è¡Œå¤„ç†")
            return _design_response(confidence=0.75)

        # è§„åˆ™1: LLMæ˜ç¡®åˆ¤æ–­ä¸ºéè®¾è®¡ç±»ï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰
        if not llm_result.get("is_design", True) and llm_result.get("confidence", 0) > 0.8:
            return _non_design_response(
                confidence=llm_result.get("confidence", 0.9),
                reason="LLMåˆ¤æ–­è¯¥å†…å®¹ä¸å±äºç©ºé—´è®¾è®¡é¢†åŸŸ"
            )

        # è§„åˆ™2: éè®¾è®¡ç‰¹å¾æ˜æ˜¾
        if non_design_strength >= 3 and design_strength == 0:
            return _non_design_response()
        if (
            non_design_strength >= 2
            and non_design_strength - design_strength >= 2
        ) or (
            non_design_strength >= 2
            and design_strength <= 2
            and len(design_stats["keywords"]) <= 1
        ):
            return _non_design_response()
        
        # è§„åˆ™3: è®¾è®¡ç‰¹å¾æ˜æ˜¾
        if design_strength >= 3 and llm_result.get("is_design", True):
            confidence = max(
                self._compute_confidence(design_stats),
                llm_result.get("confidence", 0.0)
            )
            return _design_response(confidence)

        # è§„åˆ™4: LLMé«˜ç½®ä¿¡åº¦åˆ¤æ–­ä¸ºè®¾è®¡ç±»ï¼ˆå³ä½¿å…³é”®è¯å¾—åˆ†ä½ï¼‰
        # ä¿®å¤ï¼šç¡®ä¿ confidence æ˜¯æµ®ç‚¹æ•°æ¯”è¾ƒ
        llm_confidence = float(llm_result.get("confidence", 0))
        if llm_result.get("is_design", True) and llm_confidence > 0.8:
            return _design_response(llm_confidence)

        # è§„åˆ™5: è®¾è®¡ç‰¹å¾è¾ƒå¼±ä½†å…³é”®è¯æœ‰ä¸€å®šæ”¯æŒ
        if design_strength >= 2 and llm_result.get("is_design", True):
            return _design_response()

        # è§„åˆ™6: è¾¹ç•Œæƒ…å†µï¼Œéœ€è¦æ¾„æ¸…
        return {
            "is_design_related": "unclear",
            "confidence": 0.5,
            "clarification_needed": True,
            "suggested_questions": [
                "æ‚¨æ˜¯å¦éœ€è¦è¿›è¡Œç©ºé—´è®¾è®¡æ–¹é¢çš„åˆ†æï¼Ÿ",
                "è¿™ä¸ªé¡¹ç›®æ˜¯å¦æ¶‰åŠå»ºç­‘ã€å®¤å†…æˆ–æ™¯è§‚è®¾è®¡ï¼Ÿ",
                "æ‚¨å¸Œæœ›æˆ‘å¸®æ‚¨è®¾è®¡ä»€ä¹ˆç±»å‹çš„ç©ºé—´ï¼Ÿï¼ˆå¦‚åŠå…¬å®¤ã€å±•å…ã€åº—é“ºç­‰ï¼‰"
            ]
        }
    
    def _analyze_keywords(self, text: str, keyword_dict: Dict[str, List[str]]) -> Dict[str, Any]:
        """åˆ†æå…³é”®è¯å‘½ä¸­æƒ…å†µï¼Œè¿”å›å‘½ä¸­ç»Ÿè®¡æ•°æ®"""
        categories = []
        matched_keywords = set()
        total_hits = 0

        for category, keywords in keyword_dict.items():
            hits = []
            for kw in keywords:
                kw_lower = kw.lower()
                if kw_lower and kw_lower in text:
                    hits.append(kw)

            if hits:
                categories.append(category)
                matched_keywords.update(hits)
                total_hits += len(hits)

        strength = total_hits + len(categories)

        return {
            "hits": total_hits,
            "categories": categories,
            "keywords": list(matched_keywords),
            "strength": strength
        }

    def _compute_confidence(self, stats: Dict[str, Any], base: float = 0.55) -> float:
        """æ ¹æ®å‘½ä¸­æƒ…å†µè®¡ç®—ç½®ä¿¡åº¦"""
        if stats["hits"] == 0 and not stats["categories"]:
            return 0.5

        confidence = base
        confidence += 0.1 * min(stats["hits"], 3)
        confidence += 0.05 * min(len(stats["categories"]), 4)

        return min(1.0, confidence)
    
    def _llm_classify(self, user_input: str) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œé¢†åŸŸåˆ†ç±»"""
        if not self.llm_model:
            return {"is_design": True, "confidence": 0.5, "categories": []}
        
        try:
            from langchain_core.messages import HumanMessage
            
            prompt = f"""ä½ æ˜¯ç©ºé—´è®¾è®¡é¢†åŸŸåˆ†ç±»ä¸“å®¶ã€‚åˆ¤æ–­ä»¥ä¸‹ç”¨æˆ·è¾“å…¥æ˜¯å¦å±äºç©ºé—´è®¾è®¡é¢†åŸŸã€‚

ç©ºé—´è®¾è®¡é¢†åŸŸåŒ…æ‹¬ï¼š
âœ… å»ºç­‘è®¾è®¡ã€å®¤å†…è®¾è®¡ã€æ™¯è§‚è®¾è®¡
âœ… åŠå…¬ç©ºé—´ã€é›¶å”®ç©ºé—´ã€å±•å…ç©ºé—´ã€é¤é¥®ç©ºé—´ã€ä½å®…ç©ºé—´
âœ… ç©ºé—´è§„åˆ’ã€åŠ¨çº¿è®¾è®¡ã€è£…ä¿®æ–¹æ¡ˆ
âœ… ææ–™é€‰æ‹©ã€è‰²å½©æ­é…ã€ç…§æ˜è®¾è®¡
âœ… å®¶å…·å¸ƒç½®ã€è½¯è£…è®¾è®¡

ä¸å±äºè®¾è®¡é¢†åŸŸï¼š
âŒ ç¼–ç¨‹å¼€å‘ã€åŒ»ç–—å¥åº·ã€æ³•å¾‹é‡‘è
âŒ ç½‘ç«™è®¾è®¡ã€APPè®¾è®¡ï¼ˆé™¤éæ˜¯å±•å…çš„æ•°å­—ç•Œé¢ï¼‰
âŒ å¹³é¢è®¾è®¡ã€UIè®¾è®¡ï¼ˆé™¤éä¸ç©ºé—´è®¾è®¡ç»“åˆï¼‰

ç”¨æˆ·è¾“å…¥ï¼š
{user_input}

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{{
    "is_design": true/false,
    "confidence": 0.0-1.0,
    "categories": ["åŠå…¬ç©ºé—´", "é›¶å”®ç©ºé—´"ç­‰],
    "reasoning": "åˆ¤æ–­ç†ç”±ï¼ˆ50å­—å†…ï¼‰"
}}

æ³¨æ„è¾¹ç•Œæƒ…å†µï¼š
- "è®¾è®¡ç½‘ç«™" â†’ falseï¼ˆçº¯æ•°å­—äº§å“ï¼‰
- "è®¾è®¡å±•å…çš„äº¤äº’ç•Œé¢" â†’ trueï¼ˆä¸ç©ºé—´è®¾è®¡ç»“åˆï¼‰
- "åŠå…¬å®¤è£…ä¿®" â†’ trueï¼ˆç©ºé—´è®¾è®¡ï¼‰
- "å†™ä»£ç " â†’ falseï¼ˆç¼–ç¨‹ï¼‰"""

            messages = [HumanMessage(content=prompt)]
            response = self.llm_model.invoke(messages)
            
            # è§£æå“åº”
            content = response.content if hasattr(response, 'content') else str(response)
            
            # æå–JSON
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result
            
            # è§£æå¤±è´¥ï¼Œè¿”å›ä¿å®ˆç»“æœ
            return {"is_design": True, "confidence": 0.5, "categories": []}
            
        except Exception as e:
            logger.error(f"âŒ LLMåˆ†ç±»å¼‚å¸¸: {e}")
            return {"is_design": True, "confidence": 0.5, "categories": []}

    def _check_task_type_override(self, user_input: str) -> Optional[Dict[str, Any]]:
        """
        P0.2ä¼˜åŒ–: ä»»åŠ¡ç±»å‹ä¼˜å…ˆçº§åˆ¤æ–­ï¼ˆè¦†ç›–è§„åˆ™ï¼‰

        æŸäº›ä»»åŠ¡ç±»å‹æ— è®ºæè¿°å¤šè¯¦ç»†ï¼Œå¤æ‚åº¦éƒ½æ˜¯å›ºå®šçš„ï¼š
        - å‘½åç±» â†’ simple
        - æ¨èç±» â†’ simple/medium

        è§£å†³é—®é¢˜ï¼š#22/#23 å‘½åä»»åŠ¡å› å«"æ–‡åŒ–"è¢«è¯¯åˆ¤ä¸ºcomplex
        """
        text = user_input.lower()

        # ä¼˜å…ˆçº§1: å‘½åç±»ï¼ˆä¸€ç¥¨å¦å†³complexï¼‰
        naming_patterns = [
            r"[å‘½åèµ·åå–å].*\d+[ä¸ªé—´æ¡]",  # å‘½å8é—´æˆ¿
            r"\d+[ä¸ªé—´æ¡].*[å‘½åèµ·åå–å]",  # 8é—´æˆ¿å‘½åï¼ˆé¡ºåºç›¸åï¼‰
            r"\d+ä¸ª.*[åå­—å‘½å]",
            r"é—¨ç‰Œ.*\d+ä¸ªå­—"
        ]
        if any(re.search(p, text) for p in naming_patterns):
            # å³ä½¿å«"æ–‡åŒ–"ã€"è‹ä¸œå¡"ä¹Ÿåˆ¤simple
            logger.info("ğŸ¯ ä»»åŠ¡ç±»å‹è¦†ç›–: æ£€æµ‹åˆ°å‘½åç±»ä»»åŠ¡ï¼Œå¼ºåˆ¶åˆ¤å®šä¸ºsimple")
            return {
                "complexity": "simple",
                "confidence": 0.9,
                "reasoning": "å‘½åç±»ä»»åŠ¡ï¼ˆä»»åŠ¡ç±»å‹ä¼˜å…ˆçº§è¦†ç›–ï¼‰",
                "suggested_workflow": "quick_response",
                "suggested_experts": ["V3_å™äº‹ä¸ä½“éªŒä¸“å®¶_3-2", "V4_è®¾è®¡ç ”ç©¶å‘˜_4-1"],
                "estimated_duration": "2-5åˆ†é’Ÿ"
            }

        # ä¼˜å…ˆçº§2: çº¯æ¨èç±»/åˆ—ä¸¾ç±»
        # åŒ¹é…: "éœ€è¦10ä¸ªæ¦‚å¿µä¸»é¢˜", "ç»™å‡º10ä¸ªè®¾è®¡æ¦‚å¿µ", "æ¨è5ä¸ªé£æ ¼æ–¹æ¡ˆ"ç­‰
        recommend_patterns = [
            r"æ¨è.*\d+ä¸ª[ä¸»é¢˜æ¦‚å¿µé£æ ¼æ–¹æ¡ˆ]",  # æ¨è10ä¸ªä¸»é¢˜
            r"ç»™å‡º.*\d+ä¸ª[ä¸»é¢˜æ¦‚å¿µé£æ ¼æ–¹æ¡ˆ]",  # ç»™å‡º10ä¸ªæ¦‚å¿µ
            r"éœ€è¦\d+ä¸ª.*[ä¸»é¢˜æ¦‚å¿µé£æ ¼æ–¹æ¡ˆ]",  # éœ€è¦10ä¸ªæ¦‚å¿µä¸»é¢˜
            r"\d+ä¸ª.*[ä¸»é¢˜æ¦‚å¿µ].*[ä¸»é¢˜æ¦‚å¿µ]",  # 10ä¸ªè®¾è®¡æ¦‚å¿µä¸»é¢˜ï¼ˆä¸­é—´å¯ä»¥æœ‰ä¿®é¥°è¯ï¼‰
            r"\d+ä¸ª[ä¸»é¢˜æ¦‚å¿µé£æ ¼æ–¹æ¡ˆ]"  #10ä¸ªä¸»é¢˜ï¼ˆç´§å‡‘ç‰ˆï¼‰
        ]
        if any(re.search(p, text) for p in recommend_patterns):
            logger.info("ğŸ¯ ä»»åŠ¡ç±»å‹è¦†ç›–: æ£€æµ‹åˆ°æ¨èç±»ä»»åŠ¡ï¼Œå¼ºåˆ¶åˆ¤å®šä¸ºsimple")
            return {
                "complexity": "simple",
                "confidence": 0.85,
                "reasoning": "æ¨èç±»ä»»åŠ¡",
                "suggested_workflow": "quick_response",
                "suggested_experts": ["V4_è®¾è®¡ç ”ç©¶å‘˜_4-1"],
                "estimated_duration": "2-5åˆ†é’Ÿ"
            }

        return None  # æ— è¦†ç›–ï¼Œç»§ç»­æ­£å¸¸æµç¨‹

    def assess_task_complexity(self, user_input: str) -> Dict[str, Any]:
        """
        è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦ï¼Œå†³å®šä½¿ç”¨ç®€å•æµç¨‹è¿˜æ˜¯å®Œæ•´æµç¨‹

        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬

        Returns:
            {
                "complexity": "simple" | "medium" | "complex",
                "confidence": float,
                "reasoning": str,
                "suggested_workflow": str,
                "suggested_experts": List[str],  # ğŸ†• æ¨èçš„ä¸“å®¶ç»„åˆ
                "estimated_duration": str  # é¢„ä¼°æ—¶é•¿
            }
        """
        # ========== P0.2ä¼˜åŒ–: ä»»åŠ¡ç±»å‹ä¼˜å…ˆçº§è¦†ç›– ==========
        override_result = self._check_task_type_override(user_input)
        if override_result:
            return override_result

        text = user_input.lower()
        input_length = len(user_input)

        # ==================== ç®€å•ä»»åŠ¡ç‰¹å¾ ====================
        simple_patterns = {
            "å‘½åç±»": [r"å‘½å", r"èµ·å", r"å–å", r"å«ä»€ä¹ˆ", r"åå­—"],
            "æ¨èç±»": [r"æ¨è", r"å»ºè®®", r"ç»™æˆ‘", r"åˆ—ä¸¾", r"æä¾›"],
            "æ•°é‡é™å®š": [r"\d+[ä¸ªæ¡ç§å¼ ä»½]", r"[å‡ ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ä¸ªæ¡ç§]"],
            "å•ä¸€å…ƒç´ ": [r"é¢œè‰²", r"è‰²å½©", r"æè´¨", r"å­—ä½“", r"é£æ ¼è¯", r"å…³é”®è¯"],
            "å¿«é€Ÿå’¨è¯¢": [r"ä»€ä¹ˆæ˜¯", r"å¦‚ä½•ç†è§£", r"è®²è®²", r"è§£é‡Š"],
        }

        # ==================== ä¸­ç­‰ä»»åŠ¡ç‰¹å¾ ====================
        # æ³¨æ„ï¼šé¢ç§¯å¤§å°ä¸åº”å½±å“å¤æ‚åº¦ï¼Œå¤æ‚åº¦ç”±éœ€æ±‚ç»´åº¦å†³å®š
        medium_patterns = {
            "å•ä¸€ç©ºé—´": [r"[ä¸€]ä¸ªç©ºé—´", r"[ä¸€]ä¸ªæˆ¿é—´", r"[ä¸€]ä¸ªåŒºåŸŸ"],
            "åŠŸèƒ½æ˜ç¡®": [r"æ¥å¾…åŒº", r"ä¼šè®®å®¤", r"èŒ¶å®¤", r"ä¹¦æˆ¿", r"å§å®¤"],
            "æ°›å›´è¥é€ ": [r"æ°›å›´", r"æ„Ÿè§‰", r"è°ƒæ€§", r"æ°”è´¨"],
            "æ”¹é€ ä¼˜åŒ–": [r"æ”¹é€ ", r"ä¼˜åŒ–", r"æå‡", r"ç¿»æ–°"],
        }

        # ==================== å¤æ‚é¡¹ç›®ç‰¹å¾ ====================
        # æ³¨æ„ï¼šå¤æ‚åº¦ç”±æŠ€æœ¯éš¾åº¦ã€å¤šç³»ç»Ÿã€å¤šç©ºé—´ã€å¤šç»´åº¦å†³å®šï¼Œè€Œéé¢„ç®—é«˜ä½
        # é¢„ç®—é«˜åªè¡¨ç¤ºæŠ•èµ„è§„æ¨¡ï¼Œä¸ä»£è¡¨æŠ€æœ¯å¤æ‚
        complex_patterns = {
            # ========== ä¿ç•™ç°æœ‰æ¨¡å¼ ==========
            "å¤šç©ºé—´åè°ƒ": [r"[2-9]ä¸ª[ç©ºé—´æˆ¿é—´åŒ…æˆ¿]", r"å¤šä¸ª[ç©ºé—´åŒºåŸŸ]", r"æ‰€æœ‰[æˆ¿é—´ç©ºé—´]", r"æ•´ä½“[è®¾è®¡è§„åˆ’]", r"å¤šç©ºé—´è”åŠ¨"],
            "å¤šç³»ç»Ÿé›†æˆ": [r"æ™ºèƒ½åŒ–", r"ä¸­å¤®ç©ºè°ƒ", r"æ¶ˆé˜²", r"å¼±ç”µ", r"æœºç”µ", r"æš–é€š", r"BIM", r"ç³»ç»Ÿé›†æˆ"],
            "å¤æ‚æŠ€æœ¯": [r"ç»“æ„åŠ å›º", r"æ‰¿é‡", r"ç³»ç»Ÿé›†æˆ", r"è”åŠ¨", r"å£°å­¦è®¾è®¡", r"ç‰¹æ®Šå·¥è‰º"],
            "æ ‡å‡†åŒ–å¤åˆ¶": [r"è¿é”", r"æ ‡å‡†åŒ–", r"å¤åˆ¶", r"\d{2,}å®¶åº—", r"è½åœ°æ‰‹å†Œ", r"å“ç‰Œè¿é”"],
            "å¤šå®¢ç¾¤æœåŠ¡": [r"å¤šç§?å®¢ç¾¤", r"ä¸åŒäººç¾¤", r"å¤šå…ƒç”¨æˆ·", r"å¤šç±»å‹ç”¨æˆ·", r"å¤åˆä¸šæ€"],
            "æ–‡åŒ–ç»´åº¦": [r"æ–‡åŒ–", r"å†å²", r"ä¼ ç»Ÿ", r"æ ‡æ†", r"ç¤ºèŒƒ", r"åŸå¸‚æ›´æ–°", r"æ–‡åŒ–ä¼ æ‰¿"],
            "è·¨é¢†åŸŸåä½œ": [r"è·¨ç•Œ", r"èåˆ", r"ç»¼åˆ", r"ä¸€ä½“åŒ–", r"å…¨äº§ä¸šé“¾"],

            # ========== ğŸ†• P0.1ä¼˜åŒ–: æ–°å¢7ä¸ªç»´åº¦ ==========

            # 1. å¤§é¢ç§¯é¡¹ç›®ï¼ˆè§£å†³#7/#15/#16è¯¯åˆ¤ï¼‰
            "å¤§å‹é¡¹ç›®é¢ç§¯": [
                r"\d{4,}[å¹³æ–¹ã¡]",  # 1000+å¹³ç±³
                r"\d+ä¸‡[å¹³æ–¹]?ç±³",
                r"[2-9]\d{3}[å¹³æ–¹ã¡ç±³]",  # 2000+
            ],

            # 2. å¤šåŠŸèƒ½å¤åˆï¼ˆè§£å†³#15/#56è¯¯åˆ¤ï¼‰
            "å¤šåŠŸèƒ½å¤åˆ": [
                r"å¤åˆ[ç©ºé—´ä¸šæ€åŠŸèƒ½]",
                r"[ä¸€]ä½“åŒ–",
                r"ç»¼åˆ[ä½“ä¸šæ€åŠŸèƒ½]",
                r"å…¼é¡¾.*å…¼é¡¾",  # å¤šä¸ª"å…¼é¡¾"
                r"å¤šåŠŸèƒ½",
            ],

            # 3. ç«æ ‡/å¯¹æ ‡ï¼ˆè§£å†³#24/#16è¯¯åˆ¤ï¼‰
            "å•†ä¸šç«äº‰": [
                r"ç«æ ‡", r"æŠ•æ ‡", r"å¯¹æ ‡", r"å¯¹æ‰‹", r"ç«äº‰",
                r"PK", r"å·®å¼‚åŒ–.*ç«äº‰", r"å¸‚åœº.*æ ‡æ†"
            ],

            # 4. ç‰¹æ®Šå·¥è‰ºæŠ€æœ¯ï¼ˆè§£å†³#45/#84/#85è¯¯åˆ¤ï¼‰
            "ç‰¹æ®ŠæŠ€æœ¯å·¥è‰º": [
                r"å£°å­¦.*[ç³»ç»Ÿè®¾è®¡]", r"éš”éŸ³", r"ç»å¯¹éš”éŸ³", r"dB", r"æœæ¯”", r"å…¨æ™¯å£°",
                r"ä¾›æ°§.*ç³»ç»Ÿ", r"å¼¥æ•£.*ä¾›æ°§", r"åŒ»ç–—çº§",
                r"é˜²è….*å·¥è‰º", r"æŠ—é£.*æ„é€ ", r"æŠ—éœ‡.*åŠ å›º",
                r"å°é£.*å­£", r"ç›é›¾.*è…èš€", r"ç™½èš.*å¨èƒ",
                r"æç«¯.*ç¯å¢ƒ", r"æµ·æ‹”.*\d{4}"  # é«˜æµ·æ‹”
            ],

            # 5. ç‰¹æ®Šç”¨æˆ·éœ€æ±‚ï¼ˆè§£å†³#6/#30/#49è¯¯åˆ¤ï¼‰
            "ç‰¹æ®Šç”¨æˆ·ç¾¤ä½“": [
                r"è‡ªé—­ç—‡", r"è¿‡æ•.*ç—‡", r"å¤±çœ ", r"ç„¦è™‘",
                r"è½®æ¤…", r"æ— éšœç¢", r"æ®‹ç–¾", r"ä¸´ç»ˆ.*ç—…æˆ¿",
                r"å©šå§».*å±æœº", r"å¤åˆ.*å¤«å¦»", r"å†å©š.*å®¶åº­",
                r"[3-9]ä»£.*åŒå ‚", r"ä»£é™….*[å…³ç³»äº¤æµ]"
            ],

            # 6. é£æ ¼å†²çª/èåˆï¼ˆè§£å†³#28/#29è¯¯åˆ¤ï¼‰
            # é‡è¦ï¼šéœ€è¦æ˜ç¡®çš„èåˆ/å†²çªå…³é”®è¯ï¼Œé¿å…è¯¯åˆ¤ç®€å•çš„"æ¶µç›–å¤šç§é£æ ¼"ä»»åŠ¡
            "é£æ ¼å†²çªèåˆ": [
                r"[ä¸­è¥¿æ–°æ—§ä¼ ç»Ÿç°ä»£å¤å…¸å½“ä»£].*[èåˆç»“åˆ].*[ä¸­è¥¿æ–°æ—§ä¼ ç»Ÿç°ä»£å¤å…¸å½“ä»£]",  # æ˜ç¡®è¦æ±‚èåˆ
                r"èåˆ.*[é£æ ¼æ–‡åŒ–]",  # æ˜ç¡®èåˆ
                r"æ–°æ—§.*[å¯¹æ’ç¢°æ’]",  # æ˜ç¡®å¯¹æ’
                r"[å¯¹æ’ç¢°æ’].*[é£æ ¼]",
                r"å››åˆé™¢.*[Ll]oft",  # å…·ä½“çš„å†²çªæ¡ˆä¾‹
                r"çº½çº¦.*[Ll]oft.*[ä¸­å¼ä¼ ç»Ÿå››åˆé™¢]",  # Loft+ä¸­å¼
                r"ç¦…æ„.*æ´¾å¯¹"  # å…·ä½“çš„å†²çªæ¡ˆä¾‹
            ],

            # 7. é¢„ç®—/æ—¶é—´çº¦æŸï¼ˆè§£å†³#76/#77/#83è¯¯åˆ¤ï¼‰
            "ä¸¥æ ¼çº¦æŸæ¡ä»¶": [
                r"é¢„ç®—.*[æœ‰é™ç´§å¼ æä½]",
                r"æˆæœ¬.*é™åˆ¶", r"ä½[æˆæœ¬é¢„ç®—].*é«˜[è¦æ±‚å“è´¨]",
                r"3000å…ƒ[\/æ¯]å¹³ç±³", r"\d+ä¸‡.*å…¨åŒ…",  # ä½é¢„ç®—æ ‡å‡†
                r"å·¥æœŸ.*\d+[å¤©å°æ—¶]", r"å¤œé—´.*æ–½å·¥",
                r"ä¸é—­åº—.*è£…ä¿®", r"å¿«é€Ÿ.*[æ–½å·¥æ­å»º]"
            ]
        }

        # è®¡ç®—å„ç»´åº¦å¾—åˆ†
        simple_score = 0
        simple_matches = []
        for category, patterns in simple_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text):
                    simple_score += 1
                    simple_matches.append(category)
                    break  # æ¯ä¸ªç±»åˆ«åªè®¡ä¸€æ¬¡

        medium_score = 0
        medium_matches = []
        for category, patterns in medium_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text):
                    medium_score += 1
                    medium_matches.append(category)
                    break

        complex_score = 0
        complex_matches = []
        for category, patterns in complex_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text):
                    complex_score += 1
                    complex_matches.append(category)
                    break

        logger.info(f"ğŸ“Š å¤æ‚åº¦å¾—åˆ†: ç®€å•={simple_score}, ä¸­ç­‰={medium_score}, å¤æ‚={complex_score}")
        logger.info(f"   ç®€å•ç‰¹å¾: {simple_matches}")
        logger.info(f"   ä¸­ç­‰ç‰¹å¾: {medium_matches}")
        logger.info(f"   å¤æ‚ç‰¹å¾: {complex_matches}")

        # ==================== å†³ç­–é€»è¾‘ ====================

        # ä¼˜å…ˆçº§1: å¤æ‚é¡¹ç›®çš„å¼ºç‰¹å¾ï¼ˆä¸€ç¥¨å¦å†³ï¼‰
        if complex_score >= 2:
            return {
                "complexity": "complex",
                "confidence": 0.9,
                "reasoning": f"æ£€æµ‹åˆ°å¤æ‚é¡¹ç›®ç‰¹å¾: {', '.join(complex_matches)}",
                "suggested_workflow": "full_analysis",
                "suggested_experts": ["all"],  # å®Œæ•´æµç¨‹
                "estimated_duration": "15-30åˆ†é’Ÿ"
            }

        # ä¼˜å…ˆçº§2: ç®€å•ä»»åŠ¡çš„æ˜ç¡®ç‰¹å¾
        # é‡è¦ï¼šç§»é™¤å­—æ•°é™åˆ¶ï¼ŒåªåŸºäºå†…å®¹ç‰¹å¾åˆ¤æ–­
        if simple_score >= 2 and complex_score == 0 and medium_score <= 1:
            # æ™ºèƒ½æ¨èä¸“å®¶ç»„åˆ
            experts = self._recommend_experts_for_simple_task(user_input)
            return {
                "complexity": "simple",
                "confidence": 0.85,
                "reasoning": f"æ£€æµ‹åˆ°ç®€å•ä»»åŠ¡ç‰¹å¾: {', '.join(set(simple_matches))}",
                "suggested_workflow": "quick_response",
                "suggested_experts": experts,
                "estimated_duration": "2-5åˆ†é’Ÿ"
            }

        # ä¼˜å…ˆçº§3: ä¸­ç­‰å¤æ‚åº¦
        if (medium_score >= 2 or (medium_score >= 1 and simple_score >= 1)) and complex_score <= 1:
            experts = self._recommend_experts_for_medium_task(user_input, medium_matches)
            return {
                "complexity": "medium",
                "confidence": 0.75,
                "reasoning": f"æ£€æµ‹åˆ°ä¸­ç­‰ä»»åŠ¡ç‰¹å¾: {', '.join(set(medium_matches))}",
                "suggested_workflow": "standard",
                "suggested_experts": experts,
                "estimated_duration": "6-12åˆ†é’Ÿ"
            }

        # ========== P0.3+P0.4ä¼˜åŒ–: å®Œå…¨ç§»é™¤å­—æ•°åˆ¤å®šé€»è¾‘ ==========
        # ä¼˜å…ˆçº§4: è¾¹ç•Œæƒ…å†µ - æœ‰å¤æ‚ç‰¹å¾
        # é‡è¦åŸåˆ™ï¼šå¤æ‚åº¦ä¸æè¿°é•¿çŸ­æ— å…³ï¼Œåªä¸å†…å®¹æœ‰å…³
        if complex_score >= 1:
            return {
                "complexity": "complex",
                "confidence": 0.8,  # å›ºå®šç½®ä¿¡åº¦ï¼Œä¸å—å­—æ•°å½±å“
                "reasoning": f"åŒ…å«å¤æ‚ç‰¹å¾: {', '.join(complex_matches)}",
                "suggested_workflow": "full_analysis",
                "suggested_experts": ["all"],
                "estimated_duration": "10-20åˆ†é’Ÿ"
            }

        # é»˜è®¤ï¼šä¸­ç­‰å¤æ‚åº¦ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        return {
            "complexity": "medium",
            "confidence": 0.7,  # P0.4: ä»0.6æé«˜åˆ°0.7ï¼Œå‡å°‘ä¸å¿…è¦çš„äºŒæ¬¡éªŒè¯
            "reasoning": "æ— æ³•æ˜ç¡®åˆ¤æ–­ï¼Œä½¿ç”¨æ ‡å‡†æµç¨‹ç¡®ä¿è´¨é‡",
            "suggested_workflow": "standard",
            "suggested_experts": ["v2", "v4", "v5"],  # åŸºç¡€é…ç½®
            "estimated_duration": "8-15åˆ†é’Ÿ"
        }

    def _recommend_experts_for_simple_task(self, user_input: str) -> List[str]:
        """
        ä¸ºç®€å•ä»»åŠ¡æ¨èä¸“å®¶ç»„åˆ

        ğŸ”¥ é‡è¦ï¼šè¿”å›å®Œæ•´çš„è§’è‰²IDï¼ˆå¦‚ "V3_å™äº‹ä¸ä½“éªŒä¸“å®¶_3-2"ï¼‰ï¼Œè€Œä¸æ˜¯ç®€åŒ–IDï¼ˆå¦‚ "v3"ï¼‰
        è¿™æ ·å¯ä»¥ç¡®ä¿ä¸å®Œæ•´æµç¨‹ï¼ˆProjectDirectorï¼‰é€‰æ‹©ç›¸åŒçš„å­è§’è‰²ï¼Œä¿æŒé€»è¾‘ä¸€è‡´æ€§

        å‚è€ƒ ProjectDirector çš„"è½»é‡çº§ä»»åŠ¡"é…ç½®ï¼š
        - å‘½å/ä¸»é¢˜ç­–åˆ’/æ¦‚å¿µæç‚¼ â†’ V3_å“ç‰Œå™äº‹ä¸“å®¶(3-2) + V4_è®¾è®¡ç ”ç©¶å‘˜(4-1)
        """
        text = user_input.lower()
        experts = []

        # å‘½åã€æ–‡åŒ–ã€è¯—è¯ç›¸å…³ â†’ V3_å“ç‰Œå™äº‹ä¸“å®¶(3-2) + V4_è®¾è®¡ç ”ç©¶å‘˜(4-1)
        # å¯¹åº”å®Œæ•´æµç¨‹ä¸­ ProjectDirector çš„"è½»é‡çº§ä»»åŠ¡"é…ç½®
        if any(kw in text for kw in ["å‘½å", "èµ·å", "å–å", "è¯—è¯", "è¯—æ„", "æ–‡åŒ–", "ä¼ ç»Ÿ", "ç¦…æ„", "æ„å¢ƒ"]):
            experts.extend([
                "V3_å™äº‹ä¸ä½“éªŒä¸“å®¶_3-2",  # å“ç‰Œå™äº‹ä¸“å®¶ï¼ˆæ“…é•¿å‘½åã€å“ç‰Œæ•…äº‹ï¼‰
                "V4_è®¾è®¡ç ”ç©¶å‘˜_4-1"        # è®¾è®¡ç ”ç©¶å‘˜ï¼ˆæ“…é•¿æ¡ˆä¾‹å¯¹æ ‡ï¼‰
            ])

        # é¢œè‰²ã€æè´¨ â†’ æš‚æ—¶ä¿ç•™ç®€åŒ–IDï¼ˆéœ€è¦ç¡®è®¤V8é…ç½®åå†æ›´æ–°ï¼‰
        elif any(kw in text for kw in ["é¢œè‰²", "è‰²å½©", "æè´¨", "ææ–™", "æœ¨æ", "çŸ³æ", "å¸ƒæ–™"]):
            experts.append("v8")
            # å¦‚æœæåˆ°æ–‡åŒ–é£æ ¼ï¼ŒåŠ ä¸ŠV4
            if any(kw in text for kw in ["ä¸­å¼", "æ—¥å¼", "ç¦…", "èŒ¶å®¤"]):
                experts.append("V4_è®¾è®¡ç ”ç©¶å‘˜_4-1")

        # é£æ ¼è§£é‡Š â†’ V4
        elif any(kw in text for kw in ["ä»€ä¹ˆæ˜¯", "é£æ ¼", "ç‰¹ç‚¹", "å…ƒç´ "]):
            experts.append("V4_è®¾è®¡ç ”ç©¶å‘˜_4-1")

        # å…³é”®è¯ã€ä¸»é¢˜è¯ â†’ V3_å“ç‰Œå™äº‹ä¸“å®¶
        elif any(kw in text for kw in ["å…³é”®è¯", "ä¸»é¢˜è¯", "æè¿°è¯"]):
            experts.append("V3_å™äº‹ä¸ä½“éªŒä¸“å®¶_3-2")

        # é»˜è®¤ç»„åˆï¼šå“ç‰Œå™äº‹ + è®¾è®¡ç ”ç©¶ï¼ˆä¸ ProjectDirector ä¸€è‡´ï¼‰
        if not experts:
            experts = [
                "V3_å™äº‹ä¸ä½“éªŒä¸“å®¶_3-2",
                "V4_è®¾è®¡ç ”ç©¶å‘˜_4-1"
            ]

        return experts

    def _recommend_experts_for_medium_task(self, user_input: str, medium_matches: List[str]) -> List[str]:
        """ä¸ºä¸­ç­‰ä»»åŠ¡æ¨èä¸“å®¶ç»„åˆ"""
        text = user_input.lower()
        experts = ["v2"]  # ä¸­ç­‰ä»»åŠ¡å¿…é¡»æœ‰æ€»ç›‘

        # æ ¹æ®ç©ºé—´ç±»å‹æ·»åŠ ä¸“å®¶
        if any(kw in text for kw in ["å’–å•¡", "é¤å…", "èŒ¶å®¤", "èŒ¶é¥®"]):
            experts.append("v10")  # é¤é¥®ä¸“å®¶

        if any(kw in text for kw in ["åŠå…¬", "å·¥ä½", "ä¼šè®®å®¤"]):
            experts.append("v7")  # åŠå…¬ä¸“å®¶

        # åŠ¨çº¿ã€åˆ†åŒº
        if any(kw in text for kw in ["åŠ¨çº¿", "åˆ†åŒº", "å¸ƒå±€", "è§„åˆ’", "æ¥å¾…"]):
            experts.append("v5")  # åŠ¨çº¿ä¸“å®¶

        # æ–‡åŒ–ã€é£æ ¼
        if any(kw in text for kw in ["ä¸­å¼", "æ–‡åŒ–", "è°ƒæ€§", "å“ç‰Œ", "æ°›å›´"]):
            experts.append("v4")  # æ–‡åŒ–ä¸“å®¶

        # ç…§æ˜
        if any(kw in text for kw in ["ç¯å…‰", "ç…§æ˜", "å…‰çº¿"]):
            experts.append("v6")  # ç…§æ˜ä¸“å®¶

        # æè´¨å®¶å…·
        if any(kw in text for kw in ["æè´¨", "å®¶å…·", "è½¯è£…"]):
            experts.append("v8")  # æè´¨ä¸“å®¶

        # ç¡®ä¿è‡³å°‘3ä¸ªä¸“å®¶
        if len(experts) < 3:
            if "v4" not in experts:
                experts.append("v4")
            if "v5" not in experts:
                experts.append("v5")

        return experts

