"""
æŠ¥å‘Šå®¡æ ¸èŠ‚ç‚¹ - æœ€ç»ˆè¾“å‡ºå†…å®¹å®‰å…¨æ£€æŸ¥
"""

from typing import Dict, Any, Optional
from loguru import logger
from langgraph.store.base import BaseStore

from intelligent_project_analyzer.core.state import ProjectAnalysisState
from intelligent_project_analyzer.security.content_safety_guard import ContentSafetyGuard
from intelligent_project_analyzer.security.violation_logger import ViolationLogger


class ReportGuardNode:
    """æŠ¥å‘Šå®¡æ ¸èŠ‚ç‚¹ - æœ€åŽä¸€é“é˜²çº¿"""
    
    @staticmethod
    def execute(
        state: ProjectAnalysisState,
        store: Optional[BaseStore] = None,
        llm_model = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡ŒæŠ¥å‘Šå†…å®¹å®‰å…¨æ£€æŸ¥
        
        æ£€æŸ¥é€»è¾‘ï¼š
        1. æå–æœ€ç»ˆæŠ¥å‘Šæ–‡æœ¬
        2. å†…å®¹å®‰å…¨æ£€æµ‹
        3. å¦‚æœ‰è¿è§„ï¼Œæ›¿æ¢/è„±æ•
        4. è®°å½•å®¡æ ¸æ—¥å¿—
        
        Args:
            state: é¡¹ç›®åˆ†æžçŠ¶æ€
            store: å­˜å‚¨æŽ¥å£
            llm_model: LLMæ¨¡åž‹å®žä¾‹
            
        Returns:
            æ›´æ–°åŽçš„çŠ¶æ€
        """
        logger.info("=" * 100)
        logger.info("ðŸ›¡ï¸ æŠ¥å‘Šå®¡æ ¸ï¼šæœ€ç»ˆå†…å®¹å®‰å…¨æ£€æŸ¥")
        logger.info("=" * 100)
        
        final_report = state.get("final_report", "")
        session_id = state.get("session_id", "")
        
        if not final_report:
            logger.warning("âš ï¸ æŠ¥å‘Šå†…å®¹ä¸ºç©ºï¼Œè·³è¿‡å®¡æ ¸")
            return {}
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        safety_guard = ContentSafetyGuard(llm_model=llm_model)
        violation_logger = ViolationLogger()
        
        # æå–æ–‡æœ¬ï¼ˆå¦‚æžœæ˜¯å­—å…¸/å¯¹è±¡ï¼Œå…ˆè½¬æ¢ï¼‰
        report_text = ReportGuardNode._extract_text(final_report)
        
        logger.info(f"ðŸ“„ æŠ¥å‘Šé•¿åº¦: {len(report_text)} å­—ç¬¦")
        
        # === å†…å®¹å®‰å…¨æ£€æµ‹ ===
        safety_result = safety_guard.check(report_text, context="report")
        
        if not safety_result["is_safe"]:
            logger.warning(f"âš ï¸ æŠ¥å‘ŠåŒ…å«ä¸å½“å†…å®¹: {safety_result['violations']}")
            
            # è®°å½•è¿è§„
            violation_logger.log({
                "session_id": session_id,
                "violation_type": "report_content_violation",
                "details": safety_result["violations"],
                "report_length": len(report_text),
                "action_taken": safety_result["action"]
            })
            
            # æ ¹æ®é£Žé™©çº§åˆ«å¤„ç†
            if safety_result["risk_level"] == "high":
                logger.error("ðŸš¨ é«˜é£Žé™©å†…å®¹ï¼Œæ›¿æ¢ä¸ºå®‰å…¨ç‰ˆæœ¬")
                safe_report = ReportGuardNode._generate_error_report(safety_result)
                
                return {
                    "final_report": safe_report,
                    "report_safety_status": "rejected",
                    "report_violations": safety_result["violations"]
                }
            
            elif safety_result["risk_level"] == "medium":
                logger.warning("âš ï¸ ä¸­é£Žé™©å†…å®¹ï¼Œæ‰§è¡Œè„±æ•å¤„ç†")
                sanitized_text = safety_result.get("sanitized_text", report_text)
                
                # å¦‚æžœæŠ¥å‘Šæ˜¯å­—å…¸ï¼Œæ›¿æ¢å¯¹åº”å­—æ®µ
                if isinstance(final_report, dict):
                    sanitized_report = ReportGuardNode._sanitize_report_dict(
                        final_report, 
                        report_text, 
                        sanitized_text
                    )
                else:
                    sanitized_report = sanitized_text
                
                return {
                    "final_report": sanitized_report,
                    "report_safety_status": "sanitized",
                    "report_violations": safety_result["violations"]
                }
            
            else:  # low risk
                logger.info("â„¹ï¸ ä½Žé£Žé™©å†…å®¹ï¼Œæ ‡è®°ä½†æ”¾è¡Œ")
                return {
                    "report_safety_status": "flagged",
                    "report_violations": safety_result["violations"]
                }
        
        # === é€šè¿‡æ£€æµ‹ ===
        logger.info("âœ… æŠ¥å‘Šå†…å®¹å®‰å…¨æ£€æŸ¥é€šè¿‡")
        logger.info("=" * 100)
        return {
            "report_safety_status": "passed",
            "report_safety_check_passed": True
        }
    
    @staticmethod
    def _extract_text(report: Any) -> str:
        """ä»ŽæŠ¥å‘Šå¯¹è±¡ä¸­æå–æ–‡æœ¬"""
        if isinstance(report, str):
            return report
        
        if isinstance(report, dict):
            # å°è¯•å¸¸è§å­—æ®µ
            for field in ["content", "text", "report_content", "markdown", "summary"]:
                if field in report and isinstance(report[field], str):
                    return report[field]
            
            # æ‹¼æŽ¥æ‰€æœ‰å­—ç¬¦ä¸²å€¼
            texts = []
            for value in report.values():
                if isinstance(value, str):
                    texts.append(value)
                elif isinstance(value, (list, tuple)):
                    for item in value:
                        if isinstance(item, str):
                            texts.append(item)
            return "\n".join(texts)
        
        # å…¶ä»–ç±»åž‹ï¼Œè½¬å­—ç¬¦ä¸²
        return str(report)
    
    @staticmethod
    def _generate_error_report(safety_result: Dict) -> str:
        """ç”Ÿæˆé”™è¯¯æŠ¥å‘Šï¼ˆé«˜é£Žé™©å†…å®¹æ›¿æ¢ï¼‰"""
        violations = safety_result.get("violations", [])
        violation_types = [v.get("category", "æœªçŸ¥") for v in violations]
        
        return f"""# æŠ¥å‘Šç”Ÿæˆå¤±è´¥

å¾ˆæŠ±æ­‰ï¼Œç”±äºŽå†…å®¹å®‰å…¨åŽŸå› ï¼Œæ— æ³•ç”Ÿæˆå®Œæ•´æŠ¥å‘Šã€‚

## é—®é¢˜è¯´æ˜Ž

åˆ†æžè¿‡ç¨‹ä¸­æ£€æµ‹åˆ°ä»¥ä¸‹å†…å®¹å®‰å…¨é—®é¢˜ï¼š
{chr(10).join(f"- {vtype}" for vtype in violation_types)}

## å»ºè®®

1. è¯·æ£€æŸ¥è¾“å…¥éœ€æ±‚ï¼Œé¿å…åŒ…å«æ•æ„Ÿä¿¡æ¯
2. å¦‚éœ€é‡æ–°åˆ†æžï¼Œè¯·è°ƒæ•´é¡¹ç›®æè¿°
3. å¦‚æœ‰ç–‘é—®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜

---
*æœ¬æŠ¥å‘Šç”±å†…å®¹å®‰å…¨ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""
    
    @staticmethod
    def _sanitize_report_dict(
        original_report: Dict,
        original_text: str,
        sanitized_text: str
    ) -> Dict:
        """è„±æ•å¤„ç†æŠ¥å‘Šå­—å…¸"""
        # ç®€å•å®žçŽ°ï¼šæ‰¾åˆ°åŒ…å«åŽŸå§‹æ–‡æœ¬çš„å­—æ®µå¹¶æ›¿æ¢
        sanitized_report = original_report.copy()
        
        for key, value in original_report.items():
            if isinstance(value, str) and value in original_text:
                # æ‰¾åˆ°å¯¹åº”çš„è„±æ•ä½ç½®
                start_pos = original_text.find(value)
                if start_pos >= 0:
                    end_pos = start_pos + len(value)
                    sanitized_report[key] = sanitized_text[start_pos:end_pos]
        
        return sanitized_report
