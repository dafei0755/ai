# æœåŠ¡å±‚æ¨¡å— - AI åä½œæ–‡æ¡£

> ğŸ“ **è·¯å¾„å¯¼èˆª**: [æ ¹ç›®å½•](../../CLAUDE.md) > [intelligent_project_analyzer](../) > **services**

---

## ğŸ“‹ æ¨¡å—èŒè´£

**æœåŠ¡å±‚ (Service Layer)**

æœ¬æ¨¡å—æä¾›å·¥å‚æ¨¡å¼çš„æœåŠ¡å±‚ï¼Œè´Ÿè´£åˆ›å»ºå’Œç®¡ç† LLM å®ä¾‹ã€å·¥å…·å®ä¾‹å’Œå›¾ä¸Šä¸‹æ–‡ã€‚

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ­ **LLM å·¥å‚**: åˆ›å»ºå’Œé…ç½® LLM æ¨¡å‹
- ğŸ› ï¸ **å·¥å…·å·¥å‚**: åˆ›å»ºå’Œæ³¨å†Œå¤–éƒ¨å·¥å…·
- ğŸ“Š **å›¾ä¸Šä¸‹æ–‡**: ç®¡ç† LangGraph æ‰§è¡Œä¸Šä¸‹æ–‡

---

## ğŸ“ æ–‡ä»¶ç»“æ„

```
services/
â”œâ”€â”€ llm_factory.py         # LLM å·¥å‚
â”œâ”€â”€ tool_factory.py        # å·¥å…·å·¥å‚
â””â”€â”€ graph_context.py       # å›¾ä¸Šä¸‹æ–‡ç®¡ç†
```

---

## ğŸ”‘ æ ¸å¿ƒæœåŠ¡

### 1. LLM Factory

**èŒè´£**: åˆ›å»ºå’Œé…ç½® LLM æ¨¡å‹å®ä¾‹ã€‚

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from intelligent_project_analyzer.services.llm_factory import create_llm

llm = create_llm(
    provider="openai",
    model="gpt-4",
    temperature=0.7,
    max_tokens=4000
)
```

---

### 2. Tool Factory

**èŒè´£**: åˆ›å»ºå’Œæ³¨å†Œå¤–éƒ¨å·¥å…·ã€‚

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from intelligent_project_analyzer.services.tool_factory import create_tools

tools = create_tools(
    enable_tavily=True,
    enable_arxiv=True,
    enable_ragflow=True
)
```

---

### 3. Graph Context

**èŒè´£**: ç®¡ç† LangGraph æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬é…ç½®ã€å­˜å‚¨ç­‰ã€‚

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from intelligent_project_analyzer.services.graph_context import GraphContext

context = GraphContext(thread_id="session_123")
config = context.get_config()
```

---

## ğŸ“š ç›¸å…³èµ„æº

- [æ ¸å¿ƒçŠ¶æ€ç®¡ç†](../core/CLAUDE.md)
- [å¤–éƒ¨å·¥å…·](../tools/CLAUDE.md)
- [ç»Ÿä¸€é…ç½®](../settings.py)

---

**æœ€åæ›´æ–°**: 2025-11-16
**è¦†ç›–ç‡**: 100%
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0
