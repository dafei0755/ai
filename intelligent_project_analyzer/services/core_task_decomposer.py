"""
æ ¸å¿ƒä»»åŠ¡æ‹†è§£æœåŠ¡

v7.80.1: å°†ç”¨æˆ·æ¨¡ç³Šè¾“å…¥æ‹†è§£ä¸ºç»“æ„åŒ–çš„å¯æ‰§è¡Œä»»åŠ¡åˆ—è¡¨
ç”¨äº Step 1: æ˜ç¡®æ ¸å¿ƒä»»åŠ¡
"""

import json
import yaml
from typing import Dict, Any, List, Optional
from pathlib import Path
from loguru import logger


class CoreTaskDecomposer:
    """
    æ ¸å¿ƒä»»åŠ¡æ‹†è§£å™¨

    ä½¿ç”¨ LLM å°†ç”¨æˆ·è¾“å…¥æ‹†è§£ä¸ºç²¾å‡†çš„ã€å¯æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨ã€‚
    """

    _instance = None
    _config = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if self._config is None:
            self._load_config()

    def _load_config(self) -> None:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_path = Path(__file__).parent.parent / "config" / "prompts" / "core_task_decomposer.yaml"
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                self._config = yaml.safe_load(f)
            logger.info(f"âœ… [CoreTaskDecomposer] é…ç½®åŠ è½½æˆåŠŸ: {config_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ [CoreTaskDecomposer] é…ç½®åŠ è½½å¤±è´¥: {e}")
            self._config = {}

    @property
    def config(self) -> Dict[str, Any]:
        """è·å–é…ç½®"""
        return self._config or {}

    def build_prompt(self, user_input: str, structured_data: Optional[Dict[str, Any]] = None) -> str:
        """
        æ„å»º LLM è°ƒç”¨çš„ prompt

        Args:
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
            structured_data: éœ€æ±‚åˆ†æé˜¶æ®µäº§å‡ºçš„ç»“æ„åŒ–æ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            å®Œæ•´çš„ prompt å­—ç¬¦ä¸²
        """
        # æ„å»ºç»“æ„åŒ–æ•°æ®æ‘˜è¦
        structured_summary = ""
        if structured_data:
            summary_parts = []

            # æå–å…³é”®å­—æ®µ
            project_task = structured_data.get("project_task", "")
            if project_task:
                summary_parts.append(f"é¡¹ç›®ä»»åŠ¡: {project_task}")

            character_narrative = structured_data.get("character_narrative", "")
            if character_narrative:
                summary_parts.append(f"äººç‰©å™äº‹: {character_narrative}")

            physical_context = structured_data.get("physical_context", "")
            if physical_context:
                summary_parts.append(f"ç‰©ç†åœºæ™¯: {physical_context}")

            project_type = structured_data.get("project_type", "")
            if project_type:
                summary_parts.append(f"é¡¹ç›®ç±»å‹: {project_type}")

            # L1-L5 åˆ†æå±‚ä¿¡æ¯
            analysis_layers = structured_data.get("analysis_layers", {})
            if analysis_layers:
                l3_tension = analysis_layers.get("L3_core_tension", "")
                if l3_tension:
                    summary_parts.append(f"æ ¸å¿ƒå¼ åŠ›: {l3_tension}")

            structured_summary = "\n".join(summary_parts) if summary_parts else "æš‚æ— è¡¥å……ä¿¡æ¯"

        # è·å– prompt æ¨¡æ¿
        system_prompt = self.config.get("system_prompt", "")
        user_template = self.config.get("user_prompt_template", "")

        # å¡«å……ç”¨æˆ· prompt
        user_prompt = user_template.format(
            user_input=user_input,
            structured_data_summary=structured_summary
        )

        return f"{system_prompt}\n\n{user_prompt}"

    def parse_response(self, response: str) -> List[Dict[str, Any]]:
        """
        è§£æ LLM å“åº”ï¼Œæå–ä»»åŠ¡åˆ—è¡¨

        Args:
            response: LLM è¿”å›çš„åŸå§‹å“åº”

        Returns:
            ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å« id, title, description, source_keywords, task_type, priority
        """
        try:
            # ğŸ†• P1: å¢å¼º JSON æå–èƒ½åŠ› - æ·»åŠ  debug æ—¥å¿—
            logger.debug(f"[CoreTaskDecomposer] LLM åŸå§‹å“åº” (å‰500å­—ç¬¦): {response[:500]}")

            response_text = response.strip()

            # ç­–ç•¥ 1: ç§»é™¤ markdown ä»£ç å—æ ‡è®°
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            elif response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]

            response_text = response_text.strip()

            # ç­–ç•¥ 2: å¦‚æœè¿˜ä¸æ˜¯ JSONï¼Œå°è¯•æå– { } ä¹‹é—´çš„å†…å®¹
            if not response_text.startswith("{"):
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª {
                start_idx = response_text.find("{")
                if start_idx != -1:
                    # æŸ¥æ‰¾åŒ¹é…çš„ }ï¼ˆå¹³è¡¡æ‹¬å·ï¼‰
                    brace_count = 0
                    end_idx = -1
                    for i in range(start_idx, len(response_text)):
                        if response_text[i] == "{":
                            brace_count += 1
                        elif response_text[i] == "}":
                            brace_count -= 1
                            if brace_count == 0:
                                end_idx = i + 1
                                break

                    if end_idx != -1:
                        response_text = response_text[start_idx:end_idx]
                        logger.info(f"âœ… [CoreTaskDecomposer] ä½¿ç”¨æ‹¬å·å¹³è¡¡æå– JSON (é•¿åº¦: {len(response_text)})")

            # ç­–ç•¥ 3: å°è¯•ç§»é™¤ JSON ä¸­çš„æ³¨é‡Šï¼ˆ// æˆ– /* */ï¼‰
            import re
            response_text = re.sub(r'//.*?$', '', response_text, flags=re.MULTILINE)  # ç§»é™¤å•è¡Œæ³¨é‡Š
            response_text = re.sub(r'/\*.*?\*/', '', response_text, flags=re.DOTALL)  # ç§»é™¤å¤šè¡Œæ³¨é‡Š

            # è§£æ JSON
            data = json.loads(response_text)

            # æå–ä»»åŠ¡åˆ—è¡¨
            tasks = data.get("tasks", [])

            # å¦‚æœ tasks ä¸ºç©ºï¼Œå°è¯•ä»å…¶ä»–å¯èƒ½çš„å­—æ®µæå–
            if not tasks:
                # å¯èƒ½æ˜¯ç›´æ¥è¿”å›äº†ä»»åŠ¡æ•°ç»„
                if isinstance(data, list):
                    tasks = data
                # æˆ–è€…ä»»åŠ¡åœ¨å…¶ä»–å­—æ®µä¸­
                elif "task_list" in data:
                    tasks = data["task_list"]
                elif "core_tasks" in data:
                    tasks = data["core_tasks"]

            # éªŒè¯å’Œè§„èŒƒåŒ–ä»»åŠ¡
            validated_tasks = []
            for i, task in enumerate(tasks):
                validated_task = {
                    "id": task.get("id", f"task_{i + 1}"),
                    "title": task.get("title", "æœªå‘½åä»»åŠ¡"),
                    "description": task.get("description", ""),
                    "source_keywords": task.get("source_keywords", []),
                    "task_type": task.get("task_type", "research"),
                    "priority": task.get("priority", "medium")
                }
                validated_tasks.append(validated_task)

            logger.info(f"âœ… [CoreTaskDecomposer] æˆåŠŸè§£æ {len(validated_tasks)} ä¸ªä»»åŠ¡")
            return validated_tasks

        except json.JSONDecodeError as e:
            logger.error(f"âŒ [CoreTaskDecomposer] JSON è§£æå¤±è´¥: {e}")
            logger.debug(f"[CoreTaskDecomposer] è§£æå¤±è´¥çš„æ–‡æœ¬: {response_text[:200]}")
            return self._fallback_decompose(response)
        except Exception as e:
            logger.error(f"âŒ [CoreTaskDecomposer] å“åº”è§£æå¼‚å¸¸: {e}")
            return []

    def _fallback_decompose(self, text: str) -> List[Dict[str, Any]]:
        """
        å›é€€ç­–ç•¥ï¼šå½“ LLM å“åº”æ ¼å¼ä¸æ­£ç¡®æ—¶ï¼Œä½¿ç”¨ç®€å•çš„è§„åˆ™æå–

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            ç®€åŒ–çš„ä»»åŠ¡åˆ—è¡¨
        """
        logger.warning("âš ï¸ [CoreTaskDecomposer] ä½¿ç”¨å›é€€ç­–ç•¥æå–ä»»åŠ¡")

        # å°è¯•ä»æ–‡æœ¬ä¸­æå–ç¼–å·åˆ—è¡¨
        lines = text.split("\n")
        tasks = []

        for i, line in enumerate(lines):
            line = line.strip()
            # åŒ¹é… "1." "1ã€" "1)" "- " ç­‰æ ¼å¼
            if line and (
                (line[0].isdigit() and len(line) > 2 and line[1] in ".ã€)") or
                line.startswith("- ") or
                line.startswith("â€¢ ")
            ):
                # æå–ä»»åŠ¡å†…å®¹
                content = line.lstrip("0123456789.ã€)- â€¢").strip()
                if content and len(content) > 5:
                    tasks.append({
                        "id": f"task_{len(tasks) + 1}",
                        "title": content[:50] if len(content) > 50 else content,
                        "description": content,
                        "source_keywords": [],
                        "task_type": "research",
                        "priority": "medium"
                    })

        # é™åˆ¶ä»»åŠ¡æ•°é‡
        return tasks[:7] if tasks else []


async def decompose_core_tasks(
    user_input: str,
    structured_data: Optional[Dict[str, Any]] = None,
    llm: Optional[Any] = None
) -> List[Dict[str, Any]]:
    """
    å¼‚æ­¥æ‰§è¡Œæ ¸å¿ƒä»»åŠ¡æ‹†è§£

    Args:
        user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
        structured_data: éœ€æ±‚åˆ†æé˜¶æ®µäº§å‡ºçš„ç»“æ„åŒ–æ•°æ®ï¼ˆå¯é€‰ï¼‰
        llm: LLM å®ä¾‹ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤ LLMï¼‰

    Returns:
        ä»»åŠ¡åˆ—è¡¨
    """
    decomposer = CoreTaskDecomposer()

    # æ„å»º prompt
    prompt = decomposer.build_prompt(user_input, structured_data)

    # å¦‚æœæ²¡æœ‰æä¾› LLMï¼Œä½¿ç”¨é»˜è®¤
    if llm is None:
        from ..services.llm_factory import LLMFactory
        llm = LLMFactory.create_llm()

    try:
        # è°ƒç”¨ LLM
        from langchain_core.messages import HumanMessage, SystemMessage

        system_prompt = decomposer.config.get("system_prompt", "")
        user_template = decomposer.config.get("user_prompt_template", "")

        # æ„å»ºç»“æ„åŒ–æ•°æ®æ‘˜è¦
        structured_summary = ""
        if structured_data:
            summary_parts = []
            for key in ["project_task", "character_narrative", "physical_context", "project_type"]:
                if structured_data.get(key):
                    summary_parts.append(f"{key}: {structured_data[key]}")
            structured_summary = "\n".join(summary_parts) if summary_parts else "æš‚æ— "

        user_prompt = user_template.format(
            user_input=user_input,
            structured_data_summary=structured_summary
        )

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]

        response = await llm.ainvoke(messages)
        response_text = response.content if hasattr(response, "content") else str(response)

        # è§£æå“åº”
        tasks = decomposer.parse_response(response_text)

        if not tasks:
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•å›é€€
            logger.warning("âš ï¸ LLM ä»»åŠ¡æ‹†è§£ä¸ºç©ºï¼Œä½¿ç”¨å›é€€ç­–ç•¥")
            tasks = _simple_fallback_decompose(user_input, structured_data)

        return tasks

    except Exception as e:
        logger.error(f"âŒ [decompose_core_tasks] LLM è°ƒç”¨å¤±è´¥: {e}")
        # å›é€€åˆ°ç®€å•æ‹†è§£
        return _simple_fallback_decompose(user_input, structured_data)


def _simple_fallback_decompose(user_input: str, structured_data: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
    """
    å¢å¼ºç‰ˆå›é€€æ‹†è§£ç­–ç•¥ï¼ˆv7.80.2ï¼‰

    å½“ LLM è°ƒç”¨å¤±è´¥æ—¶ï¼ŒåŸºäºç»“æ„åŒ–æ•°æ®çš„å¤šç»´åº¦ä¿¡æ¯ç”Ÿæˆé«˜è´¨é‡ä»»åŠ¡åˆ—è¡¨ã€‚

    å‚è€ƒï¼šæ ¡å‡†é—®å·çš„æ™ºèƒ½è¡¥é½æœºåˆ¶ï¼ˆquestionnaire_optimization_summary.mdï¼‰

    Args:
        user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
        structured_data: éœ€æ±‚åˆ†æäº§å‡ºçš„ç»“æ„åŒ–æ•°æ®ï¼ˆåŒ…å« design_challenge, character_narrative ç­‰ï¼‰

    Returns:
        ä»»åŠ¡åˆ—è¡¨ï¼ˆ5-7ä¸ªé«˜è´¨é‡ä»»åŠ¡ï¼‰
    """
    import re

    tasks = []
    logger.info("ğŸ”„ [Fallback] ä½¿ç”¨å¢å¼ºç‰ˆå›é€€ç­–ç•¥ï¼ŒåŸºäºç»“æ„åŒ–æ•°æ®ç”Ÿæˆä»»åŠ¡")

    # ä»ç»“æ„åŒ–æ•°æ®ä¸­æå–å…³é”®ä¿¡æ¯
    design_challenge = ""
    character_narrative = ""
    project_type = ""
    if structured_data:
        design_challenge = structured_data.get("design_challenge", "")
        character_narrative = structured_data.get("character_narrative", "")
        project_type = structured_data.get("project_type", "")
        logger.info(f"ğŸ“Š [Fallback] æå–åˆ°ç»“æ„åŒ–æ•°æ®: design_challenge={bool(design_challenge)}, project_type={project_type}")

    # ==========================================================================
    # 1. æå–æ ¸å¿ƒå¼ åŠ›ä»»åŠ¡ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    # ==========================================================================
    tension_a = ""
    tension_b = ""
    if design_challenge:
        # æ¨¡å¼1: "A"...ä¸..."B" æ ¼å¼ï¼ˆä¸­æ–‡å¼•å·ï¼‰
        match = re.search(r'"([^"]{2,30})"[^"]{0,50}ä¸[^"]{0,50}"([^"]{2,30})"', design_challenge)
        if match:
            tension_a = match.group(1).strip()
            tension_b = match.group(2).strip()
            logger.info(f"âœ… [Fallback] æå–æ ¸å¿ƒå¼ åŠ›: \"{tension_a}\" vs \"{tension_b}\"")
            tasks.append({
                "id": f"task_{len(tasks) + 1}",
                "title": f"{tension_a}ä¸{tension_b}çš„å¹³è¡¡ç­–ç•¥ç ”ç©¶",
                "description": f"ç ”ç©¶å¦‚ä½•åœ¨è®¾è®¡ä¸­å¹³è¡¡{tension_a}å’Œ{tension_b}çš„éœ€æ±‚ï¼Œæ‰¾åˆ°æœ€ä½³è§£å†³æ–¹æ¡ˆ",
                "source_keywords": [tension_a, tension_b],
                "task_type": "research",
                "priority": "high"
            })
        else:
            # æ¨¡å¼2: A vs B æˆ– Aä¸å…¶å¯¹B æ ¼å¼
            match = re.search(r'(.{5,30}?)[çš„éœ€æ±‚]*(?:vs|ä¸å…¶å¯¹)(.{5,30}?)[çš„éœ€æ±‚]*', design_challenge)
            if match:
                tension_a = match.group(1).strip()
                tension_b = match.group(2).strip()
                logger.info(f"âœ… [Fallback] æå–æ ¸å¿ƒå¼ åŠ› (æ¨¡å¼2): {tension_a} vs {tension_b}")
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": f"{tension_a}ä¸{tension_b}çš„å¹³è¡¡ç­–ç•¥ç ”ç©¶",
                    "description": f"ç ”ç©¶å¦‚ä½•åœ¨è®¾è®¡ä¸­å¹³è¡¡{tension_a}å’Œ{tension_b}çš„éœ€æ±‚ï¼Œæ‰¾åˆ°æœ€ä½³è§£å†³æ–¹æ¡ˆ",
                    "source_keywords": [tension_a, tension_b],
                    "task_type": "research",
                    "priority": "high"
                })

    # ==========================================================================
    # 2. æå–å¯¹æ ‡æ¡ˆä¾‹ä»»åŠ¡
    # ==========================================================================
    benchmarking_keywords = ["å¯¹æ ‡", "å‚è€ƒ", "æ¡ˆä¾‹", "æ ‡æ†", "å¯¹æ¯”"]
    for keyword in benchmarking_keywords:
        if keyword in user_input and not any(keyword in t["title"] for t in tasks):
            # å°è¯•æå–å…·ä½“çš„å¯¹æ ‡å¯¹è±¡
            benchmark_patterns = [
                r'å¯¹æ ‡([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,30})',  # "å¯¹æ ‡è‹å·é»„æ¡¥èœå¸‚åœº"
                r'å‚è€ƒ([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,30})',
                r'([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,30})æ¡ˆä¾‹',
            ]
            benchmark_target = ""
            for pattern in benchmark_patterns:
                match = re.search(pattern, user_input)
                if match:
                    benchmark_target = match.group(1).strip()
                    break

            if benchmark_target:
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": f"å¯¹æ ‡æ¡ˆä¾‹æ·±åº¦ç ”ç©¶",
                    "description": f"é‡ç‚¹ç ”ç©¶{benchmark_target}ï¼Œå¹¶è°ƒç ”å…¶ä»–æˆåŠŸæ¡ˆä¾‹çš„è®¾è®¡ç­–ç•¥å’Œåˆ›æ–°è¦ç´ ",
                    "source_keywords": [keyword, benchmark_target],
                    "task_type": "research",
                    "priority": "high"
                })
            else:
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": "æ ‡æ†æ¡ˆä¾‹ç ”ç©¶",
                    "description": "è°ƒç ”è¡Œä¸šå†…æˆåŠŸæ¡ˆä¾‹çš„è®¾è®¡ç­–ç•¥ã€è¿è¥æ¨¡å¼å’Œåˆ›æ–°è¦ç´ ",
                    "source_keywords": [keyword],
                    "task_type": "research",
                    "priority": "high"
                })
            break

    # ==========================================================================
    # 3. æå–æ–‡åŒ–è¦ç´ ä»»åŠ¡
    # ==========================================================================
    culture_keywords = ["æ–‡åŒ–", "ä¼ ç»Ÿ", "åœ¨åœ°", "å†å²", "ç‰¹è‰²"]
    for keyword in culture_keywords:
        if keyword in user_input and not any(keyword in t["title"] for t in tasks):
            # å°è¯•æå–å…·ä½“çš„æ–‡åŒ–å¯¹è±¡
            culture_patterns = [
                r'([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,15})[æ–‡åŒ–ä¼ ç»Ÿ]',  # "è›‡å£æ¸”æ‘æ–‡åŒ–"
                r'èå…¥([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,15})',
            ]
            culture_target = ""
            for pattern in culture_patterns:
                match = re.search(pattern, user_input)
                if match:
                    culture_target = match.group(1).strip()
                    if any(c in culture_target for c in ["æ–‡åŒ–", "ä¼ ç»Ÿ", "ç‰¹è‰²"]):
                        break

            if culture_target:
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": f"{culture_target}æ–‡åŒ–æ´å¯Ÿä¸æç‚¼",
                    "description": f"æ·±å…¥è°ƒç ”{culture_target}çš„å†å²æ–‡è„‰å’Œç²¾ç¥å†…æ ¸ï¼Œæç‚¼å¯èå…¥è®¾è®¡çš„æ–‡åŒ–å…ƒç´ ",
                    "source_keywords": [keyword, culture_target],
                    "task_type": "research",
                    "priority": "high"
                })
            else:
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": "æ–‡åŒ–è°ƒç ”ä¸å…ƒç´ æç‚¼",
                    "description": "è°ƒç ”é¡¹ç›®ç›¸å…³çš„æ–‡åŒ–èƒŒæ™¯ï¼Œæç‚¼å¯èå…¥è®¾è®¡çš„æ–‡åŒ–å…ƒç´ å’Œç¬¦å·",
                    "source_keywords": [keyword],
                    "task_type": "research",
                    "priority": "high"
                })
            break

    # ==========================================================================
    # 4. æå–å®¢ç¾¤åˆ†æä»»åŠ¡
    # ==========================================================================
    audience_keywords = ["å®¢ç¾¤", "ç”¨æˆ·", "è®¿å®¢", "å±…æ°‘", "å®¢æˆ·", "äººç¾¤", "å²", "å¥³æ€§", "ç”·æ€§"]
    for keyword in audience_keywords:
        if keyword in user_input and not any("å®¢ç¾¤" in t["title"] or "ç”Ÿæ´»æ–¹å¼" in t["title"] for t in tasks):
            # å°è¯•æå–å…·ä½“çš„å®¢ç¾¤æè¿°
            audience_patterns = [
                r'(\d+å²[^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{0,10})',  # "35å²å•èº«å¥³æ€§"
                r'([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,15})[å®¢ç¾¤ç”¨æˆ·è®¿å®¢]',
                r'å…¼é¡¾([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{5,50})',  # "å…¼é¡¾è›‡å£è€å±…æ°‘è¡—åŠã€é¦™æ¸¯è®¿å®¢..."
            ]
            audience_target = ""
            for pattern in audience_patterns:
                match = re.search(pattern, user_input)
                if match:
                    audience_target = match.group(1).strip()
                    break

            # ç‰¹åˆ«å¤„ç†: 35å²å•èº«å¥³æ€§ç­‰å¹´é¾„+ç‰¹å¾çš„æƒ…å†µ
            age_match = re.search(r'(\d+)å²([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{0,10})', user_input)
            if age_match:
                age = age_match.group(1)
                traits = age_match.group(2).strip()
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": f"{age}å²{traits}ç”Ÿæ´»æ–¹å¼ç ”ç©¶",
                    "description": f"æ·±å…¥åˆ†æ{age}å²{traits}çš„å®¡ç¾åå¥½ã€ç”Ÿæ´»åœºæ™¯ã€ç¤¾äº¤éœ€æ±‚å’Œç²¾ç¥è¿½æ±‚",
                    "source_keywords": [f"{age}å²", traits],
                    "task_type": "analysis",
                    "priority": "high"
                })
            elif audience_target:
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": "å¤šå…ƒå®¢ç¾¤åˆ†æ",
                    "description": f"åˆ†æ{audience_target}çš„éœ€æ±‚å·®å¼‚ä¸å…±æ€§ï¼Œæ‰¾åˆ°è®¾è®¡çš„å¹³è¡¡ç‚¹",
                    "source_keywords": [keyword, audience_target],
                    "task_type": "analysis",
                    "priority": "high"
                })
            else:
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": "ç›®æ ‡å®¢ç¾¤ç ”ç©¶",
                    "description": "åˆ†æç›®æ ‡ç”¨æˆ·çš„éœ€æ±‚ç‰¹å¾ã€ä½¿ç”¨ä¹ æƒ¯å’ŒæœŸæœ›ä½“éªŒ",
                    "source_keywords": [keyword],
                    "task_type": "analysis",
                    "priority": "high"
                })
            break

    # ==========================================================================
    # 5. æå–å“ç‰Œç›¸å…³ä»»åŠ¡ï¼ˆæ–°å¢ï¼šé’ˆå¯¹ Tiffany ç­‰å“ç‰Œä¸»é¢˜ï¼‰
    # ==========================================================================
    # æ£€æµ‹å“ç‰Œåï¼ˆé€šå¸¸æ˜¯è‹±æ–‡æˆ–å“ç‰Œå…³é”®è¯ï¼‰
    brand_patterns = [
        r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)',  # Tiffany, Louis Vuitton
        r'([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,10})ä¸ºä¸»é¢˜',  # "è’‚èŠ™å°¼ä¸ºä¸»é¢˜"
        r'([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,10})å“ç‰Œ',
    ]
    brand_name = ""
    for pattern in brand_patterns:
        match = re.search(pattern, user_input)
        if match:
            potential_brand = match.group(1).strip()
            # è¿‡æ»¤æ‰ä¸å¤ªåƒå“ç‰Œåçš„å†…å®¹
            if len(potential_brand) >= 2 and not any(c in potential_brand for c in ["å¹³ç±³", "å¹´", "è®¾è®¡", "é¡¹ç›®"]):
                brand_name = potential_brand
                break

    if brand_name and not any(brand_name in t["title"] for t in tasks):
        tasks.append({
            "id": f"task_{len(tasks) + 1}",
            "title": f"{brand_name}å“ç‰Œæ–‡åŒ–æ´å¯Ÿ",
            "description": f"ç ”ç©¶{brand_name}çš„å“ç‰Œç²¾ç¥ã€è‰²å½©ä½“ç³»ã€ç»å…¸è®¾è®¡å…ƒç´ å’Œæ ¸å¿ƒä»·å€¼è§‚",
            "source_keywords": [brand_name, "å“ç‰Œ"],
            "task_type": "research",
            "priority": "high"
        })

    # ==========================================================================
    # 6. æå–ç©ºé—´/è§„æ¨¡ç›¸å…³ä»»åŠ¡
    # ==========================================================================
    space_match = re.search(r'(\d+)å¹³ç±³', user_input)
    space_type_keywords = ["åˆ«å¢…", "ä½å®…", "å…¬å¯“", "åŠå…¬", "å•†ä¸š", "é›¶å”®", "é…’åº—"]
    space_type = next((kw for kw in space_type_keywords if kw in user_input), "")

    if (space_match or space_type) and not any("ç©ºé—´" in t["title"] or "è§„åˆ’" in t["title"] for t in tasks):
        if space_match and space_type:
            area = space_match.group(1)
            tasks.append({
                "id": f"task_{len(tasks) + 1}",
                "title": f"{area}å¹³ç±³{space_type}ç©ºé—´åŠŸèƒ½è§„åˆ’",
                "description": f"åˆ¶å®šç¬¦åˆç”¨æˆ·éœ€æ±‚çš„{area}å¹³ç±³{space_type}ç©ºé—´å¸ƒå±€ç­–ç•¥å’ŒåŠŸèƒ½åˆ†åŒºæ–¹æ¡ˆ",
                "source_keywords": [f"{area}å¹³ç±³", space_type],
                "task_type": "design",
                "priority": "high"
            })
        elif space_type:
            tasks.append({
                "id": f"task_{len(tasks) + 1}",
                "title": f"{space_type}ç©ºé—´è®¾è®¡æ¡†æ¶",
                "description": f"è¾“å‡º{space_type}ç©ºé—´çš„æ•´ä½“è®¾è®¡æ¡†æ¶å’ŒåŠŸèƒ½è§„åˆ’ç­–ç•¥",
                "source_keywords": [space_type],
                "task_type": "design",
                "priority": "high"
            })

    # ==========================================================================
    # 7. è¡¥å……ï¼šæœ€ç»ˆäº¤ä»˜ç‰©ä»»åŠ¡
    # ==========================================================================
    deliverable_keywords = ["æ¡†æ¶", "æ–¹æ¡ˆ", "æ¦‚å¿µ", "è®¾è®¡æ€è·¯"]
    for keyword in deliverable_keywords:
        if keyword in user_input and not any(keyword in t["title"] for t in tasks):
            # æå–äº¤ä»˜ç‰©ç±»å‹
            deliverable_patterns = [
                r'([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,10})æ¡†æ¶',
                r'([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,10})æ–¹æ¡ˆ',
                r'([^ï¼Œã€‚ã€ï¼ï¼Ÿ\n]{2,10})è®¾è®¡æ€è·¯',
            ]
            deliverable_target = ""
            for pattern in deliverable_patterns:
                match = re.search(pattern, user_input)
                if match:
                    deliverable_target = match.group(1).strip()
                    break

            if deliverable_target:
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    "title": f"{deliverable_target}è®¾è®¡æ¡†æ¶è¾“å‡º",
                    "description": f"è¾“å‡º{deliverable_target}çš„æ•´ä½“è®¾è®¡æ¡†æ¶ï¼Œèåˆå‰æœŸç ”ç©¶æˆæœå’Œè®¾è®¡ç­–ç•¥",
                    "source_keywords": [keyword, deliverable_target],
                    "task_type": "design",
                    "priority": "high"
                })
            break

    # ==========================================================================
    # 8. ç¡®ä¿è‡³å°‘æœ‰ 5 ä¸ªä»»åŠ¡
    # ==========================================================================
    if len(tasks) < 5:
        logger.warning(f"âš ï¸ [Fallback] å½“å‰ä»…ç”Ÿæˆ {len(tasks)} ä¸ªä»»åŠ¡ï¼Œè¡¥å……é€šç”¨ä»»åŠ¡")
        # è¡¥å……é€šç”¨ä»»åŠ¡
        generic_tasks = [
            {
                "title": "é¡¹ç›®éœ€æ±‚æ˜ç¡®",
                "description": "æ˜ç¡®é¡¹ç›®çš„æ ¸å¿ƒéœ€æ±‚ã€æœŸæœ›ç›®æ ‡å’Œå…³é”®çº¦æŸæ¡ä»¶",
                "task_type": "analysis",
                "priority": "high"
            },
            {
                "title": "è®¾è®¡ç­–ç•¥åˆ¶å®š",
                "description": "åˆ¶å®šæ•´ä½“è®¾è®¡ç­–ç•¥å’Œå®æ–½è·¯å¾„ï¼Œç¡®å®šè®¾è®¡çš„æ ¸å¿ƒæ–¹å‘",
                "task_type": "design",
                "priority": "medium"
            },
            {
                "title": "è¡Œä¸šè¶‹åŠ¿ç ”ç©¶",
                "description": "ç ”ç©¶ç›¸å…³é¢†åŸŸçš„æœ€æ–°è¶‹åŠ¿ã€æˆåŠŸæ¡ˆä¾‹å’Œåˆ›æ–°å®è·µ",
                "task_type": "research",
                "priority": "medium"
            },
        ]

        for generic_task in generic_tasks:
            if len(tasks) >= 5:
                break
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç±»ä¼¼ä»»åŠ¡
            if not any(generic_task["title"] in t["title"] or t["title"] in generic_task["title"] for t in tasks):
                tasks.append({
                    "id": f"task_{len(tasks) + 1}",
                    **generic_task,
                    "source_keywords": []
                })

    # ç¡®ä¿ä¸è¶…è¿‡ 7 ä¸ªä»»åŠ¡
    tasks = tasks[:7]

    logger.info(f"âœ… [Fallback] ç”Ÿæˆ {len(tasks)} ä¸ªä»»åŠ¡ï¼ˆåŒ…å« {sum(1 for t in tasks if t['priority'] == 'high')} ä¸ªé«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼‰")

    return tasks


# åŒæ­¥ç‰ˆæœ¬ï¼ˆç”¨äºéå¼‚æ­¥ä¸Šä¸‹æ–‡ï¼‰
def decompose_core_tasks_sync(
    user_input: str,
    structured_data: Optional[Dict[str, Any]] = None,
    llm: Optional[Any] = None
) -> List[Dict[str, Any]]:
    """
    åŒæ­¥æ‰§è¡Œæ ¸å¿ƒä»»åŠ¡æ‹†è§£

    Args:
        user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
        structured_data: éœ€æ±‚åˆ†æé˜¶æ®µäº§å‡ºçš„ç»“æ„åŒ–æ•°æ®ï¼ˆå¯é€‰ï¼‰
        llm: LLM å®ä¾‹ï¼ˆå¯é€‰ï¼‰

    Returns:
        ä»»åŠ¡åˆ—è¡¨
    """
    import asyncio

    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œä½¿ç”¨å›é€€ç­–ç•¥
            logger.warning("âš ï¸ æ£€æµ‹åˆ°è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨å›é€€ç­–ç•¥")
            return _simple_fallback_decompose(user_input)
        else:
            return loop.run_until_complete(
                decompose_core_tasks(user_input, structured_data, llm)
            )
    except RuntimeError:
        # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä¸€ä¸ª
        return asyncio.run(
            decompose_core_tasks(user_input, structured_data, llm)
        )
