"""
æ–‡ä»¶å¤„ç†æœåŠ¡ - æ”¯æŒå¤šæ¨¡æ€æ–‡ä»¶å†…å®¹æå–

v3.7 æ–°å¢åŠŸèƒ½ï¼š
- PDF æ–‡æœ¬æå–
- TXT æ™ºèƒ½ç¼–ç æ£€æµ‹
- å›¾ç‰‡ OCR æ–‡å­—è¯†åˆ«ï¼ˆå¯é€‰ï¼‰
"""

import aiofiles
from pathlib import Path
from typing import Dict, Any, Optional
from loguru import logger
import chardet


class FileProcessor:
    """å¤šæ¨¡æ€æ–‡ä»¶å¤„ç†æœåŠ¡"""

    def __init__(self, upload_dir: str = "./data/uploads", enable_vision_api: bool = True, vision_provider: str = "openai"):
        self.upload_dir = Path(upload_dir)
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        self.enable_vision_api = enable_vision_api
        self.vision_provider = vision_provider

        # åˆå§‹åŒ–Vision LLMï¼ˆå¯é€‰ï¼‰
        self.vision_llm = None
        if enable_vision_api:
            try:
                from intelligent_project_analyzer.settings import settings

                if vision_provider == "gemini":
                    # ğŸ”¥ ä½¿ç”¨ Google Gemini Vision
                    from langchain_google_genai import ChatGoogleGenerativeAI
                    import os

                    api_key = os.getenv("GOOGLE_API_KEY") or settings.llm.api_key
                    self.vision_llm = ChatGoogleGenerativeAI(
                        model="gemini-1.5-flash",  # æˆ– gemini-1.5-pro
                        temperature=0.7,
                        google_api_key=api_key
                    )
                    logger.info("ğŸ” Vision APIå·²å¯ç”¨ (Google Gemini)")

                elif vision_provider == "gemini-openrouter":
                    # ğŸ”¥ é€šè¿‡ OpenRouter ä½¿ç”¨ Gemini Vision (è§£å†³å›½å†…ç½‘ç»œé™åˆ¶)
                    # æ³¨æ„: ç›®å‰OpenRouterä¸­Gemini Visionæ”¯æŒæœ‰é™,æ¨èä½¿ç”¨ openai-openrouter
                    from langchain_openai import ChatOpenAI
                    import os

                    api_key = os.getenv("OPENROUTER_API_KEY")
                    self.vision_llm = ChatOpenAI(
                        model="google/gemini-pro-1.5",  # OpenRouterä¸­çš„Geminiæ¨¡å‹
                        temperature=0.7,
                        api_key=api_key,
                        base_url="https://openrouter.ai/api/v1"
                    )
                    logger.info("ğŸ” Vision APIå·²å¯ç”¨ (Gemini via OpenRouter - å›½å†…å¯ç”¨)")

                elif vision_provider == "openai-openrouter":
                    # ğŸ”¥ é€šè¿‡ OpenRouter ä½¿ç”¨ GPT-4o Vision (æ¨èå›½å†…ç”¨æˆ·)
                    from langchain_openai import ChatOpenAI
                    import os

                    api_key = os.getenv("OPENROUTER_API_KEY")
                    self.vision_llm = ChatOpenAI(
                        model="openai/gpt-4o",  # OpenRouterä¸­çš„GPT-4o
                        temperature=0.7,
                        api_key=api_key,
                        base_url="https://openrouter.ai/api/v1"
                    )
                    logger.info("ğŸ” Vision APIå·²å¯ç”¨ (GPT-4o via OpenRouter - å›½å†…å¯ç”¨)")

                else:
                    # OpenAI GPT-4 Vision
                    from langchain_openai import ChatOpenAI
                    self.vision_llm = ChatOpenAI(
                        model="gpt-4o",
                        temperature=0.7,
                        api_key=settings.llm.api_key,
                        base_url=settings.llm.api_base
                    )
                    logger.info("ğŸ” Vision APIå·²å¯ç”¨ (OpenAI GPT-4V)")

            except Exception as e:
                logger.warning(f"âš ï¸ Vision APIåˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_vision_api = False

        logger.info(f"ğŸ“ æ–‡ä»¶å¤„ç†å™¨åˆå§‹åŒ–: {self.upload_dir}")

    async def save_file(self, file_content: bytes, filename: str, session_id: str) -> Path:
        """
        ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶

        Args:
            file_content: æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
            filename: åŸå§‹æ–‡ä»¶å
            session_id: ä¼šè¯ID

        Returns:
            ä¿å­˜åçš„æ–‡ä»¶è·¯å¾„
        """
        # åˆ›å»ºä¼šè¯ä¸“å±ç›®å½•
        session_dir = self.upload_dir / session_id
        session_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶è·¯å¾„
        safe_filename = self._sanitize_filename(filename)
        file_path = session_dir / safe_filename

        # å¼‚æ­¥å†™å…¥æ–‡ä»¶
        async with aiofiles.open(file_path, 'wb') as f:
            await f.write(file_content)

        logger.info(f"âœ… æ–‡ä»¶å·²ä¿å­˜: {file_path} ({len(file_content)} bytes)")
        return file_path

    def _sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å®‰å…¨å­—ç¬¦"""
        import re
        # ä¿ç•™ä¸­æ–‡ã€å­—æ¯ã€æ•°å­—ã€ç‚¹ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦
        safe_name = re.sub(r'[^\w\u4e00-\u9fa5\.\-]', '_', filename)
        return safe_name

    async def extract_content(self, file_path: Path, content_type: str) -> Dict[str, Any]:
        """
        æ ¹æ®æ–‡ä»¶ç±»å‹æå–å†…å®¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            content_type: MIMEç±»å‹

        Returns:
            æå–ç»“æœå­—å…¸
        """
        logger.info(f"ğŸ“„ å¼€å§‹æå–æ–‡ä»¶å†…å®¹: {file_path.name} ({content_type})")

        try:
            if content_type == 'application/pdf':
                return await self._extract_pdf(file_path)

            elif content_type == 'text/plain':
                return await self._extract_text(file_path)

            elif content_type in ['image/png', 'image/jpeg', 'image/jpg']:
                return await self._extract_image(file_path)

            elif 'word' in content_type or content_type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':
                return await self._extract_word(file_path)

            elif 'excel' in content_type or 'spreadsheet' in content_type or content_type == 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet':
                return await self._extract_excel(file_path)

            else:
                return {
                    "type": "unknown",
                    "text": "",
                    "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {content_type}"
                }

        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶æå–å¤±è´¥: {file_path.name} - {str(e)}")
            return {
                "type": "error",
                "text": "",
                "error": f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}"
            }

    async def _extract_pdf(self, file_path: Path) -> Dict[str, Any]:
        """
        æå–PDFå†…å®¹ï¼ˆæ–‡æœ¬ï¼‰

        ä½¿ç”¨ pdfplumber æå–æ–‡æœ¬å†…å®¹
        """
        try:
            import pdfplumber
        except ImportError:
            logger.warning("âš ï¸ pdfplumber æœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨ PyPDF2")
            return await self._extract_pdf_pypdf2(file_path)

        text_content = []
        total_pages = 0

        try:
            with pdfplumber.open(file_path) as pdf:
                total_pages = len(pdf.pages)

                for page_num, page in enumerate(pdf.pages, 1):
                    text = page.extract_text()
                    if text and text.strip():
                        text_content.append(f"=== ç¬¬ {page_num} é¡µ ===\n{text}")

            full_text = "\n\n".join(text_content)

            logger.info(f"âœ… PDFæå–å®Œæˆ: {total_pages}é¡µ, {len(full_text)}å­—ç¬¦")

            return {
                "type": "pdf",
                "text": full_text,
                "pages": total_pages,
                "summary": f"PDFæ–‡æ¡£ï¼Œå…±{total_pages}é¡µï¼Œæå–æ–‡æœ¬{len(full_text)}å­—ç¬¦"
            }

        except Exception as e:
            logger.error(f"âŒ PDFæå–å¤±è´¥: {str(e)}")
            return {
                "type": "pdf",
                "text": "",
                "error": f"PDFå¤„ç†å¤±è´¥: {str(e)}"
            }

    async def _extract_pdf_pypdf2(self, file_path: Path) -> Dict[str, Any]:
        """
        ä½¿ç”¨ PyPDF2 æå–PDFå†…å®¹ï¼ˆfallbackï¼‰
        """
        try:
            import PyPDF2

            text_content = []

            with open(file_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                total_pages = len(pdf_reader.pages)

                for page_num, page in enumerate(pdf_reader.pages, 1):
                    text = page.extract_text()
                    if text and text.strip():
                        text_content.append(f"=== ç¬¬ {page_num} é¡µ ===\n{text}")

            full_text = "\n\n".join(text_content)

            return {
                "type": "pdf",
                "text": full_text,
                "pages": total_pages,
                "summary": f"PDFæ–‡æ¡£ï¼Œå…±{total_pages}é¡µï¼Œæå–æ–‡æœ¬{len(full_text)}å­—ç¬¦"
            }

        except Exception as e:
            return {
                "type": "pdf",
                "text": "",
                "error": f"PDFå¤„ç†å¤±è´¥: {str(e)}"
            }

    async def _extract_text(self, file_path: Path) -> Dict[str, Any]:
        """
        æå–TXTå†…å®¹ï¼ˆæ™ºèƒ½ç¼–ç æ£€æµ‹ï¼‰
        """
        # è¯»å–æ–‡ä»¶å­—èŠ‚
        async with aiofiles.open(file_path, 'rb') as f:
            raw_data = await f.read()

        # ä½¿ç”¨ chardet æ£€æµ‹ç¼–ç 
        detected = chardet.detect(raw_data)
        encoding = detected.get('encoding', 'utf-8')
        confidence = detected.get('confidence', 0)

        logger.info(f"ğŸ” æ£€æµ‹åˆ°ç¼–ç : {encoding} (ç½®ä¿¡åº¦: {confidence:.2%})")

        # å°è¯•è§£ç 
        encodings_to_try = [encoding, 'utf-8', 'gbk', 'gb2312', 'utf-16', 'latin-1']

        for enc in encodings_to_try:
            try:
                content = raw_data.decode(enc)
                logger.info(f"âœ… æˆåŠŸä½¿ç”¨ç¼–ç  {enc} è§£ç æ–‡æœ¬æ–‡ä»¶")

                return {
                    "type": "text",
                    "text": content,
                    "encoding": enc,
                    "length": len(content),
                    "summary": f"æ–‡æœ¬æ–‡ä»¶ï¼Œç¼–ç {enc}ï¼Œå…±{len(content)}å­—ç¬¦"
                }
            except (UnicodeDecodeError, AttributeError):
                continue

        logger.error("âŒ æ— æ³•è¯†åˆ«æ–‡æœ¬ç¼–ç ")
        return {
            "type": "text",
            "text": "",
            "error": "æ— æ³•è¯†åˆ«æ–‡æœ¬ç¼–ç "
        }

    async def _extract_image(self, file_path: Path) -> Dict[str, Any]:
        """
        æå–å›¾ç‰‡å†…å®¹

        ğŸ”¥ v3.8æ–°å¢: Vision APIåˆ†æå›¾ç‰‡å†…å®¹
        """
        try:
            from PIL import Image
            import base64

            img = Image.open(file_path)
            width, height = img.size
            format_name = img.format

            logger.info(f"ğŸ–¼ï¸ å›¾ç‰‡ä¿¡æ¯: {width}x{height}, {format_name}")

            # ğŸ”¥ ä½¿ç”¨Vision APIåˆ†æå›¾ç‰‡å†…å®¹
            vision_analysis = ""
            if self.enable_vision_api and self.vision_llm:
                try:
                    # è¯»å–å›¾ç‰‡ä¸ºbase64
                    with open(file_path, "rb") as image_file:
                        image_data = base64.b64encode(image_file.read()).decode()

                    # æ„é€ Vision APIè¯·æ±‚
                    vision_prompt = """è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œç‰¹åˆ«å…³æ³¨è®¾è®¡ç›¸å…³çš„å…ƒç´ ï¼š

1. **ä¸»è¦å†…å®¹**ï¼šæè¿°å›¾ç‰‡ä¸­çš„ä¸»è¦å¯¹è±¡ã€åœºæ™¯æˆ–è®¾è®¡
2. **é£æ ¼ç‰¹å¾**ï¼šè‰²å½©ã€æè´¨ã€é£æ ¼ç±»å‹ï¼ˆç°ä»£/ç®€çº¦/åŒ—æ¬§ç­‰ï¼‰
3. **ç©ºé—´å¸ƒå±€**ï¼šå¦‚æœæ˜¯å®¤å†…è®¾è®¡ï¼Œæè¿°ç©ºé—´åˆ’åˆ†å’ŒåŠ¨çº¿
4. **è®¾è®¡äº®ç‚¹**ï¼šå€¼å¾—å€Ÿé‰´çš„è®¾è®¡ç»†èŠ‚
5. **æ–‡å­—ä¿¡æ¯**ï¼šå›¾ç‰‡ä¸­åŒ…å«çš„ä»»ä½•æ–‡å­—æˆ–æ ‡è¯†

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œèšç„¦äºè®¾è®¡å’Œç©ºé—´è§„åˆ’ç›¸å…³çš„ä¿¡æ¯ã€‚"""

                    # è°ƒç”¨Vision API
                    import asyncio
                    from langchain_core.messages import HumanMessage

                    message = HumanMessage(
                        content=[
                            {"type": "text", "text": vision_prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
                            }
                        ]
                    )

                    # ğŸ”¥ æ·»åŠ 30ç§’è¶…æ—¶ä¿æŠ¤
                    try:
                        response = await asyncio.wait_for(
                            asyncio.to_thread(self.vision_llm.invoke, [message]),
                            timeout=30.0
                        )
                        vision_analysis = response.content
                        logger.info(f"âœ… Vision APIåˆ†æå®Œæˆ: {len(vision_analysis)}å­—ç¬¦")
                    except asyncio.TimeoutError:
                        logger.warning(f"âš ï¸ Vision APIè°ƒç”¨è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
                        vision_analysis = "[Vision APIè°ƒç”¨è¶…æ—¶ï¼Œè·³è¿‡å›¾ç‰‡åˆ†æ]"

                except Exception as e:
                    logger.warning(f"âš ï¸ Vision APIè°ƒç”¨å¤±è´¥: {e}")
                    vision_analysis = f"[Vision APIåˆ†æå¤±è´¥: {str(e)}]"

            # æ„é€ è¿”å›æ–‡æœ¬
            if vision_analysis:
                text_content = f"""[å›¾ç‰‡æ–‡ä»¶: {file_path.name}]
å°ºå¯¸: {width}x{height}
æ ¼å¼: {format_name}

## AIè§†è§‰åˆ†æ

{vision_analysis}
"""
            else:
                text_content = f"[å›¾ç‰‡æ–‡ä»¶: {file_path.name}, å°ºå¯¸ {width}x{height}, æ ¼å¼ {format_name}]"

            return {
                "type": "image",
                "text": text_content,
                "width": width,
                "height": height,
                "format": format_name,
                "vision_analysis": vision_analysis,
                "summary": f"å›¾ç‰‡æ–‡ä»¶ï¼Œ{width}x{height}ï¼Œæ ¼å¼{format_name}" + (" (å·²AIåˆ†æ)" if vision_analysis else "")
            }

        except Exception as e:
            return {
                "type": "image",
                "text": f"[å›¾ç‰‡æ–‡ä»¶: {file_path.name}]",
                "error": f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}"
            }


    async def _extract_word(self, file_path: Path) -> Dict[str, Any]:
        """
        æå–Wordæ–‡æ¡£å†…å®¹ (.docx)

        ğŸ”¥ v3.8æ–°å¢: æ”¯æŒWordæ–‡æ¡£
        """
        try:
            from docx import Document

            doc = Document(file_path)

            # æå–æ®µè½
            paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]

            # æå–è¡¨æ ¼
            tables_text = []
            for table_idx, table in enumerate(doc.tables, 1):
                table_data = []
                for row in table.rows:
                    row_data = [cell.text.strip() for cell in row.cells]
                    table_data.append(" | ".join(row_data))

                if table_data:
                    tables_text.append(f"\n[è¡¨æ ¼ {table_idx}]\n" + "\n".join(table_data))

            full_text = "\n\n".join(paragraphs)
            if tables_text:
                full_text += "\n\n" + "\n".join(tables_text)

            logger.info(f"âœ… Wordæå–å®Œæˆ: {len(paragraphs)}æ®µè½, {len(doc.tables)}è¡¨æ ¼")

            return {
                "type": "word",
                "text": full_text,
                "paragraphs": len(paragraphs),
                "tables": len(doc.tables),
                "summary": f"Wordæ–‡æ¡£ï¼Œ{len(paragraphs)}æ®µè½ï¼Œ{len(doc.tables)}è¡¨æ ¼"
            }

        except Exception as e:
            logger.error(f"âŒ Wordæå–å¤±è´¥: {str(e)}")
            return {
                "type": "word",
                "text": "",
                "error": f"Wordå¤„ç†å¤±è´¥: {str(e)}"
            }

    async def _extract_excel(self, file_path: Path) -> Dict[str, Any]:
        """
        æå–Excelè¡¨æ ¼å†…å®¹ (.xlsx)

        ğŸ”¥ v3.8æ–°å¢: æ”¯æŒExcelè¡¨æ ¼
        """
        try:
            import pandas as pd

            # è¯»å–æ‰€æœ‰å·¥ä½œè¡¨
            dfs = pd.read_excel(file_path, sheet_name=None)

            text_parts = []
            total_rows = 0

            for sheet_name, df in dfs.items():
                total_rows += len(df)

                text_parts.append(f"\n=== å·¥ä½œè¡¨: {sheet_name} ({len(df)}è¡Œ x {len(df.columns)}åˆ—) ===\n")

                # è½¬æ¢ä¸ºæ–‡æœ¬è¡¨æ ¼ï¼ˆé™åˆ¶å‰100è¡Œï¼‰
                if len(df) > 100:
                    text_parts.append(df.head(100).to_string(index=False))
                    text_parts.append(f"\n... (å…±{len(df)}è¡Œï¼Œä»…æ˜¾ç¤ºå‰100è¡Œ) ...\n")
                else:
                    text_parts.append(df.to_string(index=False))

            full_text = "\n".join(text_parts)

            logger.info(f"âœ… Excelæå–å®Œæˆ: {len(dfs)}å·¥ä½œè¡¨, {total_rows}è¡Œ")

            return {
                "type": "excel",
                "text": full_text,
                "sheets": len(dfs),
                "total_rows": total_rows,
                "summary": f"Excelè¡¨æ ¼ï¼Œ{len(dfs)}å·¥ä½œè¡¨ï¼Œå…±{total_rows}è¡Œ"
            }

        except Exception as e:
            logger.error(f"âŒ Excelæå–å¤±è´¥: {str(e)}")
            return {
                "type": "excel",
                "text": "",
                "error": f"Excelå¤„ç†å¤±è´¥: {str(e)}"
            }



def build_combined_input(user_text: str, file_contents: list[Dict[str, Any]]) -> str:
    """
    åˆå¹¶ç”¨æˆ·è¾“å…¥å’Œæ–‡ä»¶å†…å®¹ï¼Œç”Ÿæˆç»Ÿä¸€çš„åˆ†æè¾“å…¥

    Args:
        user_text: ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
        file_contents: æ–‡ä»¶æå–ç»“æœåˆ—è¡¨

    Returns:
        åˆå¹¶åçš„å®Œæ•´è¾“å…¥æ–‡æœ¬
    """
    parts = []

    # 1. ç”¨æˆ·åŸå§‹è¾“å…¥
    if user_text.strip():
        parts.append(f"## ç”¨æˆ·éœ€æ±‚æè¿°\n\n{user_text}\n")

    # 2. é™„ä»¶å†…å®¹
    if file_contents:
        parts.append("## é™„ä»¶ææ–™\n")
        parts.append("**è¯´æ˜**: ä»¥ä¸‹é™„ä»¶ä¸ºç”¨æˆ·æä¾›çš„èƒŒæ™¯èµ„æ–™å’Œå‚è€ƒä¿¡æ¯ï¼Œä»…ä¾›å‚è€ƒã€‚è¯·æ ¹æ®ã€Œç”¨æˆ·éœ€æ±‚æè¿°ã€ä¸­çš„æ˜ç¡®è¦æ±‚ï¼Œç»“åˆè¿™äº›èƒŒæ™¯èµ„æ–™è¿›è¡Œåˆ†æï¼Œè€Œä¸æ˜¯å°†æ‰€æœ‰é™„ä»¶å†…å®¹éƒ½è§†ä¸ºå¿…é¡»å®ç°çš„éœ€æ±‚ã€‚\n")

        for idx, content in enumerate(file_contents, 1):
            file_type = content.get("type", "unknown")
            text = content.get("text", "")
            summary = content.get("summary", "")
            error = content.get("error", "")

            if error:
                parts.append(f"### é™„ä»¶ {idx} ({file_type.upper()}) - å¤„ç†å¤±è´¥\n\n{error}\n")
                continue

            # æ™ºèƒ½æˆªæ–­ï¼ˆä¿ç•™é‡è¦ä¿¡æ¯ï¼‰
            if len(text) > 5000:
                text = text[:5000] + f"\n\n...(å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­ï¼Œå®Œæ•´å†…å®¹å…±{len(text)}å­—ç¬¦)..."

            parts.append(f"### é™„ä»¶ {idx} ({file_type.upper()})\n")
            if summary:
                parts.append(f"**æ‘˜è¦**: {summary}\n")
            parts.append(f"\n{text}\n")

    combined = "\n".join(parts)

    logger.info(f"âœ… å†…å®¹åˆå¹¶å®Œæˆ: åŸå§‹æ–‡æœ¬={len(user_text)}å­—ç¬¦, æ–‡ä»¶={len(file_contents)}ä¸ª, åˆå¹¶å={len(combined)}å­—ç¬¦")

    return combined


# å…¨å±€å®ä¾‹
# ğŸ”¥ å¯é€šè¿‡ç¯å¢ƒå˜é‡ VISION_PROVIDER é€‰æ‹©ï¼šopenai æˆ– gemini
import os
vision_provider = os.getenv("VISION_PROVIDER", "openai")  # é»˜è®¤ OpenAI
file_processor = FileProcessor(vision_provider=vision_provider)
