"""
å›¾åƒç”ŸæˆæœåŠ¡ - Gemini Nano Banana Pro é›†æˆ

é€šè¿‡ OpenRouter è°ƒç”¨ Gemini 2.5 Flash çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚

æ”¯æŒæ¨¡å‹:
- google/gemini-2.5-flash-preview-image-generation (æ¨èï¼Œæ€§ä»·æ¯”é«˜)
- google/gemini-2.0-flash-exp:free (å…è´¹ç‰ˆï¼Œè´¨é‡ç¨ä½)

ä½¿ç”¨æ–¹å¼:
    from services.image_generator import ImageGeneratorService
    
    generator = ImageGeneratorService()
    result = await generator.generate_image(
        prompt="ç°ä»£ç®€çº¦é£æ ¼å®¢å…æ¦‚å¿µå›¾ï¼Œè‡ªç„¶å…‰çº¿ï¼Œæœ¨è´¨å®¶å…·",
        aspect_ratio="16:9"
    )
    # result = {"image_url": "data:image/png;base64,...", "revised_prompt": "..."}
"""

import os
import base64
import httpx
import json
from typing import Optional, Dict, Any, List
from loguru import logger
from pydantic import BaseModel, Field
from enum import Enum


class ImageAspectRatio(str, Enum):
    """æ”¯æŒçš„å›¾åƒå®½é«˜æ¯”"""
    SQUARE = "1:1"          # æ­£æ–¹å½¢ï¼Œç¤¾äº¤åª’ä½“
    LANDSCAPE = "16:9"      # æ¨ªå‘ï¼Œæ¼”ç¤ºæ–‡ç¨¿
    PORTRAIT = "9:16"       # çºµå‘ï¼Œæ‰‹æœºå±•ç¤º
    WIDE = "4:3"            # ä¼ ç»Ÿå®½å±
    ULTRAWIDE = "21:9"      # è¶…å®½å±


class ImageGenerationRequest(BaseModel):
    """å›¾åƒç”Ÿæˆè¯·æ±‚"""
    prompt: str = Field(..., description="å›¾åƒç”Ÿæˆæç¤ºè¯")
    aspect_ratio: ImageAspectRatio = Field(default=ImageAspectRatio.LANDSCAPE, description="å®½é«˜æ¯”")
    style: Optional[str] = Field(default=None, description="é£æ ¼æç¤ºï¼Œå¦‚ 'architectural rendering', 'watercolor'")
    negative_prompt: Optional[str] = Field(default=None, description="è´Ÿé¢æç¤ºè¯ï¼ˆä¸å¸Œæœ›å‡ºç°çš„å…ƒç´ ï¼‰")


class ImageGenerationResult(BaseModel):
    """å›¾åƒç”Ÿæˆç»“æœ"""
    success: bool
    image_url: Optional[str] = Field(default=None, description="Base64 Data URL æˆ–è¿œç¨‹ URL")
    image_data: Optional[bytes] = Field(default=None, description="åŸå§‹å›¾åƒå­—èŠ‚æ•°æ®")
    revised_prompt: Optional[str] = Field(default=None, description="æ¨¡å‹ä¿®è®¢åçš„æç¤ºè¯")
    error: Optional[str] = Field(default=None, description="é”™è¯¯ä¿¡æ¯")
    model_used: Optional[str] = Field(default=None, description="å®é™…ä½¿ç”¨çš„æ¨¡å‹")    # ğŸ”¥ v7.60.5: Tokenè¿½è¸ªå­—æ®µï¼ˆåç½®Tokenè¿½è¸ªï¼‰
    prompt_tokens: int = Field(default=0, description="æç¤ºè¯Tokenæ•°")
    completion_tokens: int = Field(default=0, description="ç”ŸæˆTokenæ•°")
    total_tokens: int = Field(default=0, description="æ€»Tokenæ•°")

class ImageGeneratorService:
    """
    å›¾åƒç”ŸæˆæœåŠ¡ - é€šè¿‡ OpenRouter è°ƒç”¨ Gemini Nano Banana Pro
    
    ç‰¹ç‚¹:
    - æ”¯æŒ Gemini 3 Pro å›¾åƒç”Ÿæˆ (Nano Banana Pro)
    - è‡ªåŠ¨æ„å»ºè®¾è®¡é¢†åŸŸä¸“ä¸šæç¤ºè¯
    - è¿”å› Base64 Data URL ä¾¿äºå‰ç«¯ç›´æ¥æ˜¾ç¤º
    - æ”¯æŒå¤šç§å®½é«˜æ¯”
    - ä»·æ ¼: $2/M input, $12/M output
    """
    
    # é»˜è®¤æ¨¡å‹ - Nano Banana Pro (Gemini 3 Pro Image Preview)
    DEFAULT_MODEL = "google/gemini-3-pro-image-preview"
    # å¤‡é€‰æ¨¡å‹ - Nano Banana (Gemini 2.5 Flash Image)
    FALLBACK_MODEL = "google/gemini-2.5-flash-image"
    
    # è®¾è®¡é¢†åŸŸé£æ ¼å¢å¼ºæç¤ºè¯
    DESIGN_STYLE_ENHANCERS = {
        "interior": "professional interior design visualization, photorealistic rendering, natural lighting",
        "product": "product design concept, clean background, studio lighting, high-end commercial photography",
        "branding": "brand identity design, clean vector style, modern minimalist aesthetic",
        "architecture": "architectural visualization, professional rendering, dramatic lighting",
        "default": "professional design concept, high quality, detailed"
    }
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        base_url: str = "https://openrouter.ai/api/v1",
        timeout: int = 120,
    ):
        """
        åˆå§‹åŒ–å›¾åƒç”ŸæˆæœåŠ¡
        
        Args:
            api_key: OpenRouter API Key (é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–)
            model: ä½¿ç”¨çš„æ¨¡å‹ (é»˜è®¤ä½¿ç”¨ Gemini 2.5 Flash)
            base_url: OpenRouter API åœ°å€
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ (å›¾åƒç”Ÿæˆè¾ƒæ…¢ï¼Œé»˜è®¤ 120 ç§’)
        """
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("âŒ Missing OPENROUTER_API_KEY environment variable")
        
        self.model = model or os.getenv("IMAGE_GENERATION_MODEL", self.DEFAULT_MODEL)
        self.base_url = base_url
        self.timeout = timeout
        
        # OpenRouter éœ€è¦çš„ headers
        self.app_name = os.getenv("OPENROUTER_APP_NAME", "Intelligent Project Analyzer")
        self.site_url = os.getenv("OPENROUTER_SITE_URL", "https://github.com/your-repo")
        
        # ğŸ†• v7.50: LLM æç¤ºè¯æå–æ¨¡å‹ï¼ˆä½¿ç”¨è½»é‡æ¨¡å‹é™ä½æˆæœ¬ï¼‰
        self.prompt_extraction_model = os.getenv(
            "PROMPT_EXTRACTION_MODEL", 
            "openai/gpt-4o-mini"  # é»˜è®¤ä½¿ç”¨ gpt-4o-miniï¼Œæˆæœ¬ä½ä¸”é€Ÿåº¦å¿«
        )
        
        logger.info(f"ğŸ¨ ImageGeneratorService initialized: model={self.model}")
    
    async def _llm_extract_visual_prompt(
        self,
        expert_content: str,
        expert_name: str = "",
        project_type: str = "interior",
        top_constraints: str = ""
    ) -> str:
        """
        ğŸ†• v7.50: ä½¿ç”¨ LLM ä»ä¸“å®¶æŠ¥å‘Šä¸­æå–é«˜è´¨é‡å›¾åƒç”Ÿæˆæç¤ºè¯
        
        ç›¸æ¯”æ­£åˆ™æå–çš„ä¼˜åŠ¿ï¼š
        1. ç†è§£è¯­ä¹‰ï¼Œæ•æ‰æ·±å±‚è®¾è®¡æ„å›¾
        2. æå–å®Œæ•´çš„è§†è§‰å™äº‹ï¼Œè€Œéç¢ç‰‡åŒ–å…³é”®è¯
        3. è‡ªåŠ¨æ„å»ºç¬¦åˆå›¾åƒç”Ÿæˆæ¨¡å‹æœŸæœ›çš„ prompt ç»“æ„
        
        Args:
            expert_content: ä¸“å®¶æŠ¥å‘Šå†…å®¹
            expert_name: ä¸“å®¶åç§°ï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰
            project_type: é¡¹ç›®ç±»å‹
            top_constraints: é¡¹ç›®é¡¶å±‚çº¦æŸ
        
        Returns:
            ä¼˜åŒ–åçš„è‹±æ–‡å›¾åƒç”Ÿæˆæç¤ºè¯ (100-150 words)
        """
        # é™åˆ¶è¾“å…¥é•¿åº¦ä»¥æ§åˆ¶æˆæœ¬
        content_preview = expert_content[:2500] if len(expert_content) > 2500 else expert_content
        
        # é¡¹ç›®ç±»å‹åˆ°åœºæ™¯æè¿°çš„æ˜ å°„
        type_context = {
            "interior": "interior design / residential space",
            "architecture": "architectural / building exterior",
            "product": "product design / industrial design",
            "branding": "brand identity / visual design",
        }.get(project_type, "design concept")
        
        system_prompt = """You are a professional image prompt engineer specializing in design visualization.

Your task is to extract visual elements from design analysis reports and create high-quality prompts for AI image generation (like Midjourney, DALL-E, Gemini).

Output Requirements:
1. Write in English only
2. 100-150 words, no more
3. Focus on VISUAL elements: materials, colors, lighting, atmosphere, spatial relationships
4. Include specific design details that make the concept unique
5. Use professional architectural/interior photography terminology
6. End with quality descriptors like "professional rendering, photorealistic, high detail"

Do NOT include:
- Abstract concepts or emotions that can't be visualized
- Chinese characters
- Explanations or meta-commentary
- Client names or personal information

Output format: Just the prompt, nothing else."""

        user_prompt = f"""Design Context: {type_context}
Expert Role: {expert_name if expert_name else "Design Expert"}

Project Constraints:
{top_constraints if top_constraints else "Not specified"}

Expert Analysis Content:
{content_preview}

---
Generate an optimized image prompt based on the above design analysis:"""

        try:
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers=self._build_headers(),
                    json={
                        "model": self.prompt_extraction_model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 300,
                    }
                )
                
                if response.status_code != 200:
                    logger.warning(f"âš ï¸ LLM prompt extraction failed: {response.status_code}")
                    return ""
                
                result = response.json()
                extracted_prompt = result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
                
                if extracted_prompt:
                    logger.info(f"âœ… [v7.50] LLM æå–æç¤ºè¯æˆåŠŸ ({len(extracted_prompt)} å­—ç¬¦)")
                    logger.debug(f"ğŸ“ æå–çš„æç¤ºè¯: {extracted_prompt[:200]}...")
                    return extracted_prompt
                else:
                    logger.warning("âš ï¸ LLM è¿”å›ç©ºæç¤ºè¯")
                    return ""
                    
        except Exception as e:
            logger.warning(f"âš ï¸ LLM prompt extraction error: {e}")
            return ""
    
    async def _enhance_prompt_with_user_input(
        self,
        user_prompt: str,
        expert_context: str = "",
        conversation_history: str = "",
        project_constraints: str = "",
        vision_analysis: Optional[str] = None
    ) -> str:
        """
        ğŸ†• v7.50: ä¸ºç¼–è¾‘ç¯èŠ‚ä¼˜åŒ–ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        ğŸ”¥ v7.61: æ·»åŠ  Vision åˆ†æç»“æœé›†æˆ
        
        å°†ç”¨æˆ·çš„ç®€çŸ­æè¿°æ‰©å±•ä¸ºä¸“ä¸šçš„å›¾åƒç”Ÿæˆæç¤ºè¯ï¼Œ
        åŒæ—¶ä¿æŒä¸ä¸“å®¶æŠ¥å‘Šå†…å®¹å’Œå¯¹è¯å†å²çš„è¿è´¯æ€§ã€‚
        
        Args:
            user_prompt: ç”¨æˆ·è¾“å…¥çš„æè¿°
            expert_context: ç›¸å…³ä¸“å®¶æŠ¥å‘Šæ‘˜è¦
            conversation_history: ä¹‹å‰çš„å¯¹è¯è®°å½•
            project_constraints: é¡¹ç›®çº¦æŸ
            vision_analysis: Vision æ¨¡å‹åˆ†æçš„å‚è€ƒå›¾ç‰¹å¾ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            ä¼˜åŒ–åçš„è‹±æ–‡å›¾åƒç”Ÿæˆæç¤ºè¯
        """
        system_prompt = """You are a professional image prompt engineer. 
Enhance the user's brief description into a detailed, professional image generation prompt.

Requirements:
1. Write in English only, 80-120 words
2. Preserve the user's core intent and specific requests
3. Add professional visual details: materials, lighting, composition, atmosphere
4. Incorporate relevant context from conversation history
5. Maintain design coherence with the expert's analysis
6. End with quality descriptors

Output: Just the enhanced prompt, no explanations."""

        context_block = ""
        # ğŸ”¥ v7.61: Vision åˆ†æä¼˜å…ˆçº§æœ€é«˜ï¼ˆå¦‚æœæœ‰å‚è€ƒå›¾ï¼‰
        if vision_analysis:
            context_block += f"\nReference Image Analysis (high priority, maintain these features):\n{vision_analysis[:800]}\n"
        if expert_context:
            context_block += f"\nExpert Analysis Context (for reference):\n{expert_context[:800]}\n"
        if conversation_history:
            context_block += f"\nConversation History:\n{conversation_history[-500:]}\n"
        if project_constraints:
            context_block += f"\nProject Constraints:\n{project_constraints[:300]}\n"

        user_message = f"""{context_block}
User's current request:
{user_prompt}

---
Generate an enhanced, professional image prompt:"""

        try:
            async with httpx.AsyncClient(timeout=20) as client:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers=self._build_headers(),
                    json={
                        "model": self.prompt_extraction_model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_message}
                        ],
                        "temperature": 0.6,
                        "max_tokens": 250,
                    }
                )
                
                if response.status_code != 200:
                    logger.warning(f"âš ï¸ Prompt enhancement failed: {response.status_code}")
                    return user_prompt  # å¤±è´¥æ—¶è¿”å›åŸå§‹æç¤ºè¯
                
                result = response.json()
                enhanced = result.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
                
                if enhanced and len(enhanced) > len(user_prompt):
                    logger.info(f"âœ… [v7.50] ç”¨æˆ·æç¤ºè¯å¢å¼ºæˆåŠŸ: {len(user_prompt)} â†’ {len(enhanced)} å­—ç¬¦")
                    return enhanced
                else:
                    return user_prompt
                    
        except Exception as e:
            logger.warning(f"âš ï¸ Prompt enhancement error: {e}, using original")
            return user_prompt
    
    def _build_headers(self) -> Dict[str, str]:
        """æ„å»ºè¯·æ±‚å¤´"""
        return {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": self.site_url,
            "X-Title": self.app_name,
        }
    
    def _enhance_prompt(
        self, 
        prompt: str, 
        style: Optional[str] = None,
        aspect_ratio: ImageAspectRatio = ImageAspectRatio.LANDSCAPE
    ) -> str:
        """
        å¢å¼ºæç¤ºè¯ï¼Œæ·»åŠ è®¾è®¡é¢†åŸŸä¸“ä¸šæè¿°
        
        Args:
            prompt: åŸå§‹æç¤ºè¯
            style: é£æ ¼ç±»å‹ (interior/product/branding/architecture)
            aspect_ratio: å®½é«˜æ¯”
        
        Returns:
            å¢å¼ºåçš„æç¤ºè¯
        """
        # é€‰æ‹©é£æ ¼å¢å¼ºå™¨
        style_key = style.lower() if style else "default"
        enhancer = self.DESIGN_STYLE_ENHANCERS.get(style_key, self.DESIGN_STYLE_ENHANCERS["default"])
        
        # æ·»åŠ å®½é«˜æ¯”è¯´æ˜ï¼ˆæŸäº›æ¨¡å‹éœ€è¦ï¼‰
        ratio_hint = f"aspect ratio {aspect_ratio.value}"
        
        # ç»„åˆæœ€ç»ˆæç¤ºè¯
        enhanced = f"{prompt}. {enhancer}, {ratio_hint}"
        
        logger.debug(f"ğŸ¨ Enhanced prompt: {enhanced[:100]}...")
        return enhanced
    
    async def generate_image(
        self,
        prompt: str,
        aspect_ratio: ImageAspectRatio = ImageAspectRatio.LANDSCAPE,
        style: Optional[str] = None,
        negative_prompt: Optional[str] = None,
    ) -> ImageGenerationResult:
        """
        ç”Ÿæˆå›¾åƒ
        
        Args:
            prompt: å›¾åƒæè¿°æç¤ºè¯
            aspect_ratio: å®½é«˜æ¯”
            style: é£æ ¼ç±»å‹ (interior/product/branding/architecture)
            negative_prompt: è´Ÿé¢æç¤ºè¯
        
        Returns:
            ImageGenerationResult åŒ…å«å›¾åƒ URL æˆ–é”™è¯¯ä¿¡æ¯
        """
        try:
            # å¢å¼ºæç¤ºè¯
            enhanced_prompt = self._enhance_prompt(prompt, style, aspect_ratio)
            
            # æ„å»ºè¯·æ±‚ä½“ - ä½¿ç”¨ Gemini çš„ multimodal æ ¼å¼
            # Gemini å›¾åƒç”Ÿæˆé€šè¿‡ chat completion with responseModalities
            request_body = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": enhanced_prompt
                    }
                ],
                # Gemini ç‰¹å®šå‚æ•° - è¯·æ±‚å›¾åƒè¾“å‡º
                "modalities": ["text", "image"],  # å…è®¸å›¾åƒè¾“å‡º
                "max_tokens": 4096,  # ğŸ”¥ v7.60.3: å¢åŠ åˆ°4096ä»¥æ”¯æŒå›¾åƒç”Ÿæˆ (åŸ1024ä¸è¶³ï¼Œæ‰€æœ‰tokenè¢«reasoningæ¶ˆè€—)
                "temperature": 0.8,  # å›¾åƒç”Ÿæˆéœ€è¦ä¸€å®šåˆ›é€ æ€§
            }
            
            # æ·»åŠ è´Ÿé¢æç¤ºè¯ï¼ˆå¦‚æœæ”¯æŒï¼‰
            if negative_prompt:
                request_body["messages"][0]["content"] += f"\n\nDo NOT include: {negative_prompt}"
            
            logger.info(f"ğŸ¨ Generating image with {self.model}...")
            logger.debug(f"ğŸ“¤ Request: {request_body}")
            
            # å‘é€è¯·æ±‚
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers=self._build_headers(),
                    json=request_body
                )
                
                if response.status_code != 200:
                    error_text = response.text
                    logger.error(f"âŒ Image generation failed: {response.status_code} - {error_text}")
                    return ImageGenerationResult(
                        success=False,
                        error=f"API error {response.status_code}: {error_text[:200]}",
                        model_used=self.model
                    )
                
                result = response.json()
                logger.debug(f"ğŸ“¥ Response: {str(result)[:500]}...")
                
                # è§£æå“åº” - Gemini è¿”å›çš„å›¾åƒåœ¨ content ä¸­
                return self._parse_response(result, enhanced_prompt)
                
        except httpx.TimeoutException:
            logger.error(f"âŒ Image generation timeout after {self.timeout}s")
            return ImageGenerationResult(
                success=False,
                error=f"Request timeout after {self.timeout} seconds",
                model_used=self.model
            )
        except Exception as e:
            logger.error(f"âŒ Image generation error: {e}")
            return ImageGenerationResult(
                success=False,
                error=str(e),
                model_used=self.model
            )
    
    async def generate_with_vision_reference(
        self,
        user_prompt: str,
        reference_image: str,
        aspect_ratio: ImageAspectRatio = ImageAspectRatio.LANDSCAPE,
        style: Optional[str] = None,
        vision_weight: float = 0.7
    ) -> ImageGenerationResult:
        """
        ğŸ”¥ v7.61: ä½¿ç”¨ Vision åˆ†æå‚è€ƒå›¾åç”Ÿæˆæ–°å›¾åƒ
        
        ä¸¤é˜¶æ®µæµç¨‹ï¼š
        1. Vision æ¨¡å‹åˆ†æå‚è€ƒå›¾ â†’ æå–è§†è§‰ç‰¹å¾
        2. å°† Vision ç‰¹å¾ + ç”¨æˆ·æŒ‡ä»¤æ··åˆ â†’ ç”Ÿæˆæ–°å›¾åƒ
        
        Args:
            user_prompt: ç”¨æˆ·ä¿®æ”¹æŒ‡ä»¤ï¼ˆå¦‚"ä¿ç•™å…¶ä»–ï¼Œåªå–æ¶ˆåŠå…¬æ¡Œ"ï¼‰
            reference_image: å‚è€ƒå›¾åƒï¼ˆbase64 æˆ– URLï¼‰
            aspect_ratio: å®½é«˜æ¯”
            style: é£æ ¼ç±»å‹
            vision_weight: Vision ç‰¹å¾æƒé‡ (0-1)ï¼Œé»˜è®¤ 0.7
        
        Returns:
            ImageGenerationResult åŒ…å«ç”Ÿæˆçš„å›¾åƒ
        """
        try:
            logger.info(f"ğŸ¨ [v7.61] å¼€å§‹ Vision + ç”Ÿæˆæ··åˆæµç¨‹")
            
            # Stage 1: Vision åˆ†æå‚è€ƒå›¾
            from .vision_service import get_vision_service
            vision_service = get_vision_service()
            
            logger.info("ğŸ” Stage 1: Vision åˆ†æå‚è€ƒå›¾...")
            vision_result = await vision_service.analyze_design_image(
                image_data=reference_image,
                analysis_type="comprehensive"
            )
            
            if not vision_result.success:
                logger.warning(f"âš ï¸ Vision åˆ†æå¤±è´¥: {vision_result.error}")
                logger.info("â¡ï¸ é™çº§åˆ°çº¯æ–‡æœ¬ç”Ÿæˆæ¨¡å¼")
                # é™çº§ï¼šä¸ä½¿ç”¨ Vision ç‰¹å¾
                return await self.generate_image(
                    prompt=user_prompt,
                    aspect_ratio=aspect_ratio,
                    style=style
                )
            
            logger.info(f"âœ… Vision åˆ†ææˆåŠŸ: {len(vision_result.features or {})} ä¸ªç‰¹å¾")
            
            # Stage 2: æ··åˆæç¤ºè¯ï¼ˆVision ç‰¹å¾ + ç”¨æˆ·æŒ‡ä»¤ï¼‰
            vision_analysis_text = vision_result.analysis or ""
            
            # æå–ç»“æ„åŒ–ç‰¹å¾ä½œä¸ºè¡¥å……
            features = vision_result.features or {}
            if features.get("colors"):
                vision_analysis_text += f"\nä¸»è‰²è°ƒ: {', '.join(features['colors'][:3])}"
            if features.get("styles"):
                vision_analysis_text += f"\né£æ ¼: {', '.join(features['styles'][:3])}"
            if features.get("materials"):
                vision_analysis_text += f"\næè´¨: {', '.join(features['materials'][:3])}"
            
            logger.info("ğŸ”€ Stage 2: æ··åˆæç¤ºè¯ï¼ˆVision + ç”¨æˆ·æŒ‡ä»¤ï¼‰...")
            
            # ä½¿ç”¨ _enhance_prompt_with_user_input è¿›è¡Œæ··åˆ
            # vision_analysis ä¼šè¢«ä¼˜å…ˆæ³¨å…¥åˆ° context
            enhanced_prompt = await self._enhance_prompt_with_user_input(
                user_prompt=user_prompt,
                vision_analysis=vision_analysis_text
            )
            
            logger.info("ğŸ¨ Stage 3: ç”Ÿæˆæ–°å›¾åƒ...")
            # ä½¿ç”¨å¢å¼ºåçš„æç¤ºè¯ç”Ÿæˆå›¾åƒ
            result = await self.generate_image(
                prompt=enhanced_prompt,
                aspect_ratio=aspect_ratio,
                style=style
            )
            
            # åœ¨ç»“æœä¸­æ ‡è®°ä½¿ç”¨äº† Vision
            if result.success:
                logger.info("âœ… Vision + ç”Ÿæˆæµç¨‹å®Œæˆ")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Vision + ç”Ÿæˆæµç¨‹å¤±è´¥: {e}")
            return ImageGenerationResult(
                success=False,
                error=f"Vision generation failed: {e}",
                model_used=self.model
            )
    
    def _parse_response(self, response: Dict[str, Any], prompt: str) -> ImageGenerationResult:
        """
        è§£æ OpenRouter/Gemini å“åº”
        
        ğŸ”¥ v7.38.1: OpenRouter å›¾åƒç”Ÿæˆæ­£ç¡®å“åº”æ ¼å¼ (æ¥è‡ªå®˜æ–¹æ–‡æ¡£):
        {
            "choices": [{
                "message": {
                    "role": "assistant",
                    "content": "I've generated a beautiful sunset image for you.",
                    "images": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA..."
                            }
                        }
                    ]
                }
            }],
            "usage": {
                "prompt_tokens": 150,
                "completion_tokens": 1500,
                "total_tokens": 1650
            }
        }
        """
        try:
            # ğŸ”¥ v7.60.5: æå–Tokenä½¿ç”¨ä¿¡æ¯ï¼ˆåç½®Tokenè¿½è¸ªï¼‰
            usage = response.get("usage", {})
            prompt_tokens = usage.get("prompt_tokens", 0)
            completion_tokens = usage.get("completion_tokens", 0)
            total_tokens = usage.get("total_tokens", 0)
            
            if total_tokens > 0:
                logger.info(f"âœ… [Tokenæå–-å›¾åƒç”Ÿæˆ] usage -> {total_tokens} tokens (prompt: {prompt_tokens}, completion: {completion_tokens})")
            
            choices = response.get("choices", [])
            if not choices:
                return ImageGenerationResult(
                    success=False,
                    error="No choices in response",
                    model_used=self.model,
                    # ğŸ”¥ v7.60.5
                    prompt_tokens=prompt_tokens,
                    completion_tokens=completion_tokens,
                    total_tokens=total_tokens
                )
            
            # ğŸ”¥ v7.60.3: æ£€æµ‹Tokenè€—å°½æƒ…å†µ
            finish_reason = choices[0].get("finish_reason", "")
            if finish_reason in ("length", "MAX_TOKENS"):
                logger.warning(f"âš ï¸ Token limit reached (finish_reason={finish_reason}). Consider increasing max_tokens.")
            
            message = choices[0].get("message", {})
            content = message.get("content", "")
            
            # ğŸ”¥ v7.38.1: é¦–å…ˆæ£€æŸ¥ message.images å­—æ®µ (OpenRouter æ ‡å‡†å“åº”æ ¼å¼)
            images = message.get("images", [])
            if images:
                for img in images:
                    if isinstance(img, dict):
                        # æ ¼å¼: {"type": "image_url", "image_url": {"url": "data:..."}}
                        image_url = img.get("image_url", {}).get("url")
                        if image_url:
                            logger.info(f"âœ… Image generated successfully via message.images")
                            # ğŸ”¥ v7.40.1: ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ promptï¼ˆå®é™…ä½¿ç”¨çš„æç¤ºè¯ï¼‰ï¼Œè€Œé API è¿”å›çš„ content
                            final_prompt = prompt
                            if isinstance(content, str) and content.strip() and len(content) > len(prompt):
                                final_prompt = content  # åªæœ‰å½“ content æ›´è¯¦ç»†æ—¶æ‰ä½¿ç”¨
                            return ImageGenerationResult(
                                success=True,
                                image_url=image_url,
                                revised_prompt=final_prompt,
                                model_used=self.model,
                                # ğŸ”¥ v7.60.5
                                prompt_tokens=prompt_tokens,
                                completion_tokens=completion_tokens,
                                total_tokens=total_tokens
                            )
            
            # å¤‡ç”¨æ–¹æ¡ˆ1: æ£€æŸ¥ content æ˜¯å¦ä¸ºå¤šæ¨¡æ€æ•°ç»„
            if isinstance(content, list):
                image_url = None
                text_content = ""
                
                for item in content:
                    if isinstance(item, dict):
                        if item.get("type") == "image_url":
                            image_url = item.get("image_url", {}).get("url")
                        elif item.get("type") == "text":
                            text_content = item.get("text", "")
                
                if image_url:
                    logger.info(f"âœ… Image generated successfully via content array")
                    # ğŸ”¥ v7.40.1: ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ prompt
                    return ImageGenerationResult(
                        success=True,
                        image_url=image_url,
                        revised_prompt=text_content if text_content.strip() else prompt,
                        model_used=self.model,
                        # ğŸ”¥ v7.60.5
                        prompt_tokens=prompt_tokens,
                        completion_tokens=completion_tokens,
                        total_tokens=total_tokens
                    )
            
            # å¤‡ç”¨æ–¹æ¡ˆ2: çº¯æ–‡æœ¬å“åº” - å¯èƒ½åŒ…å« base64 å›¾åƒ
            elif isinstance(content, str):
                if "data:image" in content:
                    import re
                    match = re.search(r'(data:image/[^;]+;base64,[A-Za-z0-9+/=]+)', content)
                    if match:
                        logger.info(f"âœ… Image extracted from content string")
                        return ImageGenerationResult(
                            success=True,
                            image_url=match.group(1),
                            revised_prompt=prompt,  # ä½¿ç”¨ä¼ å…¥çš„è¯¦ç»† prompt
                            model_used=self.model,
                            # ğŸ”¥ v7.60.5
                            prompt_tokens=prompt_tokens,
                            completion_tokens=completion_tokens,
                            total_tokens=total_tokens
                        )
            
            # æ²¡æœ‰æ‰¾åˆ°å›¾åƒ
            logger.warning(f"âš ï¸ No image in response: {str(content)[:200]}")
            return ImageGenerationResult(
                success=False,
                error="No image found in response",
                revised_prompt=prompt,  # ğŸ”¥ v7.40.1: å³ä½¿å¤±è´¥ä¹Ÿä¿ç•™è¯¦ç»† prompt
                model_used=self.model,
                # ğŸ”¥ v7.60.5
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens,
                total_tokens=total_tokens
            )
            
        except Exception as e:
            logger.error(f"âŒ Error parsing response: {e}")
            return ImageGenerationResult(
                success=False,
                error=f"Response parsing error: {e}",
                model_used=self.model,
                # ğŸ”¥ v7.60.5
                prompt_tokens=0,
                completion_tokens=0,
                total_tokens=0
            )
    
    async def generate_concept_images(
        self,
        expert_summary: str,
        project_type: str = "interior",
        num_images: int = 2,
        expert_name: str = "",
        top_constraints: str = "",
        use_llm_extraction: bool = True,
    ) -> List[ImageGenerationResult]:
        """
        åŸºäºä¸“å®¶åˆ†ææ‘˜è¦ç”Ÿæˆæ¦‚å¿µå›¾
        
        ğŸ†• v7.50: æ”¯æŒ LLM è¯­ä¹‰æå–ï¼Œå¤§å¹…æå‡æç¤ºè¯è´¨é‡
        
        Args:
            expert_summary: ä¸“å®¶åˆ†ææ‘˜è¦æ–‡æœ¬
            project_type: é¡¹ç›®ç±»å‹ (interior/product/branding/architecture)
            num_images: ç”Ÿæˆå›¾åƒæ•°é‡
            expert_name: ä¸“å®¶åç§°ï¼ˆç”¨äº LLM ä¸Šä¸‹æ–‡ï¼‰
            top_constraints: é¡¹ç›®é¡¶å±‚çº¦æŸ
            use_llm_extraction: æ˜¯å¦ä½¿ç”¨ LLM è¯­ä¹‰æå–ï¼ˆé»˜è®¤ Trueï¼‰
        
        Returns:
            ImageGenerationResult åˆ—è¡¨
        """
        prompts = []
        
        # ğŸ†• v7.50: ä¼˜å…ˆä½¿ç”¨ LLM è¯­ä¹‰æå–
        if use_llm_extraction:
            llm_prompt = await self._llm_extract_visual_prompt(
                expert_content=expert_summary,
                expert_name=expert_name,
                project_type=project_type,
                top_constraints=top_constraints
            )
            if llm_prompt:
                prompts = [llm_prompt]
                logger.info(f"ğŸ§  [v7.50] ä½¿ç”¨ LLM è¯­ä¹‰æå–çš„æç¤ºè¯")
        
        # Fallback: æ­£åˆ™æå–ï¼ˆå¦‚æœ LLM å¤±è´¥æˆ–ç¦ç”¨ï¼‰
        if not prompts:
            prompts = self._extract_visual_concepts(expert_summary, project_type)
            logger.info(f"ğŸ“ [v7.50] Fallback åˆ°æ­£åˆ™æå–çš„æç¤ºè¯")
        
        # é™åˆ¶æ•°é‡
        prompts = prompts[:num_images]
        
        results = []
        for i, prompt in enumerate(prompts):
            logger.info(f"ğŸ¨ Generating concept image {i+1}/{len(prompts)}...")
            logger.info(f"ğŸ“ ä½¿ç”¨æç¤ºè¯: {prompt[:100]}...")
            result = await self.generate_image(
                prompt=prompt,
                style=project_type,
                aspect_ratio=ImageAspectRatio.LANDSCAPE
            )
            # ğŸ”¥ v7.40.1: å¦‚æœ API æ²¡æœ‰è¿”å› revised_promptï¼Œä½¿ç”¨åŸå§‹ prompt
            if result.success and not result.revised_prompt:
                result.revised_prompt = prompt
                logger.debug(f"ğŸ“ ä½¿ç”¨åŸå§‹ prompt ä½œä¸º revised_prompt")
            results.append(result)
        
        return results
    
    def _extract_visual_concepts(self, text: str, project_type: str) -> List[str]:
        """
        ğŸ”§ v7.39.5: ä»ä¸“å®¶åˆ†ææ–‡æœ¬ä¸­æ™ºèƒ½æå–å¯è§†åŒ–æ¦‚å¿µ
        
        æ”¹è¿›ï¼š
        1. çœŸæ­£åˆ†æä¸“å®¶å†…å®¹ï¼Œæå–å…³é”®è®¾è®¡å…ƒç´ 
        2. æ„å»ºä¸ä¸“å®¶åˆ†æç›¸å…³çš„å…·ä½“ prompt
        3. ä½¿ç”¨ä¸­è‹±æ··åˆ prompt æé«˜ç”Ÿæˆè´¨é‡
        """
        import re
        
        # æå–ä¸“å®¶åˆ†æä¸­çš„å…³é”®è®¾è®¡æ¦‚å¿µ
        design_concepts = []
        
        # 1. æå–å¼•å·ä¸­çš„å…³é”®è¯/è®¾è®¡ç†å¿µ
        quoted_terms = re.findall(r'[ã€Œ""]([^ã€Œ""]{2,20})[ã€""]', text)
        design_concepts.extend(quoted_terms[:5])
        
        # 2. æå–"é£æ ¼/ç†å¿µ/æ¦‚å¿µ/ä¸»é¢˜"ç›¸å…³æè¿°
        style_patterns = [
            r'(?:é£æ ¼|ç†å¿µ|æ¦‚å¿µ|ä¸»é¢˜|æ°›å›´|è°ƒæ€§)[:ï¼š]?\s*([^ï¼Œã€‚,.\n]{3,30})',
            r'([^ï¼Œã€‚\n]{2,15}(?:é£æ ¼|ç†å¿µ|è®¾è®¡|ç©ºé—´|æ°›å›´|ä½“éªŒ))',
            r'(?:æ‰“é€ |è¥é€ |å‘ˆç°|å±•ç°)\s*([^ï¼Œã€‚,.\n]{5,40})',
        ]
        for pattern in style_patterns:
            matches = re.findall(pattern, text[:1000])
            design_concepts.extend(matches[:3])
        
        # 3. æå–ææ–™/è‰²å½©/å…ƒç´ æè¿°
        material_patterns = [
            r'(?:ææ–™|æè´¨|ç”¨æ)[:ï¼š]?\s*([^ï¼Œã€‚,.\n]{3,30})',
            r'(?:è‰²å½©|é…è‰²|é¢œè‰²)[:ï¼š]?\s*([^ï¼Œã€‚,.\n]{3,30})',
            r'([^ï¼Œã€‚\n]{2,10}(?:å¤§ç†çŸ³|æœ¨|é‡‘å±|ç»ç’ƒ|çš®é©|å¸ƒè‰º|çŸ³æ))',
        ]
        for pattern in material_patterns:
            matches = re.findall(pattern, text[:1000])
            design_concepts.extend(matches[:2])
        
        # 4. æå–ç©ºé—´/åŠŸèƒ½æè¿°
        space_patterns = [
            r'([^ï¼Œã€‚\n]{3,15}(?:åŒºåŸŸ|ç©ºé—´|åŒº|å…|å®¤|å°))',
            r'(?:åŒ…æ‹¬|è®¾æœ‰|è®¾ç½®)\s*([^ï¼Œã€‚,.\n]{5,40})',
        ]
        for pattern in space_patterns:
            matches = re.findall(pattern, text[:800])
            design_concepts.extend(matches[:3])
        
        # å»é‡å¹¶è¿‡æ»¤å¤ªçŸ­çš„æ¦‚å¿µ
        unique_concepts = []
        seen = set()
        for concept in design_concepts:
            concept = concept.strip()
            if concept and len(concept) >= 3 and concept not in seen:
                seen.add(concept)
                unique_concepts.append(concept)
        
        logger.debug(f"ğŸ¨ ä»ä¸“å®¶å†…å®¹æå–çš„è®¾è®¡æ¦‚å¿µ: {unique_concepts[:8]}")
        
        # æ„å»ºæœ€ç»ˆ prompt
        if unique_concepts:
            # ç»„åˆå‰ 6 ä¸ªæ¦‚å¿µ
            concepts_str = ", ".join(unique_concepts[:6])
            
            # æ ¹æ®é¡¹ç›®ç±»å‹é€‰æ‹©é£æ ¼æè¿°
            style_desc = {
                "interior": "interior design visualization, professional architectural rendering",
                "architecture": "architectural concept rendering, photorealistic exterior view",
                "product": "product design concept, studio photography, clean background",
                "branding": "brand identity visualization, modern graphic design",
            }.get(project_type, "professional design visualization")
            
            # æ„å»ºå®Œæ•´ prompt
            prompt = f"{concepts_str}. {style_desc}, high quality, detailed"
            return [prompt]
        
        # å¦‚æœæ²¡æå–åˆ°æ¦‚å¿µï¼Œä½¿ç”¨æ–‡æœ¬å‰ 200 å­—ç¬¦ä½œä¸ºåŸºç¡€
        text_preview = text[:200].replace('\n', ' ').strip()
        if text_preview:
            style_desc = {
                "interior": "interior design concept",
                "architecture": "architectural visualization",
                "product": "product design rendering",
                "branding": "brand design concept",
            }.get(project_type, "design concept")
            
            prompt = f"Design visualization based on: {text_preview[:150]}. {style_desc}, professional quality"
            return [prompt]
        
        # æœ€ç»ˆå…œåº•
        return ["modern design concept visualization with professional rendering quality"]


    async def generate_deliverable_image(
        self,
        deliverable_metadata: dict,
        expert_analysis: str,
        session_id: str,
        project_type: str = "interior",
        aspect_ratio: str = "16:9"
    ):
        """
        ğŸ†• v7.108: ä¸ºäº¤ä»˜ç‰©ç”Ÿæˆç²¾å‡†çš„æ¦‚å¿µå›¾ï¼ˆæ³¨å…¥çº¦æŸï¼‰

        ä¸ç°æœ‰çš„generate_concept_imagesä¸åŒï¼Œæœ¬æ–¹æ³•ï¼š
        1. åŸºäºå…·ä½“äº¤ä»˜ç‰©çš„å…ƒæ•°æ®ï¼ˆkeywords, constraintsï¼‰
        2. æ³¨å…¥äº¤ä»˜ç‰©çº¦æŸåˆ°Promptä¸­
        3. è¿”å›ImageMetadataå¯¹è±¡ï¼ˆæ”¯æŒæ–‡ä»¶å­˜å‚¨ï¼‰

        Args:
            deliverable_metadata: äº¤ä»˜ç‰©å…ƒæ•°æ®å­—å…¸
                {
                    "id": "2-1_1_143022_abc",
                    "name": "ç©ºé—´åŠŸèƒ½åˆ†åŒºæ–¹æ¡ˆ",
                    "keywords": ["ç°ä»£", "ç®€çº¦"],
                    "constraints": {
                        "must_include": ["è‡ªç„¶å…‰", "æœ¨è´¨å…ƒç´ "],
                        "style_preferences": "professional rendering"
                    },
                    "owner_role": "2-1"
                }
            expert_analysis: ä¸“å®¶åˆ†æå†…å®¹ï¼ˆæ‘˜è¦ï¼‰
            session_id: ä¼šè¯IDï¼ˆç”¨äºæ–‡ä»¶å­˜å‚¨è·¯å¾„ï¼‰
            project_type: é¡¹ç›®ç±»å‹ (interior/product/branding/architecture)
            aspect_ratio: å®½é«˜æ¯” (16:9, 9:16, 1:1)

        Returns:
            ImageMetadataå¯¹è±¡ï¼ˆåŒ…å«æ–‡ä»¶è·¯å¾„å’ŒURLï¼‰
        """
        from ..models.image_metadata import ImageMetadata
        from datetime import datetime

        logger.info(f"ğŸ¨ [v7.108] ä¸ºäº¤ä»˜ç‰©ç”Ÿæˆæ¦‚å¿µå›¾: {deliverable_metadata.get('name', 'Unknown')}")

        try:
            # 1. æ„å»ºå¢å¼ºPromptï¼ˆæ³¨å…¥äº¤ä»˜ç‰©çº¦æŸï¼‰
            deliverable_name = deliverable_metadata.get("name", "è®¾è®¡äº¤ä»˜ç‰©")
            keywords = deliverable_metadata.get("keywords", [])
            constraints = deliverable_metadata.get("constraints", {})

            # ä¸­æ–‡æç¤ºè¯ï¼ˆç»™LLMè¯­ä¹‰æå–ç”¨ï¼‰
            enhanced_prompt = f"""
è®¾è®¡å¯è§†åŒ–éœ€æ±‚ï¼š{deliverable_name}

ã€äº¤ä»˜ç‰©æ ¸å¿ƒå…³é”®è¯ã€‘
{', '.join(keywords) if keywords else 'ç°ä»£è®¾è®¡'}

ã€å¿…é¡»åŒ…å«çš„è®¾è®¡å…ƒç´ ã€‘
{', '.join(constraints.get('must_include', [])) if constraints.get('must_include') else 'æ— ç‰¹æ®Šè¦æ±‚'}

ã€é£æ ¼åå¥½ã€‘
{constraints.get('style_preferences', 'professional design rendering')}

ã€ä¸“å®¶åˆ†ææ‘˜è¦ã€‘
{expert_analysis[:500] if expert_analysis else 'ä¸“ä¸šè®¾è®¡åˆ†æ'}

è¯·åŸºäºä»¥ä¸Šäº¤ä»˜ç‰©è¦æ±‚å’Œä¸“å®¶åˆ†æï¼Œæå–è§†è§‰åŒ–æç¤ºè¯ã€‚
"""

            logger.debug(f"  ğŸ“ æ„å»ºçš„å¢å¼ºPrompt:\n{enhanced_prompt[:200]}...")

            # 2. ä½¿ç”¨ç°æœ‰çš„LLMè¯­ä¹‰æå–æ–¹æ³•
            logger.info("  ğŸ” è°ƒç”¨LLMæå–è§†è§‰Prompt...")
            visual_prompts = await self._llm_extract_visual_prompt(
                enhanced_prompt,
                project_type
            )

            if not visual_prompts:
                logger.warning("  âš ï¸ LLMæå–å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€Prompt")
                visual_prompt = f"{deliverable_name}, {', '.join(keywords)}, professional rendering"
            else:
                visual_prompt = visual_prompts[0]

            logger.info(f"  âœ… æå–çš„è§†è§‰Prompt: {visual_prompt[:100]}...")

            # 3. ç”Ÿæˆå›¾ç‰‡
            logger.info(f"  ğŸ–¼ï¸ è°ƒç”¨å›¾ç‰‡ç”ŸæˆAPI (å®½é«˜æ¯”: {aspect_ratio})...")
            generation_result = await self.generate_image(
                prompt=visual_prompt,
                aspect_ratio=ImageAspectRatio(aspect_ratio),
                num_outputs=1
            )

            if not generation_result.success:
                logger.error(f"  âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {generation_result.error}")
                raise Exception(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {generation_result.error}")

            logger.info("  âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼")

            # 4. ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿï¼ˆPhase 3æ–°å¢ï¼‰
            from ..services.image_storage_manager import ImageStorageManager

            deliverable_id = deliverable_metadata.get("id", "unknown")
            owner_role = deliverable_metadata.get("owner_role", "unknown")
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{deliverable_id}_{project_type}_{timestamp}.png"

            # ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ
            saved_metadata = await ImageStorageManager.save_image(
                base64_data=generation_result.image_url,
                session_id=session_id,
                deliverable_id=deliverable_id,
                owner_role=owner_role,
                filename=filename,
                visual_prompt=visual_prompt,
                aspect_ratio=aspect_ratio
            )

            # åˆ›å»ºImageMetadataå¯¹è±¡ï¼ˆä¸å«Base64ï¼‰
            from ..models.image_metadata import ImageMetadata
            metadata = ImageMetadata(**saved_metadata)

            logger.info(f"âœ… [v7.108] æ¦‚å¿µå›¾å·²ä¿å­˜: {filename}")
            return metadata

        except Exception as e:
            logger.error(f"âŒ [v7.108] ç”Ÿæˆäº¤ä»˜ç‰©æ¦‚å¿µå›¾å¤±è´¥: {e}")
            logger.exception(e)
            # è¿”å›Noneæˆ–æŠ›å‡ºå¼‚å¸¸ç”±è°ƒç”¨æ–¹å¤„ç†
            raise

    async def edit_image_with_mask(
        self,
        original_image: str,
        mask_image: str,
        prompt: str,
        aspect_ratio: Optional[ImageAspectRatio] = None,
        style: Optional[str] = None,
        inpainting_service = None
    ) -> ImageGenerationResult:
        """
        ğŸ”¥ v7.62: ä½¿ç”¨ Mask ç¼–è¾‘å›¾åƒï¼ˆåŒæ¨¡å¼æ¶æ„ï¼‰
        
        æ¨¡å¼é€‰æ‹©é€»è¾‘ï¼š
        - æœ‰ mask_image ä¸” inpainting_service å¯ç”¨ â†’ Inpaintingæ¨¡å¼ï¼ˆOption Dï¼‰
        - æ—  mask æˆ– Inpainting ä¸å¯ç”¨ â†’ å›é€€åˆ° Vision+ç”Ÿæˆï¼ˆOption Cï¼‰
        
        Args:
            original_image: åŸå§‹å›¾åƒ Base64
            mask_image: Mask å›¾åƒ Base64ï¼ˆå¯é€‰ï¼‰
            prompt: ç¼–è¾‘æç¤ºè¯
            aspect_ratio: è¾“å‡ºå®½é«˜æ¯”
            style: é£æ ¼æç¤º
            inpainting_service: InpaintingService å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            ImageGenerationResult å¯¹è±¡
        """
        logger.info("ğŸ¨ [v7.62 Dual-Mode] æ¥æ”¶å›¾åƒå¤„ç†è¯·æ±‚")
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰ Maskï¼ˆå†³å®šæ¨¡å¼ï¼‰
        if mask_image and inpainting_service and inpainting_service.is_available():
            logger.info("âœ… [Inpainting Mode] ä½¿ç”¨ DALL-E 2 Edit APIï¼ˆOption Dï¼‰")
            
            try:
                # è°ƒç”¨ Inpainting æœåŠ¡
                inpainting_result = await inpainting_service.edit_image_with_mask(
                    original_image=original_image,
                    mask_image=mask_image,
                    prompt=prompt,
                    size="1024x1024",  # å›ºå®šä½¿ç”¨æœ€é«˜è´¨é‡
                    n=1
                )
                
                if inpainting_result.success:
                    logger.info("âœ… [Inpainting Mode] å›¾åƒç¼–è¾‘æˆåŠŸ")
                    return ImageGenerationResult(
                        success=True,
                        image_url=inpainting_result.edited_image_url,
                        revised_prompt=inpainting_result.original_prompt,
                        model_used=inpainting_result.model_used or "dall-e-2-edit"
                    )
                else:
                    # Inpainting å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶å›é€€
                    logger.warning(f"âš ï¸ [Inpainting Mode] å¤±è´¥: {inpainting_result.error}")
                    logger.warning("ğŸ”„ å›é€€åˆ° Vision+ç”Ÿæˆ æ¨¡å¼ï¼ˆOption Cï¼‰")
            
            except Exception as e:
                logger.error(f"âŒ [Inpainting Mode] å¼‚å¸¸: {e}")
                logger.warning("ğŸ”„ å›é€€åˆ° Vision+ç”Ÿæˆ æ¨¡å¼ï¼ˆOption Cï¼‰")
        
        # 2. å›é€€åˆ° Vision+ç”Ÿæˆ æ¨¡å¼ï¼ˆOption Cï¼‰
        logger.info("âœ… [Generation Mode] ä½¿ç”¨ Vision+ç”Ÿæˆï¼ˆOption Cï¼‰")
        
        # å¦‚æœæœ‰å‚è€ƒå›¾åƒï¼Œä½¿ç”¨ Vision åˆ†æ
        if original_image:
            result = await self.generate_with_vision_reference(
                user_prompt=prompt,
                reference_image=original_image,
                aspect_ratio=aspect_ratio or ImageAspectRatio.LANDSCAPE,
                style=style or "interior",
                vision_weight=0.7  # Vision ç‰¹å¾æƒé‡ 70%
            )
        else:
            # æ— å‚è€ƒå›¾åƒï¼Œç›´æ¥ç”Ÿæˆ
            result = await self.generate_image(
                prompt=prompt,
                aspect_ratio=aspect_ratio or ImageAspectRatio.LANDSCAPE,
                style=style
            )
        
        return result


# ä¾¿æ·å‡½æ•°
async def generate_concept_image(prompt: str, style: str = "interior") -> ImageGenerationResult:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¿«é€Ÿç”Ÿæˆæ¦‚å¿µå›¾
    
    Example:
        result = await generate_concept_image("ç°ä»£ç®€çº¦é£æ ¼å®¢å…")
        if result.success:
            print(result.image_url)
    """
    generator = ImageGeneratorService()
    return await generator.generate_image(prompt=prompt, style=style)
