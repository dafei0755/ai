"""
LLM Gap Question Generator
v7.105: LLM é©±åŠ¨çš„ä»»åŠ¡ä¿¡æ¯å®Œæ•´æ€§è¡¥å……é—®é¢˜ç”Ÿæˆå™¨

åŠŸèƒ½ï¼š
- æ›¿ä»£ç¡¬ç¼–ç é—®é¢˜æ¨¡æ¿
- æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œç¼ºå¤±ç»´åº¦åŠ¨æ€ç”Ÿæˆé’ˆå¯¹æ€§é—®é¢˜
- ç´§å¯†ç»“åˆé¡¹ç›®ä¸Šä¸‹æ–‡
- å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ°ç¡¬ç¼–ç é—®é¢˜

ä¾èµ–ï¼š
- gap_question_generator.yaml é…ç½®æ–‡ä»¶
- TaskCompletenessAnalyzer ä½œä¸ºå›é€€æ–¹æ¡ˆ
"""

import json
from pathlib import Path
from typing import Any, Dict, List, Optional

import yaml
from langchain_core.messages import HumanMessage, SystemMessage
from loguru import logger


class LLMGapQuestionGenerator:
    """åŸºäº LLM ç”Ÿæˆä»»åŠ¡ä¿¡æ¯è¡¥å……é—®é¢˜"""

    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨ï¼ŒåŠ è½½é…ç½®æ–‡ä»¶"""
        self.config = self._load_config()
        self.system_prompt = self.config.get("system_prompt", "")
        self.user_template = self.config.get("user_prompt_template", "")
        self.generation_config = self.config.get("generation_config", {})

    def _load_config(self) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶

        Returns:
            é…ç½®å­—å…¸
        """
        config_path = Path(__file__).parent.parent / "config" / "prompts" / "gap_question_generator.yaml"
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
                logger.info(f"âœ… [LLMGapQuestionGenerator] é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
                return config
        except Exception as e:
            logger.error(f"âŒ [LLMGapQuestionGenerator] é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            return {}

    def _calculate_target_count(self, missing_dimensions: List[str]) -> int:
        """
        æ ¹æ®ç¼ºå¤±ç»´åº¦æ•°é‡è®¡ç®—ç›®æ ‡é—®é¢˜æ•°

        Args:
            missing_dimensions: ç¼ºå¤±ç»´åº¦åˆ—è¡¨

        Returns:
            ç›®æ ‡é—®é¢˜æ•°é‡
        """
        count = len(missing_dimensions)
        strategy = self.generation_config.get("question_count_strategy", {})
        by_missing = strategy.get("by_missing_dimensions", {})

        if count <= 2:
            min_q, max_q = by_missing.get("1-2", [3, 5])
        elif count <= 4:
            min_q, max_q = by_missing.get("3-4", [6, 8])
        else:
            min_q, max_q = by_missing.get("5+", [9, 10])

        # è¿”å›ä¸­é—´å€¼
        target = (min_q + max_q) // 2
        logger.info(f"[LLMGapQuestionGenerator] ç¼ºå¤± {count} ä¸ªç»´åº¦ï¼Œç›®æ ‡ç”Ÿæˆ {target} ä¸ªé—®é¢˜")
        return target

    async def generate(
        self,
        user_input: str,
        confirmed_tasks: List[Dict[str, Any]],
        missing_dimensions: List[str],
        covered_dimensions: List[str],
        existing_info_summary: str,
        completeness_score: float,
        llm: Optional[Any] = None,
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆä»»åŠ¡ä¿¡æ¯è¡¥å……é—®é¢˜

        Args:
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
            confirmed_tasks: Step 1 ç¡®è®¤çš„ä»»åŠ¡åˆ—è¡¨
            missing_dimensions: ç¼ºå¤±ç»´åº¦åˆ—è¡¨
            covered_dimensions: å·²è¦†ç›–ç»´åº¦åˆ—è¡¨
            existing_info_summary: å·²æœ‰ä¿¡æ¯æ‘˜è¦
            completeness_score: å®Œæ•´æ€§è¯„åˆ† (0-1)
            llm: LLM å®ä¾‹ï¼ˆå¯é€‰ï¼‰

        Returns:
            é—®é¢˜åˆ—è¡¨ [{"id": "", "question": "", "type": "", ...}]
        """
        try:
            # è®¡ç®—ç›®æ ‡é—®é¢˜æ•°é‡
            target_count = self._calculate_target_count(missing_dimensions)

            # æ„å»ºä»»åŠ¡æ‘˜è¦
            task_summary = "\n".join(
                [
                    f"- {task.get('title', 'æœªå‘½åä»»åŠ¡')}: {task.get('description', 'æ— æè¿°')}"
                    for task in confirmed_tasks[:5]  # æœ€å¤šæ˜¾ç¤º5ä¸ªä»»åŠ¡
                ]
            )

            # å¡«å……ç”¨æˆ· Prompt
            user_prompt = self.user_template.format(
                user_input=user_input,
                task_summary=task_summary or "ï¼ˆæ— å·²ç¡®è®¤ä»»åŠ¡ï¼‰",
                missing_dimensions=", ".join(missing_dimensions) if missing_dimensions else "æ— ",
                covered_dimensions=", ".join(covered_dimensions) if covered_dimensions else "æ— ",
                existing_info_summary=existing_info_summary or "ï¼ˆæ— å·²æœ‰ä¿¡æ¯ï¼‰",
                completeness_score=int(completeness_score * 100),
                target_count=target_count,
            )

            logger.info(f"[LLMGapQuestionGenerator] å¼€å§‹ç”Ÿæˆé—®é¢˜...")
            logger.debug(f"[LLMGapQuestionGenerator] ç”¨æˆ·è¾“å…¥: {user_input[:100]}...")
            logger.debug(f"[LLMGapQuestionGenerator] ç¼ºå¤±ç»´åº¦: {missing_dimensions}")

            # è·å– LLM å®ä¾‹
            if llm is None:
                from ..services.llm_factory import LLMFactory

                llm = LLMFactory.create_llm(
                    temperature=self.generation_config.get("temperature", 0.7),
                    max_tokens=self.generation_config.get("max_tokens", 2000),
                )

            # è°ƒç”¨ LLM
            messages = [SystemMessage(content=self.system_prompt), HumanMessage(content=user_prompt)]

            response = await llm.ainvoke(messages)
            response_text = response.content if hasattr(response, "content") else str(response)

            # ğŸ†• P1ä¿®å¤: ä½¿ç”¨ç»Ÿä¸€JSONè§£æå™¨
            from ..utils.json_parser import parse_json_safe

            data = parse_json_safe(
                response_text,
                extract_from_markdown=True,
                fix_quotes=True,
                default={"questions": [], "generation_rationale": ""},
            )

            questions = data.get("questions", [])
            rationale = data.get("generation_rationale", "")

            # ğŸ†• v7.110: éªŒè¯å’Œä¿®å¤é—®é¢˜ç±»å‹ï¼ˆå¤ç”¨ LLMQuestionGenerator çš„é€»è¾‘ï¼‰
            questions = self._validate_and_fix_questions(questions)

            logger.info(f"âœ… [LLMGapQuestionGenerator] æˆåŠŸç”Ÿæˆ {len(questions)} ä¸ªé—®é¢˜")
            if rationale:
                logger.info(f"[LLMGapQuestionGenerator] ç”Ÿæˆç†ç”±: {rationale}")

            return questions

        except Exception as e:
            logger.error(f"âŒ [LLMGapQuestionGenerator] å¤„ç†å¤±è´¥: {e}")
            return self._fallback_generate(missing_dimensions, confirmed_tasks)

        except Exception as e:
            logger.error(f"âŒ [LLMGapQuestionGenerator] LLM è°ƒç”¨å¤±è´¥: {e}")
            return self._fallback_generate(missing_dimensions, confirmed_tasks)

    def _fallback_generate(
        self, missing_dimensions: List[str], confirmed_tasks: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        å›é€€ç­–ç•¥ï¼šä½¿ç”¨ TaskCompletenessAnalyzer ç”Ÿæˆç¡¬ç¼–ç é—®é¢˜

        Args:
            missing_dimensions: ç¼ºå¤±ç»´åº¦åˆ—è¡¨
            confirmed_tasks: ç¡®è®¤çš„ä»»åŠ¡åˆ—è¡¨

        Returns:
            ç¡¬ç¼–ç é—®é¢˜åˆ—è¡¨
        """
        logger.warning("[LLMGapQuestionGenerator] å¯ç”¨å›é€€ç­–ç•¥ï¼šä½¿ç”¨ç¡¬ç¼–ç é—®é¢˜")

        try:
            from ..services.task_completeness_analyzer import TaskCompletenessAnalyzer

            analyzer = TaskCompletenessAnalyzer()

            fallback_count = self.generation_config.get("fallback_min_questions", 5)
            questions = analyzer.generate_gap_questions(
                missing_dimensions=missing_dimensions,
                critical_gaps=[],
                confirmed_tasks=confirmed_tasks,
                existing_info_summary="",
                target_count=fallback_count,
            )

            logger.info(f"âœ… [LLMGapQuestionGenerator] å›é€€æˆåŠŸï¼Œç”Ÿæˆ {len(questions)} ä¸ªç¡¬ç¼–ç é—®é¢˜")
            return questions

        except Exception as e:
            logger.error(f"âŒ [LLMGapQuestionGenerator] å›é€€ç­–ç•¥å¤±è´¥: {e}")
            return []

    def _validate_and_fix_questions(self, questions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        éªŒè¯å’Œä¿®å¤é—®é¢˜æ ¼å¼ï¼ˆä¸ LLMQuestionGenerator ä¿æŒä¸€è‡´ï¼‰

        ğŸ†• v7.110: æ·»åŠ ç±»å‹æ ‡å‡†åŒ–ï¼Œä¿®å¤ multi_choice ç­‰é”™è¯¯ç±»å‹

        Args:
            questions: åŸå§‹é—®é¢˜åˆ—è¡¨

        Returns:
            éªŒè¯åçš„é—®é¢˜åˆ—è¡¨
        """
        validated = []
        type_count = {"single_choice": 0, "multiple_choice": 0, "open_ended": 0}

        for i, q in enumerate(questions):
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
            if not isinstance(q, dict):
                continue

            question_text = q.get("question", "")
            if not question_text:
                continue

            # ç¡®ä¿æœ‰å”¯ä¸€ID
            if not q.get("id"):
                q["id"] = f"gap_q_{i + 1}"

            # éªŒè¯å’Œä¿®æ­£typeå­—æ®µ
            q_type = q.get("type", "").lower()
            original_type = q_type  # è®°å½•åŸå§‹ç±»å‹ç”¨äºæ—¥å¿—

            # ğŸ†• v7.110: ç±»å‹åˆ«åæ ‡å‡†åŒ–æ˜ å°„ï¼ˆä¿®å¤ multi_choice ç­‰é”™è¯¯ç±»å‹ï¼‰
            type_aliases = {
                # multiple_choice çš„å„ç§é”™è¯¯æ‹¼å†™
                "multi_choice": "multiple_choice",
                "multi-choice": "multiple_choice",
                "multichoice": "multiple_choice",
                "checkbox": "multiple_choice",
                "checkboxes": "multiple_choice",
                "multi": "multiple_choice",
                # single_choice çš„å„ç§é”™è¯¯æ‹¼å†™
                "single": "single_choice",
                "single-choice": "single_choice",
                "singlechoice": "single_choice",
                "radio": "single_choice",
                "select": "single_choice",
                "dropdown": "single_choice",
                # open_ended çš„å„ç§é”™è¯¯æ‹¼å†™
                "open": "open_ended",
                "open-ended": "open_ended",
                "openended": "open_ended",
                "text": "open_ended",
                "textarea": "open_ended",
                "input": "open_ended",
                "free_text": "open_ended",
                "free-text": "open_ended",
            }

            # åº”ç”¨ç±»å‹åˆ«åæ˜ å°„
            if q_type in type_aliases:
                q_type = type_aliases[q_type]
                logger.warning(f"ğŸ”§ [Gapç±»å‹ä¿®å¤] é—®é¢˜ {q.get('id', i+1)}: '{original_type}' â†’ '{q_type}'")

            # å¦‚æœä»ç„¶ä¸åˆæ³•ï¼Œä»é—®é¢˜æ–‡æœ¬æ¨æ–­ç±»å‹
            if q_type not in ["single_choice", "multiple_choice", "open_ended"]:
                # ä»é—®é¢˜æ–‡æœ¬æ¨æ–­ç±»å‹
                if "(å•é€‰)" in question_text or "å•é€‰" in question_text:
                    q_type = "single_choice"
                elif "(å¤šé€‰)" in question_text or "å¤šé€‰" in question_text:
                    q_type = "multiple_choice"
                elif "(å¼€æ”¾é¢˜)" in question_text or "å¼€æ”¾" in question_text:
                    q_type = "open_ended"
                else:
                    # å¦‚æœæœ‰optionsåˆ™ä¸ºé€‰æ‹©é¢˜ï¼Œå¦åˆ™ä¸ºå¼€æ”¾é¢˜
                    if q.get("options"):
                        q_type = "single_choice"
                    else:
                        q_type = "open_ended"

                # è®°å½•æ¨æ–­ç»“æœ
                if original_type:
                    logger.warning(f"ğŸ” [Gapç±»å‹æ¨æ–­] é—®é¢˜ {q.get('id', i+1)}: æœªçŸ¥ç±»å‹ '{original_type}' â†’ æ¨æ–­ä¸º '{q_type}'")

            q["type"] = q_type
            type_count[q_type] = type_count.get(q_type, 0) + 1

            # éªŒè¯é€‰é¡¹ï¼ˆé€‰æ‹©é¢˜å¿…é¡»æœ‰optionsï¼‰
            if q_type in ["single_choice", "multiple_choice"]:
                if not q.get("options") or not isinstance(q["options"], list):
                    q["options"] = ["é€‰é¡¹A", "é€‰é¡¹B", "é€‰é¡¹C"]
                    logger.warning(f"âš ï¸ Gapé—®é¢˜ {q['id']} ç¼ºå°‘é€‰é¡¹ï¼Œä½¿ç”¨å ä½é€‰é¡¹")

            # éªŒè¯å¼€æ”¾é¢˜çš„placeholder
            if q_type == "open_ended":
                if not q.get("placeholder"):
                    q["placeholder"] = "è¯·è¯¦ç»†æè¿°..."

            # ç¡®ä¿contextå­˜åœ¨
            if not q.get("context"):
                q["context"] = ""

            validated.append(q)

        logger.info(
            f"ğŸ“Š [Gapé—®å·éªŒè¯] é—®é¢˜ç±»å‹åˆ†å¸ƒ: å•é€‰={type_count['single_choice']}, "
            f"å¤šé€‰={type_count['multiple_choice']}, å¼€æ”¾={type_count['open_ended']}"
        )

        return validated

    def generate_sync(
        self,
        user_input: str,
        confirmed_tasks: List[Dict[str, Any]],
        missing_dimensions: List[str],
        covered_dimensions: List[str],
        existing_info_summary: str,
        completeness_score: float,
        llm: Optional[Any] = None,
    ) -> List[Dict[str, Any]]:
        """
        åŒæ­¥ç‰ˆæœ¬çš„ generate æ–¹æ³•ï¼ˆä¾›éå¼‚æ­¥ç¯å¢ƒè°ƒç”¨ï¼‰

        ä½¿ç”¨ asyncio.run() åœ¨ç‹¬ç«‹äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥ä»»åŠ¡

        Args:
            å‚æ•°åŒ generate()

        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        import asyncio

        try:
            return asyncio.run(
                self.generate(
                    user_input=user_input,
                    confirmed_tasks=confirmed_tasks,
                    missing_dimensions=missing_dimensions,
                    covered_dimensions=covered_dimensions,
                    existing_info_summary=existing_info_summary,
                    completeness_score=completeness_score,
                    llm=llm,
                )
            )
        except Exception as e:
            logger.error(f"âŒ [LLMGapQuestionGenerator] åŒæ­¥è°ƒç”¨å¤±è´¥: {e}")
            return self._fallback_generate(missing_dimensions, confirmed_tasks)
