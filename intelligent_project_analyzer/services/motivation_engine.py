"""
åŠ¨æœºè¯†åˆ«å¼•æ“

v7.106: é…ç½®åŒ–ã€å¯æ‰©å±•ã€è‡ªå­¦ä¹ çš„åŠ¨æœºç±»å‹è¯†åˆ«ç³»ç»Ÿ
"""

import asyncio
import json
from dataclasses import asdict, dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import yaml
from loguru import logger


@dataclass
class MotivationType:
    """åŠ¨æœºç±»å‹å®šä¹‰"""

    id: str
    label_zh: str
    label_en: str
    priority: str
    description: str
    keywords: Dict[str, float]  # å…³é”®è¯åŠå…¶æƒé‡
    llm_examples: List[str]
    enabled: bool = True
    color: str = "#808080"


@dataclass
class MotivationResult:
    """åŠ¨æœºè¯†åˆ«ç»“æœ"""

    primary: str  # ä¸»è¦åŠ¨æœºç±»å‹
    primary_label: str  # ä¸»è¦åŠ¨æœºä¸­æ–‡æ ‡ç­¾
    scores: Dict[str, float]  # æ‰€æœ‰ç±»å‹çš„è¯„åˆ† 0-1
    confidence: float  # ç½®ä¿¡åº¦
    reasoning: str  # æ¨ç†è¯´æ˜
    method: str  # è¯†åˆ«æ–¹æ³•: llm/keyword/rule/default
    secondary: Optional[List[str]] = None  # æ¬¡è¦åŠ¨æœºç±»å‹
    tags: List[str] = field(default_factory=list)  # ç»†ç²’åº¦æ ‡ç­¾
    requires_human_review: bool = False  # æ˜¯å¦éœ€è¦äººå·¥å®¡æ ¸
    fallback_used: bool = False  # æ˜¯å¦ä½¿ç”¨äº†é™çº§ç­–ç•¥


@dataclass
class UnmatchedCase:
    """æœªåŒ¹é…æ¡ˆä¾‹ï¼ˆç”¨äºå­¦ä¹ ï¼‰"""

    timestamp: str
    task_title: str
    task_description: str
    user_input_snippet: str
    assigned_type: str
    confidence: float
    method: str
    session_id: Optional[str] = None


class MotivationTypeRegistry:
    """åŠ¨æœºç±»å‹æ³¨å†Œè¡¨ - æ”¯æŒåŠ¨æ€åŠ è½½"""

    _instance = None
    _types: Dict[str, MotivationType] = {}
    _config: Dict[str, Any] = {}

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not self._types:
            self.load_from_config()

    def load_from_config(self, config_path: Optional[str] = None):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½åŠ¨æœºç±»å‹"""
        if config_path is None:
            config_path = Path(__file__).parent.parent / "config" / "motivation_types.yaml"

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                self._config = yaml.safe_load(f)

            # åŠ è½½åŠ¨æœºç±»å‹
            for item in self._config.get("motivation_types", []):
                if item.get("enabled", True):
                    # è½¬æ¢keywordsï¼šå¦‚æœæ˜¯åˆ—è¡¨ï¼Œè½¬ä¸ºå­—å…¸ï¼ˆé»˜è®¤æƒé‡1.0ï¼‰
                    keywords = item.get("keywords", [])
                    if isinstance(keywords, list):
                        item["keywords"] = {kw: 1.0 for kw in keywords}

                    motivation_type = MotivationType(**item)
                    self._types[motivation_type.id] = motivation_type

            logger.info(f"âœ… [MotivationRegistry] åŠ è½½ {len(self._types)} ä¸ªåŠ¨æœºç±»å‹")
            logger.debug(f"   å¯ç”¨ç±»å‹: {list(self._types.keys())}")

        except Exception as e:
            logger.error(f"âŒ [MotivationRegistry] é…ç½®åŠ è½½å¤±è´¥: {e}")
            self._load_fallback_types()

    def _load_fallback_types(self):
        """é™çº§ï¼šåŠ è½½æœ€å°å¿…éœ€ç±»å‹"""
        logger.warning("âš ï¸ [MotivationRegistry] ä½¿ç”¨ç¡¬ç¼–ç é™çº§ç±»å‹")
        basic_types = [
            MotivationType(
                id="functional",
                label_zh="åŠŸèƒ½æ€§éœ€æ±‚",
                label_en="Functional",
                priority="BASELINE",
                description="åŸºç¡€åŠŸèƒ½éœ€æ±‚",
                keywords={"åŠŸèƒ½": 1.0, "ç©ºé—´": 1.0, "å¸ƒå±€": 1.0},
                llm_examples=[],
                enabled=True,
            ),
            MotivationType(
                id="mixed",
                label_zh="ç»¼åˆéœ€æ±‚",
                label_en="Mixed",
                priority="FALLBACK",
                description="ç»¼åˆéœ€æ±‚",
                keywords={},
                llm_examples=[],
                enabled=True,
            ),
        ]
        for t in basic_types:
            self._types[t.id] = t

    def get_type(self, type_id: str) -> Optional[MotivationType]:
        """è·å–æŒ‡å®šç±»å‹"""
        return self._types.get(type_id)

    def get_all_types(self) -> List[MotivationType]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„ç±»å‹"""
        return [t for t in self._types.values() if t.enabled]

    def get_types_by_priority(self, priority: str) -> List[MotivationType]:
        """æŒ‰ä¼˜å…ˆçº§è·å–ç±»å‹"""
        return [t for t in self._types.values() if t.priority == priority and t.enabled]

    def get_config(self, key: str, default: Any = None) -> Any:
        """è·å–é…ç½®é¡¹"""
        keys = key.split(".")
        value = self._config
        for k in keys:
            if isinstance(value, dict):
                value = value.get(k, default)
            else:
                return default
        return value if value is not None else default


class MotivationLearningSystem:
    """åŠ¨æœºè¯†åˆ«å­¦ä¹ ç³»ç»Ÿ"""

    def __init__(self, registry: MotivationTypeRegistry):
        self.registry = registry
        self.feedback_log = Path(registry.get_config("learning.feedback_log_path", "logs/motivation_feedback.jsonl"))
        self.enabled = registry.get_config("learning.enabled", True)
        self.min_confidence = registry.get_config("learning.min_confidence_threshold", 0.7)

        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        self.feedback_log.parent.mkdir(parents=True, exist_ok=True)

    def record_unmatched_case(self, task: Dict[str, Any], user_input: str, result: MotivationResult):
        """è®°å½•ä½ç½®ä¿¡åº¦æˆ–æœªåŒ¹é…çš„æ¡ˆä¾‹"""

        if not self.enabled:
            return

        if result.confidence < self.min_confidence or result.primary == "mixed":
            case = UnmatchedCase(
                timestamp=datetime.now().isoformat(),
                task_title=task.get("title", ""),
                task_description=task.get("description", ""),
                user_input_snippet=user_input[:200] if user_input else "",
                assigned_type=result.primary,
                confidence=result.confidence,
                method=result.method,
                session_id=task.get("session_id"),
            )

            try:
                with open(self.feedback_log, "a", encoding="utf-8") as f:
                    f.write(json.dumps(asdict(case), ensure_ascii=False) + "\n")
                logger.debug(f"ğŸ“ [Learning] è®°å½•å¾…å­¦ä¹ æ¡ˆä¾‹: {case.task_title[:30]}...")
            except Exception as e:
                logger.warning(f"âš ï¸ [Learning] è®°å½•å¤±è´¥: {e}")

    def get_recent_cases(self, days: int = 7) -> List[UnmatchedCase]:
        """è·å–æœ€è¿‘Nå¤©çš„å¾…å­¦ä¹ æ¡ˆä¾‹"""
        if not self.feedback_log.exists():
            return []

        cases = []
        cutoff = datetime.now().timestamp() - (days * 86400)

        try:
            with open(self.feedback_log, "r", encoding="utf-8") as f:
                for line in f:
                    case_dict = json.loads(line)
                    case_time = datetime.fromisoformat(case_dict["timestamp"]).timestamp()
                    if case_time >= cutoff:
                        cases.append(UnmatchedCase(**case_dict))
        except Exception as e:
            logger.warning(f"âš ï¸ [Learning] è¯»å–æ—¥å¿—å¤±è´¥: {e}")

        return cases

    async def weekly_pattern_analysis(self) -> Dict[str, Any]:
        """
        æ¯å‘¨åˆ†æå­¦ä¹ æ¡ˆä¾‹ï¼Œå‘ç°æ–°æ¨¡å¼

        Returns:
            åˆ†ææŠ¥å‘Šå­—å…¸ï¼ŒåŒ…å«ï¼š
            - status: åˆ†æçŠ¶æ€
            - case_count: æ¡ˆä¾‹æ•°é‡
            - type_distribution: ç±»å‹åˆ†å¸ƒ
            - llm_analysis: LLMèšç±»åˆ†æç»“æœ
            - recommendation: é…ç½®æ›´æ–°å»ºè®®
        """

        if not self.enabled:
            return {"status": "disabled", "message": "å­¦ä¹ ç³»ç»Ÿæœªå¯ç”¨"}

        cases = self.get_recent_cases(days=7)

        if len(cases) < 5:
            return {"status": "insufficient_data", "case_count": len(cases), "message": "æ¡ˆä¾‹ä¸è¶³5ä¸ªï¼Œè·³è¿‡åˆ†æ"}

        logger.info(f"ğŸ” [Learning] å¼€å§‹åˆ†æ {len(cases)} ä¸ªæ¡ˆä¾‹...")

        # ç»Ÿè®¡ç±»å‹åˆ†å¸ƒ
        type_distribution = {}
        low_confidence_cases = []

        for case in cases:
            type_distribution[case.assigned_type] = type_distribution.get(case.assigned_type, 0) + 1
            if case.confidence < self.min_confidence:
                low_confidence_cases.append(case)

        # æå–é«˜é¢‘çŸ­è¯­
        frequent_phrases = self._extract_frequent_phrases(cases)

        # LLMèšç±»åˆ†æ
        try:
            llm_analysis = await self._llm_pattern_discovery(cases, frequent_phrases)
        except Exception as e:
            logger.warning(f"âš ï¸ [Learning] LLMåˆ†æå¤±è´¥: {e}")
            llm_analysis = {"error": str(e)}

        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "status": "completed",
            "timestamp": datetime.now().isoformat(),
            "case_count": len(cases),
            "low_confidence_count": len(low_confidence_cases),
            "mixed_count": type_distribution.get("mixed", 0),
            "type_distribution": type_distribution,
            "frequent_phrases": frequent_phrases[:20],  # å‰20ä¸ª
            "llm_analysis": llm_analysis,
            "recommendation": self._generate_recommendation(llm_analysis, type_distribution),
        }

        # ä¿å­˜æŠ¥å‘Š
        report_path = self.feedback_log.parent / f"analysis_{datetime.now().strftime('%Y%m%d')}.json"
        try:
            with open(report_path, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… [Learning] åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ [Learning] ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

        return report

    def _extract_frequent_phrases(self, cases: List[UnmatchedCase], top_n: int = 50) -> List[Dict[str, Any]]:
        """æå–é«˜é¢‘çŸ­è¯­ï¼ˆä½¿ç”¨jiebaåˆ†è¯ï¼‰"""
        try:
            from collections import Counter

            import jieba

            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
            all_text = " ".join(
                [f"{case.task_title} {case.task_description} {case.user_input_snippet}" for case in cases]
            )

            # åˆ†è¯å¹¶ç»Ÿè®¡
            words = jieba.lcut(all_text)
            # è¿‡æ»¤åœç”¨è¯å’Œå•å­—
            words = [w for w in words if len(w) >= 2 and w.strip()]

            # ç»Ÿè®¡è¯é¢‘
            counter = Counter(words)

            return [{"phrase": phrase, "count": count} for phrase, count in counter.most_common(top_n)]

        except Exception as e:
            logger.warning(f"âš ï¸ [Learning] æå–çŸ­è¯­å¤±è´¥: {e}")
            return []

    async def _llm_pattern_discovery(
        self, cases: List[UnmatchedCase], frequent_phrases: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œèšç±»åˆ†æï¼Œå‘ç°æ–°æ¨¡å¼"""

        # æ„å»ºæ¡ˆä¾‹æ‘˜è¦
        case_summaries = []
        for i, case in enumerate(cases[:30], 1):  # é™åˆ¶30ä¸ªæ¡ˆä¾‹
            case_summaries.append(
                f"{i}. [{case.assigned_type}] {case.task_title} " f"(ç½®ä¿¡åº¦: {case.confidence:.2f}, æ–¹æ³•: {case.method})"
            )

        # æ„å»ºçŸ­è¯­åˆ—è¡¨
        phrase_list = [f"- {p['phrase']} ({p['count']}æ¬¡)" for p in frequent_phrases[:15]]

        # æ„å»ºprompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªè®¾è®¡ç ”ç©¶ä¸“å®¶ï¼Œæ­£åœ¨åˆ†æè®¾è®¡ä»»åŠ¡çš„åŠ¨æœºç±»å‹è¯†åˆ«é—®é¢˜ã€‚

å½“å‰åŠ¨æœºç±»å‹ç³»ç»ŸåŒ…å«ä»¥ä¸‹ç±»å‹ï¼š
{', '.join([t.label_zh for t in self.registry.get_all_types()])}

ä»¥ä¸‹æ˜¯æœ€è¿‘ä¸€å‘¨æ”¶é›†çš„ {len(cases)} ä¸ªä½ç½®ä¿¡åº¦æˆ–æœªè¯†åˆ«æ¡ˆä¾‹ï¼š

{chr(10).join(case_summaries)}

é«˜é¢‘å…³é”®è¯/çŸ­è¯­ï¼š
{chr(10).join(phrase_list)}

è¯·åˆ†æï¼š
1. è¿™äº›æ¡ˆä¾‹æ˜¯å¦å­˜åœ¨å…±åŒçš„æ¨¡å¼æˆ–èšç±»ï¼Ÿ
2. æ˜¯å¦å‘ç°æ–°çš„åŠ¨æœºç»´åº¦ï¼ˆå½“å‰ç±»å‹æœªè¦†ç›–ï¼‰ï¼Ÿ
3. å“ªäº›ç°æœ‰ç±»å‹çš„å…³é”®è¯é…ç½®éœ€è¦åŠ å¼ºï¼Ÿ

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
  "discovered_patterns": [
    {{
      "pattern_name": "æ¨¡å¼åç§°",
      "case_count": ç›¸å…³æ¡ˆä¾‹æ•°é‡,
      "description": "æ¨¡å¼æè¿°",
      "example_keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
    }}
  ],
  "new_dimensions": [
    {{
      "dimension_name": "æ–°ç»´åº¦åç§°",
      "description": "ç»´åº¦æè¿°",
      "rationale": "ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªç»´åº¦",
      "suggested_keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
    }}
  ],
  "enhancement_suggestions": [
    {{
      "type_id": "ç±»å‹ID",
      "add_keywords": ["å»ºè®®æ·»åŠ çš„å…³é”®è¯"],
      "reason": "åŸå› è¯´æ˜"
    }}
  ]
}}"""

        try:
            from langchain_core.messages import HumanMessage

            from intelligent_project_analyzer.services.llm_factory import LLMFactory

            llm = LLMFactory.create_llm()
            response = await asyncio.wait_for(llm.ainvoke([HumanMessage(content=prompt)]), timeout=60)  # 60ç§’è¶…æ—¶

            # æå–JSON
            import re

            json_match = re.search(r"\{.*\}", response.content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {"error": "LLMæœªè¿”å›æœ‰æ•ˆJSON", "raw_response": response.content[:500]}

        except Exception as e:
            logger.error(f"âŒ [Learning] LLMæ¨¡å¼å‘ç°å¤±è´¥: {e}")
            return {"error": str(e)}

    def _generate_recommendation(
        self, llm_analysis: Dict[str, Any], type_distribution: Dict[str, int]
    ) -> Dict[str, Any]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®"""

        recommendations = {"priority": "low", "actions": []}

        # æ£€æŸ¥mixedæ¯”ä¾‹
        total_cases = sum(type_distribution.values())
        mixed_ratio = type_distribution.get("mixed", 0) / total_cases if total_cases > 0 else 0

        if mixed_ratio > 0.3:
            recommendations["priority"] = "high"
            recommendations["actions"].append(
                {"type": "high_mixed_ratio", "message": f"Mixedç±»å‹å æ¯” {mixed_ratio:.1%}ï¼Œå»ºè®®æ£€æŸ¥å…³é”®è¯é…ç½®æˆ–å¢åŠ æ–°ç±»å‹"}
            )

        # å¤„ç†LLMå‘ç°çš„æ–°ç»´åº¦
        if "new_dimensions" in llm_analysis and llm_analysis["new_dimensions"]:
            recommendations["priority"] = "medium"
            recommendations["actions"].append(
                {
                    "type": "new_dimensions_discovered",
                    "count": len(llm_analysis["new_dimensions"]),
                    "dimensions": llm_analysis["new_dimensions"],
                }
            )

        # å¤„ç†å¢å¼ºå»ºè®®
        if "enhancement_suggestions" in llm_analysis and llm_analysis["enhancement_suggestions"]:
            recommendations["actions"].append(
                {"type": "keyword_enhancement", "suggestions": llm_analysis["enhancement_suggestions"]}
            )

        return recommendations


class MotivationInferenceEngine:
    """åŠ¨æœºæ¨æ–­å¼•æ“ - 4çº§é™çº§ç­–ç•¥"""

    def __init__(self):
        self.registry = MotivationTypeRegistry()
        self.learning = MotivationLearningSystem(self.registry)

    async def infer(
        self, task: Dict[str, Any], user_input: str, structured_data: Optional[Dict[str, Any]] = None
    ) -> MotivationResult:
        """
        æ¨æ–­ä»»åŠ¡çš„åŠ¨æœºç±»å‹ï¼ˆ4çº§é™çº§ç­–ç•¥ï¼‰

        Level 1: LLMæ™ºèƒ½æ¨ç†ï¼ˆé¦–é€‰ï¼‰
        Level 2: å¢å¼ºå…³é”®è¯åŒ¹é…
        Level 3: è§„åˆ™å¼•æ“
        Level 4: é»˜è®¤mixed + è®°å½•
        """

        # Level 1: LLMæ™ºèƒ½æ¨ç†
        if self.registry.get_config("llm_inference.enabled", False):
            try:
                result = await self._llm_inference(task, user_input, structured_data)
                threshold = self.registry.get_config("llm_inference.min_confidence_threshold", 0.7)

                if result.confidence >= threshold:
                    logger.info(f"âœ… [Level 1] LLMè¯†åˆ«: {result.primary} (ç½®ä¿¡åº¦: {result.confidence:.2f})")
                    self.learning.record_unmatched_case(task, user_input, result)
                    return result
                else:
                    logger.debug(f"âš ï¸ [Level 1] LLMç½®ä¿¡åº¦ä½ ({result.confidence:.2f})ï¼Œé™çº§")
            except Exception as e:
                logger.warning(f"âš ï¸ [Level 1] LLMå¤±è´¥: {e}ï¼Œé™çº§åˆ°å…³é”®è¯åŒ¹é…")

        # Level 2: å¢å¼ºå…³é”®è¯åŒ¹é…
        result = self._keyword_matching(task, user_input, structured_data)
        if result.confidence >= 0.6:
            logger.info(f"âœ… [Level 2] å…³é”®è¯åŒ¹é…: {result.primary} (ç½®ä¿¡åº¦: {result.confidence:.2f})")
            self.learning.record_unmatched_case(task, user_input, result)
            return result

        # Level 3: è§„åˆ™å¼•æ“
        result = self._rule_based_inference(task, structured_data)
        if result.confidence >= 0.5:
            logger.info(f"âœ… [Level 3] è§„åˆ™æ¨æ–­: {result.primary} (ç½®ä¿¡åº¦: {result.confidence:.2f})")
            self.learning.record_unmatched_case(task, user_input, result)
            return result

        # Level 4: é»˜è®¤mixed
        logger.warning(f"âš ï¸ [Level 4] ä½¿ç”¨é»˜è®¤mixedï¼Œç½®ä¿¡åº¦ä½ ({result.confidence:.2f})")
        result = MotivationResult(
            primary="mixed",
            primary_label="ç»¼åˆéœ€æ±‚",
            scores={"mixed": 1.0},
            confidence=0.3,
            reasoning="æœªæ‰¾åˆ°æ˜ç¡®åŠ¨æœºæ¨¡å¼ï¼Œå»ºè®®äººå·¥review",
            method="default",
            requires_human_review=True,
        )
        self.learning.record_unmatched_case(task, user_input, result)
        return result

    async def _llm_inference(
        self, task: Dict[str, Any], user_input: str, structured_data: Optional[Dict[str, Any]]
    ) -> MotivationResult:
        """Level 1: LLMæ™ºèƒ½æ¨ç†"""

        # æ„å»ºåŠ¨æœºç±»å‹åˆ—è¡¨æè¿°
        type_descriptions = []
        for mtype in self.registry.get_all_types():
            if mtype.id != "mixed":  # æ’é™¤mixed
                examples = mtype.llm_examples[:2] if mtype.llm_examples else []
                examples_text = f"\n     ç¤ºä¾‹: {', '.join(examples)}" if examples else ""
                # ä½¿ç”¨æ›´å®Œæ•´çš„æ ¼å¼ï¼Œå¸®åŠ©LLMç†è§£æ¯ä¸ªç±»å‹
                type_descriptions.append(f"  {mtype.id} ({mtype.label_zh}åŠ¨æœº): {mtype.description}{examples_text}")

        types_text = "\n".join(type_descriptions)

        # æ„å»ºç»“æ„åŒ–æ•°æ®æ‘˜è¦
        context_parts = []
        if structured_data:
            if structured_data.get("project_task"):
                context_parts.append(f"é¡¹ç›®ä»»åŠ¡: {structured_data['project_task']}")
            if structured_data.get("design_challenge"):
                context_parts.append(f"è®¾è®¡æŒ‘æˆ˜: {structured_data['design_challenge']}")
            if structured_data.get("character_narrative"):
                context_parts.append(f"äººç‰©å™äº‹: {structured_data['character_narrative']}")

        context_text = "\n".join(context_parts) if context_parts else "æ— é¢å¤–ä¸Šä¸‹æ–‡"

        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±å®¤å†…è®¾è®¡é¡¾é—®ï¼Œéœ€è¦åˆ†æé¡¹ç›®**å•ä¸ªä»»åŠ¡**çš„æ ¸å¿ƒåŠ¨æœºç±»å‹ã€‚

ã€å¯é€‰åŠ¨æœºç±»å‹ã€‘
{types_text}

ã€å½“å‰ä»»åŠ¡ã€‘ï¼ˆé‡ç‚¹åˆ†æï¼‰
- æ ‡é¢˜: {task.get('title', '')}
- æè¿°: {task.get('description', '')}
- å…³é”®è¯: {', '.join(task.get('source_keywords', []))}

ã€é¡¹ç›®èƒŒæ™¯ã€‘ï¼ˆä»…ä¾›å‚è€ƒï¼‰
ç”¨æˆ·æ•´ä½“éœ€æ±‚: {user_input[:300] if user_input else "æ— "}

ã€è¡¥å……ä¸Šä¸‹æ–‡ã€‘
{context_text}

âš ï¸ **åˆ†æé‡ç‚¹**ï¼š
1. **ä¸“æ³¨äºå½“å‰ä»»åŠ¡æœ¬èº«**ï¼Œè€Œéæ•´ä¸ªé¡¹ç›®çš„æ•´ä½“åŠ¨æœº
2. åŒä¸€ä¸ªé¡¹ç›®ä¸­ï¼Œä¸åŒä»»åŠ¡å¯ä»¥æœ‰ä¸åŒçš„åŠ¨æœºç±»å‹
3. æ ¹æ®ä»»åŠ¡çš„å…·ä½“å†…å®¹å’Œå…³é”®è¯åˆ¤æ–­ï¼Œä¸è¦è¢«é¡¹ç›®æ•´ä½“æè¿°è¿‡åº¦å½±å“

ä¾‹å¦‚ï¼š
- "é«˜åŸç¯å¢ƒé€‚åº”æ€§ç ”ç©¶" â†’ technicalï¼ˆæŠ€æœ¯åˆ›æ–°ï¼‰
- "æ–‡åŒ–ç¬¦å·æç‚¼" â†’ culturalï¼ˆæ–‡åŒ–è®¤åŒï¼‰
- "æƒ…æ„Ÿæ°›å›´è¥é€ " â†’ emotionalï¼ˆæƒ…æ„Ÿæ€§ï¼‰
- "ææ–™ä¾›åº”é“¾è§„åˆ’" â†’ sustainableï¼ˆå¯æŒç»­ä»·å€¼ï¼‰

è¯·åˆ†æå½“å‰ä»»åŠ¡çš„åŠ¨æœºç±»å‹ï¼š
1. é€‰æ‹©æœ€åŒ¹é…çš„ä¸»è¦åŠ¨æœºç±»å‹ï¼ˆprimaryï¼‰
2. å¦‚æœæœ‰æ˜æ˜¾çš„æ¬¡è¦åŠ¨æœºï¼Œåˆ—å‡º1-2ä¸ªï¼ˆsecondaryï¼‰
3. ç»™å‡º0-1ä¹‹é—´çš„ç½®ä¿¡åº¦ï¼ˆconfidenceï¼‰
4. ç”¨ç®€çŸ­ä¸€å¥è¯è¯´æ˜æ¨ç†è¿‡ç¨‹ï¼ˆreasoningï¼Œ30å­—ä»¥å†…ï¼‰

ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{{
    "primary": "ç±»å‹è‹±æ–‡ID",
    "secondary": ["ç±»å‹1", "ç±»å‹2"],
    "confidence": 0.XX,
    "reasoning": "æ¨ç†è¯´æ˜"
}}"""

        # è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡ºPromptçš„å‰500å­—ç¬¦
        logger.debug(f"ğŸ” [LLM Prompt Preview] ä»»åŠ¡: {task.get('title', '')[:30]}")
        logger.debug(f"ğŸ” [åŠ¨æœºç±»å‹åˆ—è¡¨] {types_text[:300]}...")

        try:
            # å¯¼å…¥LLM
            from langchain_core.messages import HumanMessage

            from ..services.llm_factory import LLMFactory

            llm = LLMFactory.create_llm()
            timeout = self.registry.get_config("llm_inference.timeout", 30)

            # å¼‚æ­¥è°ƒç”¨LLM
            response = await asyncio.wait_for(llm.ainvoke([HumanMessage(content=prompt)]), timeout=timeout)

            # è§£æå“åº”
            response_text = response.content if hasattr(response, "content") else str(response)

            # æå–JSON
            import re

            json_match = re.search(r"\{[^{}]*\}", response_text, re.DOTALL)
            if not json_match:
                raise ValueError("æœªæ‰¾åˆ°JSONæ ¼å¼å“åº”")

            result_data = json.loads(json_match.group())

            # éªŒè¯ç»“æœ
            primary_id = result_data.get("primary", "mixed")
            primary_type = self.registry.get_type(primary_id)

            if not primary_type:
                logger.warning(f"âš ï¸ LLMè¿”å›æœªçŸ¥ç±»å‹: {primary_id}ï¼Œä½¿ç”¨mixed")
                primary_id = "mixed"
                primary_type = self.registry.get_type("mixed")

            confidence = float(result_data.get("confidence", 0.5))
            reasoning = result_data.get("reasoning", "LLMåˆ†æç»“æœ")
            secondary = result_data.get("secondary", [])

            # æ„å»ºè¯„åˆ†å­—å…¸
            scores = {primary_id: confidence}
            for sec_id in secondary:
                if self.registry.get_type(sec_id):
                    scores[sec_id] = confidence * 0.6  # æ¬¡è¦åŠ¨æœºè¯„åˆ†ä¸ºä¸»è¦çš„60%

            logger.info(f"âœ… [LLM] æ¨æ–­å®Œæˆ: {primary_type.label_zh} (ç½®ä¿¡åº¦: {confidence:.2f})")

            return MotivationResult(
                primary=primary_id,
                primary_label=primary_type.label_zh,
                scores=scores,
                confidence=confidence,
                reasoning=reasoning,
                method="llm",
                secondary=secondary if secondary else None,
            )

        except asyncio.TimeoutError:
            logger.warning(f"âš ï¸ [LLM] è¶…æ—¶ ({timeout}s)ï¼Œé™çº§åˆ°å…³é”®è¯åŒ¹é…")
            raise
        except Exception as e:
            logger.warning(f"âš ï¸ [LLM] æ¨ç†å¤±è´¥: {e}")
            raise

    def _keyword_matching(
        self, task: Dict[str, Any], user_input: str, structured_data: Optional[Dict[str, Any]]
    ) -> MotivationResult:
        """Level 2: å¢å¼ºå…³é”®è¯åŒ¹é…"""

        title = task.get("title", "").lower()
        desc = task.get("description", "").lower()
        user_text = (user_input or "").lower()

        # è·å–æƒé‡é…ç½®
        title_weight = self.registry.get_config("keyword_matching.title_weight", 2.0)
        desc_weight = self.registry.get_config("keyword_matching.description_weight", 1.0)
        context_weight = self.registry.get_config("keyword_matching.context_weight", 0.5)

        # è®¡ç®—æ¯ä¸ªç±»å‹çš„åŒ¹é…åˆ†æ•°
        scores = {}
        for mtype in self.registry.get_all_types():
            if not mtype.keywords:
                continue

            score = 0.0
            matched_keywords = []

            for keyword in mtype.keywords:
                kw = keyword.lower()
                if kw in title:
                    score += title_weight
                    matched_keywords.append(keyword)
                if kw in desc:
                    score += desc_weight
                    matched_keywords.append(keyword)
                if kw in user_text:
                    score += context_weight

            if score > 0:
                scores[mtype.id] = min(score / 10.0, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
                logger.debug(f"   {mtype.label_zh}: {scores[mtype.id]:.2f} (å…³é”®è¯: {matched_keywords[:3]})")

        # æ‰¾åˆ°æœ€é«˜åˆ†
        if not scores:
            return MotivationResult(
                primary="mixed",
                primary_label="ç»¼åˆéœ€æ±‚",
                scores={"mixed": 1.0},
                confidence=0.3,
                reasoning="æœªåŒ¹é…åˆ°ä»»ä½•å…³é”®è¯",
                method="keyword",
            )

        primary_id = max(scores.items(), key=lambda x: x[1])[0]
        primary_type = self.registry.get_type(primary_id)
        confidence = scores[primary_id]

        # æ‰¾æ¬¡è¦ç±»å‹
        secondary = [k for k, v in sorted(scores.items(), key=lambda x: -x[1])[1:3] if v >= 0.4]

        return MotivationResult(
            primary=primary_id,
            primary_label=primary_type.label_zh,
            scores=scores,
            confidence=confidence,
            reasoning=f"åŸºäºå…³é”®è¯åŒ¹é…è¯†åˆ«ä¸º{primary_type.label_zh}",
            method="keyword",
            secondary=secondary if secondary else None,
        )

    def _rule_based_inference(
        self, task: Dict[str, Any], structured_data: Optional[Dict[str, Any]]
    ) -> MotivationResult:
        """Level 3: è§„åˆ™å¼•æ“ï¼ˆåŸºäºé¡¹ç›®ç±»å‹ç­‰ï¼‰"""

        # ç®€å•è§„åˆ™ï¼šåŸºäºä»»åŠ¡ç±»å‹
        task_type = task.get("task_type", "").lower()

        if task_type == "research":
            return MotivationResult(
                primary="functional",
                primary_label="åŠŸèƒ½æ€§éœ€æ±‚",
                scores={"functional": 0.6},
                confidence=0.5,
                reasoning="ç ”ç©¶ç±»ä»»åŠ¡é»˜è®¤ä¸ºåŠŸèƒ½æ€§éœ€æ±‚",
                method="rule",
            )

        # é»˜è®¤
        return MotivationResult(
            primary="mixed",
            primary_label="ç»¼åˆéœ€æ±‚",
            scores={"mixed": 0.5},
            confidence=0.4,
            reasoning="æ— åŒ¹é…è§„åˆ™ï¼Œé»˜è®¤ç»¼åˆéœ€æ±‚",
            method="rule",
        )


# å…¨å±€å•ä¾‹
_engine: Optional[MotivationInferenceEngine] = None


def get_motivation_engine() -> MotivationInferenceEngine:
    """è·å–åŠ¨æœºæ¨æ–­å¼•æ“å•ä¾‹"""
    global _engine
    if _engine is None:
        _engine = MotivationInferenceEngine()
    return _engine


# ==================== æ·±åº¦æ´å¯Ÿåˆ†æ ====================


@dataclass
class MotivationInsight:
    """åŠ¨æœºæ·±åº¦æ´å¯Ÿç»“æœ"""

    l1_surface: Dict[str, Any]  # L1å±‚ï¼šè¡¨å±‚éœ€æ±‚
    l2_implicit: Dict[str, Any]  # L2å±‚ï¼šéšå«åŠ¨æœº
    l3_deep: Dict[str, Any]  # L3å±‚ï¼šæ·±å±‚é©±åŠ¨
    core_tensions: List[str]  # æ ¸å¿ƒå¼ åŠ›
    unspoken_expectations: List[str]  # æœªè¯´å‡ºå£çš„æœŸå¾…
    risk_blind_spots: List[str]  # é£é™©ç›²åŒº


async def deep_motivation_analysis(
    task: Dict[str, Any],
    user_input: str,
    basic_result: MotivationResult,
    structured_data: Optional[Dict[str, Any]] = None,
) -> MotivationInsight:
    """
    æ·±åº¦åŠ¨æœºæ´å¯Ÿåˆ†æï¼ˆL1/L2/L3å±‚æ¬¡ï¼‰

    Args:
        task: ä»»åŠ¡ä¿¡æ¯
        user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
        basic_result: åŸºç¡€åŠ¨æœºè¯†åˆ«ç»“æœ
        structured_data: ç»“æ„åŒ–ä¸Šä¸‹æ–‡

    Returns:
        MotivationInsight: æ·±åº¦æ´å¯Ÿç»“æœ
    """

    # L1å±‚ï¼šè¡¨å±‚éœ€æ±‚ï¼ˆç›´æ¥ä»basic_resultæå–ï¼‰
    l1_surface = {
        "primary_motivation": basic_result.primary,
        "primary_label": basic_result.primary_label,
        "confidence": basic_result.confidence,
        "scores": basic_result.scores,
        "explicit_keywords": _extract_explicit_keywords(user_input, basic_result),
    }

    # L2/L3å±‚éœ€è¦LLMæ·±åº¦åˆ†æ
    try:
        llm_insight = await _llm_deep_analysis(task, user_input, basic_result, structured_data)

        l2_implicit = llm_insight.get("l2_implicit", {})
        l3_deep = llm_insight.get("l3_deep", {})
        core_tensions = llm_insight.get("core_tensions", [])
        unspoken_expectations = llm_insight.get("unspoken_expectations", [])
        risk_blind_spots = llm_insight.get("risk_blind_spots", [])

    except Exception as e:
        logger.warning(f"âš ï¸ [Deep Insight] LLMåˆ†æå¤±è´¥: {e}")

        # é™çº§ï¼šåŸºäºè§„åˆ™çš„ç®€åŒ–åˆ†æ
        l2_implicit = _rule_based_implicit_analysis(basic_result)
        l3_deep = _rule_based_deep_analysis(basic_result)
        core_tensions = []
        unspoken_expectations = []
        risk_blind_spots = []

    return MotivationInsight(
        l1_surface=l1_surface,
        l2_implicit=l2_implicit,
        l3_deep=l3_deep,
        core_tensions=core_tensions,
        unspoken_expectations=unspoken_expectations,
        risk_blind_spots=risk_blind_spots,
    )


def _extract_explicit_keywords(user_input: str, result: MotivationResult) -> List[str]:
    """æå–ç”¨æˆ·è¾“å…¥ä¸­çš„æ˜¾æ€§å…³é”®è¯"""
    registry = MotivationTypeRegistry()
    motivation_type = registry.get_type(result.primary)

    if not motivation_type:
        return []

    # æ£€æŸ¥å“ªäº›å…³é”®è¯å‡ºç°åœ¨ç”¨æˆ·è¾“å…¥ä¸­
    explicit_keywords = []
    for keyword, weight in motivation_type.keywords.items():
        if keyword in user_input.lower():
            explicit_keywords.append(keyword)

    return explicit_keywords[:10]  # æœ€å¤š10ä¸ª


async def _llm_deep_analysis(
    task: Dict[str, Any], user_input: str, basic_result: MotivationResult, structured_data: Optional[Dict[str, Any]]
) -> Dict[str, Any]:
    """ä½¿ç”¨LLMè¿›è¡ŒL2/L3æ·±åº¦åˆ†æ"""

    # æ„å»ºä¸Šä¸‹æ–‡
    context_parts = []
    if structured_data:
        for key, value in structured_data.items():
            if value:
                context_parts.append(f"- {key}: {value}")
    context_text = "\n".join(context_parts) if context_parts else "ï¼ˆæ— é¢å¤–ä¸Šä¸‹æ–‡ï¼‰"

    # æ„å»ºprompt
    prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„è®¾è®¡ç ”ç©¶ä¸“å®¶ï¼Œæ“…é•¿æ´å¯Ÿç”¨æˆ·çš„æ·±å±‚éœ€æ±‚å’ŒåŠ¨æœºã€‚

**ä»»åŠ¡ä¿¡æ¯ï¼š**
- æ ‡é¢˜ï¼š{task.get('title', 'æœªçŸ¥')}
- æè¿°ï¼š{task.get('description', 'æœªçŸ¥')}

**ç”¨æˆ·åŸå§‹è¾“å…¥ï¼š**
{user_input}

**ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š**
{context_text}

**åˆæ­¥åŠ¨æœºè¯†åˆ«ï¼š**
- ä¸»è¦åŠ¨æœºï¼š{basic_result.primary_label} ({basic_result.primary})
- ç½®ä¿¡åº¦ï¼š{basic_result.confidence:.2f}
- æ¨ç†ï¼š{basic_result.reasoning}

è¯·è¿›è¡Œä¸‰å±‚æ·±åº¦åˆ†æï¼š

**L1å±‚ - è¡¨å±‚éœ€æ±‚**ï¼ˆå·²è¯†åˆ«ï¼‰ï¼š
{basic_result.primary_label}

**L2å±‚ - éšå«åŠ¨æœº**ï¼š
ä»ç”¨æˆ·çš„è¡¨è¿°ã€è¯­æ°”ã€å…³æ³¨ç‚¹ä¸­ï¼Œæ¨æ–­å‡ºæœªæ˜ç¡®è¯´å‡ºçš„éšå«åŠ¨æœºã€‚è¿™äº›åŠ¨æœºå¯èƒ½å½±å“å†³ç­–æ–¹å‘ï¼Œä½†ç”¨æˆ·è‡ªå·±å¯èƒ½æœªæ„è¯†åˆ°ã€‚

**L3å±‚ - æ·±å±‚é©±åŠ¨**ï¼š
ç»“åˆé©¬æ–¯æ´›éœ€æ±‚å±‚æ¬¡ç†è®ºï¼Œåˆ†ææ›´æ·±å±‚çš„å¿ƒç†é©±åŠ¨ï¼š
- ç”Ÿç†éœ€æ±‚ï¼šåŸºæœ¬åŠŸèƒ½ã€èˆ’é€‚åº¦
- å®‰å…¨éœ€æ±‚ï¼šç¨³å®šæ€§ã€å¯é æ€§ã€é£é™©è§„é¿
- ç¤¾äº¤éœ€æ±‚ï¼šå½’å±æ„Ÿã€è®¤åŒæ„Ÿã€å…³ç³»å»ºç«‹
- å°Šé‡éœ€æ±‚ï¼šåœ°ä½ã€å£°èª‰ã€æˆå°±æ„Ÿ
- è‡ªæˆ‘å®ç°ï¼šåˆ›æ–°ã€æ„ä¹‰ã€ä»·å€¼åˆ›é€ 

**å…³é”®åˆ†æç‚¹ï¼š**
1. æ ¸å¿ƒå¼ åŠ›ï¼šç”¨æˆ·éœ€æ±‚ä¸­å­˜åœ¨å“ªäº›çŸ›ç›¾æˆ–å¼ åŠ›ï¼Ÿï¼ˆå¦‚æˆæœ¬vsè´¨é‡ã€åˆ›æ–°vsç¨³å¦¥ï¼‰
2. æœªè¯´å‡ºå£çš„æœŸå¾…ï¼šç”¨æˆ·å¯èƒ½æœŸå¾…ä½†æœªæ˜ç¡®æåŠçš„ä¸œè¥¿ï¼Ÿ
3. é£é™©ç›²åŒºï¼šç”¨æˆ·å¯èƒ½å¿½è§†ä½†é‡è¦çš„é£é™©ç‚¹ï¼Ÿ

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
  "l2_implicit": {{
    "hidden_motivations": ["éšå«åŠ¨æœº1", "éšå«åŠ¨æœº2"],
    "emotional_drivers": ["æƒ…ç»ªé©±åŠ¨1", "æƒ…ç»ªé©±åŠ¨2"],
    "stakeholder_concerns": ["åˆ©ç›Šç›¸å…³è€…å…³æ³¨1", "å…³æ³¨2"]
  }},
  "l3_deep": {{
    "maslow_level": "å¯¹åº”çš„é©¬æ–¯æ´›å±‚æ¬¡",
    "psychological_drivers": ["å¿ƒç†é©±åŠ¨1", "é©±åŠ¨2"],
    "underlying_values": ["åº•å±‚ä»·å€¼è§‚1", "ä»·å€¼è§‚2"],
    "long_term_impact": "é•¿æœŸå½±å“åˆ†æ"
  }},
  "core_tensions": ["å¼ åŠ›1ï¼šA vs B", "å¼ åŠ›2ï¼šX vs Y"],
  "unspoken_expectations": ["æœŸå¾…1", "æœŸå¾…2"],
  "risk_blind_spots": ["é£é™©1ï¼šæè¿°", "é£é™©2ï¼šæè¿°"]
}}"""

    try:
        import re

        from langchain_core.messages import HumanMessage

        from intelligent_project_analyzer.services.llm_factory import LLMFactory

        llm = LLMFactory.create_llm()
        response = await asyncio.wait_for(llm.ainvoke([HumanMessage(content=prompt)]), timeout=45)  # 45ç§’è¶…æ—¶

        # æå–JSON
        json_match = re.search(r"\{.*\}", response.content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group())
        else:
            raise ValueError("LLMæœªè¿”å›æœ‰æ•ˆJSON")

    except Exception as e:
        logger.error(f"âŒ [Deep Analysis] LLMå¤±è´¥: {e}")
        raise


def _rule_based_implicit_analysis(basic_result: MotivationResult) -> Dict[str, Any]:
    """åŸºäºè§„åˆ™çš„L2å±‚ç®€åŒ–åˆ†æ"""

    # æ ¹æ®åŠ¨æœºç±»å‹æ˜ å°„å¸¸è§éšå«åŠ¨æœº
    implicit_mapping = {
        "cultural": {
            "hidden_motivations": ["æ–‡åŒ–è®¤åŒç„¦è™‘", "ä¼ ç»Ÿä¸ç°ä»£çš„å¹³è¡¡"],
            "emotional_drivers": ["å½’å±æ„Ÿ", "æ–‡åŒ–è‡ªè±ª"],
            "stakeholder_concerns": ["ç¤¾åŒºåé¦ˆ", "æ–‡åŒ–ä¸“å®¶è®¤å¯"],
        },
        "commercial": {
            "hidden_motivations": ["æŠ•èµ„å›æŠ¥å‹åŠ›", "å¸‚åœºç«äº‰ç„¦è™‘"],
            "emotional_drivers": ["æˆåŠŸæ¬²æœ›", "ç»æµå®‰å…¨æ„Ÿ"],
            "stakeholder_concerns": ["æŠ•èµ„äººæœŸå¾…", "è´¢åŠ¡å¯æŒç»­æ€§"],
        },
        "wellness": {
            "hidden_motivations": ["å¥åº·ç„¦è™‘", "ç”Ÿæ´»è´¨é‡æå‡"],
            "emotional_drivers": ["å®‰å…¨æ„Ÿ", "å…³æ€€"],
            "stakeholder_concerns": ["ç”¨æˆ·å¥åº·", "åŒ»ç–—ä¸“ä¸šæ€§"],
        },
        "functional": {
            "hidden_motivations": ["æ•ˆç‡ç„¦è™‘", "æŠ€æœ¯èƒ½åŠ›è¯æ˜"],
            "emotional_drivers": ["æ§åˆ¶æ„Ÿ", "æˆå°±æ„Ÿ"],
            "stakeholder_concerns": ["ç”¨æˆ·ä½“éªŒ", "æŠ€æœ¯å¯è¡Œæ€§"],
        },
    }

    return implicit_mapping.get(
        basic_result.primary,
        {"hidden_motivations": ["å¾…æ·±åº¦åˆ†æ"], "emotional_drivers": ["å¾…æ·±åº¦åˆ†æ"], "stakeholder_concerns": ["å¾…æ·±åº¦åˆ†æ"]},
    )


def _rule_based_deep_analysis(basic_result: MotivationResult) -> Dict[str, Any]:
    """åŸºäºè§„åˆ™çš„L3å±‚ç®€åŒ–åˆ†æ"""

    # æ ¹æ®åŠ¨æœºç±»å‹æ˜ å°„é©¬æ–¯æ´›å±‚æ¬¡
    maslow_mapping = {
        "wellness": {
            "maslow_level": "å®‰å…¨éœ€æ±‚",
            "psychological_drivers": ["å¥åº·ä¿éšœ", "é£é™©è§„é¿"],
            "underlying_values": ["ç”Ÿå‘½ä»·å€¼", "é¢„é˜²ç†å¿µ"],
            "long_term_impact": "æå‡ç”¨æˆ·é•¿æœŸå¥åº·æ°´å¹³å’Œç”Ÿæ´»è´¨é‡",
        },
        "social": {
            "maslow_level": "ç¤¾äº¤éœ€æ±‚",
            "psychological_drivers": ["å½’å±æ„Ÿ", "è¿æ¥æ„Ÿ"],
            "underlying_values": ["å…³ç³»ä»·å€¼", "ç¤¾ç¾¤è®¤åŒ"],
            "long_term_impact": "å»ºç«‹æŒä¹…çš„ç¤¾äº¤å…³ç³»å’Œç¤¾åŒºè”ç»“",
        },
        "aesthetic": {
            "maslow_level": "å°Šé‡éœ€æ±‚",
            "psychological_drivers": ["å“å‘³è®¤åŒ", "å®¡ç¾è¡¨è¾¾"],
            "underlying_values": ["ç¾å­¦ä»·å€¼", "ä¸ªæ€§è¡¨è¾¾"],
            "long_term_impact": "å¡‘é€ å“ç‰Œå½¢è±¡å’Œç”¨æˆ·æ„ŸçŸ¥",
        },
        "commercial": {
            "maslow_level": "å®‰å…¨éœ€æ±‚",
            "psychological_drivers": ["ç»æµç¨³å®š", "å•†ä¸šæˆåŠŸ"],
            "underlying_values": ["ä»·å€¼åˆ›é€ ", "å¯æŒç»­æ€§"],
            "long_term_impact": "å®ç°å•†ä¸šä»·å€¼å’Œè´¢åŠ¡å¯æŒç»­",
        },
        "cultural": {
            "maslow_level": "è‡ªæˆ‘å®ç°",
            "psychological_drivers": ["æ„ä¹‰è¿½å¯»", "æ–‡åŒ–ä¼ æ‰¿"],
            "underlying_values": ["æ–‡åŒ–ä»·å€¼", "å†å²è´£ä»»"],
            "long_term_impact": "ä¿æŠ¤å’Œä¼ æ‰¿æ–‡åŒ–é—äº§ï¼Œå»ºç«‹æ–‡åŒ–è®¤åŒ",
        },
    }

    return maslow_mapping.get(
        basic_result.primary,
        {
            "maslow_level": "å¾…æ·±åº¦åˆ†æ",
            "psychological_drivers": ["å¾…æ·±åº¦åˆ†æ"],
            "underlying_values": ["å¾…æ·±åº¦åˆ†æ"],
            "long_term_impact": "å¾…æ·±åº¦åˆ†æ",
        },
    )
