"""
Redis ä¼šè¯ç®¡ç†å™¨

è´Ÿè´£ä¼šè¯çš„æŒä¹…åŒ–å­˜å‚¨ã€åˆ†å¸ƒå¼é”ã€TTL ç®¡ç†
è§£å†³å¹¶å‘ä¼šè¯ç«äº‰é—®é¢˜
"""

import asyncio
import json
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import redis.asyncio as aioredis
from langgraph.types import Interrupt
from loguru import logger
from pydantic import BaseModel
from redis.asyncio import Redis
from redis.asyncio.lock import Lock
from redis.exceptions import LockError, RedisError

from ..settings import settings


# è‡ªå®šä¹‰ JSON ç¼–ç å™¨ï¼Œå¤„ç† Pydantic æ¨¡å‹
class PydanticEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, BaseModel):
            return obj.model_dump()
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)


class RedisSessionManager:
    """Redis ä¼šè¯ç®¡ç†å™¨"""

    @staticmethod
    def _sanitize_for_json(payload: Any) -> Any:
        """é€’å½’ç§»é™¤æ— æ³•åºåˆ—åŒ–åˆ° JSON çš„å¯¹è±¡ï¼ˆä¾‹å¦‚ Interruptï¼‰"""

        if isinstance(payload, Interrupt):
            return RedisSessionManager._sanitize_for_json(getattr(payload, "value", None))

        if isinstance(payload, dict):
            return {key: RedisSessionManager._sanitize_for_json(value) for key, value in payload.items()}

        if isinstance(payload, list):
            return [RedisSessionManager._sanitize_for_json(item) for item in payload]

        if isinstance(payload, tuple):
            return [RedisSessionManager._sanitize_for_json(item) for item in payload]

        if isinstance(payload, set):
            return [RedisSessionManager._sanitize_for_json(item) for item in payload]

        return payload

    # å¸¸é‡é…ç½®
    SESSION_PREFIX = "session:"
    LOCK_PREFIX = "lock:session:"
    WEBSOCKET_PREFIX = "ws:session:"
    SESSION_TTL = 604800  # ğŸ”¥ v3.6ä¼˜åŒ–: ä¼šè¯è¿‡æœŸæ—¶é—´ä»1å°æ—¶å»¶é•¿åˆ°7å¤©ï¼ˆ604800ç§’ï¼‰
    LOCK_TIMEOUT = 60  # âœ… Fix 1.2: é”è¶…æ—¶æ—¶é—´ä»30ç§’å¢åŠ åˆ°60ç§’

    def __init__(self, redis_url: Optional[str] = None, fallback_to_memory: bool = True):
        """
        åˆå§‹åŒ– Redis ä¼šè¯ç®¡ç†å™¨

        Args:
            redis_url: Redis è¿æ¥ URLï¼ˆé»˜è®¤ä» settings è¯»å–ï¼‰
            fallback_to_memory: Redis è¿æ¥å¤±è´¥æ—¶æ˜¯å¦å›é€€åˆ°å†…å­˜æ¨¡å¼
        """
        self.redis_url = redis_url or settings.redis_url
        self.fallback_to_memory = fallback_to_memory
        self.redis_client: Optional[Redis] = None
        self.is_connected = False

        # å†…å­˜å›é€€å­˜å‚¨ï¼ˆä»…ç”¨äºå¼€å‘ç¯å¢ƒï¼‰
        self._memory_sessions: Dict[str, Dict[str, Any]] = {}
        self._memory_mode = False

        # ğŸ”¥ v7.105: æ·»åŠ ä¼šè¯åˆ—è¡¨ç¼“å­˜ï¼ˆ10åˆ†é’ŸTTLï¼‰
        self._sessions_cache: Optional[List[Dict[str, Any]]] = None
        self._cache_timestamp: Optional[datetime] = None
        self._cache_ttl = 600  # âœ… v7.118: ä»5åˆ†é’Ÿå¢åŠ åˆ°10åˆ†é’Ÿï¼Œå‡å°‘RedisæŸ¥è¯¢é¢‘ç‡

    async def connect(self) -> bool:
        """
        è¿æ¥åˆ° Redis

        Returns:
            æ˜¯å¦æˆåŠŸè¿æ¥
        """
        try:
            # åˆ›å»ºè¿æ¥æ± é…ç½®
            self.redis_client = await aioredis.from_url(
                self.redis_url,
                encoding="utf-8",
                decode_responses=True,
                max_connections=50,
                socket_connect_timeout=10,  # ä¿æŒè¿æ¥è¶…æ—¶10ç§’
                socket_timeout=30,  # âœ… Fix 1.3: æ“ä½œè¶…æ—¶ä»10ç§’å¢åŠ åˆ°30ç§’
                retry_on_timeout=True,  # å¯ç”¨è¶…æ—¶é‡è¯•
                retry_on_error=[ConnectionError, TimeoutError],  # âœ… Fix 1.3: å¢åŠ è¿æ¥é”™è¯¯é‡è¯•
            )

            # æµ‹è¯•è¿æ¥
            await self.redis_client.ping()
            self.is_connected = True
            self._memory_mode = False
            logger.info(f"âœ… Redis è¿æ¥æˆåŠŸ: {self.redis_url}")
            return True

        except (RedisError, ConnectionError, TimeoutError) as e:
            logger.warning(f"âš ï¸ Redis è¿æ¥å¤±è´¥: {e}")

            if self.fallback_to_memory:
                logger.warning("ğŸ”„ å›é€€åˆ°å†…å­˜æ¨¡å¼ï¼ˆä»…é€‚ç”¨äºå¼€å‘ç¯å¢ƒï¼‰")
                self._memory_mode = True
                self.is_connected = False
                return True  # å†…å­˜æ¨¡å¼è§†ä¸º"æˆåŠŸ"
            else:
                logger.error("âŒ Redis ä¸å¯ç”¨ä¸”æœªå¯ç”¨å›é€€æ¨¡å¼")
                return False

    async def disconnect(self):
        """æ–­å¼€ Redis è¿æ¥"""
        if self.redis_client:
            await self.redis_client.close()
            self.is_connected = False
            logger.info("ğŸ‘‹ Redis è¿æ¥å·²å…³é—­")

    def _get_session_key(self, session_id: str) -> str:
        """è·å–ä¼šè¯é”®å"""
        return f"{self.SESSION_PREFIX}{session_id}"

    def _get_lock_key(self, session_id: str) -> str:
        """è·å–é”é”®å"""
        return f"{self.LOCK_PREFIX}{session_id}"

    async def create(self, session_id: str, session_data: Dict[str, Any]) -> bool:
        """
        åˆ›å»ºæ–°ä¼šè¯

        Args:
            session_id: ä¼šè¯ ID
            session_data: ä¼šè¯æ•°æ®

        Returns:
            æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        try:
            # æ·»åŠ åˆ›å»ºæ—¶é—´
            session_data["created_at"] = datetime.now().isoformat()
            session_data["session_id"] = session_id
            sanitized_data = self._sanitize_for_json(session_data)

            if self._memory_mode:
                # å†…å­˜æ¨¡å¼
                self._memory_sessions[session_id] = sanitized_data
                logger.debug(f"ğŸ“ [å†…å­˜] åˆ›å»ºä¼šè¯: {session_id}")
                self._invalidate_cache()  # âœ… Fix 1.4: æ¸…é™¤ç¼“å­˜
                return True

            # Redis æ¨¡å¼
            key = self._get_session_key(session_id)
            await self.redis_client.setex(
                key, self.SESSION_TTL, json.dumps(sanitized_data, ensure_ascii=False, cls=PydanticEncoder)
            )
            logger.debug(f"ğŸ“ [Redis] åˆ›å»ºä¼šè¯: {session_id} (TTL={self.SESSION_TTL}s)")
            self._invalidate_cache()  # âœ… Fix 1.4: æ¸…é™¤ç¼“å­˜
            return True

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºä¼šè¯å¤±è´¥: {session_id}, é”™è¯¯: {e}")
            return False

    async def get(self, session_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–ä¼šè¯æ•°æ®

        Args:
            session_id: ä¼šè¯ ID

        Returns:
            ä¼šè¯æ•°æ®ï¼ˆä¸å­˜åœ¨è¿”å› Noneï¼‰
        """
        max_retries = 3

        for attempt in range(max_retries):
            try:
                if self._memory_mode:
                    # å†…å­˜æ¨¡å¼
                    return self._memory_sessions.get(session_id)

                # Redis æ¨¡å¼
                key = self._get_session_key(session_id)
                data = await self.redis_client.get(key)

                if data:
                    return json.loads(data)
                return None

            except (RedisError, ConnectionError, TimeoutError) as e:
                if attempt < max_retries - 1:
                    logger.warning(f"âš ï¸ è·å–ä¼šè¯å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}, é‡è¯•ä¸­...")
                    await asyncio.sleep(0.5 * (attempt + 1))
                else:
                    logger.error(f"âŒ è·å–ä¼šè¯å¤±è´¥ (æœ€ç»ˆ): {session_id}, é”™è¯¯: {e}")
                    return None
            except Exception as e:
                logger.error(f"âŒ è·å–ä¼šè¯å¤±è´¥ (æœªçŸ¥é”™è¯¯): {session_id}, é”™è¯¯: {e}")
                return None

    async def update(self, session_id: str, updates: Dict[str, Any]) -> bool:
        """
        æ›´æ–°ä¼šè¯æ•°æ®ï¼ˆåˆå¹¶æ›´æ–°ï¼‰

        Args:
            session_id: ä¼šè¯ ID
            updates: è¦æ›´æ–°çš„å­—æ®µ

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        max_retries = 3

        for attempt in range(max_retries):
            try:
                if self._memory_mode:
                    # å†…å­˜æ¨¡å¼
                    if session_id not in self._memory_sessions:
                        logger.warning(f"âš ï¸ ä¼šè¯ä¸å­˜åœ¨: {session_id}")
                        return False

                    sanitized_updates = self._sanitize_for_json(updates)
                    self._memory_sessions[session_id].update(sanitized_updates)
                    logger.debug(f"ğŸ”„ [å†…å­˜] æ›´æ–°ä¼šè¯: {session_id}")
                    return True

                # Redis æ¨¡å¼ - ä½¿ç”¨åˆ†å¸ƒå¼é”é˜²æ­¢å¹¶å‘å†²çª
                lock = Lock(self.redis_client, self._get_lock_key(session_id), timeout=self.LOCK_TIMEOUT)

                try:
                    async with lock:
                        session_data = await self.get(session_id)
                        if not session_data:
                            logger.warning(f"âš ï¸ ä¼šè¯ä¸å­˜åœ¨: {session_id}")
                            return False

                        # åˆå¹¶æ›´æ–°
                        sanitized_updates = self._sanitize_for_json(updates)
                        session_data.update(sanitized_updates)
                        sanitized_session = self._sanitize_for_json(session_data)

                        # å†™å› Redis å¹¶åˆ·æ–° TTL
                        key = self._get_session_key(session_id)
                        await self.redis_client.setex(
                            key,
                            self.SESSION_TTL,
                            json.dumps(sanitized_session, ensure_ascii=False, cls=PydanticEncoder),
                        )

                        logger.debug(f"ğŸ”„ [Redis] æ›´æ–°ä¼šè¯: {session_id}")
                        self._invalidate_cache()  # âœ… Fix 1.4: æ¸…é™¤ç¼“å­˜
                        return True

                except LockError as e:
                    # âœ… Fix 1.2: Separate handling for lock errors
                    if "no longer owned" in str(e):
                        logger.warning(f"âš ï¸ æ›´æ–°ä¼šè¯æ—¶é”å·²è¿‡æœŸ (å°è¯• {attempt + 1}/{max_retries}): {session_id}")
                        # Data was likely written before lock expired
                        if attempt == 0:  # Only log info once
                            logger.info(f"â„¹ï¸ ä¼šè¯æ›´æ–°å¯èƒ½å·²å®Œæˆï¼Œå°½ç®¡é”é‡Šæ”¾å¤±è´¥")
                        return True  # Treat as success since data was written
                    else:
                        # Lock acquisition failed - will retry
                        logger.warning(f"âš ï¸ è·å–é”å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                        raise  # Re-raise to trigger retry logic

            except (RedisError, ConnectionError, TimeoutError, LockError) as e:
                if attempt < max_retries - 1:
                    logger.warning(f"âš ï¸ æ›´æ–°ä¼šè¯å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}, é‡è¯•ä¸­...")
                    await asyncio.sleep(0.5 * (attempt + 1))
                else:
                    logger.error(f"âŒ æ›´æ–°ä¼šè¯å¤±è´¥ (æœ€ç»ˆ): {session_id}, é”™è¯¯: {e}")
                    return False
            except Exception as e:
                logger.error(f"âŒ æ›´æ–°ä¼šè¯å¤±è´¥ (æœªçŸ¥é”™è¯¯): {session_id}, é”™è¯¯: {e}")
                return False

    async def cleanup_invalid_user_sessions(self, user_id: str) -> int:
        """
        æ¸…ç†ç”¨æˆ·ç´¢å¼•ä¸­çš„æ— æ•ˆä¼šè¯ï¼ˆä¼šè¯æ•°æ®ä¸å­˜åœ¨ä½†ç´¢å¼•æ®‹ç•™ï¼‰

        ğŸ†• v7.106.1: è‡ªåŠ¨æ¸…ç†å¹½çµä¼šè¯ç´¢å¼•

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            æ¸…ç†çš„æ— æ•ˆä¼šè¯æ•°é‡
        """
        if self._memory_mode:
            return 0

        try:
            user_sessions_key = f"user:sessions:{user_id}"
            # è·å–ç”¨æˆ·ç´¢å¼•åˆ—è¡¨ä¸­çš„æ‰€æœ‰ä¼šè¯ID
            session_ids = await self.redis_client.lrange(user_sessions_key, 0, -1)

            if not session_ids:
                return 0

            invalid_count = 0
            for session_id in session_ids:
                # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
                session_key = self._get_session_key(session_id)
                exists = await self.redis_client.exists(session_key)

                if not exists:
                    # ä¼šè¯ä¸å­˜åœ¨ï¼Œä»ç”¨æˆ·ç´¢å¼•ä¸­ç§»é™¤
                    await self.redis_client.lrem(user_sessions_key, 1, session_id)
                    invalid_count += 1
                    logger.info(f"ğŸ§¹ æ¸…ç†æ— æ•ˆä¼šè¯ç´¢å¼•: {session_id} (ç”¨æˆ·: {user_id})")

            if invalid_count > 0:
                logger.info(f"âœ… æ¸…ç†å®Œæˆ: {invalid_count} ä¸ªæ— æ•ˆä¼šè¯ç´¢å¼• (ç”¨æˆ·: {user_id})")

            return invalid_count
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ— æ•ˆä¼šè¯ç´¢å¼•å¤±è´¥ (ç”¨æˆ·: {user_id}): {e}")
            return 0

    async def delete(self, session_id: str) -> bool:
        """
        åˆ é™¤ä¼šè¯ï¼ˆå«åˆ†å¸ƒå¼é”ä¿æŠ¤å’Œçº§è”åˆ é™¤ï¼‰

        ğŸ†• v7.106: æ·»åŠ åˆ†å¸ƒå¼é”ã€çº§è”åˆ é™¤ç”¨æˆ·ç´¢å¼•ã€è¿›åº¦æ•°æ®ã€æ´»è·ƒä¼šè¯æ ‡è®°

        Args:
            session_id: ä¼šè¯ ID

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        lock_key = f"lock:delete:{session_id}"
        lock = None

        try:
            # ğŸ†• v7.106: è·å–åˆ†å¸ƒå¼é”ï¼ˆé˜²æ­¢å¹¶å‘åˆ é™¤ï¼‰
            if not self._memory_mode:
                lock = self.redis_client.lock(lock_key, timeout=10)
                acquired = await lock.acquire(blocking_timeout=3)
                if not acquired:
                    logger.warning(f"âš ï¸ è·å–åˆ é™¤é”å¤±è´¥ï¼ˆä¼šè¯å¯èƒ½æ­£åœ¨è¢«åˆ é™¤ï¼‰: {session_id}")
                    return False

            # 1. è·å–ä¼šè¯ä¿¡æ¯ï¼ˆéœ€è¦user_idï¼‰
            session = await self.get(session_id)
            if not session:
                logger.debug(f"ğŸ—‘ï¸ ä¼šè¯ä¸å­˜åœ¨ï¼ˆå·²åˆ é™¤ï¼‰: {session_id}")
                return True

            user_id = session.get("user_id")

            # 2. åˆ é™¤ä¸»ä¼šè¯æ•°æ®
            if self._memory_mode:
                if session_id in self._memory_sessions:
                    del self._memory_sessions[session_id]
                    logger.debug(f"ğŸ—‘ï¸ [å†…å­˜] åˆ é™¤ä¼šè¯: {session_id}")
            else:
                key = self._get_session_key(session_id)
                await self.redis_client.delete(key)
                logger.debug(f"ğŸ—‘ï¸ [Redis] åˆ é™¤ä¸»ä¼šè¯æ•°æ®: {session_id}")

            # ğŸ†• 3. åˆ é™¤ç”¨æˆ·ç´¢å¼•ï¼ˆå…³é”®ï¼é¿å…ç”¨æˆ·é¢æ¿æ˜¾ç¤ºå¹½çµä¼šè¯ï¼‰
            if user_id and not self._memory_mode:
                user_sessions_key = f"user:sessions:{user_id}"
                removed = await self.redis_client.lrem(user_sessions_key, 1, session_id)
                logger.debug(f"ğŸ—‘ï¸ åˆ é™¤ç”¨æˆ·ç´¢å¼•: {user_sessions_key}, ç§»é™¤æ•°: {removed}")

            # ğŸ†• 4. åˆ é™¤ç”¨æˆ·è¿›åº¦æ•°æ®
            if user_id and not self._memory_mode:
                progress_key = f"user:progress:{user_id}:{session_id}"
                await self.redis_client.delete(progress_key)
                logger.debug(f"ğŸ—‘ï¸ åˆ é™¤è¿›åº¦æ•°æ®: {progress_key}")

            # ğŸ†• 5. æ¸…é™¤æ´»è·ƒä¼šè¯æ ‡è®°ï¼ˆå¦‚æœæ˜¯å½“å‰æ´»è·ƒä¼šè¯ï¼‰
            if user_id and not self._memory_mode:
                active_key = f"user:active:{user_id}"
                current_active = await self.redis_client.get(active_key)
                if current_active and current_active == session_id:
                    await self.redis_client.delete(active_key)
                    logger.debug(f"ğŸ—‘ï¸ æ¸…é™¤æ´»è·ƒä¼šè¯æ ‡è®°: {active_key}")

            # 6. æ¸…é™¤ç¼“å­˜
            self._invalidate_cache()

            logger.info(f"âœ… ä¼šè¯åŠå…³è”æ•°æ®å·²åˆ é™¤: {session_id}, ç”¨æˆ·: {user_id or 'N/A'}")
            return True

        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ä¼šè¯å¤±è´¥: {session_id}, é”™è¯¯: {e}", exc_info=True)
            return False
        finally:
            # é‡Šæ”¾åˆ†å¸ƒå¼é”
            if lock:
                try:
                    await lock.release()
                except Exception as e:
                    logger.warning(f"âš ï¸ é‡Šæ”¾åˆ é™¤é”å¤±è´¥: {e}")

    async def exists(self, session_id: str) -> bool:
        """
        æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨

        Args:
            session_id: ä¼šè¯ ID

        Returns:
            æ˜¯å¦å­˜åœ¨
        """
        try:
            if self._memory_mode:
                return session_id in self._memory_sessions

            key = self._get_session_key(session_id)
            return await self.redis_client.exists(key) > 0

        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ä¼šè¯å­˜åœ¨æ€§å¤±è´¥: {session_id}, é”™è¯¯: {e}")
            return False

    async def extend_ttl(self, session_id: str, ttl: Optional[int] = None) -> bool:
        """
        å»¶é•¿ä¼šè¯è¿‡æœŸæ—¶é—´ï¼ˆç”¨äºæ´»è·ƒä¼šè¯ç»­æœŸï¼‰

        Args:
            session_id: ä¼šè¯ ID
            ttl: æ–°çš„ TTLï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ SESSION_TTL

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            if self._memory_mode:
                # å†…å­˜æ¨¡å¼ä¸éœ€è¦ TTL
                return True

            ttl = ttl or self.SESSION_TTL
            key = self._get_session_key(session_id)
            await self.redis_client.expire(key, ttl)
            logger.debug(f"â° [Redis] å»¶é•¿ä¼šè¯ TTL: {session_id} â†’ {ttl}s")
            return True

        except Exception as e:
            logger.error(f"âŒ å»¶é•¿ä¼šè¯ TTL å¤±è´¥: {session_id}, é”™è¯¯: {e}")
            return False

    async def list_all_sessions(self) -> List[str]:
        """
        åˆ—å‡ºæ‰€æœ‰ä¼šè¯ IDï¼ˆç”¨äºç®¡ç†å’Œè°ƒè¯•ï¼‰

        Returns:
            ä¼šè¯ ID åˆ—è¡¨
        """
        try:
            if self._memory_mode:
                return list(self._memory_sessions.keys())

            # Redis æ¨¡å¼ - ä½¿ç”¨ SCAN éå†ï¼ˆé¿å…é˜»å¡ï¼‰
            session_keys = []
            async for key in self.redis_client.scan_iter(match=f"{self.SESSION_PREFIX}*"):
                session_id = key.replace(self.SESSION_PREFIX, "")
                session_keys.append(session_id)

            return session_keys

        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºä¼šè¯å¤±è´¥: {e}")
            return []

    async def cleanup_expired(self) -> int:
        """
        æ¸…ç†è¿‡æœŸä¼šè¯ï¼ˆRedis è‡ªåŠ¨æ¸…ç†ï¼Œæ­¤æ–¹æ³•ç”¨äºå†…å­˜æ¨¡å¼ï¼‰

        Returns:
            æ¸…ç†çš„ä¼šè¯æ•°é‡
        """
        if not self._memory_mode:
            # Redis æ¨¡å¼è‡ªåŠ¨å¤„ç† TTLï¼Œæ— éœ€æ‰‹åŠ¨æ¸…ç†
            return 0

        # å†…å­˜æ¨¡å¼ - æ‰‹åŠ¨æ¸…ç†ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
        try:
            count = 0
            now = datetime.now()
            expired_sessions = []

            for session_id, data in self._memory_sessions.items():
                created_at = datetime.fromisoformat(data.get("created_at", now.isoformat()))
                if now - created_at > timedelta(seconds=self.SESSION_TTL):
                    expired_sessions.append(session_id)

            for session_id in expired_sessions:
                del self._memory_sessions[session_id]
                count += 1

            if count > 0:
                logger.info(f"ğŸ§¹ [å†…å­˜] æ¸…ç†è¿‡æœŸä¼šè¯: {count} ä¸ª")

            return count

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è¿‡æœŸä¼šè¯å¤±è´¥: {e}")
            return 0

    async def get_all_sessions(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰ä¼šè¯åˆ—è¡¨

        Returns:
            ä¼šè¯åˆ—è¡¨
        """
        try:
            if self._memory_mode:
                # å†…å­˜æ¨¡å¼ - ç›´æ¥è¿”å›æ‰€æœ‰ä¼šè¯
                return list(self._memory_sessions.values())

            # ğŸ”¥ v7.105: æ£€æŸ¥ç¼“å­˜
            if self._sessions_cache and self._cache_timestamp:
                cache_age = (datetime.now() - self._cache_timestamp).total_seconds()
                if cache_age < self._cache_ttl:
                    logger.debug(f"âš¡ ä½¿ç”¨ä¼šè¯åˆ—è¡¨ç¼“å­˜ (age: {cache_age:.1f}s)")
                    return self._sessions_cache

            # ğŸ”¥ v7.106: æ€§èƒ½ä¼˜åŒ– - æ‰¹é‡è·å–ä¼šè¯
            # ç¬¬1æ­¥ï¼šå¿«é€Ÿæ‰«ææ‰€æœ‰é”®ï¼ˆåªè·å–é”®åï¼Œä¸è·å–å€¼ï¼‰
            all_keys = []
            pattern = f"{self.SESSION_PREFIX}*"
            async for key in self.redis_client.scan_iter(match=pattern, count=1000):
                # è§£ç é”®åï¼ˆbytes -> strï¼‰
                key_str = key.decode("utf-8") if isinstance(key, bytes) else key
                # ğŸ”¥ åªä¿ç•™ä¸»ä¼šè¯é”®ï¼ˆæ’é™¤å­é”®å¦‚ :ffollowup_historyï¼‰
                # ä¼šè¯é”®æ ¼å¼: session:api-20251201211627-35b71dec
                # å­é”®æ ¼å¼: session:api-20251201211627-35b71dec:ffollowup_history
                if ":" not in key_str.replace(self.SESSION_PREFIX, "", 1):
                    all_keys.append(key_str)

            if not all_keys:
                logger.debug("ğŸ“­ æœªæ‰¾åˆ°ä»»ä½•ä¼šè¯")
                return []

            # ç¬¬2æ­¥ï¼šâœ… Fix 1.5 + v7.118: åˆ†å—æ‰¹é‡è·å–ä¼šè¯æ•°æ®ï¼ˆä½¿ç”¨Pipelineä¼˜åŒ–ï¼‰
            CHUNK_SIZE = 30  # âœ… v7.118: ä»20å¢åŠ åˆ°30ï¼Œå‡å°‘æ‰¹æ¬¡æ•°
            num_chunks = (len(all_keys) + CHUNK_SIZE - 1) // CHUNK_SIZE
            logger.debug(f"ğŸ“¦ æ‰¹é‡è·å– {len(all_keys)} ä¸ªä¼šè¯æ•°æ®ï¼ˆåˆ† {num_chunks} æ‰¹ï¼‰...")

            sessions = []
            try:
                for i in range(0, len(all_keys), CHUNK_SIZE):
                    chunk_keys = all_keys[i : i + CHUNK_SIZE]
                    chunk_num = i // CHUNK_SIZE + 1

                    try:
                        # è·å–æœ¬æ‰¹æ¬¡æ•°æ®
                        chunk_values = await self.redis_client.mget(chunk_keys)

                        for key, value in zip(chunk_keys, chunk_values):
                            if not value:
                                continue

                            try:
                                session = json.loads(value)
                                if isinstance(session, dict):
                                    # Ensure session_id is included
                                    if "session_id" not in session:
                                        session["session_id"] = key.replace(self.SESSION_PREFIX, "")
                                    sessions.append(session)
                                else:
                                    logger.warning(f"âš ï¸ ä¼šè¯æ•°æ®ç±»å‹é”™è¯¯: {key}, ç±»å‹: {type(session)}")
                            except json.JSONDecodeError as e:
                                logger.warning(f"âš ï¸ è§£æä¼šè¯æ•°æ®å¤±è´¥: {key}, é”™è¯¯: {e}")
                                continue

                    except (RedisError, TimeoutError) as e:
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡ {chunk_num}/{num_chunks} è·å–å¤±è´¥: {e}ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹")
                        continue

                logger.debug(f"âœ… æ‰¹é‡è·å–å®Œæˆï¼Œæœ‰æ•ˆä¼šè¯: {len(sessions)}/{len(all_keys)}")
            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡è·å–ä¼šè¯å¤±è´¥: {e}")
                return []

            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
            # ğŸ”¥ ä¿®å¤ï¼šæ·»åŠ ç±»å‹æ£€æŸ¥å’Œé»˜è®¤å€¼
            sessions.sort(key=lambda x: x.get("created_at", "") if isinstance(x, dict) else "", reverse=True)

            # âœ… Fix 1.4: æ·»åŠ ä¼šè¯ç»Ÿè®¡è¯Šæ–­
            status_counts = {}
            old_sessions = []
            now = datetime.now()

            for session in sessions:
                status = session.get("status", "unknown")
                status_counts[status] = status_counts.get(status, 0) + 1

                # æ£€æŸ¥å·²å®Œæˆçš„æ—§ä¼šè¯
                created_at_str = session.get("created_at", "")
                if created_at_str and status in ["completed", "failed"]:
                    try:
                        created_at = datetime.fromisoformat(created_at_str)
                        age_hours = (now - created_at).total_seconds() / 3600
                        if age_hours > 24:  # è¶…è¿‡24å°æ—¶
                            old_sessions.append(
                                {
                                    "session_id": session.get("session_id"),
                                    "status": status,
                                    "age_hours": round(age_hours, 1),
                                }
                            )
                    except (ValueError, TypeError):
                        pass

            logger.info(f"ğŸ“Š Redis ä¼šè¯ç»Ÿè®¡: {status_counts}")
            if old_sessions:
                logger.warning(f"âš ï¸ å‘ç° {len(old_sessions)} ä¸ªæ—§çš„å·²å®Œæˆä¼šè¯ (>24å°æ—¶)")
                logger.debug(f"æ—§ä¼šè¯åˆ—è¡¨: {old_sessions[:5]}")  # åªè®°å½•å‰5ä¸ª

            # ğŸ”¥ v7.105: æ›´æ–°ç¼“å­˜
            self._sessions_cache = sessions
            self._cache_timestamp = datetime.now()
            logger.debug(f"âœ… ä¼šè¯åˆ—è¡¨å·²ç¼“å­˜ ({len(sessions)} ä¸ªä¼šè¯)")

            return sessions

        except Exception as e:
            logger.error(f"âŒ è·å–æ‰€æœ‰ä¼šè¯å¤±è´¥: {e}")
            # è¿”å›ç¼“å­˜æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if self._sessions_cache:
                logger.warning(f"âš ï¸ è¿”å›ç¼“å­˜æ•°æ® ({len(self._sessions_cache)} ä¸ªä¼šè¯)")
                return self._sessions_cache
            return []

    async def cleanup_old_sessions(self, max_age_hours: int = 24) -> int:
        """
        âœ… Fix 1.4: æ¸…ç†å·²å®Œæˆçš„æ—§ä¼šè¯ï¼ˆå½’æ¡£ååˆ é™¤ï¼‰

        Args:
            max_age_hours: ä¼šè¯æœ€å¤§å¹´é¾„ï¼ˆå°æ—¶ï¼‰ï¼Œé»˜è®¤24å°æ—¶

        Returns:
            æ¸…ç†çš„ä¼šè¯æ•°
        """
        try:
            all_sessions = await self.get_all_sessions()
            cleaned = 0
            now = datetime.now()

            for session in all_sessions:
                session_id = session.get("session_id")
                status = session.get("status", "")
                created_at_str = session.get("created_at", "")

                # åªæ¸…ç†å·²å®Œæˆ/å¤±è´¥çš„ä¼šè¯
                if status not in ["completed", "failed"]:
                    continue

                try:
                    created_at = datetime.fromisoformat(created_at_str)
                    age_hours = (now - created_at).total_seconds() / 3600

                    if age_hours > max_age_hours:
                        # å½’æ¡£ååˆ é™¤ (æ³¨æ„: å®é™…ä½¿ç”¨æ—¶éœ€è¦é›†æˆ session_archive_manager)
                        # ç°åœ¨åªä» Redis åˆ é™¤
                        await self.delete(session_id)
                        cleaned += 1
                        logger.info(f"ğŸ—‘ï¸ æ¸…ç†æ—§ä¼šè¯: {session_id} (å¹´é¾„: {age_hours:.1f}å°æ—¶, çŠ¶æ€: {status})")

                except (ValueError, TypeError) as e:
                    logger.debug(f"â­ï¸ è·³è¿‡ä¼šè¯ {session_id}: æ—¥æœŸè§£æå¤±è´¥ ({e})")
                    continue

            if cleaned > 0:
                logger.info(f"âœ… æ¸…ç†å®Œæˆ: åˆ é™¤ {cleaned} ä¸ªæ—§ä¼šè¯")
                # æ¸…é™¤ç¼“å­˜ä»¥åæ˜ æ›´æ–°
                self._invalidate_cache()

            return cleaned

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ—§ä¼šè¯å¤±è´¥: {e}")
            return 0

    def _invalidate_cache(self):
        """æ¸…é™¤ä¼šè¯åˆ—è¡¨ç¼“å­˜"""
        self._sessions_cache = None
        self._cache_timestamp = None
        logger.debug("ğŸ”„ ä¼šè¯åˆ—è¡¨ç¼“å­˜å·²å¤±æ•ˆ")

    async def get_dimension_historical_data(self, limit: int = 100) -> List[Dict[str, Any]]:
        """
        ğŸ†• v7.117: è·å–ç»´åº¦ä½¿ç”¨å†å²æ•°æ®ï¼ˆç”¨äºæ™ºèƒ½å­¦ä¹ ä¼˜åŒ–ï¼‰

        ä»æœ€è¿‘çš„å·²å®Œæˆä¼šè¯ä¸­æå–ç»´åº¦é€‰æ‹©å’Œç”¨æˆ·åé¦ˆæ•°æ®ï¼Œ
        ä¾› AdaptiveDimensionGenerator è¿›è¡Œå­¦ä¹ ä¼˜åŒ–ã€‚

        Args:
            limit: æœ€å¤§è¿”å›è®°å½•æ•°ï¼Œé»˜è®¤100

        Returns:
            å†å²æ•°æ®åˆ—è¡¨ï¼Œæ¯æ¡åŒ…å«ï¼š
            - session_id: ä¼šè¯ID
            - selected_dimensions: é€‰ä¸­çš„ç»´åº¦åˆ—è¡¨
            - dimension_values: ç”¨æˆ·è®¾ç½®çš„ç»´åº¦å€¼
            - feedback: ç”¨æˆ·åé¦ˆï¼ˆå¦‚æœæœ‰ï¼‰
            - project_type: é¡¹ç›®ç±»å‹
        """
        try:
            # è·å–æ‰€æœ‰å·²å®Œæˆä¼šè¯
            all_sessions = await self.get_all_sessions()

            # ç­›é€‰å·²å®Œæˆçš„ä¼šè¯
            completed_sessions = [s for s in all_sessions if s.get("status") == "completed"]

            # æŒ‰åˆ›å»ºæ—¶é—´å€’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            completed_sessions.sort(key=lambda x: x.get("created_at", ""), reverse=True)

            historical_data = []

            for session_meta in completed_sessions[:limit]:
                session_id = session_meta.get("session_id")
                if not session_id:
                    continue

                # è·å–å®Œæ•´ä¼šè¯æ•°æ®
                session_data = await self.get(session_id)
                if not session_data:
                    continue

                # æå–ç»´åº¦ç›¸å…³æ•°æ®
                selected_dimensions = session_data.get("selected_radar_dimensions", [])
                dimension_values = session_data.get("radar_dimension_values", {})

                # å¦‚æœæ²¡æœ‰ç»´åº¦æ•°æ®ï¼Œè·³è¿‡
                if not selected_dimensions and not dimension_values:
                    continue

                # æå–åé¦ˆæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
                usage_metadata = session_data.get("dimension_usage_metadata", {})
                feedback = usage_metadata.get("feedback") if usage_metadata else None

                historical_data.append(
                    {
                        "session_id": session_id,
                        "selected_dimensions": selected_dimensions,
                        "dimension_values": dimension_values,
                        "feedback": feedback,
                        "project_type": session_data.get("project_type", "unknown"),
                        "created_at": session_meta.get("created_at"),
                    }
                )

            logger.info(f"ğŸ“š [å†å²æ•°æ®] åŠ è½½äº† {len(historical_data)} æ¡ç»´åº¦ä½¿ç”¨è®°å½• " f"(æ¥è‡ª {len(completed_sessions)} ä¸ªå·²å®Œæˆä¼šè¯)")

            return historical_data

        except Exception as e:
            logger.error(f"âŒ è·å–ç»´åº¦å†å²æ•°æ®å¤±è´¥: {e}")
            return []


# å…¨å±€å•ä¾‹å®ä¾‹
_session_manager: Optional[RedisSessionManager] = None


async def get_session_manager() -> RedisSessionManager:
    """
    è·å–å…¨å±€ä¼šè¯ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        RedisSessionManager å®ä¾‹
    """
    global _session_manager

    if _session_manager is None:
        _session_manager = RedisSessionManager()
        await _session_manager.connect()

    return _session_manager
