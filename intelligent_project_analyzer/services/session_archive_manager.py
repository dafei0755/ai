"""
ä¼šè¯å½’æ¡£ç®¡ç†å™¨

è´Ÿè´£å°†ä¼šè¯æ•°æ®å½’æ¡£åˆ°æ•°æ®åº“ï¼Œå®ç°æ°¸ä¹…ä¿å­˜
è§£å†³Redis TTLé™åˆ¶ï¼ˆ7å¤©ï¼‰çš„é—®é¢˜
"""

import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

from loguru import logger
from sqlalchemy import Boolean, Column, DateTime, Index, Integer, String, Text, create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import Session, defer, sessionmaker

Base = declarative_base()


class ArchivedSession(Base):
    """å½’æ¡£ä¼šè¯æ•°æ®æ¨¡å‹"""

    __tablename__ = "archived_sessions"

    # ä¸»é”®
    session_id = Column(String(100), primary_key=True, index=True)

    # ğŸ†• P0ä¿®å¤: æ·»åŠ user_idåˆ—
    user_id = Column(String(100), nullable=True, index=True)

    # åŸºæœ¬ä¿¡æ¯
    user_input = Column(Text, nullable=False)
    status = Column(String(50), nullable=False, index=True)
    mode = Column(String(20), default="api")

    # æ—¶é—´æˆ³
    created_at = Column(DateTime, nullable=False, index=True)
    archived_at = Column(DateTime, default=datetime.now, nullable=False)
    completed_at = Column(DateTime, nullable=True)

    # ä¼šè¯æ•°æ®ï¼ˆJSONå­˜å‚¨ï¼‰
    session_data = Column(Text, nullable=False)  # å®Œæ•´ä¼šè¯çŠ¶æ€
    final_report = Column(Text, nullable=True)  # æœ€ç»ˆæŠ¥å‘Š

    # ç»Ÿè®¡ä¿¡æ¯
    progress = Column(Integer, default=0)
    current_stage = Column(String(100), nullable=True)

    # ç”¨æˆ·ç®¡ç†å­—æ®µ
    display_name = Column(String(200), nullable=True)  # ç”¨æˆ·è‡ªå®šä¹‰åç§°
    pinned = Column(Boolean, default=False, index=True)  # æ˜¯å¦ç½®é¡¶
    tags = Column(String(500), nullable=True)  # æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰

    # ç´¢å¼•
    __table_args__ = (
        Index("idx_created_at_status", "created_at", "status"),
        Index("idx_pinned_created_at", "pinned", "created_at"),
        Index("idx_user_created", "user_id", "created_at"),  # ğŸ†• P0ä¿®å¤: ç”¨æˆ·+æ—¶é—´å¤åˆç´¢å¼•
    )


class SessionArchiveManager:
    """ä¼šè¯å½’æ¡£ç®¡ç†å™¨"""

    def __init__(self, database_url: str = None):
        """
        åˆå§‹åŒ–å½’æ¡£ç®¡ç†å™¨

        Args:
            database_url: æ•°æ®åº“URLï¼ˆé»˜è®¤ä½¿ç”¨SQLiteï¼‰
        """
        if database_url is None:
            # é»˜è®¤ä½¿ç”¨SQLiteï¼Œå­˜å‚¨åœ¨dataç›®å½•
            data_dir = Path(__file__).parent.parent.parent / "data"
            data_dir.mkdir(exist_ok=True)
            database_url = f"sqlite:///{data_dir / 'archived_sessions.db'}"

        self.database_url = database_url
        self.engine = create_engine(
            database_url,
            echo=False,  # ç”Ÿäº§ç¯å¢ƒå…³é—­SQLæ—¥å¿—
            pool_pre_ping=True,  # è¿æ¥æ± å¥åº·æ£€æŸ¥
            connect_args={"check_same_thread": False} if "sqlite" in database_url else {},
        )

        # åˆ›å»ºè¡¨
        Base.metadata.create_all(self.engine)

        # ğŸ†• P0ä¿®å¤: Schemaè‡ªæ£€ä¸è‡ªåŠ¨è¿ç§»
        self._verify_and_migrate_schema()

        # åˆ›å»ºä¼šè¯å·¥å‚
        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)

        logger.info(f"âœ… ä¼šè¯å½’æ¡£ç®¡ç†å™¨å·²åˆå§‹åŒ–: {database_url}")

    def _verify_and_migrate_schema(self):
        """
        ğŸ†• P0ä¿®å¤: éªŒè¯Schemaå¹¶è‡ªåŠ¨è¿ç§»

        æ£€æŸ¥archived_sessionsè¡¨æ˜¯å¦åŒ…å«user_idåˆ—ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨æ·»åŠ 
        """
        if "sqlite" not in self.database_url:
            # éSQLiteæ•°æ®åº“æš‚ä¸æ”¯æŒè‡ªåŠ¨è¿ç§»
            return

        try:
            import sqlite3

            # ä»database_urlæå–æ–‡ä»¶è·¯å¾„
            db_path = self.database_url.replace("sqlite:///", "")

            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            # æ£€æŸ¥user_idåˆ—æ˜¯å¦å­˜åœ¨
            cursor.execute("PRAGMA table_info(archived_sessions)")
            columns = [col[1] for col in cursor.fetchall()]

            if "user_id" not in columns:
                logger.warning("âš ï¸ æ£€æµ‹åˆ°Schemaç¼ºé™·ï¼šarchived_sessionsè¡¨ç¼ºå°‘user_idåˆ—")
                logger.info("ğŸ”§ æ‰§è¡Œè‡ªåŠ¨è¿ç§»...")

                # æ·»åŠ user_idåˆ—
                cursor.execute(
                    """
                    ALTER TABLE archived_sessions
                    ADD COLUMN user_id VARCHAR(100) DEFAULT NULL
                """
                )

                # åˆ›å»ºç´¢å¼•
                cursor.execute(
                    """
                    CREATE INDEX IF NOT EXISTS idx_user_id
                    ON archived_sessions(user_id)
                """
                )

                cursor.execute(
                    """
                    CREATE INDEX IF NOT EXISTS idx_user_created
                    ON archived_sessions(user_id, created_at DESC)
                """
                )

                conn.commit()
                logger.success("âœ… Schemaè¿ç§»å®Œæˆï¼šå·²æ·»åŠ user_idåˆ—åŠç´¢å¼•")
            else:
                logger.debug("âœ“ SchemaéªŒè¯é€šè¿‡ï¼šuser_idåˆ—å·²å­˜åœ¨")

            conn.close()

        except Exception as e:
            logger.error(f"âŒ SchemaéªŒè¯å¤±è´¥: {e}")
            logger.warning("âš ï¸ å»ºè®®æ‰‹åŠ¨è¿è¡Œè¿ç§»è„šæœ¬: python scripts/migrate_archived_sessions.py")

    def _get_db(self) -> Session:
        """è·å–æ•°æ®åº“ä¼šè¯"""
        return self.SessionLocal()

    async def archive_session(self, session_id: str, session_data: Dict[str, Any], force: bool = False) -> bool:
        """
        å½’æ¡£ä¼šè¯åˆ°æ•°æ®åº“

        Args:
            session_id: ä¼šè¯ID
            session_data: ä¼šè¯æ•°æ®
            force: æ˜¯å¦å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„å½’æ¡£

        Returns:
            æ˜¯å¦å½’æ¡£æˆåŠŸ
        """
        try:
            db = self._get_db()

            # æ£€æŸ¥æ˜¯å¦å·²å½’æ¡£
            existing = db.query(ArchivedSession).filter(ArchivedSession.session_id == session_id).first()

            if existing and not force:
                logger.warning(f"âš ï¸ ä¼šè¯å·²å½’æ¡£ï¼Œè·³è¿‡: {session_id}")
                db.close()
                return False  # ğŸ”¥ v3.6ä¿®å¤ï¼šå·²å­˜åœ¨ä¸”ä¸å¼ºåˆ¶æ—¶è¿”å›False

            # æå–å…³é”®å­—æ®µ
            user_input = session_data.get("user_input", "")
            status = session_data.get("status", "unknown")
            mode = session_data.get("mode", "api")
            progress = session_data.get("progress", 0)
            current_stage = session_data.get("current_node", "")
            final_report = session_data.get("final_report", "")

            # è§£ææ—¶é—´
            created_at_str = session_data.get("created_at")
            if isinstance(created_at_str, str):
                created_at = datetime.fromisoformat(created_at_str)
            else:
                created_at = datetime.now()

            completed_at_str = session_data.get("completed_at")
            completed_at = None
            if completed_at_str:
                try:
                    completed_at = datetime.fromisoformat(completed_at_str)
                except:
                    pass

            # åºåˆ—åŒ–å®Œæ•´ä¼šè¯æ•°æ®
            session_json = json.dumps(session_data, ensure_ascii=False)
            report_json = json.dumps(final_report, ensure_ascii=False) if final_report else None

            if existing:
                # æ›´æ–°ç°æœ‰å½’æ¡£
                existing.user_input = user_input
                existing.status = status
                existing.mode = mode
                existing.session_data = session_json
                existing.final_report = report_json
                existing.progress = progress
                existing.current_stage = current_stage
                existing.completed_at = completed_at
                existing.archived_at = datetime.now()

                logger.info(f"ğŸ”„ æ›´æ–°å½’æ¡£ä¼šè¯: {session_id}")
            else:
                # åˆ›å»ºæ–°å½’æ¡£
                archived = ArchivedSession(
                    session_id=session_id,
                    user_input=user_input,
                    status=status,
                    mode=mode,
                    created_at=created_at,
                    archived_at=datetime.now(),
                    completed_at=completed_at,
                    session_data=session_json,
                    final_report=report_json,
                    progress=progress,
                    current_stage=current_stage,
                )
                db.add(archived)

                logger.info(f"ğŸ“¦ æ–°å¢å½’æ¡£ä¼šè¯: {session_id}")

            db.commit()
            db.close()
            return True

        except Exception as e:
            logger.error(f"âŒ å½’æ¡£ä¼šè¯å¤±è´¥: {session_id}, é”™è¯¯: {e}")
            if db:
                db.rollback()
                db.close()
            return False

    async def get_archived_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–å½’æ¡£ä¼šè¯

        Args:
            session_id: ä¼šè¯ID

        Returns:
            ä¼šè¯æ•°æ®ï¼ˆä¸å­˜åœ¨è¿”å›Noneï¼‰
        """
        try:
            db = self._get_db()
            archived = db.query(ArchivedSession).filter(ArchivedSession.session_id == session_id).first()

            if not archived:
                db.close()
                return None

            # ååºåˆ—åŒ–ä¼šè¯æ•°æ®
            session_data = json.loads(archived.session_data)

            # æ·»åŠ å½’æ¡£å…ƒæ•°æ®
            session_data["_archived"] = True
            session_data["_archived_at"] = archived.archived_at.isoformat()

            db.close()
            return session_data

        except Exception as e:
            logger.error(f"âŒ è·å–å½’æ¡£ä¼šè¯å¤±è´¥: {session_id}, é”™è¯¯: {e}")
            if db:
                db.close()
            return None

    async def list_archived_sessions(
        self, limit: int = 50, offset: int = 0, status: Optional[str] = None, pinned_only: bool = False
    ) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºå½’æ¡£ä¼šè¯

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            offset: åç§»é‡ï¼ˆåˆ†é¡µï¼‰
            status: è¿‡æ»¤çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
            pinned_only: ä»…è¿”å›ç½®é¡¶ä¼šè¯

        Returns:
            ä¼šè¯åˆ—è¡¨
        """
        try:
            db = self._get_db()

            # âœ… Fix 2.1: æ„å»ºæŸ¥è¯¢ - DEFERå¤§å­—æ®µé¿å…åŠ è½½35MB session_dataå’Œ11MB final_report
            query = db.query(ArchivedSession).options(
                defer(ArchivedSession.session_data),  # ä¸åŠ è½½session_data (æœ€å¤§35MB)
                defer(ArchivedSession.final_report),  # ä¸åŠ è½½final_report (æœ€å¤§11MB)
            )

            if status:
                query = query.filter(ArchivedSession.status == status)

            if pinned_only:
                query = query.filter(ArchivedSession.pinned == True)

            # æ’åºï¼šç½®é¡¶ä¼˜å…ˆï¼Œç„¶åæŒ‰åˆ›å»ºæ—¶é—´å€’åº
            query = query.order_by(ArchivedSession.pinned.desc(), ArchivedSession.created_at.desc())

            # åˆ†é¡µ
            query = query.offset(offset).limit(limit)

            # æ‰§è¡ŒæŸ¥è¯¢
            results = query.all()

            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            sessions = []
            for archived in results:
                sessions.append(
                    {
                        "session_id": archived.session_id,
                        "user_input": archived.user_input,
                        "status": archived.status,
                        "mode": archived.mode,
                        "created_at": archived.created_at.isoformat(),
                        "archived_at": archived.archived_at.isoformat(),
                        "progress": archived.progress,
                        "current_stage": archived.current_stage,
                        "display_name": archived.display_name,
                        "pinned": archived.pinned,
                        "tags": archived.tags.split(",") if archived.tags else [],
                        "_archived": True,
                    }
                )

            db.close()
            return sessions

        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºå½’æ¡£ä¼šè¯å¤±è´¥: {e}")
            if db:
                db.close()
            return []

    async def update_metadata(
        self,
        session_id: str,
        display_name: Optional[str] = None,
        pinned: Optional[bool] = None,
        tags: Optional[List[str]] = None,
    ) -> bool:
        """
        æ›´æ–°ä¼šè¯å…ƒæ•°æ®ï¼ˆé‡å‘½åã€ç½®é¡¶ã€æ ‡ç­¾ï¼‰

        Args:
            session_id: ä¼šè¯ID
            display_name: æ˜¾ç¤ºåç§°
            pinned: æ˜¯å¦ç½®é¡¶
            tags: æ ‡ç­¾åˆ—è¡¨

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            db = self._get_db()
            archived = db.query(ArchivedSession).filter(ArchivedSession.session_id == session_id).first()

            if not archived:
                logger.warning(f"å½’æ¡£ä¼šè¯ä¸å­˜åœ¨: {session_id}")
                db.close()
                return False

            # æ›´æ–°å­—æ®µ
            if display_name is not None:
                archived.display_name = display_name

            if pinned is not None:
                archived.pinned = pinned

            if tags is not None:
                archived.tags = ",".join(tags)

            db.commit()
            db.close()

            logger.info(f"âœ… æ›´æ–°å½’æ¡£ä¼šè¯å…ƒæ•°æ®: {session_id}")
            return True

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å½’æ¡£ä¼šè¯å…ƒæ•°æ®å¤±è´¥: {session_id}, é”™è¯¯: {e}")
            if db:
                db.rollback()
                db.close()
            return False

    async def delete_archived_session(self, session_id: str) -> bool:
        """
        åˆ é™¤å½’æ¡£ä¼šè¯

        Args:
            session_id: ä¼šè¯ID

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            db = self._get_db()
            result = db.query(ArchivedSession).filter(ArchivedSession.session_id == session_id).delete()

            db.commit()
            db.close()

            if result > 0:
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤å½’æ¡£ä¼šè¯: {session_id}")
                return True
            else:
                logger.warning(f"å½’æ¡£ä¼šè¯ä¸å­˜åœ¨: {session_id}")
                return False

        except Exception as e:
            logger.error(f"âŒ åˆ é™¤å½’æ¡£ä¼šè¯å¤±è´¥: {session_id}, é”™è¯¯: {e}")
            if db:
                db.rollback()
                db.close()
            return False

    async def count_archived_sessions(
        self, status: Optional[str] = None, pinned_only: bool = False  # ğŸ”¥ v3.6ä¿®å¤ï¼šæ·»åŠ  pinned_only å‚æ•°
    ) -> int:
        """
        ç»Ÿè®¡å½’æ¡£ä¼šè¯æ•°é‡

        Args:
            status: è¿‡æ»¤çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
            pinned_only: æ˜¯å¦åªç»Ÿè®¡ç½®é¡¶ä¼šè¯ï¼ˆé»˜è®¤Falseï¼‰

        Returns:
            ä¼šè¯æ•°é‡
        """
        try:
            db = self._get_db()
            query = db.query(ArchivedSession)

            if status:
                query = query.filter(ArchivedSession.status == status)

            if pinned_only:
                query = query.filter(ArchivedSession.pinned == True)

            count = query.count()
            db.close()

            return count

        except Exception as e:
            logger.error(f"âŒ ç»Ÿè®¡å½’æ¡£ä¼šè¯å¤±è´¥: {e}")
            if db:
                db.close()
            return 0

    async def archive_old_sessions(self, days_threshold: int = 30) -> int:
        """
        âœ… Fix 2.2: å°†æ—§çš„å·²å½’æ¡£ä¼šè¯ç§»è‡³å†·å­˜å‚¨

        Args:
            days_threshold: å½’æ¡£é˜ˆå€¼ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤30å¤©

        Returns:
            å½’æ¡£çš„ä¼šè¯æ•°
        """
        try:
            db = self._get_db()
            cutoff_date = datetime.now() - timedelta(days=days_threshold)

            # æŸ¥æ‰¾æ—§ä¼šè¯
            old_sessions = db.query(ArchivedSession).filter(ArchivedSession.archived_at < cutoff_date).all()

            archived_count = 0
            cold_storage_dir = Path("data/cold_storage")
            cold_storage_dir.mkdir(parents=True, exist_ok=True)

            for session in old_sessions:
                try:
                    # å¯¼å‡ºä¸ºJSONæ–‡ä»¶
                    file_path = cold_storage_dir / f"{session.session_id}.json"
                    with open(file_path, "w", encoding="utf-8") as f:
                        json.dump(
                            {
                                "session_id": session.session_id,
                                "user_id": session.user_id,
                                "user_input": session.user_input,
                                "status": session.status,
                                "mode": session.mode,
                                "created_at": session.created_at.isoformat(),
                                "archived_at": session.archived_at.isoformat(),
                                "session_data": session.session_data,
                                "final_report": session.final_report,
                                "progress": session.progress,
                                "current_stage": session.current_stage,
                                "display_name": session.display_name,
                                "pinned": session.pinned,
                                "tags": session.tags,
                            },
                            f,
                            ensure_ascii=False,
                            indent=2,
                        )

                    # ä»æ•°æ®åº“åˆ é™¤
                    db.delete(session)
                    archived_count += 1

                except Exception as e:
                    logger.error(f"âŒ å½’æ¡£ä¼šè¯ {session.session_id} å¤±è´¥: {e}")
                    continue

            db.commit()
            db.close()

            logger.info(f"âœ… å½’æ¡£å®Œæˆ: {archived_count} ä¸ªä¼šè¯ç§»è‡³å†·å­˜å‚¨")
            return archived_count

        except Exception as e:
            logger.error(f"âŒ å½’æ¡£æ—§ä¼šè¯å¤±è´¥: {e}")
            if db:
                db.close()
            return 0

    async def vacuum_database(self) -> bool:
        """
        âœ… Fix 2.2: å‹ç¼©æ•°æ®åº“æ–‡ä»¶ï¼ˆå›æ”¶å·²åˆ é™¤æ•°æ®å ç”¨çš„ç©ºé—´ï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            db = self._get_db()
            db.execute("VACUUM")
            db.close()

            # æ£€æŸ¥å‹ç¼©åçš„å¤§å°
            db_path = Path(self.db_path)
            size_mb = db_path.stat().st_size / (1024 * 1024)
            logger.info(f"âœ… æ•°æ®åº“å‹ç¼©å®Œæˆï¼Œå½“å‰å¤§å°: {size_mb:.1f} MB")
            return True

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å‹ç¼©å¤±è´¥: {e}")
            if db:
                db.close()
            return False


# å…¨å±€å•ä¾‹å®ä¾‹
_archive_manager: Optional[SessionArchiveManager] = None


def get_archive_manager() -> SessionArchiveManager:
    """
    è·å–å…¨å±€å½’æ¡£ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        SessionArchiveManager å®ä¾‹
    """
    global _archive_manager

    if _archive_manager is None:
        from ...settings import settings

        _archive_manager = SessionArchiveManager(settings.database_url)

    return _archive_manager
