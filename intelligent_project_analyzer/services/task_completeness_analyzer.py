"""
ä»»åŠ¡å®Œæ•´æ€§åˆ†æå™¨

v7.80.6: Step 3 æ ¸å¿ƒæœåŠ¡ï¼Œåˆ†ææ ¸å¿ƒä»»åŠ¡çš„ä¿¡æ¯å®Œæ•´æ€§
æ£€æŸ¥ 6å¤§ç»´åº¦ï¼šåŸºæœ¬ä¿¡æ¯ã€æ ¸å¿ƒç›®æ ‡ã€é¢„ç®—çº¦æŸã€æ—¶é—´èŠ‚ç‚¹ã€äº¤ä»˜è¦æ±‚ã€ç‰¹æ®Šéœ€æ±‚
"""

import re
from typing import Dict, Any, List, Optional, Set
from loguru import logger


class TaskCompletenessAnalyzer:
    """
    ä»»åŠ¡å®Œæ•´æ€§åˆ†æå™¨

    åˆ†ææ ¸å¿ƒä»»åŠ¡åˆ—è¡¨æ˜¯å¦åŒ…å«è¶³å¤Ÿçš„æ‰§è¡Œä¿¡æ¯ï¼Œè¯†åˆ«ç¼ºå¤±ç»´åº¦å¹¶ç”Ÿæˆè¡¥å……é—®é¢˜
    """

    # 6å¤§ä¿¡æ¯å®Œæ•´æ€§ç»´åº¦
    DIMENSIONS = {
        "åŸºæœ¬ä¿¡æ¯": ["é¡¹ç›®ç±»å‹", "åœ°ç‚¹", "è§„æ¨¡", "é¢ç§¯"],
        "æ ¸å¿ƒç›®æ ‡": ["æ ¸å¿ƒä»»åŠ¡", "æœŸæœ›æ„¿æ™¯", "ç›®æ ‡å®šä½"],
        "é¢„ç®—çº¦æŸ": ["é¢„ç®—èŒƒå›´", "èµ„æºé™åˆ¶", "æˆæœ¬"],
        "æ—¶é—´èŠ‚ç‚¹": ["äº¤ä»˜æ—¶é—´", "é‡Œç¨‹ç¢‘", "å·¥æœŸ"],
        "äº¤ä»˜è¦æ±‚": ["äº¤ä»˜ç‰©ç±»å‹", "è´¨é‡æ ‡å‡†", "æˆæœå½¢å¼"],
        "ç‰¹æ®Šéœ€æ±‚": ["ç‰¹æ®Šåœºæ™¯", "çº¦æŸæ¡ä»¶", "ç‰¹æ®Šè¦æ±‚"]
    }

    def __init__(self):
        pass

    def analyze(
        self,
        confirmed_tasks: List[Dict[str, Any]],
        user_input: str,
        structured_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åˆ†æä»»åŠ¡ä¿¡æ¯å®Œæ•´æ€§

        Args:
            confirmed_tasks: Step 1 ç¡®è®¤çš„ä»»åŠ¡åˆ—è¡¨
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
            structured_data: requirements_analyst çš„ç»“æ„åŒ–æ•°æ®

        Returns:
            {
                "completeness_score": 0.65,  # å®Œæ•´åº¦è¯„åˆ† (0-1)
                "covered_dimensions": ["åŸºæœ¬ä¿¡æ¯", "æ ¸å¿ƒç›®æ ‡"],
                "missing_dimensions": ["é¢„ç®—çº¦æŸ", "æ—¶é—´èŠ‚ç‚¹", "äº¤ä»˜è¦æ±‚"],
                "critical_gaps": [
                    {"dimension": "é¢„ç®—çº¦æŸ", "reason": "æœªæ˜ç¡®é¢„ç®—èŒƒå›´"},
                    {"dimension": "æ—¶é—´èŠ‚ç‚¹", "reason": "æœªè¯´æ˜äº¤ä»˜æ—¶é—´"}
                ],
                "dimension_scores": {"åŸºæœ¬ä¿¡æ¯": 0.8, ...}
            }
        """
        # 1. åˆå¹¶æ‰€æœ‰æ–‡æœ¬ä¿¡æ¯
        all_text = self._merge_text(confirmed_tasks, user_input, structured_data)

        # 2. è¯„ä¼°æ¯ä¸ªç»´åº¦çš„è¦†ç›–åº¦
        dimension_scores = {}
        for dim, keywords in self.DIMENSIONS.items():
            score = self._calculate_dimension_score(all_text, keywords)
            dimension_scores[dim] = score

        # 3. è¯†åˆ«å·²è¦†ç›–å’Œç¼ºå¤±ç»´åº¦
        covered_dimensions = [dim for dim, score in dimension_scores.items() if score > 0.3]
        missing_dimensions = [dim for dim, score in dimension_scores.items() if score <= 0.3]

        # 4. è¯†åˆ«å…³é”®ç¼ºå¤±ç‚¹
        critical_gaps = self._identify_critical_gaps(missing_dimensions, all_text)

        # 5. è®¡ç®—æ•´ä½“å®Œæ•´æ€§è¯„åˆ†
        task_density_score = self._calculate_task_density(confirmed_tasks)
        completeness_score = (
            (len(covered_dimensions) / len(self.DIMENSIONS)) * 0.6 +
            task_density_score * 0.4
        )

        return {
            "completeness_score": completeness_score,
            "covered_dimensions": covered_dimensions,
            "missing_dimensions": missing_dimensions,
            "critical_gaps": critical_gaps,
            "dimension_scores": dimension_scores
        }

    def _merge_text(
        self,
        confirmed_tasks: List[Dict[str, Any]],
        user_input: str,
        structured_data: Dict[str, Any]
    ) -> str:
        """åˆå¹¶æ‰€æœ‰æ–‡æœ¬ä¿¡æ¯"""
        texts = [user_input]

        # æ·»åŠ ä»»åŠ¡æ ‡é¢˜å’Œæè¿°
        for task in confirmed_tasks:
            texts.append(task.get("title", ""))
            texts.append(task.get("description", ""))

        # æ·»åŠ ç»“æ„åŒ–æ•°æ®ä¸­çš„å…³é”®å­—æ®µ
        for key in ["project_type", "physical_context", "resource_constraints", "core_objectives"]:
            value = structured_data.get(key, "")
            if value:
                if isinstance(value, (list, tuple)):
                    texts.extend(str(v) for v in value)
                else:
                    texts.append(str(value))

        return " ".join(texts)

    def _calculate_dimension_score(self, text: str, keywords: List[str]) -> float:
        """è®¡ç®—å•ä¸ªç»´åº¦çš„è¦†ç›–è¯„åˆ†"""
        matched = 0
        for keyword in keywords:
            if keyword in text:
                matched += 1

        # å¦‚æœæ²¡æœ‰å…³é”®è¯åŒ¹é…ï¼Œæ£€æŸ¥ç›¸å…³æ¨¡å¼
        if matched == 0:
            # é¢„ç®—æ¨¡å¼
            if any(kw in keywords for kw in ["é¢„ç®—", "æˆæœ¬"]):
                if re.search(r'\d+ä¸‡|\d+å…ƒ|é¢„ç®—|æˆæœ¬|è´¹ç”¨', text):
                    matched += 1

            # æ—¶é—´æ¨¡å¼
            if any(kw in keywords for kw in ["æ—¶é—´", "å·¥æœŸ"]):
                if re.search(r'\d+æœˆ|\d+å¤©|æ—¶é—´|å·¥æœŸ|å‘¨æœŸ', text):
                    matched += 1

            # é¢ç§¯æ¨¡å¼
            if any(kw in keywords for kw in ["è§„æ¨¡", "é¢ç§¯"]):
                if re.search(r'\d+å¹³|å¹³ç±³|m2|ã¡', text):
                    matched += 1

        return min(matched / max(len(keywords), 1), 1.0)

    def _calculate_task_density(self, confirmed_tasks: List[Dict[str, Any]]) -> float:
        """è®¡ç®—ä»»åŠ¡æè¿°çš„ä¿¡æ¯å¯†åº¦"""
        if not confirmed_tasks:
            return 0.0

        total_chars = 0
        total_keywords = 0

        for task in confirmed_tasks:
            desc = task.get("description", "")
            total_chars += len(desc)
            # ç®€å•ç»Ÿè®¡å…³é”®è¯ï¼ˆé€—å·ã€é¡¿å·åˆ†éš”çš„ç‰‡æ®µæ•°ï¼‰
            total_keywords += len(re.split(r'[ï¼Œã€ï¼›,;]', desc))

        # å½’ä¸€åŒ–ï¼šå¹³å‡æ¯ä¸ªä»»åŠ¡ 30-50 å­—ä¸ºæ ‡å‡†å¯†åº¦
        avg_chars = total_chars / len(confirmed_tasks) if confirmed_tasks else 0
        density = min(avg_chars / 40, 1.0)

        return density

    def _identify_critical_gaps(
        self,
        missing_dimensions: List[str],
        all_text: str
    ) -> List[Dict[str, str]]:
        """è¯†åˆ«å…³é”®ç¼ºå¤±ç‚¹"""
        critical_gaps = []

        for dim in missing_dimensions:
            reason = self._generate_gap_reason(dim, all_text)
            if reason:  # åªæ·»åŠ å…³é”®æ€§ç¼ºå¤±
                critical_gaps.append({
                    "dimension": dim,
                    "reason": reason
                })

        return critical_gaps

    def _generate_gap_reason(self, dimension: str, all_text: str) -> Optional[str]:
        """ç”Ÿæˆç¼ºå¤±åŸå› è¯´æ˜"""
        reasons = {
            "é¢„ç®—çº¦æŸ": "æœªæ˜ç¡®é¢„ç®—èŒƒå›´ï¼Œå½±å“è®¾è®¡æ–¹å‘å’Œææ–™é€‰æ‹©",
            "æ—¶é—´èŠ‚ç‚¹": "æœªè¯´æ˜äº¤ä»˜æ—¶é—´ï¼Œæ— æ³•è§„åˆ’å·¥ä½œæµç¨‹å’Œé‡Œç¨‹ç¢‘",
            "äº¤ä»˜è¦æ±‚": "æœªæ˜ç¡®äº¤ä»˜ç‰©ç±»å‹ï¼Œå¯èƒ½å½±å“æˆæœé¢„æœŸ",
            "ç‰¹æ®Šéœ€æ±‚": "å¯èƒ½å­˜åœ¨æœªè¡¨è¾¾çš„ç‰¹æ®Šçº¦æŸæ¡ä»¶",
        }

        # åŸºæœ¬ä¿¡æ¯å’Œæ ¸å¿ƒç›®æ ‡é€šå¸¸ä¸æ˜¯å…³é”®ç¼ºå¤±ï¼ˆå·²åœ¨ Step 1 ç¡®è®¤ï¼‰
        if dimension in ["åŸºæœ¬ä¿¡æ¯", "æ ¸å¿ƒç›®æ ‡"]:
            return None

        return reasons.get(dimension)

    def generate_gap_questions(
        self,
        missing_dimensions: List[str],
        critical_gaps: List[Dict[str, str]],
        confirmed_tasks: List[Dict[str, Any]],
        existing_info_summary: str = "",
        target_count: int = 10
    ) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆé’ˆå¯¹æ€§è¡¥å……é—®é¢˜

        Args:
            missing_dimensions: ç¼ºå¤±ç»´åº¦åˆ—è¡¨
            critical_gaps: å…³é”®ç¼ºå¤±ç‚¹
            confirmed_tasks: ç¡®è®¤çš„ä»»åŠ¡åˆ—è¡¨
            existing_info_summary: å·²æœ‰ä¿¡æ¯æ‘˜è¦
            target_count: ç›®æ ‡é—®é¢˜æ•°é‡ï¼ˆé»˜è®¤10ä¸ªï¼‰

        Returns:
            é—®é¢˜åˆ—è¡¨ï¼Œæ¯ä¸ªé—®é¢˜åŒ…å«:
            {
                "id": "budget_range",
                "question": "è¯·é—®æ‚¨çš„é¢„ç®—èŒƒå›´å¤§è‡´æ˜¯ï¼Ÿ",
                "type": "single_choice",
                "options": ["10ä¸‡ä»¥ä¸‹", "10-30ä¸‡", ...],
                "is_required": True,
                "priority": 1,
                "weight": 10
            }
        """
        questions = []

        # 1. ä¸ºæ¯ä¸ªå…³é”®ç¼ºå¤±ç‚¹ç”Ÿæˆå¿…ç­”é—®é¢˜
        for gap in critical_gaps:
            dim = gap["dimension"]
            question = self._generate_question_for_dimension(dim, is_required=True)
            if question:
                questions.append(question)

        # 2. ä¸ºå…¶ä»–ç¼ºå¤±ç»´åº¦ç”Ÿæˆé€‰ç­”é—®é¢˜
        for dim in missing_dimensions:
            if dim not in [g["dimension"] for g in critical_gaps]:
                question = self._generate_question_for_dimension(dim, is_required=False)
                if question:
                    questions.append(question)

        # 3. å¦‚æœé—®é¢˜ä¸è¶³ target_countï¼Œæ·»åŠ é€šç”¨è¡¥å……é—®é¢˜
        if len(questions) < target_count:
            generic_questions = self._generate_generic_questions()
            questions.extend(generic_questions[:target_count - len(questions)])

        # 4. é™åˆ¶æœ€å¤š target_count ä¸ªé—®é¢˜
        return questions[:target_count]

    def _generate_question_for_dimension(
        self,
        dimension: str,
        is_required: bool
    ) -> Optional[Dict[str, Any]]:
        """ä¸ºç‰¹å®šç»´åº¦ç”Ÿæˆé—®é¢˜"""

        question_templates = {
            "é¢„ç®—çº¦æŸ": {
                "id": "budget_range",
                "question": "è¯·é—®æ‚¨çš„é¢„ç®—èŒƒå›´å¤§è‡´æ˜¯ï¼Ÿ",
                "type": "single_choice",
                "options": ["10ä¸‡ä»¥ä¸‹", "10-30ä¸‡", "30-50ä¸‡", "50-100ä¸‡", "100ä¸‡ä»¥ä¸Š"],
                "priority": 1,
                "weight": 10
            },
            "æ—¶é—´èŠ‚ç‚¹": {
                "id": "timeline",
                "question": "è¯·é—®æœŸæœ›çš„äº¤ä»˜æ—¶é—´æ˜¯ï¼Ÿ",
                "type": "single_choice",
                "options": ["1ä¸ªæœˆå†…", "1-3ä¸ªæœˆ", "3-6ä¸ªæœˆ", "6ä¸ªæœˆä»¥ä¸Š", "æš‚æ— æ˜ç¡®è¦æ±‚"],
                "priority": 2,
                "weight": 9
            },
            "äº¤ä»˜è¦æ±‚": {
                "id": "deliverables",
                "question": "æ‚¨æœŸæœ›çš„äº¤ä»˜ç‰©åŒ…æ‹¬å“ªäº›ï¼Ÿï¼ˆå¯å¤šé€‰ï¼‰",
                "type": "multiple_choice",
                "options": ["è®¾è®¡æ–¹æ¡ˆ", "æ•ˆæœå›¾", "æ–½å·¥å›¾", "è½¯è£…æ¸…å•", "é¢„ç®—æ¸…å•", "å…¶ä»–"],
                "priority": 3,
                "weight": 8
            },
            "ç‰¹æ®Šéœ€æ±‚": {
                "id": "special_requirements",
                "question": "æ˜¯å¦æœ‰å…¶ä»–ç‰¹æ®Šéœ€æ±‚æˆ–çº¦æŸæ¡ä»¶ï¼Ÿ",
                "type": "open_ended",
                "priority": 4,
                "weight": 7
            }
        }

        template = question_templates.get(dimension)
        if template:
            template["is_required"] = is_required
            return template

        return None

    def _generate_generic_questions(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆé€šç”¨è¡¥å……é—®é¢˜"""
        return [
            {
                "id": "design_style_preference",
                "question": "å¯¹è®¾è®¡é£æ ¼æœ‰æ²¡æœ‰ç‰¹åˆ«åå¥½æˆ–ç¦å¿Œï¼Ÿ",
                "type": "open_ended",
                "is_required": False,
                "priority": 5,
                "weight": 6
            },
            {
                "id": "color_preference",
                "question": "å¯¹è‰²å½©æ­é…æœ‰ä»€ä¹ˆå€¾å‘ï¼Ÿï¼ˆå¯å¤šé€‰ï¼‰",
                "type": "multiple_choice",
                "options": ["æ˜äº®æ¸…æ–°", "æ¸©æš–èˆ’é€‚", "æ²‰ç¨³å¤§æ°”", "å†·å³»ç°ä»£", "å¤šå½©æ´»åŠ›", "æ— ç‰¹åˆ«è¦æ±‚"],
                "is_required": False,
                "priority": 6,
                "weight": 5
            },
            {
                "id": "material_preference",
                "question": "å¯¹æè´¨æœ‰ä»€ä¹ˆåå¥½ï¼Ÿï¼ˆå¯å¤šé€‰ï¼‰",
                "type": "multiple_choice",
                "options": ["å¤©ç„¶æœ¨æ", "çŸ³æå¤§ç†çŸ³", "é‡‘å±è´¨æ„Ÿ", "ç»ç’ƒé€šé€", "ç»‡ç‰©è½¯è£…", "æ— ç‰¹åˆ«è¦æ±‚"],
                "is_required": False,
                "priority": 7,
                "weight": 4
            },
            {
                "id": "lighting_preference",
                "question": "å¯¹å…‰çº¿æ°›å›´æœ‰ä»€ä¹ˆæœŸæœ›ï¼Ÿ",
                "type": "single_choice",
                "options": ["æ˜äº®å……è¶³", "æŸ”å’Œæ¸©é¦¨", "å±‚æ¬¡ä¸°å¯Œ", "å¯è°ƒèŠ‚å˜åŒ–", "æ— ç‰¹åˆ«è¦æ±‚"],
                "is_required": False,
                "priority": 8,
                "weight": 3
            },
            {
                "id": "sustainability_concern",
                "question": "æ˜¯å¦å…³æ³¨ç¯ä¿å’Œå¯æŒç»­æ€§ï¼Ÿ",
                "type": "single_choice",
                "options": ["éå¸¸é‡è§†", "é€‚åº¦è€ƒè™‘", "ä¸æ˜¯ä¼˜å…ˆè€ƒè™‘", "æ— ç‰¹åˆ«è¦æ±‚"],
                "is_required": False,
                "priority": 9,
                "weight": 2
            },
            {
                "id": "future_flexibility",
                "question": "æ˜¯å¦éœ€è¦è€ƒè™‘æœªæ¥è°ƒæ•´çš„çµæ´»æ€§ï¼Ÿ",
                "type": "single_choice",
                "options": ["éœ€è¦é«˜åº¦çµæ´»", "é€‚åº¦çµæ´»", "å›ºå®šä½¿ç”¨", "æ— ç‰¹åˆ«è¦æ±‚"],
                "is_required": False,
                "priority": 10,
                "weight": 1
            }
        ]

    def detect_special_scenarios(
        self,
        user_input: str,
        task_summary: str
    ) -> Dict[str, Dict[str, Any]]:
        """
        æ£€æµ‹ç‰¹æ®Šåœºæ™¯ï¼ˆv7.80.15 P1.2ï¼‰

        ç”¨äº Step 1 è¯—æ„è§£è¯»å’Œç‰¹æ®Šåœºæ™¯æ³¨å…¥

        Args:
            user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
            task_summary: ä»»åŠ¡æ‘˜è¦

        Returns:
            {
                "poetic_philosophical": {
                    "matched_keywords": ["æœˆäº®", "æ¹–é¢", "è¯—æ„"],
                    "trigger_message": "æ£€æµ‹åˆ°è¯—æ„è¡¨è¾¾"
                },
                ...
            }
        """
        special_scenarios = {}

        # åœºæ™¯æ£€æµ‹è§„åˆ™
        scenario_rules = {
            "poetic_philosophical": {
                "keywords": ["æœˆäº®", "æ¹–é¢", "è¯—æ„", "å“²å­¦", "çµé­‚", "ç¦…", "æ„å¢ƒ"],
                "message": "æ£€æµ‹åˆ°è¯—æ„/å“²å­¦è¡¨è¾¾"
            },
            "extreme_environment": {
                "keywords": ["é«˜æµ·æ‹”", "ä¸¥å¯’", "é…·æš‘", "æç«¯", "æ²™æ¼ ", "é«˜åŸ"],
                "message": "æ£€æµ‹åˆ°æç«¯ç¯å¢ƒåœºæ™¯"
            },
            "medical_special_needs": {
                "keywords": ["æ— éšœç¢", "é€‚è€", "è½®æ¤…", "åŒ»ç–—", "åº·å¤", "è¾…åŠ©"],
                "message": "æ£€æµ‹åˆ°åŒ»ç–—/æ— éšœç¢éœ€æ±‚"
            },
            "cultural_depth": {
                "keywords": ["ä¼ ç»Ÿæ–‡åŒ–", "éé—", "æ–‡åŒ–ä¼ æ‰¿", "authentic", "åœ¨åœ°æ–‡åŒ–"],
                "message": "æ£€æµ‹åˆ°æ–‡åŒ–æ·±åº¦éœ€æ±‚"
            },
            "tech_geek": {
                "keywords": ["å£°å­¦", "å½•éŸ³", "éŸ³ä¹å®¤", "ä¸“ä¸šçº§", "å‘çƒ§å‹"],
                "message": "æ£€æµ‹åˆ°ç§‘æŠ€æå®¢åœºæ™¯"
            },
            "complex_relationships": {
                "keywords": ["å¤šä»£åŒå ‚", "å†²çª", "éšç§", "è¾¹ç•Œ", "ç‹¬ç«‹ç©ºé—´"],
                "message": "æ£€æµ‹åˆ°å¤æ‚å…³ç³»åœºæ™¯"
            }
        }

        combined_text = f"{user_input} {task_summary}"

        for scenario_id, rule in scenario_rules.items():
            matched = [kw for kw in rule["keywords"] if kw in combined_text]
            if len(matched) >= 2:  # è‡³å°‘åŒ¹é…2ä¸ªå…³é”®è¯
                special_scenarios[scenario_id] = {
                    "matched_keywords": matched,
                    "trigger_message": rule["message"]
                }
                logger.info(f"ğŸ¯ [ç‰¹æ®Šåœºæ™¯æ£€æµ‹] {scenario_id}: {matched}")

        return special_scenarios
