"""
ç»Ÿä¸€é…ç½®ç®¡ç† - åŸºäºPydantic Settings 2.x (2025å¹´æ ‡å‡†)

ä½¿ç”¨Pydantic Settingsè‡ªåŠ¨åŠ è½½ç¯å¢ƒå˜é‡,æ— éœ€æ‰‹åŠ¨è°ƒç”¨load_dotenv()
"""

import os
from pathlib import Path
from pydantic import BaseModel, Field, field_validator, model_validator
from pydantic_settings import BaseSettings, SettingsConfigDict
from enum import Enum
from typing import Optional
from dotenv import load_dotenv

# ç¡®ä¿.envæ–‡ä»¶è¢«åŠ è½½åˆ°ç¯å¢ƒå˜é‡ä¸­
env_path = Path(__file__).parent.parent / '.env'
if env_path.exists():
    load_dotenv(env_path)


class Environment(str, Enum):
    """ç¯å¢ƒç±»å‹"""
    DEV = "dev"
    STAGING = "staging"
    PROD = "prod"


class LLMConfig(BaseModel):
    """LLMé…ç½® - å•ä¸€çœŸå®æ¥æº"""
    provider: str = "openai"
    # model ä» .env çš„ {PROVIDER}_MODEL è¯»å–,æ­¤å¤„ä»…ä¸ºåå¤‡é»˜è®¤å€¼
    model: str = Field(default="gpt-4.1", description="é»˜è®¤LLMæ¨¡å‹")
    max_tokens: int = Field(default=4000, description="æœ€å¤§tokenæ•°", alias="MAX_TOKENS")
    timeout: int = Field(default=60, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)", alias="LLM_TIMEOUT")
    temperature: float = Field(default=0.7, description="æ¸©åº¦å‚æ•°", alias="TEMPERATURE")
    api_key: str = Field(default="", description="LLM APIå¯†é’¥", alias="OPENAI_API_KEY")
    api_base: Optional[str] = Field(default=None, description="è‡ªå®šä¹‰API Base URL")
    # é‡è¯•é…ç½®
    max_retries: int = Field(default=3, description="LLMè°ƒç”¨å¤±è´¥é‡è¯•æ¬¡æ•°", alias="MAX_RETRIES")
    retry_delay: int = Field(default=5, description="é‡è¯•é—´éš”(ç§’)", alias="RETRY_DELAY")

    model_config = {"populate_by_name": True}  # å…è®¸ä½¿ç”¨åˆ«å


class TavilyConfig(BaseModel):
    """Tavilyæœç´¢å·¥å…·é…ç½®"""
    api_key: str = Field(default="", description="Tavily APIå¯†é’¥", alias="TAVILY_API_KEY")
    max_results: int = Field(default=5, description="æœ€å¤§æœç´¢ç»“æœæ•°")
    search_depth: str = Field(default="basic", description="æœç´¢æ·±åº¦: basic/advanced")
    timeout: int = Field(default=30, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)")

    model_config = {"populate_by_name": True}


class RagflowConfig(BaseModel):
    """RagflowçŸ¥è¯†åº“é…ç½®"""
    endpoint: str = Field(default="http://localhost:9380", description="RagflowæœåŠ¡ç«¯ç‚¹", alias="RAGFLOW_ENDPOINT")
    api_key: str = Field(default="", description="Ragflow APIå¯†é’¥", alias="RAGFLOW_API_KEY")
    dataset_id: Optional[str] = Field(default=None, description="æ•°æ®é›†ID", alias="RAGFLOW_DATASET_ID")
    timeout: int = Field(default=30, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)")

    model_config = {"populate_by_name": True}


class ArxivConfig(BaseModel):
    """Arxivæœç´¢é…ç½®"""
    enabled: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨Arxivæœç´¢")
    timeout: int = Field(default=30, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)")


class BochaConfig(BaseModel):
    """åšæŸ¥æœç´¢é…ç½® (v7.63+)"""
    enabled: bool = Field(default=False, description="æ˜¯å¦å¯ç”¨åšæŸ¥æœç´¢", alias="BOCHA_ENABLED")
    api_key: str = Field(default="", description="åšæŸ¥APIå¯†é’¥", alias="BOCHA_API_KEY")
    base_url: str = Field(default="https://api.bocha.cn", description="åšæŸ¥APIåœ°å€", alias="BOCHA_BASE_URL")
    default_count: int = Field(default=5, description="é»˜è®¤æœç´¢ç»“æœæ•°é‡", alias="BOCHA_DEFAULT_COUNT")
    timeout: int = Field(default=30, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)", alias="BOCHA_TIMEOUT")
    freshness: str = Field(default="oneYear", description="æœç´¢ç»“æœæ—¶æ•ˆæ€§", alias="BOCHA_FRESHNESS")

    model_config = {"populate_by_name": True}


class ImageGenerationConfig(BaseModel):
    """
    AI å›¾åƒç”Ÿæˆé…ç½® (v7.38+)
    
    é€šè¿‡ OpenRouter è°ƒç”¨ Gemini 3 Pro å›¾åƒç”Ÿæˆ (Nano Banana Pro)
    ä»·æ ¼: $2/M input, $12/M output
    """
    enabled: bool = Field(default=False, description="æ˜¯å¦å¯ç”¨ AI æ¦‚å¿µå›¾ç”Ÿæˆ", alias="IMAGE_GENERATION_ENABLED")
    model: str = Field(
        default="google/gemini-3-pro-image-preview",
        description="å›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆOpenRouter æ ¼å¼ï¼‰",
        alias="IMAGE_GENERATION_MODEL"
    )
    max_images_per_report: int = Field(
        default=2, 
        description="æ¯ä¸ªä¸“å®¶æŠ¥å‘Šæœ€å¤šç”Ÿæˆå‡ å¼ æ¦‚å¿µå›¾",
        alias="IMAGE_GENERATION_MAX_IMAGES_PER_REPORT"
    )
    timeout: int = Field(
        default=120, 
        description="å›¾åƒç”Ÿæˆè¶…æ—¶æ—¶é—´(ç§’)",
        alias="IMAGE_GENERATION_TIMEOUT"
    )
    
    # ğŸ”¥ v7.61: Vision å›¾åƒåˆ†æé…ç½®
    vision_enabled: bool = Field(
        default=False,
        description="æ˜¯å¦å¯ç”¨ Vision æ¨¡å‹åˆ†æå‚è€ƒå›¾",
        alias="VISION_ANALYSIS_ENABLED"
    )
    vision_provider: str = Field(
        default="openai-openrouter",
        description="Vision æ¨¡å‹æä¾›å•† (openai-openrouter|gemini-openrouter|openai)",
        alias="VISION_MODEL_PROVIDER"
    )
    vision_model: str = Field(
        default="openai/gpt-4o",
        description="Vision æ¨¡å‹åç§°",
        alias="VISION_MODEL"
    )
    vision_timeout: int = Field(
        default=30,
        description="Vision åˆ†æè¶…æ—¶æ—¶é—´(ç§’)",
        alias="VISION_ANALYSIS_TIMEOUT"
    )
    vision_max_tokens: int = Field(
        default=500,
        description="Vision åˆ†ææœ€å¤§ token æ•°",
        alias="VISION_ANALYSIS_MAX_TOKENS"
    )
    
    # ä½¿ç”¨ OpenRouter API Key (å¤ç”¨ç°æœ‰é…ç½®)
    # api_key ä» OPENROUTER_API_KEY è¯»å–
    
    model_config = {"populate_by_name": True}


class InpaintingConfig(BaseModel):
    """
    AI å›¾åƒç¼–è¾‘ï¼ˆInpaintingï¼‰é…ç½® (v7.62+)
    
    é€šè¿‡ OpenAI DALL-E 2 Edit API å®ç°åƒç´ çº§ç²¾ç¡®å›¾åƒç¼–è¾‘
    è¦æ±‚: åŸå›¾ + Maskï¼ˆé»‘è‰²=ä¿ç•™ï¼Œé€æ˜=ç¼–è¾‘ï¼‰ + æç¤ºè¯
    ä»·æ ¼: $0.020 / å›¾åƒ
    """
    enabled: bool = Field(
        default=False,
        description="æ˜¯å¦å¯ç”¨ Inpainting å›¾åƒç¼–è¾‘",
        alias="INPAINTING_ENABLED"
    )
    provider: str = Field(
        default="openai",
        description="Inpainting æä¾›å•†ï¼ˆå½“å‰ä»…æ”¯æŒ openaiï¼‰",
        alias="INPAINTING_PROVIDER"
    )
    model: str = Field(
        default="dall-e-2",
        description="Inpainting æ¨¡å‹ï¼ˆDALL-E 2 Edit APIï¼‰",
        alias="INPAINTING_MODEL"
    )
    timeout: int = Field(
        default=120,
        description="Inpainting è¶…æ—¶æ—¶é—´(ç§’)",
        alias="INPAINTING_TIMEOUT"
    )
    
    # OpenAI API Key ä» OPENAI_API_KEY ç¯å¢ƒå˜é‡è¯»å–ï¼ˆç‹¬ç«‹äº OpenRouterï¼‰
    
    model_config = {"populate_by_name": True}


class StorageConfig(BaseModel):
    """æ–‡ä»¶å­˜å‚¨é…ç½®"""
    upload_dir: str = Field(default="./data/uploads", description="ä¸Šä¼ ç›®å½•", alias="UPLOAD_DIR")
    output_dir: str = Field(default="./data/outputs", description="è¾“å‡ºç›®å½•", alias="OUTPUT_DIR")
    temp_dir: str = Field(default="./data/temp", description="ä¸´æ—¶ç›®å½•", alias="TEMP_DIR")
    database_url: str = Field(default="sqlite:///./data/project_analyzer.db", description="æ•°æ®åº“URL", alias="DATABASE_URL")

    model_config = {"populate_by_name": True}


class ConcurrencyConfig(BaseModel):
    """å¹¶å‘é…ç½®"""
    max_concurrent_agents: int = Field(default=6, description="æœ€å¤§å¹¶å‘æ™ºèƒ½ä½“æ•°", alias="MAX_CONCURRENT_AGENTS")
    agent_timeout: int = Field(default=300, description="æ™ºèƒ½ä½“è¶…æ—¶æ—¶é—´(ç§’)", alias="AGENT_TIMEOUT")

    model_config = {"populate_by_name": True}


class Settings(BaseSettings):
    """
    å…¨å±€é…ç½® - 2025å¹´æ ‡å‡†

    ä½¿ç”¨Pydantic Settingsè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
    æ”¯æŒåµŒå¥—é…ç½®: LLM__MAX_TOKENS=8000
    """

    # ç¯å¢ƒé…ç½®
    environment: Environment = Field(default=Environment.DEV, description="è¿è¡Œç¯å¢ƒ")
    debug: bool = Field(default=False, description="è°ƒè¯•æ¨¡å¼", alias="DEBUG")
    log_level: str = Field(default="INFO", description="æ—¥å¿—çº§åˆ«", alias="LOG_LEVEL")

    # åº”ç”¨é…ç½®
    app_name: str = Field(default="Intelligent Project Analyzer", description="åº”ç”¨åç§°", alias="APP_NAME")
    app_version: str = Field(default="2.0.0", description="åº”ç”¨ç‰ˆæœ¬", alias="APP_VERSION")
    post_completion_followup_enabled: bool = Field(
        default=True,
        description="æŠ¥å‘Šç”Ÿæˆåæ˜¯å¦è‡ªåŠ¨è§¦å‘è¿½é—®äº¤äº’"
    )

    # LLMé…ç½® (åµŒå¥—) - âœ… æä¾›é»˜è®¤å€¼
    llm: LLMConfig = Field(default_factory=LLMConfig)

    # å·¥å…·é…ç½® (åµŒå¥—) - âœ… æä¾›é»˜è®¤å€¼
    tavily: TavilyConfig = Field(default_factory=TavilyConfig)
    ragflow: RagflowConfig = Field(default_factory=RagflowConfig)
    arxiv: ArxivConfig = Field(default_factory=ArxivConfig)
    bocha: BochaConfig = Field(default_factory=BochaConfig)  # ğŸ†• v7.63: åšæŸ¥æœç´¢
    
    # ğŸ†• v7.38: AI å›¾åƒç”Ÿæˆé…ç½®
    image_generation: ImageGenerationConfig = Field(default_factory=ImageGenerationConfig)
    
    # ğŸ†• v7.62: AI å›¾åƒç¼–è¾‘ï¼ˆInpaintingï¼‰é…ç½®
    inpainting: InpaintingConfig = Field(default_factory=InpaintingConfig)

    # å­˜å‚¨é…ç½®
    storage: StorageConfig = Field(default_factory=StorageConfig)

    # å¹¶å‘é…ç½®
    concurrency: ConcurrencyConfig = Field(default_factory=ConcurrencyConfig)

    # æ•°æ®åº“é…ç½®
    database_url: str = Field(default="sqlite:///./data/project_analyzer.db", description="æ•°æ®åº“URL", alias="DATABASE_URL")
    redis_url: str = Field(default="redis://localhost:6379/0", description="Redis URL", alias="REDIS_URL")

    # å‰ç«¯é…ç½®
    api_base_url: str = Field(default="http://localhost:8000", description="APIæœåŠ¡åœ°å€")
    streamlit_port: int = Field(default=8501, description="Streamlitç«¯å£", alias="STREAMLIT_PORT")
    streamlit_host: str = Field(default="localhost", description="Streamlitä¸»æœº", alias="STREAMLIT_HOST")

    model_config = SettingsConfigDict(
        env_file='.env',
        env_file_encoding='utf-8',
        env_nested_delimiter='__',  # æ”¯æŒ LLM__MAX_TOKENS=8000
        case_sensitive=False,
        extra='ignore'  # å¿½ç•¥æœªå®šä¹‰çš„ç¯å¢ƒå˜é‡
    )

    @model_validator(mode='after')
    def load_from_flat_env(self):
        """ä»æ‰å¹³ç¯å¢ƒå˜é‡åŠ è½½é…ç½®(å…¼å®¹æ—§.envæ ¼å¼)"""
        # è¯»å–LLMé…ç½® - æ ¹æ®æä¾›å•†é€‰æ‹©æ­£ç¡®çš„API Key
        provider = os.getenv('LLM_PROVIDER', 'openai').lower()

        if provider == 'openrouter':
            # OpenRouter: ä¼˜å…ˆä½¿ç”¨ OPENROUTER_API_KEY
            if not self.llm.api_key and os.getenv('OPENROUTER_API_KEY'):
                self.llm.api_key = os.getenv('OPENROUTER_API_KEY', '')
        elif provider == 'deepseek':
            # DeepSeek
            if not self.llm.api_key and os.getenv('DEEPSEEK_API_KEY'):
                self.llm.api_key = os.getenv('DEEPSEEK_API_KEY', '')
        elif provider == 'qwen':
            # Qwen
            if not self.llm.api_key and os.getenv('QWEN_API_KEY'):
                self.llm.api_key = os.getenv('QWEN_API_KEY', '')
        else:
            # OpenAI (é»˜è®¤)
            if not self.llm.api_key and os.getenv('OPENAI_API_KEY'):
                self.llm.api_key = os.getenv('OPENAI_API_KEY', '')

        # ğŸ”„ å…¼å®¹æ—§ç‰ˆ .env å­—æ®µ (æœ€åçš„åå¤‡é€‰é¡¹)
        if not self.llm.api_key and os.getenv('LLM_API_KEY'):
            self.llm.api_key = os.getenv('LLM_API_KEY', '')

        # åŠ è½½æ¨¡å‹åç§° - æ ¹æ®æä¾›å•†é€‰æ‹©
        if provider == 'openrouter' and os.getenv('OPENROUTER_MODEL'):
            self.llm.model = os.getenv('OPENROUTER_MODEL', self.llm.model)
        elif provider == 'deepseek' and os.getenv('DEEPSEEK_MODEL'):
            self.llm.model = os.getenv('DEEPSEEK_MODEL', self.llm.model)
        elif provider == 'qwen' and os.getenv('QWEN_MODEL'):
            self.llm.model = os.getenv('QWEN_MODEL', self.llm.model)
        elif os.getenv('OPENAI_MODEL'):
            self.llm.model = os.getenv('OPENAI_MODEL', self.llm.model)
        elif os.getenv('LLM_MODEL_NAME'):
            self.llm.model = os.getenv('LLM_MODEL_NAME', self.llm.model)

        # åŠ è½½ Base URL - æ ¹æ®æä¾›å•†é€‰æ‹©
        if provider == 'openrouter' and os.getenv('OPENROUTER_BASE_URL'):
            self.llm.api_base = os.getenv('OPENROUTER_BASE_URL', self.llm.api_base)
        elif provider == 'deepseek' and os.getenv('DEEPSEEK_BASE_URL'):
            self.llm.api_base = os.getenv('DEEPSEEK_BASE_URL', self.llm.api_base)
        elif provider == 'qwen' and os.getenv('QWEN_BASE_URL'):
            self.llm.api_base = os.getenv('QWEN_BASE_URL', self.llm.api_base)
        elif os.getenv('OPENAI_BASE_URL'):
            self.llm.api_base = os.getenv('OPENAI_BASE_URL', self.llm.api_base)
        elif os.getenv('LLM_BASE_URL'):
            self.llm.api_base = os.getenv('LLM_BASE_URL', self.llm.api_base)
        if os.getenv('MAX_TOKENS'):
            self.llm.max_tokens = int(os.getenv('MAX_TOKENS', self.llm.max_tokens))
        if os.getenv('LLM_TIMEOUT'):
            self.llm.timeout = int(os.getenv('LLM_TIMEOUT', self.llm.timeout))
        if os.getenv('TEMPERATURE'):
            self.llm.temperature = float(os.getenv('TEMPERATURE', self.llm.temperature))
        if os.getenv('MAX_RETRIES'):
            self.llm.max_retries = int(os.getenv('MAX_RETRIES', self.llm.max_retries))
        if os.getenv('RETRY_DELAY'):
            self.llm.retry_delay = int(os.getenv('RETRY_DELAY', self.llm.retry_delay))

        # ğŸ†• v7.38: è¯»å–å›¾åƒç”Ÿæˆé…ç½®
        if os.getenv('IMAGE_GENERATION_ENABLED'):
            self.image_generation.enabled = os.getenv('IMAGE_GENERATION_ENABLED', 'false').lower() in ('true', '1', 'yes')
        if os.getenv('IMAGE_GENERATION_MODEL'):
            self.image_generation.model = os.getenv('IMAGE_GENERATION_MODEL', self.image_generation.model)
        if os.getenv('IMAGE_GENERATION_MAX_IMAGES_PER_REPORT'):
            self.image_generation.max_images_per_report = int(os.getenv('IMAGE_GENERATION_MAX_IMAGES_PER_REPORT', self.image_generation.max_images_per_report))
        if os.getenv('IMAGE_GENERATION_TIMEOUT'):
            self.image_generation.timeout = int(os.getenv('IMAGE_GENERATION_TIMEOUT', self.image_generation.timeout))

        # ğŸ†• v7.62: è¯»å– Inpainting å›¾åƒç¼–è¾‘é…ç½®
        if os.getenv('INPAINTING_ENABLED'):
            self.inpainting.enabled = os.getenv('INPAINTING_ENABLED', 'false').lower() in ('true', '1', 'yes')
        if os.getenv('INPAINTING_PROVIDER'):
            self.inpainting.provider = os.getenv('INPAINTING_PROVIDER', self.inpainting.provider)
        if os.getenv('INPAINTING_MODEL'):
            self.inpainting.model = os.getenv('INPAINTING_MODEL', self.inpainting.model)
        if os.getenv('INPAINTING_TIMEOUT'):
            self.inpainting.timeout = int(os.getenv('INPAINTING_TIMEOUT', self.inpainting.timeout))

        # è¯»å–Tavilyé…ç½®
        if not self.tavily.api_key and os.getenv('TAVILY_API_KEY'):
            self.tavily.api_key = os.getenv('TAVILY_API_KEY', '')

        # è¯»å–Ragflowé…ç½®
        if not self.ragflow.api_key and os.getenv('RAGFLOW_API_KEY'):
            self.ragflow.api_key = os.getenv('RAGFLOW_API_KEY', '')
        if os.getenv('RAGFLOW_ENDPOINT'):
            self.ragflow.endpoint = os.getenv('RAGFLOW_ENDPOINT', self.ragflow.endpoint)
        if os.getenv('RAGFLOW_DATASET_ID'):
            self.ragflow.dataset_id = os.getenv('RAGFLOW_DATASET_ID')

        # ğŸ†• v7.63: è¯»å–åšæŸ¥é…ç½®
        if os.getenv('BOCHA_ENABLED'):
            self.bocha.enabled = os.getenv('BOCHA_ENABLED', 'false').lower() in ('true', '1', 'yes')
        if not self.bocha.api_key and os.getenv('BOCHA_API_KEY'):
            self.bocha.api_key = os.getenv('BOCHA_API_KEY', '')
        if os.getenv('BOCHA_BASE_URL'):
            self.bocha.base_url = os.getenv('BOCHA_BASE_URL', self.bocha.base_url)
        if os.getenv('BOCHA_DEFAULT_COUNT'):
            self.bocha.default_count = int(os.getenv('BOCHA_DEFAULT_COUNT', self.bocha.default_count))

        return self
    
    @property
    def is_production(self) -> bool:
        """æ˜¯å¦ä¸ºç”Ÿäº§ç¯å¢ƒ"""
        return self.environment == Environment.PROD
    
    @property
    def is_development(self) -> bool:
        """æ˜¯å¦ä¸ºå¼€å‘ç¯å¢ƒ"""
        return self.environment == Environment.DEV


# å…¨å±€é…ç½®å®ä¾‹ - å•ä¾‹æ¨¡å¼
settings = Settings()

