"""
ç»Ÿä¸€é…ç½®ç®¡ç† - åŸºäºPydantic Settings 2.x (2025å¹´æ ‡å‡†)

ä½¿ç”¨Pydantic Settingsè‡ªåŠ¨åŠ è½½ç¯å¢ƒå˜é‡,æ— éœ€æ‰‹åŠ¨è°ƒç”¨load_dotenv()
"""

import os
from pathlib import Path
from pydantic import BaseModel, Field, field_validator, model_validator
from pydantic_settings import BaseSettings, SettingsConfigDict
from enum import Enum
from typing import Optional
from dotenv import load_dotenv

# ç¡®ä¿.envæ–‡ä»¶è¢«åŠ è½½åˆ°ç¯å¢ƒå˜é‡ä¸­
env_path = Path(__file__).parent.parent / '.env'
if env_path.exists():
    load_dotenv(env_path)


class Environment(str, Enum):
    """ç¯å¢ƒç±»å‹"""
    DEV = "dev"
    STAGING = "staging"
    PROD = "prod"


class LLMConfig(BaseModel):
    """LLMé…ç½® - å•ä¸€çœŸå®æ¥æº"""
    provider: str = "openai"
    # model ä» .env çš„ {PROVIDER}_MODEL è¯»å–,æ­¤å¤„ä»…ä¸ºåå¤‡é»˜è®¤å€¼
    model: str = Field(default="gpt-4.1", description="é»˜è®¤LLMæ¨¡å‹")
    max_tokens: int = Field(default=4000, description="æœ€å¤§tokenæ•°", alias="MAX_TOKENS")
    timeout: int = Field(default=60, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)", alias="LLM_TIMEOUT")
    temperature: float = Field(default=0.7, description="æ¸©åº¦å‚æ•°", alias="TEMPERATURE")
    api_key: str = Field(default="", description="LLM APIå¯†é’¥", alias="OPENAI_API_KEY")
    api_base: Optional[str] = Field(default=None, description="è‡ªå®šä¹‰API Base URL")
    # é‡è¯•é…ç½®
    max_retries: int = Field(default=3, description="LLMè°ƒç”¨å¤±è´¥é‡è¯•æ¬¡æ•°", alias="MAX_RETRIES")
    retry_delay: int = Field(default=5, description="é‡è¯•é—´éš”(ç§’)", alias="RETRY_DELAY")

    model_config = {"populate_by_name": True}  # å…è®¸ä½¿ç”¨åˆ«å


class TavilyConfig(BaseModel):
    """Tavilyæœç´¢å·¥å…·é…ç½®"""
    api_key: str = Field(default="", description="Tavily APIå¯†é’¥", alias="TAVILY_API_KEY")
    max_results: int = Field(default=5, description="æœ€å¤§æœç´¢ç»“æœæ•°")
    search_depth: str = Field(default="basic", description="æœç´¢æ·±åº¦: basic/advanced")
    timeout: int = Field(default=30, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)")

    model_config = {"populate_by_name": True}


class RagflowConfig(BaseModel):
    """RagflowçŸ¥è¯†åº“é…ç½®"""
    endpoint: str = Field(default="http://localhost:9380", description="RagflowæœåŠ¡ç«¯ç‚¹", alias="RAGFLOW_ENDPOINT")
    api_key: str = Field(default="", description="Ragflow APIå¯†é’¥", alias="RAGFLOW_API_KEY")
    dataset_id: Optional[str] = Field(default=None, description="æ•°æ®é›†ID", alias="RAGFLOW_DATASET_ID")
    timeout: int = Field(default=30, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)")

    model_config = {"populate_by_name": True}


class ArxivConfig(BaseModel):
    """Arxivæœç´¢é…ç½®"""
    enabled: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨Arxivæœç´¢")
    timeout: int = Field(default=30, description="è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)")


class StorageConfig(BaseModel):
    """æ–‡ä»¶å­˜å‚¨é…ç½®"""
    upload_dir: str = Field(default="./data/uploads", description="ä¸Šä¼ ç›®å½•", alias="UPLOAD_DIR")
    output_dir: str = Field(default="./data/outputs", description="è¾“å‡ºç›®å½•", alias="OUTPUT_DIR")
    temp_dir: str = Field(default="./data/temp", description="ä¸´æ—¶ç›®å½•", alias="TEMP_DIR")
    database_url: str = Field(default="sqlite:///./data/project_analyzer.db", description="æ•°æ®åº“URL", alias="DATABASE_URL")

    model_config = {"populate_by_name": True}


class ConcurrencyConfig(BaseModel):
    """å¹¶å‘é…ç½®"""
    max_concurrent_agents: int = Field(default=6, description="æœ€å¤§å¹¶å‘æ™ºèƒ½ä½“æ•°", alias="MAX_CONCURRENT_AGENTS")
    agent_timeout: int = Field(default=300, description="æ™ºèƒ½ä½“è¶…æ—¶æ—¶é—´(ç§’)", alias="AGENT_TIMEOUT")

    model_config = {"populate_by_name": True}


class Settings(BaseSettings):
    """
    å…¨å±€é…ç½® - 2025å¹´æ ‡å‡†

    ä½¿ç”¨Pydantic Settingsè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
    æ”¯æŒåµŒå¥—é…ç½®: LLM__MAX_TOKENS=8000
    """

    # ç¯å¢ƒé…ç½®
    environment: Environment = Field(default=Environment.DEV, description="è¿è¡Œç¯å¢ƒ")
    debug: bool = Field(default=False, description="è°ƒè¯•æ¨¡å¼", alias="DEBUG")
    log_level: str = Field(default="INFO", description="æ—¥å¿—çº§åˆ«", alias="LOG_LEVEL")

    # åº”ç”¨é…ç½®
    app_name: str = Field(default="Intelligent Project Analyzer", description="åº”ç”¨åç§°", alias="APP_NAME")
    app_version: str = Field(default="2.0.0", description="åº”ç”¨ç‰ˆæœ¬", alias="APP_VERSION")
    post_completion_followup_enabled: bool = Field(
        default=True,
        description="æŠ¥å‘Šç”Ÿæˆåæ˜¯å¦è‡ªåŠ¨è§¦å‘è¿½é—®äº¤äº’"
    )

    # LLMé…ç½® (åµŒå¥—) - âœ… æä¾›é»˜è®¤å€¼
    llm: LLMConfig = Field(default_factory=LLMConfig)

    # å·¥å…·é…ç½® (åµŒå¥—) - âœ… æä¾›é»˜è®¤å€¼
    tavily: TavilyConfig = Field(default_factory=TavilyConfig)
    ragflow: RagflowConfig = Field(default_factory=RagflowConfig)
    arxiv: ArxivConfig = Field(default_factory=ArxivConfig)

    # å­˜å‚¨é…ç½®
    storage: StorageConfig = Field(default_factory=StorageConfig)

    # å¹¶å‘é…ç½®
    concurrency: ConcurrencyConfig = Field(default_factory=ConcurrencyConfig)

    # æ•°æ®åº“é…ç½®
    database_url: str = Field(default="sqlite:///./data/project_analyzer.db", description="æ•°æ®åº“URL", alias="DATABASE_URL")
    redis_url: str = Field(default="redis://localhost:6379/0", description="Redis URL", alias="REDIS_URL")

    # å‰ç«¯é…ç½®
    api_base_url: str = Field(default="http://localhost:8000", description="APIæœåŠ¡åœ°å€")
    streamlit_port: int = Field(default=8501, description="Streamlitç«¯å£", alias="STREAMLIT_PORT")
    streamlit_host: str = Field(default="localhost", description="Streamlitä¸»æœº", alias="STREAMLIT_HOST")

    model_config = SettingsConfigDict(
        env_file='.env',
        env_file_encoding='utf-8',
        env_nested_delimiter='__',  # æ”¯æŒ LLM__MAX_TOKENS=8000
        case_sensitive=False,
        extra='ignore'  # å¿½ç•¥æœªå®šä¹‰çš„ç¯å¢ƒå˜é‡
    )

    @model_validator(mode='after')
    def load_from_flat_env(self):
        """ä»æ‰å¹³ç¯å¢ƒå˜é‡åŠ è½½é…ç½®(å…¼å®¹æ—§.envæ ¼å¼)"""
        # è¯»å–LLMé…ç½®
        if not self.llm.api_key and os.getenv('OPENAI_API_KEY'):
            self.llm.api_key = os.getenv('OPENAI_API_KEY', '')
        # ğŸ”„ å…¼å®¹æ—§ç‰ˆ .env å­—æ®µ
        if not self.llm.api_key and os.getenv('LLM_API_KEY'):
            self.llm.api_key = os.getenv('LLM_API_KEY', '')
        if os.getenv('LLM_MODEL_NAME'):
            self.llm.model = os.getenv('LLM_MODEL_NAME', self.llm.model)
        if os.getenv('LLM_BASE_URL'):
            self.llm.api_base = os.getenv('LLM_BASE_URL', self.llm.api_base)
        if os.getenv('MAX_TOKENS'):
            self.llm.max_tokens = int(os.getenv('MAX_TOKENS', self.llm.max_tokens))
        if os.getenv('LLM_TIMEOUT'):
            self.llm.timeout = int(os.getenv('LLM_TIMEOUT', self.llm.timeout))
        if os.getenv('TEMPERATURE'):
            self.llm.temperature = float(os.getenv('TEMPERATURE', self.llm.temperature))
        if os.getenv('MAX_RETRIES'):
            self.llm.max_retries = int(os.getenv('MAX_RETRIES', self.llm.max_retries))
        if os.getenv('RETRY_DELAY'):
            self.llm.retry_delay = int(os.getenv('RETRY_DELAY', self.llm.retry_delay))

        # è¯»å–Tavilyé…ç½®
        if not self.tavily.api_key and os.getenv('TAVILY_API_KEY'):
            self.tavily.api_key = os.getenv('TAVILY_API_KEY', '')

        # è¯»å–Ragflowé…ç½®
        if not self.ragflow.api_key and os.getenv('RAGFLOW_API_KEY'):
            self.ragflow.api_key = os.getenv('RAGFLOW_API_KEY', '')
        if os.getenv('RAGFLOW_ENDPOINT'):
            self.ragflow.endpoint = os.getenv('RAGFLOW_ENDPOINT', self.ragflow.endpoint)
        if os.getenv('RAGFLOW_DATASET_ID'):
            self.ragflow.dataset_id = os.getenv('RAGFLOW_DATASET_ID')

        return self
    
    @property
    def is_production(self) -> bool:
        """æ˜¯å¦ä¸ºç”Ÿäº§ç¯å¢ƒ"""
        return self.environment == Environment.PROD
    
    @property
    def is_development(self) -> bool:
        """æ˜¯å¦ä¸ºå¼€å‘ç¯å¢ƒ"""
        return self.environment == Environment.DEV


# å…¨å±€é…ç½®å®ä¾‹ - å•ä¾‹æ¨¡å¼
settings = Settings()

