"""
ä¸“å®¶æŒ‘æˆ˜é—­ç¯æœºåˆ¶æµ‹è¯•

æµ‹è¯•v3.5.1æ–°å¢çš„ä¸‰ç§é—­ç¯æœºåˆ¶:
1. Acceptå†³ç­–: æ›´æ–°expert_driven_insights
2. Synthesizeå†³ç­–: ç»¼åˆç«äº‰æ€§æ¡†æ¶
3. Escalateå†³ç­–: æäº¤ç”²æ–¹è£å†³
"""

import json
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, "d:\\11-20\\langgraph-design")

# æµ‹è¯•æ•°æ®
MOCK_EXPERT_OUTPUTS = {
    "V2_è®¾è®¡æ€»ç›‘_2-1": {
        "challenge_flags": [
            {
                "challenged_item": "æ ¸å¿ƒå¼ åŠ›å®šä¹‰",
                "rationale": "çœŸæ­£çš„å¼ åŠ›ä¸æ˜¯'ä¼ ç»Ÿvsç°ä»£'ï¼Œè€Œæ˜¯'ä»ªå¼æ„Ÿvsæ—¥å¸¸æ„Ÿ'",
                "reinterpretation": "ç”¨æˆ·éœ€è¦çš„æ˜¯å¯ä»¥'åˆ‡æ¢æ¨¡å¼'çš„ç©ºé—´",
                "design_impact": "è®¾è®¡ç­–ç•¥ä»'èåˆ'è½¬å‘'å¤šæ¨¡æ€åˆ‡æ¢'"
            }
        ]
    },
    "V3_äººç‰©åŠå™äº‹ä¸“å®¶_3-1": {
        "challenge_flags": [
            {
                "challenged_item": "ç”¨æˆ·ç”»åƒå‡†ç¡®æ€§",
                "rationale": "éœ€æ±‚åˆ†æå¸ˆè®¤ä¸ºç›®æ ‡ç”¨æˆ·æ˜¯'è¿½æ±‚å“è´¨çš„ä¸­äº§'ï¼Œä½†æˆ‘æ ‡è®°ä¸ç¡®å®š",
                "reinterpretation": "å»ºè®®å›è®¿ç”¨æˆ·ç¡®è®¤ï¼Œæ˜¯'è¿½æ±‚å“è´¨'è¿˜æ˜¯'è¿½æ±‚ç‹¬ç‰¹æ€§'",
                "design_impact": "åœ¨ç¡®è®¤å‰ï¼Œæä¾›ä¸¤ä¸ªæ–¹æ¡ˆ"
            }
        ]
    },
    "V5_åœºæ™¯ä¸ç”¨æˆ·ç”Ÿæ€ä¸“å®¶_5-1": {
        "challenge_flags": [
            {
                "challenged_item": "æ ¸å¿ƒåœºæ™¯ä¼˜å…ˆçº§",
                "rationale": "ä¸V2å¯¹åœºæ™¯é‡è¦æ€§çš„åˆ¤æ–­ä¸ä¸€è‡´",
                "reinterpretation": "æˆ‘è®¤ä¸ºç¤¾äº¤åœºæ™¯æ˜¯æ ¸å¿ƒï¼Œè€Œéæ”¯æ’‘",
                "design_impact": "éœ€è¦ç»¼åˆä¸¤ç§æ¡†æ¶"
            }
        ]
    },
    "V6_ä¸“ä¸šæ€»å·¥ç¨‹å¸ˆ_6-1": {
        "challenge_flags": [
            {
                "challenged_item": "é¢„ç®—åˆ†é…ç­–ç•¥",
                "rationale": "éœ€æ±‚åˆ†æå¸ˆå»ºè®®70%ç”¨äºç¡¬è£…ï¼Œä½†è¿™è¶…å‡ºæˆ‘çš„æŠ€æœ¯è¯„ä¼°èŒƒå›´",
                "reinterpretation": "è¿™æ˜¯æˆ˜ç•¥å†³ç­–ï¼Œå»ºè®®äº¤ç”²æ–¹è£å†³",
                "design_impact": "é¢„ç®—æ¯”ä¾‹å½±å“æ•´ä½“è´¨é‡"
            }
        ]
    }
}


def test_accept_closure():
    """æµ‹è¯•1: Acceptå†³ç­–çš„é—­ç¯æœºåˆ¶"""
    print("\n" + "="*80)
    print("æµ‹è¯•1: Acceptå†³ç­–çš„é—­ç¯æœºåˆ¶")
    print("="*80)
    
    # æ¨¡æ‹Ÿä¸“å®¶æŒ‘æˆ˜
    challenge = {
        "expert_role": "V2_è®¾è®¡æ€»ç›‘_2-1",
        "challenged_item": "æ ¸å¿ƒå¼ åŠ›å®šä¹‰",
        "rationale": "çœŸæ­£çš„å¼ åŠ›ä¸æ˜¯'ä¼ ç»Ÿvsç°ä»£'ï¼Œè€Œæ˜¯'ä»ªå¼æ„Ÿvsæ—¥å¸¸æ„Ÿ'",
        "reinterpretation": "ç”¨æˆ·éœ€è¦çš„æ˜¯å¯ä»¥'åˆ‡æ¢æ¨¡å¼'çš„ç©ºé—´",
        "design_impact": "è®¾è®¡ç­–ç•¥ä»'èåˆ'è½¬å‘'å¤šæ¨¡æ€åˆ‡æ¢'"
    }
    
    # æ¨¡æ‹Ÿstate
    mock_state = {}
    
    # å¯¼å…¥å®é™…çš„é—­ç¯å‡½æ•°
    from intelligent_project_analyzer.agents.dynamic_project_director import _apply_accepted_reinterpretation
    
    # æ‰§è¡Œé—­ç¯é€»è¾‘
    _apply_accepted_reinterpretation(mock_state, challenge)
    
    # éªŒè¯ç»“æœ
    print("\nâœ… éªŒè¯1: expert_driven_insightså­—æ®µå­˜åœ¨")
    assert "expert_driven_insights" in mock_state, "âŒ ç¼ºå°‘expert_driven_insightså­—æ®µ"
    print(f"   âœ“ expert_driven_insights: {list(mock_state['expert_driven_insights'].keys())}")
    
    print("\nâœ… éªŒè¯2: åŒ…å«è¢«æŒ‘æˆ˜çš„é¡¹ç›®")
    assert "æ ¸å¿ƒå¼ åŠ›å®šä¹‰" in mock_state["expert_driven_insights"], "âŒ ç¼ºå°‘'æ ¸å¿ƒå¼ åŠ›å®šä¹‰'æ¡ç›®"
    insight = mock_state["expert_driven_insights"]["æ ¸å¿ƒå¼ åŠ›å®šä¹‰"]
    print(f"   âœ“ ä¸“å®¶: {insight['accepted_from']}")
    print(f"   âœ“ é‡æ–°è¯ é‡Š: {insight['expert_reinterpretation'][:50]}...")
    print(f"   âœ“ è®¾è®¡å½±å“: {insight['design_impact'][:50]}...")
    
    print("\nâœ… éªŒè¯3: insight_updateså­—æ®µå­˜åœ¨")
    assert "insight_updates" in mock_state, "âŒ ç¼ºå°‘insight_updateså­—æ®µ"
    assert len(mock_state["insight_updates"]) > 0, "âŒ insight_updatesä¸ºç©º"
    print(f"   âœ“ æ›´æ–°æ•°é‡: {len(mock_state['insight_updates'])}")
    print(f"   âœ“ æ›´æ–°å†…å®¹: {mock_state['insight_updates'][0]['reason']}")
    
    print("\nğŸ‰ æµ‹è¯•1é€šè¿‡: Accepté—­ç¯æœºåˆ¶æ­£å¸¸å·¥ä½œ")
    return True


def test_synthesize_closure():
    """æµ‹è¯•2: Synthesizeå†³ç­–çš„é—­ç¯æœºåˆ¶"""
    print("\n" + "="*80)
    print("æµ‹è¯•2: Synthesizeå†³ç­–çš„é—­ç¯æœºåˆ¶")
    print("="*80)
    
    # æ¨¡æ‹Ÿå¤šä¸ªä¸“å®¶æå‡ºç«äº‰æ€§æ¡†æ¶
    challenges = [
        {
            "expert_role": "V2_è®¾è®¡æ€»ç›‘_2-1",
            "challenged_item": "æ ¸å¿ƒåœºæ™¯ä¼˜å…ˆçº§",
            "rationale": "æˆ‘è®¤ä¸ºç¤¾äº¤åœºæ™¯æ˜¯æ”¯æ’‘",
            "reinterpretation": "æ–¹æ¡ˆA: ä»¥ç‹¬å¤„ä¸ºæ ¸å¿ƒï¼Œç¤¾äº¤ä¸ºç‚¹ç¼€",
            "design_impact": "å¼ºè°ƒç§å¯†æ€§"
        },
        {
            "expert_role": "V5_åœºæ™¯ä¸ç”¨æˆ·ç”Ÿæ€ä¸“å®¶_5-1",
            "challenged_item": "æ ¸å¿ƒåœºæ™¯ä¼˜å…ˆçº§",
            "rationale": "æˆ‘è®¤ä¸ºç¤¾äº¤åœºæ™¯æ˜¯æ ¸å¿ƒ",
            "reinterpretation": "æ–¹æ¡ˆB: ä»¥ç¤¾äº¤ä¸ºæ ¸å¿ƒï¼Œç‹¬å¤„ä¸ºè¿‡æ¸¡",
            "design_impact": "å¼ºè°ƒå¼€æ”¾æ€§"
        }
    ]
    
    # æ¨¡æ‹Ÿstate
    mock_state = {}
    
    # å¯¼å…¥å®é™…çš„é—­ç¯å‡½æ•°
    from intelligent_project_analyzer.agents.dynamic_project_director import _synthesize_competing_frames
    
    # æ‰§è¡Œé—­ç¯é€»è¾‘
    _synthesize_competing_frames(mock_state, challenges)
    
    # éªŒè¯ç»“æœ
    print("\nâœ… éªŒè¯1: framework_synthesiså­—æ®µå­˜åœ¨")
    assert "framework_synthesis" in mock_state, "âŒ ç¼ºå°‘framework_synthesiså­—æ®µ"
    print(f"   âœ“ framework_synthesis: {list(mock_state['framework_synthesis'].keys())}")
    
    print("\nâœ… éªŒè¯2: åŒ…å«ç«äº‰é¡¹çš„ç»¼åˆ")
    assert "æ ¸å¿ƒåœºæ™¯ä¼˜å…ˆçº§" in mock_state["framework_synthesis"], "âŒ ç¼ºå°‘'æ ¸å¿ƒåœºæ™¯ä¼˜å…ˆçº§'ç»¼åˆ"
    synthesis = mock_state["framework_synthesis"]["æ ¸å¿ƒåœºæ™¯ä¼˜å…ˆçº§"]
    print(f"   âœ“ ç«äº‰æ¡†æ¶æ•°é‡: {len(synthesis['competing_frames'])}")
    print(f"   âœ“ ç»¼åˆæ‘˜è¦: {synthesis['synthesis_summary'][:80]}...")
    print(f"   âœ“ æ¨èæ–¹æ¡ˆ: {synthesis['recommendation'][:60]}...")
    
    print("\nâœ… éªŒè¯3: æ ‡å¿—ä½æ­£ç¡®è®¾ç½®")
    assert mock_state.get("has_competing_frameworks") == True, "âŒ has_competing_frameworksæœªè®¾ç½®"
    assert mock_state.get("synthesis_required") == True, "âŒ synthesis_requiredæœªè®¾ç½®"
    print("   âœ“ has_competing_frameworks: True")
    print("   âœ“ synthesis_required: True")
    
    print("\nğŸ‰ æµ‹è¯•2é€šè¿‡: Synthesizeé—­ç¯æœºåˆ¶æ­£å¸¸å·¥ä½œ")
    return True


def test_escalate_closure():
    """æµ‹è¯•3: Escalateå†³ç­–çš„é—­ç¯æœºåˆ¶"""
    print("\n" + "="*80)
    print("æµ‹è¯•3: Escalateå†³ç­–çš„é—­ç¯æœºåˆ¶")
    print("="*80)
    
    # æ¨¡æ‹Ÿéœ€è¦ç”²æ–¹è£å†³çš„æŒ‘æˆ˜
    from intelligent_project_analyzer.agents.dynamic_project_director import detect_and_handle_challenges_node
    
    mock_state = {
        "batch_results": {
            "batch_6": {
                "V6_ä¸“ä¸šæ€»å·¥ç¨‹å¸ˆ_6-1": {
                    "challenge_flags": [
                        {
                            "challenged_item": "é¢„ç®—åˆ†é…ç­–ç•¥",
                            "rationale": "éœ€æ±‚åˆ†æå¸ˆå»ºè®®70%ç”¨äºç¡¬è£…ï¼Œä½†è¿™è¶…å‡ºæˆ‘çš„æŠ€æœ¯è¯„ä¼°èŒƒå›´",
                            "reinterpretation": "è¿™æ˜¯æˆ˜ç•¥å†³ç­–ï¼Œå»ºè®®äº¤ç”²æ–¹è£å†³",
                            "design_impact": "é¢„ç®—æ¯”ä¾‹å½±å“æ•´ä½“è´¨é‡"
                        }
                    ]
                }
            }
        }
    }
    
    # æ‰§è¡Œæ£€æµ‹å’Œå¤„ç†
    updated_state = detect_and_handle_challenges_node(mock_state)
    
    # åˆå¹¶æ›´æ–°
    for key, value in updated_state.items():
        mock_state[key] = value
    
    # éªŒè¯ç»“æœ
    print("\nâœ… éªŒè¯1: escalated_challengeså­—æ®µå­˜åœ¨")
    assert "escalated_challenges" in mock_state, "âŒ ç¼ºå°‘escalated_challengeså­—æ®µ"
    print(f"   âœ“ éœ€è¦ç”²æ–¹è£å†³çš„æŒ‘æˆ˜æ•°é‡: {len(mock_state['escalated_challenges'])}")
    
    print("\nâœ… éªŒè¯2: æŒ‘æˆ˜æ ¼å¼æ­£ç¡®")
    if mock_state["escalated_challenges"]:
        escalated = mock_state["escalated_challenges"][0]
        assert "issue_id" in escalated, "âŒ ç¼ºå°‘issue_id"
        assert "requires_client_decision" in escalated, "âŒ ç¼ºå°‘requires_client_decision"
        print(f"   âœ“ issue_id: {escalated['issue_id']}")
        print(f"   âœ“ æè¿°: {escalated['description']}")
        print(f"   âœ“ éœ€è¦ç”²æ–¹å†³ç­–: {escalated['requires_client_decision']}")
    
    print("\nâœ… éªŒè¯3: requires_client_reviewæ ‡å¿—ä½")
    assert mock_state.get("requires_client_review") == True, "âŒ requires_client_reviewæœªè®¾ç½®"
    print("   âœ“ requires_client_review: True")
    
    print("\nğŸ‰ æµ‹è¯•3é€šè¿‡: Escalateé—­ç¯æœºåˆ¶æ­£å¸¸å·¥ä½œ")
    return True


def test_routing_logic():
    """æµ‹è¯•4: è·¯ç”±é€»è¾‘ä¼˜å…ˆçº§"""
    print("\n" + "="*80)
    print("æµ‹è¯•4: è·¯ç”±é€»è¾‘ä¼˜å…ˆçº§")
    print("="*80)
    
    from intelligent_project_analyzer.workflow.main_workflow import MainWorkflow
    
    # åˆ›å»ºworkflowå®ä¾‹
    workflow = MainWorkflow()
    
    # æµ‹è¯•åœºæ™¯1: escalateä¼˜å…ˆ
    print("\nåœºæ™¯1: åŒæ—¶æœ‰escalateå’Œrevisit_raï¼Œåº”ä¼˜å…ˆescalate")
    state1 = {
        "requires_client_review": True,
        "requires_feedback_loop": True,
        "escalated_challenges": [{"issue_id": "TEST"}]
    }
    route1 = workflow._route_after_challenge_detection(state1)
    assert route1 == "analysis_review", f"âŒ è·¯ç”±é”™è¯¯: {route1}"
    print(f"   âœ“ è·¯ç”±åˆ°: {route1}")
    
    # æµ‹è¯•åœºæ™¯2: åªæœ‰revisit_ra
    print("\nåœºæ™¯2: åªæœ‰revisit_raï¼Œåº”å›è®¿éœ€æ±‚åˆ†æå¸ˆ")
    state2 = {
        "requires_client_review": False,
        "requires_feedback_loop": True
    }
    route2 = workflow._route_after_challenge_detection(state2)
    assert route2 == "revisit_requirements", f"âŒ è·¯ç”±é”™è¯¯: {route2}"
    print(f"   âœ“ è·¯ç”±åˆ°: {route2}")
    
    # æµ‹è¯•åœºæ™¯3: æ— æŒ‘æˆ˜
    print("\nåœºæ™¯3: æ— æŒ‘æˆ˜ï¼Œç»§ç»­æ­£å¸¸æµç¨‹")
    state3 = {
        "requires_client_review": False,
        "requires_feedback_loop": False
    }
    route3 = workflow._route_after_challenge_detection(state3)
    assert route3 == "continue_workflow", f"âŒ è·¯ç”±é”™è¯¯: {route3}"
    print(f"   âœ“ è·¯ç”±åˆ°: {route3}")
    
    print("\nğŸ‰ æµ‹è¯•4é€šè¿‡: è·¯ç”±é€»è¾‘ä¼˜å…ˆçº§æ­£ç¡®")
    return True


def test_report_integration():
    """æµ‹è¯•5: æŠ¥å‘Šç”Ÿæˆé›†æˆ"""
    print("\n" + "="*80)
    print("æµ‹è¯•5: æŠ¥å‘Šç”Ÿæˆé›†æˆ")
    print("="*80)
    
    from intelligent_project_analyzer.report.result_aggregator import ResultAggregatorAgent
    
    # æ¨¡æ‹ŸåŒ…å«æŒ‘æˆ˜è§£å†³ç»“æœçš„state
    mock_state = {
        "expert_driven_insights": {
            "æ ¸å¿ƒå¼ åŠ›å®šä¹‰": {
                "accepted_from": "V2_è®¾è®¡æ€»ç›‘_2-1",
                "expert_reinterpretation": "ç”¨æˆ·éœ€è¦çš„æ˜¯å¯ä»¥'åˆ‡æ¢æ¨¡å¼'çš„ç©ºé—´",
                "design_impact": "è®¾è®¡ç­–ç•¥ä»'èåˆ'è½¬å‘'å¤šæ¨¡æ€åˆ‡æ¢'",
                "timestamp": datetime.now().isoformat()
            }
        },
        "framework_synthesis": {
            "æ ¸å¿ƒåœºæ™¯ä¼˜å…ˆçº§": {
                "competing_frames": [
                    {"expert": "V2", "interpretation": "æ–¹æ¡ˆA"},
                    {"expert": "V5", "interpretation": "æ–¹æ¡ˆB"}
                ],
                "synthesis_summary": "ç»¼åˆæ‘˜è¦",
                "recommendation": "å»ºè®®æ–¹æ¡ˆ"
            }
        },
        "escalated_challenges": [
            {
                "issue_id": "CHALLENGE_V6_123456",
                "description": "é¢„ç®—åˆ†é…éœ€è¦ç”²æ–¹å†³ç­–",
                "requires_client_decision": True
            }
        ]
    }
    
    # åˆ›å»ºèšåˆå™¨å®ä¾‹ï¼ˆä¸éœ€è¦LLMï¼‰
    aggregator = ResultAggregatorAgent(llm_model=None)
    
    # è°ƒç”¨æå–æ–¹æ³•
    challenge_resolutions = aggregator._extract_challenge_resolutions(mock_state)
    
    # éªŒè¯ç»“æœ
    print("\nâœ… éªŒè¯1: åŸºæœ¬ç»“æ„")
    assert challenge_resolutions["has_challenges"] == True, "âŒ has_challengesåº”ä¸ºTrue"
    print(f"   âœ“ has_challenges: True")
    
    print("\nâœ… éªŒè¯2: Acceptç»“æœ")
    assert len(challenge_resolutions["accepted_reinterpretations"]) == 1, "âŒ Acceptç»“æœæ•°é‡é”™è¯¯"
    print(f"   âœ“ é‡‡çº³çš„é‡æ–°è¯ é‡Š: {len(challenge_resolutions['accepted_reinterpretations'])}ä¸ª")
    
    print("\nâœ… éªŒè¯3: Synthesizeç»“æœ")
    assert len(challenge_resolutions["synthesized_frameworks"]) == 1, "âŒ Synthesizeç»“æœæ•°é‡é”™è¯¯"
    print(f"   âœ“ ç»¼åˆçš„æ¡†æ¶: {len(challenge_resolutions['synthesized_frameworks'])}ä¸ª")
    
    print("\nâœ… éªŒè¯4: Escalateç»“æœ")
    assert len(challenge_resolutions["escalated_to_client"]) == 1, "âŒ Escalateç»“æœæ•°é‡é”™è¯¯"
    print(f"   âœ“ æäº¤ç”²æ–¹çš„æŒ‘æˆ˜: {len(challenge_resolutions['escalated_to_client'])}ä¸ª")
    
    print("\nâœ… éªŒè¯5: ç»Ÿè®¡æ‘˜è¦")
    summary = challenge_resolutions["summary"]
    assert summary["total_challenges"] == 3, "âŒ æ€»æ•°é”™è¯¯"
    assert summary["accepted_count"] == 1, "âŒ Acceptæ•°é‡é”™è¯¯"
    assert summary["synthesized_count"] == 1, "âŒ Synthesizeæ•°é‡é”™è¯¯"
    assert summary["escalated_count"] == 1, "âŒ Escalateæ•°é‡é”™è¯¯"
    print(f"   âœ“ æ€»æŒ‘æˆ˜æ•°: {summary['total_challenges']}")
    print(f"   âœ“ é—­ç¯ç‡: {summary['closure_rate']}")
    
    print("\nğŸ‰ æµ‹è¯•5é€šè¿‡: æŠ¥å‘Šç”Ÿæˆé›†æˆæ­£å¸¸")
    return True


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸš€"*40)
    print("ä¸“å®¶æŒ‘æˆ˜é—­ç¯æœºåˆ¶ - å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("ğŸš€"*40)
    
    results = []
    
    # æµ‹è¯•1: Accepté—­ç¯
    try:
        results.append(("Accepté—­ç¯", test_accept_closure()))
    except Exception as e:
        print(f"âŒ Accepté—­ç¯æµ‹è¯•å¤±è´¥: {e}")
        results.append(("Accepté—­ç¯", False))
    
    # æµ‹è¯•2: Synthesizeé—­ç¯
    try:
        results.append(("Synthesizeé—­ç¯", test_synthesize_closure()))
    except Exception as e:
        print(f"âŒ Synthesizeé—­ç¯æµ‹è¯•å¤±è´¥: {e}")
        results.append(("Synthesizeé—­ç¯", False))
    
    # æµ‹è¯•3: Escalateé—­ç¯
    try:
        results.append(("Escalateé—­ç¯", test_escalate_closure()))
    except Exception as e:
        print(f"âŒ Escalateé—­ç¯æµ‹è¯•å¤±è´¥: {e}")
        results.append(("Escalateé—­ç¯", False))
    
    # æµ‹è¯•4: è·¯ç”±é€»è¾‘
    try:
        results.append(("è·¯ç”±é€»è¾‘", test_routing_logic()))
    except Exception as e:
        print(f"âŒ è·¯ç”±é€»è¾‘æµ‹è¯•å¤±è´¥: {e}")
        results.append(("è·¯ç”±é€»è¾‘", False))
    
    # æµ‹è¯•5: æŠ¥å‘Šé›†æˆ
    try:
        results.append(("æŠ¥å‘Šé›†æˆ", test_report_integration()))
    except Exception as e:
        print(f"âŒ æŠ¥å‘Šé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        results.append(("æŠ¥å‘Šé›†æˆ", False))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*80)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*80)
    
    for test_name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
    
    total = len(results)
    passed = sum(1 for _, p in results if p)
    
    print("\n" + "="*80)
    print(f"æ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    print("="*80)
    
    if passed == total:
        print("\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é—­ç¯æœºåˆ¶å®æ–½æˆåŠŸï¼")
    else:
        print(f"\nâš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
    
    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1)
