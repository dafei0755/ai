"""
Arxivå­¦æœ¯æœç´¢å·¥å…·

æä¾›å­¦æœ¯è®ºæ–‡æœç´¢åŠŸèƒ½ï¼Œç”¨äºè·å–ç›¸å…³ç ”ç©¶å’ŒæŠ€æœ¯æ–‡çŒ®
"""

import json
from typing import Dict, List, Optional, Any, Union
import time
from datetime import datetime
from loguru import logger

try:
    import arxiv
except ImportError:
    logger.warning("Arxiv library not installed. Please install with: pip install arxiv")
    arxiv = None

from ..core.types import ToolConfig

# ğŸ†• v7.64: å¯¼å…¥ç²¾å‡†æœç´¢å’Œè´¨é‡æ§åˆ¶æ¨¡å—
try:
    from .query_builder import DeliverableQueryBuilder
    from .quality_control import SearchQualityControl
except ImportError:
    logger.warning("âš ï¸ v7.64 modules not available. search_for_deliverable() will use fallback mode.")
    DeliverableQueryBuilder = None
    SearchQualityControl = None


class ArxivSearchTool:
    """Arxivå­¦æœ¯æœç´¢å·¥å…·ç±»"""
    
    def __init__(self, config: Optional[ToolConfig] = None):
        """
        åˆå§‹åŒ–Arxivæœç´¢å·¥å…·

        Args:
            config: å·¥å…·é…ç½®
        """
        if arxiv is None:
            raise ImportError("Arxiv library not installed. Please install with: pip install arxiv")

        self.config = config or ToolConfig(name="arxiv_search")

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.client = arxiv.Client(
            page_size=100,  # æ¯é¡µç»“æœæ•°
            delay_seconds=3.0,  # è¯·æ±‚é—´å»¶è¿Ÿ
            num_retries=3  # é‡è¯•æ¬¡æ•°
        )

        # é»˜è®¤æœç´¢å‚æ•°
        self.default_params = {
            "max_results": 10,
            "sort_by": arxiv.SortCriterion.Relevance,
            "sort_order": arxiv.SortOrder.Descending
        }

        # ğŸ†• v7.64: åˆå§‹åŒ–ç²¾å‡†æœç´¢å’Œè´¨é‡æ§åˆ¶æ¨¡å—
        self.query_builder = DeliverableQueryBuilder() if DeliverableQueryBuilder else None
        self.qc = SearchQualityControl() if SearchQualityControl else None
    
    def search(
        self,
        query: str,
        max_results: Optional[int] = None,
        sort_by: Optional[arxiv.SortCriterion] = None,
        sort_order: Optional[arxiv.SortOrder] = None,
        categories: Optional[List[str]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå­¦æœ¯è®ºæ–‡æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
            max_results: æœ€å¤§ç»“æœæ•°é‡
            sort_by: æ’åºæ–¹å¼
            sort_order: æ’åºé¡ºåº
            categories: è®ºæ–‡åˆ†ç±»è¿‡æ»¤
            **kwargs: å…¶ä»–æœç´¢å‚æ•°
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        try:
            start_time = time.time()
            
            # å‡†å¤‡æœç´¢å‚æ•°
            search_params = {
                "query": query,
                "max_results": max_results or self.default_params["max_results"],
                "sort_by": sort_by or self.default_params["sort_by"],
                "sort_order": sort_order or self.default_params["sort_order"]
            }
            
            # å¦‚æœæŒ‡å®šäº†åˆ†ç±»ï¼Œæ·»åŠ åˆ°æŸ¥è¯¢ä¸­
            if categories:
                category_filter = " OR ".join([f"cat:{cat}" for cat in categories])
                search_params["query"] = f"({query}) AND ({category_filter})"
            
            logger.info(f"Executing Arxiv search: {query}")
            
            # åˆ›å»ºæœç´¢å¯¹è±¡
            search = arxiv.Search(**search_params)
            
            # æ‰§è¡Œæœç´¢
            results = list(self.client.results(search))
            
            end_time = time.time()
            execution_time = end_time - start_time
            
            # å¤„ç†å“åº”
            processed_response = self._process_search_response(results, query, execution_time)
            
            logger.info(f"Arxiv search completed in {execution_time:.2f}s, found {len(results)} results")
            
            return processed_response
            
        except Exception as e:
            logger.error(f"Arxiv search failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "query": query,
                "results": [],
                "execution_time": 0
            }
    
    def search_by_id(self, paper_ids: List[str]) -> Dict[str, Any]:
        """
        æ ¹æ®è®ºæ–‡IDæœç´¢
        
        Args:
            paper_ids: è®ºæ–‡IDåˆ—è¡¨
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        try:
            start_time = time.time()
            
            logger.info(f"Searching Arxiv by IDs: {paper_ids}")
            
            # åˆ›å»ºIDæœç´¢
            search = arxiv.Search(id_list=paper_ids)
            results = list(self.client.results(search))
            
            end_time = time.time()
            execution_time = end_time - start_time
            
            # å¤„ç†å“åº”
            processed_response = self._process_search_response(results, f"IDs: {paper_ids}", execution_time)
            
            logger.info(f"Arxiv ID search completed in {execution_time:.2f}s")
            
            return processed_response
            
        except Exception as e:
            logger.error(f"Arxiv ID search failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "query": f"IDs: {paper_ids}",
                "results": [],
                "execution_time": 0
            }
    
    def search_recent_papers(
        self,
        query: str,
        days_back: int = 30,
        max_results: int = 10
    ) -> Dict[str, Any]:
        """
        æœç´¢æœ€è¿‘å‘å¸ƒçš„è®ºæ–‡
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            days_back: å›æº¯å¤©æ•°
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        return self.search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.SubmittedDate,
            sort_order=arxiv.SortOrder.Descending
        )
    
    def search_by_author(self, author_name: str, max_results: int = 10) -> Dict[str, Any]:
        """
        æ ¹æ®ä½œè€…æœç´¢è®ºæ–‡
        
        Args:
            author_name: ä½œè€…å§“å
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        query = f"au:{author_name}"
        return self.search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.SubmittedDate,
            sort_order=arxiv.SortOrder.Descending
        )
    
    def search_by_category(
        self,
        categories: List[str],
        query: str = "",
        max_results: int = 10
    ) -> Dict[str, Any]:
        """
        æ ¹æ®åˆ†ç±»æœç´¢è®ºæ–‡
        
        Args:
            categories: åˆ†ç±»åˆ—è¡¨ (å¦‚ ["cs.AI", "cs.LG"])
            query: é¢å¤–æŸ¥è¯¢æ¡ä»¶
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        category_query = " OR ".join([f"cat:{cat}" for cat in categories])
        
        if query:
            full_query = f"({query}) AND ({category_query})"
        else:
            full_query = category_query
        
        return self.search(
            query=full_query,
            max_results=max_results
        )
    
    def _process_search_response(
        self,
        results: List[arxiv.Result],
        query: str,
        execution_time: float
    ) -> Dict[str, Any]:
        """
        å¤„ç†æœç´¢å“åº”ï¼Œæ ‡å‡†åŒ–æ ¼å¼
        
        Args:
            results: Arxivæœç´¢ç»“æœåˆ—è¡¨
            query: åŸå§‹æŸ¥è¯¢
            execution_time: æ‰§è¡Œæ—¶é—´
            
        Returns:
            å¤„ç†åçš„å“åº”
        """
        processed = {
            "success": True,
            "query": query,
            "results": [],
            "execution_time": execution_time,
            "total_results": len(results)
        }
        
        # å¤„ç†æ¯ä¸ªç»“æœ
        for result in results:
            processed_result = {
                "title": result.title,
                "authors": [author.name for author in result.authors],
                "summary": result.summary,
                "published": result.published.isoformat() if result.published else None,
                "updated": result.updated.isoformat() if result.updated else None,
                "entry_id": result.entry_id,
                "arxiv_id": result.get_short_id(),
                "categories": result.categories,
                "primary_category": result.primary_category,
                "pdf_url": result.pdf_url,
                "links": [{"href": link.href, "title": link.title} for link in result.links],
                "journal_ref": result.journal_ref,
                "doi": result.doi,
                "comment": result.comment
            }
            processed["results"].append(processed_result)
        
        return processed
    
    def search_for_agent(
        self,
        query: str,
        agent_context: str = "",
        max_results: int = 5,
        focus_recent: bool = True
    ) -> Dict[str, Any]:
        """
        ä¸ºæ™ºèƒ½ä½“ä¼˜åŒ–çš„æœç´¢æ–¹æ³•
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            agent_context: æ™ºèƒ½ä½“ä¸Šä¸‹æ–‡ä¿¡æ¯
            max_results: æœ€å¤§ç»“æœæ•°
            focus_recent: æ˜¯å¦å…³æ³¨æœ€æ–°è®ºæ–‡
            
        Returns:
            ä¼˜åŒ–åçš„æœç´¢ç»“æœ
        """
        # æ ¹æ®æ™ºèƒ½ä½“ä¸Šä¸‹æ–‡ä¼˜åŒ–æŸ¥è¯¢
        enhanced_query = query
        if agent_context:
            # å¯ä»¥æ ¹æ®ä¸åŒæ™ºèƒ½ä½“ç±»å‹æ·»åŠ ç‰¹å®šçš„åˆ†ç±»è¿‡æ»¤
            if "æŠ€æœ¯" in agent_context or "architecture" in agent_context.lower():
                enhanced_query = f"({query}) AND (cat:cs.SE OR cat:cs.AI OR cat:cs.LG)"
            elif "è®¾è®¡" in agent_context or "design" in agent_context.lower():
                enhanced_query = f"({query}) AND (cat:cs.HC OR cat:cs.AI)"
            elif "å•†ä¸š" in agent_context or "business" in agent_context.lower():
                enhanced_query = f"({query}) AND (cat:econ.* OR cat:cs.CY)"
        
        # æ‰§è¡Œæœç´¢
        sort_by = arxiv.SortCriterion.SubmittedDate if focus_recent else arxiv.SortCriterion.Relevance
        
        results = self.search(
            query=enhanced_query,
            max_results=max_results,
            sort_by=sort_by,
            sort_order=arxiv.SortOrder.Descending
        )
        
        # ä¸ºæ™ºèƒ½ä½“ä¼˜åŒ–ç»“æœæ ¼å¼
        if results.get("success"):
            # æå–å…³é”®ä¿¡æ¯
            summary = {
                "query": query,
                "key_papers": [],
                "research_trends": [],
                "relevant_authors": set(),
                "categories": set()
            }
            
            for result in results.get("results", []):
                # å…³é”®è®ºæ–‡ä¿¡æ¯
                summary["key_papers"].append({
                    "title": result["title"],
                    "authors": result["authors"][:3],  # å‰3ä¸ªä½œè€…
                    "summary": result["summary"][:300] + "..." if len(result["summary"]) > 300 else result["summary"],
                    "published": result["published"],
                    "arxiv_id": result["arxiv_id"],
                    "categories": result["categories"]
                })
                
                # æ”¶é›†ä½œè€…å’Œåˆ†ç±»ä¿¡æ¯
                summary["relevant_authors"].update(result["authors"][:2])  # å‰2ä¸ªä½œè€…
                summary["categories"].update(result["categories"])
            
            # è½¬æ¢é›†åˆä¸ºåˆ—è¡¨
            summary["relevant_authors"] = list(summary["relevant_authors"])[:10]  # æœ€å¤š10ä¸ªä½œè€…
            summary["categories"] = list(summary["categories"])
            
            results["agent_summary"] = summary

        return results

    def search_for_deliverable(
        self,
        deliverable: Dict[str, Any],
        project_type: str = "",
        max_results: int = 10,
        enable_qc: bool = True,
        focus_recent: bool = False
    ) -> Dict[str, Any]:
        """
        ğŸ†• v7.64: é’ˆå¯¹äº¤ä»˜ç‰©çš„ç²¾å‡†å­¦æœ¯æœç´¢

        æ ¸å¿ƒæ”¹è¿›ï¼š
        1. ä»äº¤ä»˜ç‰©æ„å»ºå­¦æœ¯åŒ–æŸ¥è¯¢ï¼ˆå¼ºè°ƒæ–¹æ³•è®ºæœ¯è¯­ï¼‰
        2. åº”ç”¨è´¨é‡æ§åˆ¶ç®¡é“
        3. è‡ªåŠ¨æ·»åŠ å­¦ç§‘åˆ†ç±»è¿‡æ»¤ï¼ˆåŸºäºé¡¹ç›®ç±»å‹ï¼‰

        Args:
            deliverable: äº¤ä»˜ç‰©å­—å…¸
            project_type: é¡¹ç›®ç±»å‹
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            enable_qc: æ˜¯å¦å¯ç”¨è´¨é‡æ§åˆ¶
            focus_recent: æ˜¯å¦å…³æ³¨æœ€æ–°è®ºæ–‡

        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        try:
            start_time = time.time()

            # Step 1: æ„å»ºå­¦æœ¯åŒ–æŸ¥è¯¢
            if self.query_builder:
                # ä½¿ç”¨ä¸“é—¨çš„ArxivæŸ¥è¯¢æ„å»ºå™¨
                queries = self.query_builder.build_multi_tool_queries(
                    deliverable,
                    project_type
                )
                precise_query = queries.get("arxiv", deliverable.get("name", ""))
                logger.info(f"ğŸ” [v7.64 Arxiv] Precise query: {precise_query}")
            else:
                precise_query = deliverable.get("name", "")
                logger.warning("âš ï¸ Query builder not available, using deliverable name")

            # Step 2: æ‰§è¡Œæœç´¢
            sort_by = arxiv.SortCriterion.SubmittedDate if focus_recent else arxiv.SortCriterion.Relevance

            search_results = self.search(
                query=precise_query,
                max_results=max_results * 2 if enable_qc else max_results,
                sort_by=sort_by,
                sort_order=arxiv.SortOrder.Descending
            )

            if not search_results.get("success", False):
                return search_results

            # Step 3: å½’ä¸€åŒ–ç»“æœæ ¼å¼ï¼ˆArxivç»“æœç»“æ„ä¸åŒäºTavilyï¼‰
            normalized_results = []
            for result in search_results.get("results", []):
                normalized = {
                    "title": result.get("title", ""),
                    "content": result.get("summary", "")[:500],  # é™åˆ¶æ‘˜è¦é•¿åº¦
                    "snippet": result.get("summary", "")[:300],
                    "url": result.get("pdf_url", ""),
                    "relevance_score": 0.8,  # Arxivæ— ç›¸å…³æ€§åˆ†æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    "published_date": result.get("published", ""),
                    "authors": result.get("authors", []),
                    "arxiv_id": result.get("arxiv_id", "")
                }
                normalized_results.append(normalized)

            # Step 4: è´¨é‡æ§åˆ¶
            if enable_qc and self.qc:
                processed_results = self.qc.process_results(
                    normalized_results,
                    deliverable_context=deliverable
                )
                processed_results = processed_results[:max_results]
                search_results["results"] = processed_results
                search_results["quality_controlled"] = True
                logger.info(
                    f"âœ… [v7.64 Arxiv] Quality control: {len(processed_results)} results"
                )
            else:
                search_results["results"] = normalized_results[:max_results]
                search_results["quality_controlled"] = False

            # Step 5: æ·»åŠ ç¼–å·
            for idx, result in enumerate(search_results.get("results", []), start=1):
                result["reference_number"] = idx

            end_time = time.time()
            search_results["execution_time"] = end_time - start_time
            search_results["deliverable_name"] = deliverable.get("name", "")
            search_results["precise_query"] = precise_query

            return search_results

        except Exception as e:
            logger.error(f"âŒ [v7.64 Arxiv] search_for_deliverable failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "deliverable_name": deliverable.get("name", ""),
                "results": [],
                "execution_time": 0
            }

    def get_paper_details(self, arxiv_id: str) -> Dict[str, Any]:
        """
        è·å–ç‰¹å®šè®ºæ–‡çš„è¯¦ç»†ä¿¡æ¯
        
        Args:
            arxiv_id: Arxivè®ºæ–‡ID
            
        Returns:
            è®ºæ–‡è¯¦ç»†ä¿¡æ¯
        """
        return self.search_by_id([arxiv_id])
    
    def is_available(self) -> bool:
        """
        æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨
        
        Returns:
            æ˜¯å¦å¯ç”¨
        """
        try:
            # ç®€å•æµ‹è¯•æœç´¢
            test_search = arxiv.Search(query="test", max_results=1)
            test_results = list(self.client.results(test_search))
            return True
        except Exception as e:
            logger.error(f"Arxiv tool availability check failed: {str(e)}")
            return False
