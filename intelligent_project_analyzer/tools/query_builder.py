"""
Deliverable Query Builder (v7.64)

ä»äº¤ä»˜ç‰©è§„æ ¼ï¼ˆname + descriptionï¼‰æ„å»ºç²¾å‡†æœç´¢æŸ¥è¯¢ï¼Œé¿å…æ³›æ³›è€Œè°ˆçš„é€šç”¨æœç´¢
"""

import re
from typing import Any, Dict, List, Optional

from loguru import logger

try:
    import jieba
    import jieba.analyse
except ImportError:
    logger.warning("jieba not installed. Please install with: pip install jieba")
    jieba = None


class DeliverableQueryBuilder:
    """
    äº¤ä»˜ç‰©æŸ¥è¯¢æ„å»ºå™¨

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ä»äº¤ä»˜ç‰©çš„nameå’Œdescriptionä¸­æå–å…³é”®è¯
    2. å°†äº¤ä»˜ç‰©æ ¼å¼æ˜ å°„åˆ°æœç´¢æœ¯è¯­ï¼ˆå¦‚"persona" â†’ "user persona methodology"ï¼‰
    3. ç»“åˆé¡¹ç›®ç±»å‹æ·»åŠ ä¸Šä¸‹æ–‡
    4. ç”Ÿæˆé’ˆå¯¹æ€§å¼ºçš„æœç´¢æŸ¥è¯¢
    """

    # ğŸ”‘ äº¤ä»˜ç‰©æ ¼å¼ â†’ æœç´¢æœ¯è¯­æ˜ å°„è¡¨ (v7.65æ‰©å±•: 30ç§â†’50+ç§)
    FORMAT_SEARCH_TERMS = {
        # === è®¾è®¡ç±» ===
        "design": "design methodology",
        "concept": "concept design approach",
        "blueprint": "design blueprint standards",
        "diagram": "design diagram techniques",
        "spatial_design": "spatial planning methods",
        "moodboard": "mood board design inspiration techniques",
        "stylescape": "style scape visual direction",
        "colorpalette": "color palette theory application",
        "material_board": "material selection board methods",
        "floorplan": "floor plan design standards",
        "elevation": "elevation drawing techniques",
        "section": "section drawing methods",
        # === åˆ†æç±» ===
        "analysis": "analysis framework",
        "evaluation": "evaluation criteria",
        "assessment": "assessment methodology",
        "audit": "audit checklist",
        "benchmark": "benchmarking best practices",
        "research": "research methodology",
        "insight": "insight discovery methods",
        "swot": "SWOT analysis framework",
        "gap_analysis": "gap analysis techniques",
        "competitor_analysis": "competitive analysis methods",
        "market_research": "market research methodology",
        "trend_analysis": "trend analysis forecasting",  # ğŸ”¥ require_search=true
        # === ç­–ç•¥ç±» ===
        "strategy": "strategic planning",
        "plan": "planning framework",
        "roadmap": "implementation roadmap",
        "framework": "framework design",
        "model": "modeling approach",
        "positioning": "brand positioning strategy",
        "value_proposition": "value proposition design",
        # === ç”¨æˆ·ä½“éªŒç±» ===
        "persona": "user persona design methodology",
        "journey_map": "customer journey mapping techniques",
        "experience_map": "experience mapping methods",
        "scenario": "scenario design framework",
        "wireframe": "wireframe design best practices",
        "prototype": "prototyping methods",
        "storyboard": "storyboard visualization techniques",
        "empathy_map": "empathy mapping methods",
        "service_blueprint": "service blueprint design",
        "touchpoint_map": "touchpoint mapping methods",
        # === æ–‡æ¡£ç±» ===
        "report": "report structure",
        "proposal": "proposal writing",
        "presentation": "presentation design",
        "guideline": "guideline development",
        "manual": "manual documentation",
        "checklist": "checklist design",
        "specification": "specification writing standards",
        "whitepaper": "white paper methodology",
        # === æ¡ˆä¾‹ä¸èµ„æ–™åº“ ===  # ğŸ”¥ require_search=true
        "case_study": "case study analysis methodology",
        "case_library": "design case studies best practices",
        "best_practices": "industry best practices examples",
        "reference_library": "design reference library",
        "precedent_study": "precedent analysis methods",
        # === å…¶ä»– ===
        "recommendation": "recommendation framework",
        "summary": "summary techniques",
        "narrative": "narrative design",
        "materials_list": "materials specification",
        "budget": "budget planning methods",
        "timeline": "project timeline planning",
        "kpi": "KPI definition measurement",
    }

    # ğŸŒ é¡¹ç›®ç±»å‹ â†’ ä¸Šä¸‹æ–‡æœ¯è¯­
    PROJECT_TYPE_CONTEXT = {
        "interior_design": "interior design",
        "commercial_space": "commercial space design",
        "residential": "residential design",
        "hospitality": "hospitality design",
        "retail": "retail space design",
        "office": "office design",
        "restaurant": "restaurant design",
        "branding": "branding design",
        "product_design": "product design",
        "urban_planning": "urban planning",
    }

    def __init__(self, enable_jieba: bool = True):
        """
        åˆå§‹åŒ–æŸ¥è¯¢æ„å»ºå™¨

        Args:
            enable_jieba: æ˜¯å¦å¯ç”¨jiebaåˆ†è¯ï¼ˆä¸­æ–‡å…³é”®è¯æå–ï¼‰
        """
        self.enable_jieba = enable_jieba and jieba is not None

        if self.enable_jieba:
            # åŠ è½½jiebaè¯å…¸ï¼ˆå¯é€‰ï¼šæ·»åŠ è‡ªå®šä¹‰è¯æ±‡ï¼‰
            jieba.initialize()
            logger.info("âœ… DeliverableQueryBuilder: jieba initialized")
        else:
            logger.warning("âš ï¸ DeliverableQueryBuilder: jieba disabled")

    def build_query(self, deliverable: Dict[str, Any], project_type: str = "", agent_context: str = "") -> str:
        """
        ä»äº¤ä»˜ç‰©æ„å»ºç²¾å‡†æœç´¢æŸ¥è¯¢

        Args:
            deliverable: äº¤ä»˜ç‰©å­—å…¸ï¼ŒåŒ…å«name, description, format
            project_type: é¡¹ç›®ç±»å‹ï¼ˆå¦‚"commercial_space"ï¼‰
            agent_context: æ™ºèƒ½ä½“ä¸Šä¸‹æ–‡ï¼ˆå¦‚"V4è®¾è®¡ç ”ç©¶å‘˜"ï¼‰

        Returns:
            ç²¾å‡†çš„æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²

        Example:
            Before: "ç”¨æˆ·ç”»åƒ"
            After: "user persona design methodology commercial space"
        """
        query_parts = []

        # 1. æå–äº¤ä»˜ç‰©åç§°å…³é”®è¯ï¼ˆæƒé‡é«˜ï¼Œå–top2ï¼‰
        name = deliverable.get("name", "")
        if name:
            name_keywords = self._extract_keywords(name, topK=2)
            if name_keywords:
                query_parts.extend(name_keywords)
                logger.debug(f"ğŸ“Œ Name keywords: {name_keywords}")

        # 2. æå–äº¤ä»˜ç‰©æè¿°å…³é”®è¯ï¼ˆæƒé‡ä¸­ï¼Œå–top5ï¼‰
        description = deliverable.get("description", "")
        if description:
            desc_keywords = self._extract_keywords(description, topK=5)
            if desc_keywords:
                query_parts.extend(desc_keywords)
                logger.debug(f"ğŸ“Œ Description keywords: {desc_keywords}")

        # 3. æ·»åŠ æ ¼å¼å¯¹åº”çš„æœç´¢æœ¯è¯­ï¼ˆè‹±æ–‡ï¼Œæé«˜å›½é™…æœç´¢å‡†ç¡®æ€§ï¼‰
        fmt = deliverable.get("format", "")
        if fmt and fmt in self.FORMAT_SEARCH_TERMS:
            format_term = self.FORMAT_SEARCH_TERMS[fmt]
            query_parts.append(format_term)
            logger.debug(f"ğŸ“Œ Format term: {format_term}")

        # 4. æ·»åŠ é¡¹ç›®ç±»å‹ä¸Šä¸‹æ–‡
        if project_type and project_type in self.PROJECT_TYPE_CONTEXT:
            context_term = self.PROJECT_TYPE_CONTEXT[project_type]
            query_parts.append(context_term)
            logger.debug(f"ğŸ“Œ Project context: {context_term}")

        # 5. ç»„åˆæŸ¥è¯¢ï¼ˆå»é‡ï¼‰
        unique_parts = []
        seen = set()
        for part in query_parts:
            part_lower = part.lower()
            if part_lower not in seen:
                unique_parts.append(part)
                seen.add(part_lower)

        final_query = " ".join(unique_parts)
        logger.info(f"ğŸ” Built query for '{name}': {final_query}")

        return final_query

    def _extract_keywords(self, text: str, topK: int = 5) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯

        Args:
            text: è¾“å…¥æ–‡æœ¬
            topK: è¿”å›å‰Kä¸ªå…³é”®è¯

        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        if not text or not text.strip():
            return []

        # ä¸­æ–‡æ–‡æœ¬ä½¿ç”¨jieba
        if self.enable_jieba and self._is_chinese_text(text):
            try:
                # ä½¿ç”¨TF-IDFæå–å…³é”®è¯
                keywords = jieba.analyse.extract_tags(text, topK=topK, withWeight=False)
                return keywords
            except Exception as e:
                logger.error(f"âŒ Jieba extraction failed: {e}")
                return self._simple_keyword_extraction(text, topK)
        else:
            # è‹±æ–‡æˆ–jiebaä¸å¯ç”¨æ—¶ä½¿ç”¨ç®€å•åˆ†è¯
            return self._simple_keyword_extraction(text, topK)

    def _is_chinese_text(self, text: str) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        """
        chinese_pattern = re.compile(r"[\u4e00-\u9fff]+")
        return bool(chinese_pattern.search(text))

    def _simple_keyword_extraction(self, text: str, topK: int = 5) -> List[str]:
        """
        ç®€å•å…³é”®è¯æå–ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰

        ç­–ç•¥ï¼š
        1. åˆ†è¯ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        2. è¿‡æ»¤åœç”¨è¯
        3. æŒ‰è¯é¢‘æ’åº

        Args:
            text: è¾“å…¥æ–‡æœ¬
            topK: è¿”å›å‰Kä¸ªå…³é”®è¯

        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # åœç”¨è¯åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
        stopwords = {
            # ä¸­æ–‡åœç”¨è¯
            "çš„",
            "äº†",
            "å’Œ",
            "æ˜¯",
            "å°±",
            "éƒ½",
            "è€Œ",
            "åŠ",
            "ä¸",
            "æˆ–",
            "ç­‰",
            "å¯¹",
            "åœ¨",
            "æœ‰",
            "ä¸º",
            "ä»¥",
            "å°†",
            "å¹¶",
            "ä»",
            "æŒ‰",
            "è¯¥",
            "æ­¤",
            # è‹±æ–‡åœç”¨è¯
            "the",
            "a",
            "an",
            "and",
            "or",
            "but",
            "in",
            "on",
            "at",
            "to",
            "for",
            "of",
            "with",
            "by",
            "from",
            "as",
            "is",
            "was",
            "are",
        }

        # åˆ†è¯ï¼šæŒ‰ç©ºæ ¼å’Œå¸¸è§æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
        words = re.split(r"[\s,;ï¼Œï¼›ã€ã€‚ï¼ï¼Ÿ]+", text.lower())

        # è¿‡æ»¤ï¼šå»é™¤åœç”¨è¯ã€ç©ºå­—ç¬¦ä¸²ã€è¿‡çŸ­çš„è¯
        filtered = [w for w in words if w and len(w) >= 2 and w not in stopwords]

        # ç»Ÿè®¡è¯é¢‘
        word_freq = {}
        for word in filtered:
            word_freq[word] = word_freq.get(word, 0) + 1

        # æ’åºå¹¶å–topK
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)

        return [word for word, freq in sorted_words[:topK]]

    def build_multi_tool_queries(self, deliverable: Dict[str, Any], project_type: str = "") -> Dict[str, str]:
        """
        ä¸ºä¸åŒæœç´¢å·¥å…·æ„å»ºä¼˜åŒ–çš„æŸ¥è¯¢

        ä¸åŒå·¥å…·çš„ç‰¹ç‚¹ï¼š
        - Tavily: é€‚åˆå›½é™…æ¡ˆä¾‹ï¼Œä½¿ç”¨è‹±æ–‡å…³é”®è¯
        - Arxiv: å­¦æœ¯è®ºæ–‡ï¼Œå¼ºè°ƒæ–¹æ³•è®ºæœ¯è¯­
        - RAGFlow: å†…éƒ¨çŸ¥è¯†åº“ï¼Œä¸­æ–‡ä¸ºä¸»
        - Bocha: ä¸­æ–‡æœç´¢ï¼Œæœ¬åœŸæ¡ˆä¾‹

        Args:
            deliverable: äº¤ä»˜ç‰©å­—å…¸
            project_type: é¡¹ç›®ç±»å‹

        Returns:
            å·¥å…·åç§° â†’ æŸ¥è¯¢å­—ç¬¦ä¸²çš„æ˜ å°„
        """
        base_query = self.build_query(deliverable, project_type)

        # ä¸ºä¸åŒå·¥å…·ä¼˜åŒ–æŸ¥è¯¢
        queries = {
            "tavily": base_query,  # é»˜è®¤æŸ¥è¯¢é€‚ç”¨äºTavily
            "arxiv": self._build_arxiv_query(deliverable, base_query),
            "ragflow": self._build_ragflow_query(deliverable, base_query),
            "bocha": self._build_bocha_query(deliverable, base_query),
        }

        return queries

    def _build_arxiv_query(self, deliverable: Dict[str, Any], base_query: str) -> str:
        """ä¸ºArxivæ„å»ºå­¦æœ¯åŒ–æŸ¥è¯¢"""
        # æ·»åŠ æ–¹æ³•è®ºå…³é”®è¯
        methodology_terms = ["methodology", "framework", "approach", "model"]
        return f"{base_query} {methodology_terms[0]}"

    def _build_ragflow_query(self, deliverable: Dict[str, Any], base_query: str) -> str:
        """ä¸ºRAGFlowï¼ˆå†…éƒ¨çŸ¥è¯†åº“ï¼‰æ„å»ºæŸ¥è¯¢"""
        # ä¿ç•™ä¸­æ–‡å…³é”®è¯ä¸ºä¸»
        name = deliverable.get("name", "")
        description = deliverable.get("description", "")
        chinese_text = name if self._is_chinese_text(name) else description
        if chinese_text:
            return chinese_text[:50]  # ä¿ç•™åŸæ–‡å‰50å­—
        return base_query

    def _build_bocha_query(self, deliverable: Dict[str, Any], base_query: str) -> str:
        """ä¸ºBochaï¼ˆä¸­æ–‡æœç´¢ï¼‰æ„å»ºæŸ¥è¯¢"""
        # åŒRAGFlowï¼Œä¼˜å…ˆä½¿ç”¨ä¸­æ–‡
        return self._build_ragflow_query(deliverable, base_query)


# ============================================================================
# è¾…åŠ©å‡½æ•°ï¼šå¿«é€Ÿä½¿ç”¨
# ============================================================================


def build_deliverable_query(deliverable: Dict[str, Any], project_type: str = "") -> str:
    """
    å¿«é€Ÿæ„å»ºäº¤ä»˜ç‰©æœç´¢æŸ¥è¯¢ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Args:
        deliverable: äº¤ä»˜ç‰©å­—å…¸
        project_type: é¡¹ç›®ç±»å‹

    Returns:
        æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
    """
    builder = DeliverableQueryBuilder()
    return builder.build_query(deliverable, project_type)
