"""
v7.16 å…±äº«å·¥å…·å‡½æ•°

å°†åŸèŠ‚ç‚¹å’Œæ–° Agent çš„é‡å¤é€»è¾‘æå–ä¸ºå…±äº«å‡½æ•°ï¼Œå‡å°‘ä»£ç é‡å¤ã€‚
"""

from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
from loguru import logger
import time
import json


# ============================================================================
# æ€§èƒ½ç›‘æ§è£…é¥°å™¨
# ============================================================================

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨ - è®°å½•æ‰§è¡Œæ—¶é—´å’Œè°ƒç”¨ç»Ÿè®¡"""
    
    _metrics: Dict[str, List[Dict[str, Any]]] = {}
    _enabled: bool = True
    
    @classmethod
    def enable(cls):
        """å¯ç”¨æ€§èƒ½ç›‘æ§"""
        cls._enabled = True
    
    @classmethod
    def disable(cls):
        """ç¦ç”¨æ€§èƒ½ç›‘æ§"""
        cls._enabled = False
    
    @classmethod
    def record(cls, agent_name: str, execution_time: float, version: str = "v7.16"):
        """è®°å½•æ‰§è¡ŒæŒ‡æ ‡"""
        if not cls._enabled:
            return
        
        if agent_name not in cls._metrics:
            cls._metrics[agent_name] = []
        
        cls._metrics[agent_name].append({
            "timestamp": datetime.now().isoformat(),
            "execution_time_ms": execution_time * 1000,
            "version": version
        })
        
        # åªä¿ç•™æœ€è¿‘ 100 æ¡è®°å½•
        if len(cls._metrics[agent_name]) > 100:
            cls._metrics[agent_name] = cls._metrics[agent_name][-100:]
    
    @classmethod
    def get_stats(cls, agent_name: str) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if agent_name not in cls._metrics or not cls._metrics[agent_name]:
            return {"count": 0, "avg_ms": 0, "min_ms": 0, "max_ms": 0}
        
        times = [m["execution_time_ms"] for m in cls._metrics[agent_name]]
        return {
            "count": len(times),
            "avg_ms": sum(times) / len(times),
            "min_ms": min(times),
            "max_ms": max(times),
            "version": cls._metrics[agent_name][-1].get("version", "unknown")
        }
    
    @classmethod
    def get_comparison(cls) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰ Agent çš„æ€§èƒ½å¯¹æ¯”"""
        return {name: cls.get_stats(name) for name in cls._metrics}
    
    @classmethod
    def log_summary(cls):
        """è¾“å‡ºæ€§èƒ½æ±‡æ€»æ—¥å¿—"""
        stats = cls.get_comparison()
        if not stats:
            logger.info("ğŸ“Š æš‚æ— æ€§èƒ½æ•°æ®")
            return
        
        logger.info("ğŸ“Š v7.16 Agent æ€§èƒ½æ±‡æ€»:")
        logger.info("-" * 60)
        for name, data in stats.items():
            logger.info(f"  {name}: {data['avg_ms']:.2f}ms (avg), {data['count']} æ¬¡è°ƒç”¨")
        logger.info("-" * 60)
    
    @classmethod
    def reset(cls):
        """é‡ç½®æ‰€æœ‰æŒ‡æ ‡"""
        cls._metrics.clear()


def with_performance_monitoring(agent_name: str, version: str = "v7.16"):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                execution_time = time.time() - start_time
                PerformanceMonitor.record(agent_name, execution_time, version)
        return wrapper
    return decorator


# ============================================================================
# æŒ‘æˆ˜æ£€æµ‹å…±äº«å‡½æ•°
# ============================================================================

def extract_challenge_flags(
    agent_results: Dict[str, Any],
    batch_results: Dict[str, Any]
) -> List[Dict[str, Any]]:
    """
    ä»ä¸“å®¶è¾“å‡ºä¸­æå–æŒ‘æˆ˜æ ‡è®°
    
    å…±äº«é€»è¾‘ï¼Œè¢«ä»¥ä¸‹ç»„ä»¶ä½¿ç”¨:
    - ChallengeDetectionAgent (v7.16)
    - detect_and_handle_challenges_node (åŸç‰ˆ)
    
    Args:
        agent_results: ä¸“å®¶ç»“æœå­—å…¸
        batch_results: æ‰¹æ¬¡ç»“æœå­—å…¸
    
    Returns:
        æŒ‘æˆ˜æ ‡è®°åˆ—è¡¨
    """
    raw_challenges = []
    
    # ä» agent_results æå–
    for agent_id, result in agent_results.items():
        if not isinstance(result, dict):
            continue
        
        # æ£€æŸ¥ structured_data.challenge_flags
        structured_data = result.get("structured_data", {})
        if isinstance(structured_data, dict):
            challenge_flags = structured_data.get("challenge_flags", [])
            for flag in challenge_flags:
                raw_challenges.append({
                    "agent_id": agent_id,
                    "source": "agent_results",
                    **flag
                })
        
        # æ£€æŸ¥é¡¶å±‚ challenge_flagsï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
        top_level_flags = result.get("challenge_flags", [])
        for flag in top_level_flags:
            raw_challenges.append({
                "agent_id": agent_id,
                "source": "agent_results_top",
                **flag
            })
    
    # ä» batch_results æå–
    for batch_id, batch_data in batch_results.items():
        if not isinstance(batch_data, dict):
            continue
        
        for agent_id, agent_payload in batch_data.items():
            if not isinstance(agent_payload, dict):
                continue
            
            structured_data = agent_payload.get("structured_data", {})
            if isinstance(structured_data, dict):
                challenge_flags = structured_data.get("challenge_flags", [])
                for flag in challenge_flags:
                    raw_challenges.append({
                        "agent_id": agent_id,
                        "source": f"batch_{batch_id}",
                        **flag
                    })
    
    return raw_challenges


def classify_challenges(
    raw_challenges: List[Dict[str, Any]]
) -> Tuple[List[Dict], List[Dict], List[Dict]]:
    """
    å¯¹æŒ‘æˆ˜è¿›è¡Œåˆ†ç±»
    
    Returns:
        (high_severity, medium_severity, low_severity) ä¸‰ä¸ªåˆ—è¡¨
    """
    high = []
    medium = []
    low = []
    
    for challenge in raw_challenges:
        # æ ¹æ®å…³é”®è¯åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
        rationale = challenge.get("rationale", "").lower()
        challenged_item = challenge.get("challenged_item", "").lower()
        
        if any(kw in rationale for kw in ["ä¸¥é‡", "å…³é”®", "å¿…é¡»", "å®‰å…¨"]):
            challenge["severity"] = "high"
            high.append(challenge)
        elif any(kw in rationale for kw in ["å»ºè®®", "å¯èƒ½", "è€ƒè™‘"]):
            challenge["severity"] = "low"
            low.append(challenge)
        else:
            challenge["severity"] = "medium"
            medium.append(challenge)
    
    return high, medium, low


# ============================================================================
# æŠ¥å‘Šæå–å…±äº«å‡½æ•°
# ============================================================================

def extract_expert_reports(
    agent_results: Dict[str, Any],
    selected_roles: List[Dict[str, Any]]
) -> Dict[str, str]:
    """
    æå–ä¸“å®¶æŠ¥å‘Šå†…å®¹
    
    å…±äº«é€»è¾‘ï¼Œè¢«ä»¥ä¸‹ç»„ä»¶ä½¿ç”¨:
    - ResultAggregatorAgentV2 (v7.16)
    - ResultAggregatorAgent (åŸç‰ˆ)
    
    Args:
        agent_results: ä¸“å®¶ç»“æœå­—å…¸
        selected_roles: é€‰å®šçš„è§’è‰²åˆ—è¡¨
    
    Returns:
        ä¸“å®¶åç§° -> æŠ¥å‘Šå†…å®¹çš„æ˜ å°„
    """
    # æ„å»º role_id -> dynamic_role_name æ˜ å°„
    role_display_names = {}
    for role in selected_roles:
        role_id = role.get("role_id", "")
        dynamic_name = role.get("dynamic_role_name", role.get("role_name", ""))
        role_display_names[role_id] = dynamic_name
    
    expert_reports = {}
    
    for agent_id, result in agent_results.items():
        if not isinstance(result, dict):
            continue
        
        # è·³è¿‡éœ€æ±‚åˆ†æå¸ˆå’Œé¡¹ç›®æ€»ç›‘
        if any(skip in agent_id.lower() for skip in ["requirements", "director", "analyst"]):
            continue
        
        # æå–å†…å®¹
        content = result.get("content", "")
        structured_data = result.get("structured_data", {})
        
        if isinstance(structured_data, dict) and structured_data:
            content = json.dumps(structured_data, ensure_ascii=False, indent=2)
        
        if not content:
            continue
        
        # æ„å»ºæ˜¾ç¤ºåç§°
        display_name = _format_display_name(agent_id, role_display_names)
        expert_reports[display_name] = content
    
    return expert_reports


def _format_display_name(
    agent_id: str,
    role_display_names: Dict[str, str]
) -> str:
    """æ ¼å¼åŒ–ä¸“å®¶æ˜¾ç¤ºåç§°"""
    import re
    
    # å°è¯•ä» agent_id æå– role_id
    # æ ¼å¼: "V4_è®¾è®¡ç ”ç©¶å‘˜_4-1" -> role_id = "4-1"
    match = re.search(r"(\d+-\d+)$", agent_id)
    if match:
        role_id = match.group(1)
        if role_id in role_display_names:
            return f"{role_id} {role_display_names[role_id]}"
    
    # å›é€€: ç›´æ¥è¿”å› agent_id
    return agent_id


# ============================================================================
# é—®å·ä¸Šä¸‹æ–‡æå–å…±äº«å‡½æ•°
# ============================================================================

def extract_questionnaire_context(
    user_input: str,
    structured_data: Dict[str, Any]
) -> Dict[str, Any]:
    """
    æå–é—®å·ç”Ÿæˆæ‰€éœ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    
    å…±äº«é€»è¾‘ï¼Œè¢«ä»¥ä¸‹ç»„ä»¶ä½¿ç”¨:
    - QuestionnaireAgent (v7.16)
    - LLMQuestionGenerator (åŸç‰ˆ)
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        structured_data: ç»“æ„åŒ–æ•°æ®
    
    Returns:
        ä¸Šä¸‹æ–‡ä¿¡æ¯å­—å…¸
    """
    # æå–å…³é”®è¯
    keywords = []
    
    # ä» structured_data æå–
    if isinstance(structured_data, dict):
        keywords.extend(structured_data.get("keywords", []))
        
        # ä» project_type æå–
        project_type = structured_data.get("project_type", "")
        if project_type:
            keywords.append(project_type)
    
    # ä» user_input æå–ï¼ˆç®€å•åˆ†è¯ï¼‰
    import re
    words = re.findall(r"[\u4e00-\u9fa5]{2,6}", user_input)
    keywords.extend(words[:5])  # æœ€å¤šå– 5 ä¸ª
    
    # å»é‡
    keywords = list(dict.fromkeys(keywords))
    
    return {
        "user_input": user_input,
        "keywords": keywords[:10],  # æœ€å¤š 10 ä¸ªå…³é”®è¯
        "project_type": structured_data.get("project_type", "") if isinstance(structured_data, dict) else "",
        "summary_length": len(user_input)
    }


# ============================================================================
# è´¨é‡é¢„æ£€å…±äº«å‡½æ•°
# ============================================================================

def analyze_task_risks(
    selected_roles: List[Dict[str, Any]],
    user_requirements: str
) -> List[Dict[str, Any]]:
    """
    åˆ†æä»»åŠ¡é£é™©
    
    å…±äº«é€»è¾‘ï¼Œè¢«ä»¥ä¸‹ç»„ä»¶ä½¿ç”¨:
    - QualityPreflightAgent (v7.16)
    - QualityPreflightNode (åŸç‰ˆ)
    
    Args:
        selected_roles: é€‰å®šçš„è§’è‰²åˆ—è¡¨
        user_requirements: ç”¨æˆ·éœ€æ±‚æè¿°
    
    Returns:
        é£é™©åˆ—è¡¨
    """
    risks = []
    
    # æ£€æŸ¥è§’è‰²æ•°é‡
    if len(selected_roles) < 3:
        risks.append({
            "type": "insufficient_roles",
            "severity": "medium",
            "description": f"è§’è‰²æ•°é‡ä¸è¶³: {len(selected_roles)}/3"
        })
    
    # æ£€æŸ¥ä»»åŠ¡è¦†ç›–
    for role in selected_roles:
        task_instruction = role.get("task_instruction", {})
        if isinstance(task_instruction, dict):
            deliverables = task_instruction.get("deliverables", [])
            if not deliverables:
                risks.append({
                    "type": "missing_deliverables",
                    "severity": "high",
                    "role_id": role.get("role_id"),
                    "description": f"{role.get('dynamic_role_name', 'æœªçŸ¥è§’è‰²')} ç¼ºå°‘äº¤ä»˜ç‰©å®šä¹‰"
                })
    
    # æ£€æŸ¥ç”¨æˆ·éœ€æ±‚å¤æ‚åº¦
    if len(user_requirements) > 500:
        risks.append({
            "type": "complex_requirements",
            "severity": "low",
            "description": "ç”¨æˆ·éœ€æ±‚è¾ƒé•¿ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè½®æ¬¡çš„æ¾„æ¸…"
        })
    
    return risks


def generate_quality_checklists(
    selected_roles: List[Dict[str, Any]]
) -> Dict[str, List[str]]:
    """
    ä¸ºæ¯ä¸ªä¸“å®¶ç”Ÿæˆè´¨é‡æ£€æŸ¥æ¸…å•
    
    Args:
        selected_roles: é€‰å®šçš„è§’è‰²åˆ—è¡¨
    
    Returns:
        è§’è‰²ID -> æ£€æŸ¥é¡¹åˆ—è¡¨çš„æ˜ å°„
    """
    checklists = {}
    
    for role in selected_roles:
        role_id = role.get("role_id", "unknown")
        role_name = role.get("dynamic_role_name", role.get("role_name", ""))
        
        # åŸºç¡€æ£€æŸ¥é¡¹
        checks = [
            f"âœ“ {role_name} æ˜¯å¦ç†è§£ä»»åŠ¡ç›®æ ‡",
            f"âœ“ {role_name} æ˜¯å¦æœ‰æ˜ç¡®çš„äº¤ä»˜ç‰©",
            f"âœ“ {role_name} æ˜¯å¦è€ƒè™‘äº†ç”¨æˆ·çº¦æŸ"
        ]
        
        # æ ¹æ®è§’è‰²ç±»å‹æ·»åŠ ç‰¹å®šæ£€æŸ¥
        if "ç ”ç©¶" in role_name or "4-" in role_id:
            checks.append(f"âœ“ {role_name} æ˜¯å¦æä¾›äº†æ•°æ®æ”¯æ’‘")
        if "è®¾è®¡" in role_name or "2-" in role_id:
            checks.append(f"âœ“ {role_name} æ˜¯å¦è€ƒè™‘äº†ç¾è§‚ä¸åŠŸèƒ½å¹³è¡¡")
        if "å™äº‹" in role_name or "3-" in role_id:
            checks.append(f"âœ“ {role_name} æ˜¯å¦åˆ›å»ºäº†æƒ…æ„Ÿè¿æ¥")
        
        checklists[role_id] = checks
    
    return checklists


# ============================================================================
# ğŸ†• v7.18: é—®å·ç”Ÿæˆå…±äº«å‡½æ•°
# ============================================================================

def build_questionnaire_analysis_summary(structured_data: Dict[str, Any]) -> str:
    """
    ğŸ†• v7.18: ä»éœ€æ±‚åˆ†æç»“æœä¸­æå–å…³é”®ä¿¡æ¯ï¼Œæ„å»º LLM æç¤ºè¯ä¸Šä¸‹æ–‡
    
    ç»Ÿä¸€ llm_generator.py å’Œ questionnaire_agent.py çš„ _build_analysis_summary é€»è¾‘
    
    Args:
        structured_data: éœ€æ±‚åˆ†æå¸ˆçš„ç»“æ„åŒ–è¾“å‡º
        
    Returns:
        æ„å»ºçš„åˆ†ææ‘˜è¦æ–‡æœ¬
    """
    summary_parts = []
    
    # é¡¹ç›®æ¦‚è§ˆï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    project_overview = structured_data.get("project_overview", "")
    if project_overview:
        summary_parts.append(f"## é¡¹ç›®æ¦‚è§ˆ\n{project_overview}")
    
    # é¡¹ç›®ä»»åŠ¡ï¼ˆå…¼å®¹æ—§å­—æ®µåï¼‰
    project_task = structured_data.get("project_task", "") or structured_data.get("project_tasks", "")
    if isinstance(project_task, list):
        project_task = "ï¼›".join(project_task[:5])
    if project_task and project_task != project_overview:
        summary_parts.append(f"## é¡¹ç›®ä»»åŠ¡\n{project_task}")
    
    # æ ¸å¿ƒç›®æ ‡
    core_objectives = structured_data.get("core_objectives", [])
    if core_objectives:
        if isinstance(core_objectives, list):
            objectives_text = "\n".join([f"- {obj}" for obj in core_objectives[:5]])
        else:
            objectives_text = str(core_objectives)
        summary_parts.append(f"## æ ¸å¿ƒç›®æ ‡\n{objectives_text}")
    
    # é¡¹ç›®ç±»å‹
    project_type = structured_data.get("project_type", "")
    if project_type:
        type_label = {
            "personal_residential": "ä¸ªäººä½å®…",
            "hybrid_residential_commercial": "æ··åˆå‹ï¼ˆä½å®…+å•†ä¸šï¼‰",
            "commercial_enterprise": "å•†ä¸š/ä¼ä¸šé¡¹ç›®",
            "cultural_educational": "æ–‡åŒ–/æ•™è‚²é¡¹ç›®",
            "healthcare_wellness": "åŒ»ç–—/åº·å…»é¡¹ç›®",
            "office_coworking": "åŠå…¬/è”åˆåŠå…¬",
            "hospitality_tourism": "é…’åº—/æ–‡æ—…é¡¹ç›®",
            "sports_entertainment_arts": "ä½“è‚²/å¨±ä¹/è‰ºæœ¯"
        }.get(project_type, project_type)
        summary_parts.append(f"## é¡¹ç›®ç±»å‹\n{type_label}")
    
    # è®¾è®¡æŒ‘æˆ˜
    design_challenge = structured_data.get("design_challenge", "")
    if design_challenge:
        summary_parts.append(f"## æ ¸å¿ƒè®¾è®¡æŒ‘æˆ˜\n{design_challenge}")
    
    # æ ¸å¿ƒå¼ åŠ›
    core_tension = structured_data.get("core_tension", "")
    if core_tension:
        summary_parts.append(f"## æ ¸å¿ƒçŸ›ç›¾/å¼ åŠ›\n{core_tension}")
    
    # äººç‰©å™äº‹ï¼ˆä¼˜å…ˆ narrative_charactersï¼Œå…¼å®¹ character_narrativeï¼‰
    narrative_characters = structured_data.get("narrative_characters", "") or structured_data.get("character_narrative", "")
    if isinstance(narrative_characters, list):
        narrative_characters = "\n".join([f"- {char}" for char in narrative_characters[:3]])
    if narrative_characters:
        summary_parts.append(f"## äººç‰©å™äº‹/ç”¨æˆ·ç”»åƒ\n{narrative_characters}")
    
    # ç‰©ç†ç¯å¢ƒ
    physical_contexts = structured_data.get("physical_contexts", "")
    if isinstance(physical_contexts, list):
        physical_contexts = "ï¼›".join(physical_contexts[:3])
    if physical_contexts:
        summary_parts.append(f"## ç‰©ç†ç¯å¢ƒ\n{physical_contexts}")
    
    # èµ„æºçº¦æŸ
    resource_constraints = structured_data.get("resource_constraints", "")
    if resource_constraints:
        summary_parts.append(f"## èµ„æºçº¦æŸ\n{resource_constraints}")
    
    # çº¦æŸä¸æœºé‡
    constraints_opportunities = structured_data.get("constraints_opportunities", "")
    if isinstance(constraints_opportunities, dict):
        co_parts = []
        if constraints_opportunities.get("constraints"):
            co_parts.append(f"çº¦æŸ: {constraints_opportunities['constraints']}")
        if constraints_opportunities.get("opportunities"):
            co_parts.append(f"æœºé‡: {constraints_opportunities['opportunities']}")
        constraints_opportunities = "ï¼›".join(co_parts)
    if constraints_opportunities and constraints_opportunities != resource_constraints:
        summary_parts.append(f"## çº¦æŸä¸æœºé‡\n{constraints_opportunities}")
    
    if not summary_parts:
        logger.warning("âš ï¸ [build_questionnaire_analysis_summary] structured_data å­—æ®µå…¨éƒ¨ä¸ºç©º")
        return "ï¼ˆéœ€æ±‚åˆ†ææ•°æ®ä¸è¶³ï¼Œè¯·åŸºäºç”¨æˆ·åŸå§‹è¾“å…¥ç”Ÿæˆé—®å·ï¼‰"
    
    return "\n\n".join(summary_parts)


def extract_user_keywords(user_input: str, max_keywords: int = 15) -> List[str]:
    """
    ğŸ†• v7.18: ä»ç”¨æˆ·è¾“å…¥ä¸­æå–å…³é”®è¯
    
    ç»Ÿä¸€å„å¤„å…³é”®è¯æå–é€»è¾‘
    
    Args:
        user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
        max_keywords: æœ€å¤§è¿”å›å…³é”®è¯æ•°é‡
        
    Returns:
        å…³é”®è¯åˆ—è¡¨
    """
    import re
    
    if not user_input:
        return []
    
    keywords = []
    
    # 1. æå–æ•°å­—+å•ä½
    num_patterns = re.findall(r'\d+[\u4e00-\u9fa5ã¡a-zA-Z]+', user_input)
    keywords.extend(num_patterns)
    
    # 2. æå–å¼•å·å†…å®¹
    quoted = re.findall(r'[""ã€Œã€ã€ã€ã€ã€‘]([^""ã€Œã€ã€ã€ã€ã€‘]+)[""ã€Œã€ã€ã€ã€ã€‘]', user_input)
    keywords.extend(quoted)
    
    # 3. æå–å…³é”®åè¯
    stopwords = {
        "çš„", "æ˜¯", "åœ¨", "æœ‰", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬",
        "è¿™", "é‚£", "å’Œ", "ä¸", "æˆ–", "ä½†", "è€Œ", "äº†", "ç€", "è¿‡",
        "éœ€è¦", "å¸Œæœ›", "æƒ³è¦", "ä¸€ä¸ª", "ä¸€äº›", "è¿™ä¸ª", "é‚£ä¸ª",
        "å¦‚ä½•", "æ€ä¹ˆ", "ä»€ä¹ˆ", "å“ªäº›", "ä¸ºä»€ä¹ˆ", "è¯·", "å¸®",
        "è¿›è¡Œ", "å®ç°", "å®Œæˆ", "è€ƒè™‘", "åŒ…æ‹¬", "é€šè¿‡", "ä½¿ç”¨",
        "è®¾è®¡", "é¡¹ç›®", "æ–¹æ¡ˆ", "å»ºè®®", "èƒ½å¤Ÿ", "å¯ä»¥"
    }
    
    chinese_words = re.findall(r'[\u4e00-\u9fa5]{2,8}', user_input)
    for word in chinese_words:
        if word not in stopwords and word not in keywords:
            keywords.append(word)
    
    # å»é‡å¹¶é™åˆ¶æ•°é‡
    unique_keywords = list(dict.fromkeys(keywords))
    return unique_keywords[:max_keywords]


def check_questionnaire_relevance(
    questions: List[Dict[str, Any]],
    user_input: str,
    threshold: float = 0.3
) -> Tuple[float, List[str]]:
    """
    ğŸ†• v7.18: æ£€æŸ¥é—®é¢˜ä¸ç”¨æˆ·è¾“å…¥çš„ç›¸å…³æ€§
    
    ç»Ÿä¸€ç›¸å…³æ€§éªŒè¯é€»è¾‘
    
    Args:
        questions: é—®é¢˜åˆ—è¡¨
        user_input: ç”¨æˆ·åŸå§‹è¾“å…¥
        threshold: é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„é—®é¢˜å°†è¢«æ ‡è®°
        
    Returns:
        Tuple[å¹³å‡ç›¸å…³æ€§åˆ†æ•°, ä½ç›¸å…³æ€§é—®é¢˜IDåˆ—è¡¨]
    """
    import re
    
    if not questions or not user_input:
        return 1.0, []
    
    # æå–ç”¨æˆ·è¾“å…¥å…³é”®è¯
    stopwords = {
        "çš„", "æ˜¯", "åœ¨", "æœ‰", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬",
        "è¿™", "é‚£", "å’Œ", "ä¸", "æˆ–", "ä½†", "è€Œ", "äº†", "ç€", "è¿‡"
    }
    
    user_words = set()
    chinese_words = re.findall(r'[\u4e00-\u9fa5]{2,10}', user_input)
    for word in chinese_words:
        if word not in stopwords:
            user_words.add(word)
    
    numbers = re.findall(r'\d+[\u4e00-\u9fa5ã¡]+', user_input)
    user_words.update(numbers)
    
    if not user_words:
        return 1.0, []
    
    scores = []
    low_relevance = []
    
    for q in questions:
        question_text = q.get("question", "") + " ".join(q.get("options", []))
        hits = sum(1 for word in user_words if word in question_text)
        score = min(1.0, hits / max(3, len(user_words) * 0.3))
        scores.append(score)
        
        if score < threshold:
            low_relevance.append(q.get("id", "unknown"))
    
    avg_score = sum(scores) / len(scores) if scores else 0
    return avg_score, low_relevance
