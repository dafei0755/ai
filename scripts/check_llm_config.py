"""
æ£€æŸ¥å½“å‰ LLM é…ç½®

è¿è¡Œ: python check_llm_config.py
"""

import os
from dotenv import load_dotenv
from pathlib import Path

# åŠ è½½ .env
env_path = Path(__file__).parent / '.env'
load_dotenv(env_path)

print("=" * 60)
print("ğŸ” å½“å‰ LLM é…ç½®")
print("=" * 60)

# ä¸»è¦é…ç½®
provider = os.getenv("LLM_PROVIDER", "openai")
print(f"\nğŸ“Œ å½“å‰æä¾›å•†: {provider.upper()}")

# æ ¹æ®æä¾›å•†æ˜¾ç¤ºæ¨¡å‹
if provider == "openai":
    model = os.getenv("OPENAI_MODEL", "gpt-4.1")
    api_key = os.getenv("OPENAI_API_KEY", "")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
    print(f"ğŸ“¦ æ¨¡å‹: {model}")
    print(f"ğŸ”‘ API Key: {api_key[:20]}...{api_key[-10:] if len(api_key) > 30 else ''}")
    print(f"ğŸŒ Base URL: {base_url}")

elif provider == "deepseek":
    model = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
    api_key = os.getenv("DEEPSEEK_API_KEY", "")
    base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
    print(f"ğŸ“¦ æ¨¡å‹: {model}")
    print(f"ğŸ”‘ API Key: {api_key[:20]}...{api_key[-10:] if len(api_key) > 30 else ''}")
    print(f"ğŸŒ Base URL: {base_url}")

elif provider == "qwen":
    model = os.getenv("QWEN_MODEL", "qwen-max")
    api_key = os.getenv("QWEN_API_KEY", "")
    base_url = os.getenv("QWEN_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
    print(f"ğŸ“¦ æ¨¡å‹: {model}")
    print(f"ğŸ”‘ API Key: {api_key[:20]}...{api_key[-10:] if len(api_key) > 30 else ''}")
    print(f"ğŸŒ Base URL: {base_url}")

elif provider == "anthropic":
    model = os.getenv("ANTHROPIC_MODEL", "claude-3-5-sonnet-20241022")
    api_key = os.getenv("ANTHROPIC_API_KEY", "")
    print(f"ğŸ“¦ æ¨¡å‹: {model}")
    print(f"ğŸ”‘ API Key: {api_key[:20]}...{api_key[-10:] if len(api_key) > 30 else ''}")

elif provider == "azure":
    deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4.1")
    api_key = os.getenv("AZURE_OPENAI_API_KEY", "")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "")
    version = os.getenv("AZURE_API_VERSION", "2024-02-15-preview")
    print(f"ğŸ“¦ éƒ¨ç½²åç§°: {deployment}")
    print(f"ğŸ”‘ API Key: {api_key[:20]}...{api_key[-10:] if len(api_key) > 30 else ''}")
    print(f"ğŸŒ Endpoint: {endpoint}")
    print(f"ğŸ“‹ API Version: {version}")

# é€šç”¨å‚æ•°
print(f"\nâš™ï¸ é€šç”¨å‚æ•°:")
print(f"   Max Tokens: {os.getenv('MAX_TOKENS', '32000')}")
print(f"   Temperature: {os.getenv('TEMPERATURE', '0.7')}")
print(f"   Timeout: {os.getenv('LLM_TIMEOUT', '600')}s")
print(f"   Max Retries: {os.getenv('MAX_RETRIES', '3')}")

# è‡ªåŠ¨é™çº§
auto_fallback = os.getenv("LLM_AUTO_FALLBACK", "true").lower() == "true"
print(f"\nğŸ”„ è‡ªåŠ¨é™çº§: {'âœ… å¯ç”¨' if auto_fallback else 'âŒ ç¦ç”¨'}")
if auto_fallback:
    print(f"   ç­–ç•¥: {provider.upper()} â†’ Qwen â†’ DeepSeek")

print("\n" + "=" * 60)
