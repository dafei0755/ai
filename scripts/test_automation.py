#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è‡ªåŠ¨åŒ–è„šæœ¬
æä¾›å¤šç§æµ‹è¯•æ¨¡å¼ã€å‰ç½®æ¡ä»¶æ£€æŸ¥ã€è¦†ç›–ç‡æŠ¥å‘Šç”Ÿæˆç­‰åŠŸèƒ½
"""
import argparse
import io
import json
import os
import subprocess
import sys
from datetime import datetime
from pathlib import Path

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")


class TestAutomation:
    """æµ‹è¯•è‡ªåŠ¨åŒ–ä¸»ç±»"""

    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.tests_dir = self.project_root / "tests"
        self.coverage_dir = self.project_root / "htmlcov"
        self.reports_dir = self.project_root / "test_reports"

    def check_preconditions(self):
        """æ£€æŸ¥æµ‹è¯•å‰ç½®æ¡ä»¶"""
        print("ğŸ” æ£€æŸ¥æµ‹è¯•ç¯å¢ƒå‰ç½®æ¡ä»¶...\n")

        all_passed = True

        # 1. æ£€æŸ¥Pythonç‰ˆæœ¬
        python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
        if sys.version_info >= (3, 8):
            print(f"âœ… Python >= 3.8: {python_version}")
        else:
            print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {python_version} (éœ€è¦ >= 3.8)")
            all_passed = False

        # 2. æ£€æŸ¥å¿…éœ€çš„åŒ…
        required_packages = [
            "pytest",
            "pytest-cov",
            "pytest-asyncio",
            "pytest-mock",
        ]

        for package in required_packages:
            try:
                __import__(package.replace("-", "_"))
                print(f"âœ… Package: {package}: å·²å®‰è£…")
            except ImportError:
                print(f"âŒ Package: {package}: æœªå®‰è£…")
                all_passed = False

        # 3. æ£€æŸ¥ç¯å¢ƒå˜é‡
        env_vars = [
            "ANTHROPIC_API_KEY",
            "OPENAI_API_KEY",
        ]

        print("\nğŸ“Œ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
        for var in env_vars:
            if os.getenv(var):
                print(f"âœ… {var}: å·²è®¾ç½®")
            else:
                print(f"âš ï¸  {var}: æœªè®¾ç½® (æŸäº›æµ‹è¯•å¯èƒ½éœ€è¦)")

        # 4. æ£€æŸ¥æµ‹è¯•ç›®å½•
        print("\nğŸ“ ç›®å½•æ£€æŸ¥:")
        if self.tests_dir.exists():
            print(f"âœ… æµ‹è¯•ç›®å½•å­˜åœ¨: {self.tests_dir}")
            test_files = list(self.tests_dir.rglob("test_*.py"))
            print(f"   å‘ç° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
        else:
            print(f"âŒ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {self.tests_dir}")
            all_passed = False

        print("\n" + "=" * 60)
        if all_passed:
            print("âœ… All preconditions passed!")
        else:
            print("âŒ Some preconditions failed. Please fix them before running tests.")
        print("=" * 60 + "\n")

        return all_passed

    def run_tests(self, mode="all", verbose=True):
        """
        è¿è¡Œæµ‹è¯•

        Args:
            mode: æµ‹è¯•æ¨¡å¼ (all, unit, integration, fast, coverage, agents, workflow, interaction, security)
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
        """
        print(f"ğŸš€ è¿è¡Œæµ‹è¯•æ¨¡å¼: {mode}\n")

        # å®šä¹‰ä¸åŒæµ‹è¯•æ¨¡å¼çš„å‘½ä»¤
        commands = {
            "all": ["python", "-m", "pytest", "tests/", "-v"],
            "unit": ["python", "-m", "pytest", "tests/", "-m", "unit", "-v"],
            "integration": ["python", "-m", "pytest", "tests/", "-m", "integration", "-v"],
            "fast": ["python", "-m", "pytest", "tests/", "-m", "not slow", "-v"],
            "coverage": [
                "python",
                "-m",
                "pytest",
                "tests/",
                "--cov=intelligent_project_analyzer",
                "--cov-report=html",
                "--cov-report=term",
                "--cov-report=json",
                "-v",
            ],
            "agents": ["python", "-m", "pytest", "tests/agents/", "-v"],
            "workflow": ["python", "-m", "pytest", "tests/workflow/", "-v"],
            "interaction": ["python", "-m", "pytest", "tests/interaction/", "-v"],
            "security": ["python", "-m", "pytest", "tests/security/", "-v"],
        }

        if mode not in commands:
            print(f"âŒ æœªçŸ¥çš„æµ‹è¯•æ¨¡å¼: {mode}")
            print(f"å¯ç”¨æ¨¡å¼: {', '.join(commands.keys())}")
            return False

        cmd = commands[mode]

        try:
            result = subprocess.run(cmd, cwd=self.project_root, capture_output=not verbose, text=True)

            if result.returncode == 0:
                print(f"\nâœ… æµ‹è¯•é€šè¿‡ (æ¨¡å¼: {mode})")
                return True
            else:
                print(f"\nâŒ æµ‹è¯•å¤±è´¥ (æ¨¡å¼: {mode})")
                if not verbose and result.stdout:
                    print(result.stdout)
                return False

        except Exception as e:
            print(f"âŒ æ‰§è¡Œæµ‹è¯•æ—¶å‡ºé”™: {e}")
            return False

    def generate_coverage_report(self):
        """ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š"""
        print("ğŸ“Š ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š...\n")

        # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
        self.reports_dir.mkdir(exist_ok=True)

        # æ£€æŸ¥æ˜¯å¦æœ‰coverageæ•°æ®
        coverage_json = self.project_root / "coverage.json"
        if not coverage_json.exists():
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°coverageæ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ: python scripts/test_automation.py --mode coverage")
            return False

        try:
            # è¯»å–coverageæ•°æ®
            with open(coverage_json, "r", encoding="utf-8") as f:
                coverage_data = json.load(f)

            # ç”ŸæˆMarkdownæŠ¥å‘Š
            report_file = self.reports_dir / f"coverage_report_{datetime.now().strftime('%Y%m%d')}.md"

            with open(report_file, "w", encoding="utf-8") as f:
                f.write("# æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

                # æ€»ä½“è¦†ç›–ç‡
                totals = coverage_data.get("totals", {})
                percent_covered = totals.get("percent_covered", 0)
                f.write(f"## æ€»ä½“è¦†ç›–ç‡: {percent_covered:.2f}%\n\n")

                f.write(f"- **æ€»è¡Œæ•°**: {totals.get('num_statements', 0)}\n")
                f.write(f"- **å·²è¦†ç›–**: {totals.get('covered_lines', 0)}\n")
                f.write(f"- **æœªè¦†ç›–**: {totals.get('missing_lines', 0)}\n")
                f.write(f"- **åˆ†æ”¯è¦†ç›–**: {totals.get('percent_covered_display', 'N/A')}\n\n")

                # æ–‡ä»¶è¯¦æƒ…
                f.write("## æ–‡ä»¶è¦†ç›–ç‡è¯¦æƒ…\n\n")
                f.write("| æ–‡ä»¶ | è¦†ç›–ç‡ | è¯­å¥æ•° | å·²è¦†ç›– | æœªè¦†ç›– |\n")
                f.write("|------|--------|--------|--------|--------|\n")

                files = coverage_data.get("files", {})
                for file_path, file_data in sorted(files.items()):
                    summary = file_data.get("summary", {})
                    f.write(
                        f"| {file_path} | {summary.get('percent_covered', 0):.1f}% | "
                        f"{summary.get('num_statements', 0)} | "
                        f"{summary.get('covered_lines', 0)} | "
                        f"{summary.get('missing_lines', 0)} |\n"
                    )

                f.write("\n---\n")
                f.write(f"\n**HTMLæŠ¥å‘Š**: `htmlcov/index.html`\n")
                f.write(f"**JSONæŠ¥å‘Š**: `coverage.json`\n")

            print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            print(f"âœ… HTMLæŠ¥å‘Š: {self.coverage_dir / 'index.html'}")
            return True

        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            return False

    def clean_test_artifacts(self):
        """æ¸…ç†æµ‹è¯•ç”Ÿæˆçš„æ–‡ä»¶"""
        print("ğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...\n")

        import shutil

        artifacts = [
            self.coverage_dir,
            self.project_root / ".coverage",
            self.project_root / "coverage.json",
            self.project_root / ".pytest_cache",
        ]

        for artifact in artifacts:
            if artifact.exists():
                if artifact.is_dir():
                    shutil.rmtree(artifact)
                    print(f"âœ… å·²åˆ é™¤ç›®å½•: {artifact.name}")
                else:
                    artifact.unlink()
                    print(f"âœ… å·²åˆ é™¤æ–‡ä»¶: {artifact.name}")

        # æ¸…ç†__pycache__
        for pycache in self.project_root.rglob("__pycache__"):
            shutil.rmtree(pycache)
        print("âœ… å·²æ¸…ç†æ‰€æœ‰ __pycache__ ç›®å½•")

        print("\nâœ… æ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æµ‹è¯•è‡ªåŠ¨åŒ–è„šæœ¬")
    parser.add_argument("--check", action="store_true", help="æ£€æŸ¥æµ‹è¯•å‰ç½®æ¡ä»¶")
    parser.add_argument(
        "--mode",
        type=str,
        default="all",
        choices=["all", "unit", "integration", "fast", "coverage", "agents", "workflow", "interaction", "security"],
        help="æµ‹è¯•æ¨¡å¼",
    )
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š")
    parser.add_argument("--clean", action="store_true", help="æ¸…ç†æµ‹è¯•æ–‡ä»¶")
    parser.add_argument("--quiet", action="store_true", help="é™é»˜æ¨¡å¼")

    args = parser.parse_args()

    automation = TestAutomation()

    # æ‰§è¡Œæ“ä½œ
    if args.check:
        automation.check_preconditions()

    elif args.report:
        automation.generate_coverage_report()

    elif args.clean:
        automation.clean_test_artifacts()

    else:
        # é»˜è®¤è¿è¡Œæµ‹è¯•
        if not args.quiet:
            automation.check_preconditions()
        automation.run_tests(mode=args.mode, verbose=not args.quiet)


if __name__ == "__main__":
    main()
