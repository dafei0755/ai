"""
æµ‹è¯• LLM é™çº§æœºåˆ¶

æµ‹è¯•åœºæ™¯:
1. ä¸»æä¾›å•†æ­£å¸¸ â†’ ä½¿ç”¨ä¸»æä¾›å•†
2. ä¸»æä¾›å•†å¤±è´¥ â†’ è‡ªåŠ¨é™çº§åˆ°å¤‡é€‰
3. æ‰€æœ‰æä¾›å•†å¤±è´¥ â†’ æŠ¥é”™

è¿è¡Œ: python test_llm_fallback.py
"""

import os
import sys
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}")

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from intelligent_project_analyzer.services.llm_factory import LLMFactory
from intelligent_project_analyzer.services.multi_llm_factory import MultiLLMFactory


def test_current_provider():
    """æµ‹è¯•å½“å‰é…ç½®çš„æä¾›å•†"""
    logger.info("=" * 60)
    logger.info("ğŸ“‹ æµ‹è¯• 1: å½“å‰æä¾›å•†é…ç½®")
    logger.info("=" * 60)
    
    try:
        # è¯»å–ç¯å¢ƒå˜é‡
        provider = os.getenv("LLM_PROVIDER", "openai")
        auto_fallback = os.getenv("LLM_AUTO_FALLBACK", "false").lower() == "true"
        
        logger.info(f"ğŸ”§ LLM_PROVIDER = {provider}")
        logger.info(f"ğŸ”„ LLM_AUTO_FALLBACK = {auto_fallback}")
        
        # åˆ›å»º LLM å®ä¾‹
        logger.info("\nğŸ“¦ åˆ›å»º LLM å®ä¾‹...")
        llm = LLMFactory.create_llm()
        
        # æµ‹è¯•è°ƒç”¨
        logger.info("\nğŸ§ª æµ‹è¯• LLM è°ƒç”¨...")
        response = llm.invoke("Say 'Hello' in one word")
        logger.success(f"âœ… è°ƒç”¨æˆåŠŸ! å“åº”: {response.content}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_fallback_chain():
    """æµ‹è¯•é™çº§é“¾"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“‹ æµ‹è¯• 2: é™çº§é“¾é…ç½®ï¼ˆè¿è¡Œæ—¶é™çº§ï¼‰")
    logger.info("=" * 60)
    
    try:
        from intelligent_project_analyzer.services.multi_llm_factory import FallbackLLM
        
        # æ£€æŸ¥å„ä¸ªæä¾›å•†çš„ API Key
        providers = ["openai", "openrouter", "deepseek", "qwen"]
        available = []
        
        for provider in providers:
            key_env = {
                "openai": "OPENAI_API_KEY",
                "openrouter": "OPENROUTER_API_KEY",
                "deepseek": "DEEPSEEK_API_KEY",
                "qwen": "QWEN_API_KEY"
            }[provider]
            
            key = os.getenv(key_env, "")
            is_valid = key and key != "your_xxx_api_key_here" and not key.startswith("your_")
            
            status = "âœ… å¯ç”¨" if is_valid else "âŒ ä¸å¯ç”¨"
            logger.info(f"{provider.ljust(12)}: {status} ({key_env})")
            
            if is_valid:
                available.append(provider)
        
        logger.info(f"\nğŸ”„ å¯ç”¨çš„æä¾›å•†: {' â†’ '.join(available)}")
        
        if len(available) < 2:
            logger.warning("âš ï¸ åªæœ‰ 1 ä¸ªå¯ç”¨æä¾›å•†ï¼Œæ— æ³•æµ‹è¯•é™çº§")
            return True
        
        # æµ‹è¯•è¿è¡Œæ—¶é™çº§åˆ›å»ºï¼ˆä½¿ç”¨ FallbackLLMï¼‰
        logger.info("\nğŸ“¦ æµ‹è¯•è¿è¡Œæ—¶é™çº§é“¾åˆ›å»º...")
        llm = FallbackLLM(
            providers=available,
            temperature=0.7,
            max_tokens=100
        )
        
        logger.info(f"âœ… é™çº§é“¾åˆ›å»ºæˆåŠŸ: {type(llm).__name__}")
        
        # æµ‹è¯•è°ƒç”¨ï¼ˆä¼šè‡ªåŠ¨é™çº§ï¼‰
        logger.info("\nğŸ§ª æµ‹è¯•è¿è¡Œæ—¶é™çº§è°ƒç”¨...")
        logger.info("ğŸ’¡ é¢„æœŸ: OpenAI é…é¢ç”¨å°½ â†’ è‡ªåŠ¨åˆ‡æ¢åˆ° OpenRouter â†’ DeepSeek")
        response = llm.invoke("Say 'Test' in one word")
        logger.success(f"âœ… è°ƒç”¨æˆåŠŸ! å“åº”: {response.content}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_manual_fallback():
    """æ‰‹åŠ¨æµ‹è¯•é™çº§ï¼ˆæ¨¡æ‹Ÿä¸»æä¾›å•†å¤±è´¥ï¼‰"""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“‹ æµ‹è¯• 3: æ‰‹åŠ¨é™çº§æµ‹è¯•")
    logger.info("=" * 60)
    
    try:
        # å°è¯•åˆ›å»ºä¸€ä¸ªä¸å­˜åœ¨çš„æä¾›å•†ï¼Œè§¦å‘é™çº§
        logger.info("ğŸ”§ æµ‹è¯•åœºæ™¯: ä¸»æä¾›å•† 'invalid_provider' â†’ é™çº§åˆ° deepseek")
        
        # ä¸´æ—¶ä¿®æ”¹ç¯å¢ƒå˜é‡
        original_provider = os.getenv("LLM_PROVIDER")
        os.environ["LLM_PROVIDER"] = "invalid_provider"
        
        try:
            # è¿™åº”è¯¥ä¼šå¤±è´¥å¹¶è§¦å‘é™çº§
            llm = LLMFactory.create_llm()
            logger.error("âŒ é¢„æœŸå¤±è´¥ä½†æˆåŠŸäº†ï¼Œé™çº§æœºåˆ¶å¯èƒ½æœ‰é—®é¢˜")
            return False
        except ValueError as e:
            logger.info(f"âœ… æ­£ç¡®è§¦å‘é”™è¯¯: {e}")
        finally:
            # æ¢å¤ç¯å¢ƒå˜é‡
            if original_provider:
                os.environ["LLM_PROVIDER"] = original_provider
        
        # ç°åœ¨æµ‹è¯•æ­£å¸¸çš„é™çº§
        logger.info("\nğŸ”§ æµ‹è¯•æ­£å¸¸é™çº§: openai â†’ openrouter â†’ deepseek")
        llm = MultiLLMFactory.create_with_fallback(
            providers=["openai", "openrouter", "deepseek"],
            temperature=0.7,
            max_tokens=100
        )
        
        logger.info("âœ… é™çº§é“¾åˆ›å»ºæˆåŠŸ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹ LLM é™çº§æœºåˆ¶æµ‹è¯•\n")
    
    results = []
    
    # æµ‹è¯• 1: å½“å‰æä¾›å•†
    results.append(("å½“å‰æä¾›å•†", test_current_provider()))
    
    # æµ‹è¯• 2: é™çº§é“¾
    results.append(("é™çº§é“¾é…ç½®", test_fallback_chain()))
    
    # æµ‹è¯• 3: æ‰‹åŠ¨é™çº§
    results.append(("æ‰‹åŠ¨é™çº§", test_manual_fallback()))
    
    # è¾“å‡ºæ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{name.ljust(20)}: {status}")
    
    total = len(results)
    passed = sum(1 for _, r in results if r)
    
    logger.info(f"\næ€»è®¡: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        logger.success("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        logger.error("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
