"""
æµ‹è¯• OpenRouter è¿æ¥å’Œé…ç½®
éªŒè¯ï¼š
1. OpenRouter API Key æœ‰æ•ˆæ€§
2. æ¨¡å‹åç§°æ ¼å¼æ˜¯å¦æ­£ç¡®
3. ä¸å®˜æ–¹ OpenAI API çš„å“åº”å¯¹æ¯”
"""
import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_openrouter_config():
    """æ£€æŸ¥ OpenRouter é…ç½®"""
    print("="*60)
    print("OpenRouter é…ç½®æ£€æŸ¥")
    print("="*60)
    
    # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
    api_key = os.getenv("OPENROUTER_API_KEY")
    model = os.getenv("OPENROUTER_MODEL")
    base_url = os.getenv("OPENROUTER_BASE_URL")
    app_name = os.getenv("OPENROUTER_APP_NAME")
    site_url = os.getenv("OPENROUTER_SITE_URL")
    
    print(f"\nğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  API Key: {api_key[:20]}...{api_key[-10:] if api_key and len(api_key) > 30 else 'NOT SET'}")
    print(f"  Model: {model}")
    print(f"  Base URL: {base_url}")
    print(f"  App Name: {app_name}")
    print(f"  Site URL: {site_url}")
    
    # æ£€æŸ¥ API Key
    if not api_key or api_key == "your_openrouter_api_key_here":
        print(f"\nâŒ OpenRouter API Key æœªé…ç½®!")
        print(f"   è¯·è®¿é—® https://openrouter.ai/keys è·å– API Key")
        print(f"   ç„¶åä¿®æ”¹ .env æ–‡ä»¶: OPENROUTER_API_KEY=sk-or-v1-...")
        return False
    
    # æ£€æŸ¥æ¨¡å‹åç§°æ ¼å¼
    if model and not "/" in model:
        print(f"\nâš ï¸ è­¦å‘Š: æ¨¡å‹åç§°æ ¼å¼å¯èƒ½ä¸æ­£ç¡®")
        print(f"   å½“å‰: {model}")
        print(f"   æ¨è: openai/gpt-4o (éœ€è¦åŠ æä¾›å•†å‰ç¼€)")
    
    print(f"\nâœ… é…ç½®æ£€æŸ¥å®Œæˆ!")
    return True

def test_openrouter_connection():
    """æµ‹è¯• OpenRouter è¿æ¥"""
    print("\n" + "="*60)
    print("OpenRouter è¿æ¥æµ‹è¯•")
    print("="*60)
    
    try:
        from intelligent_project_analyzer.services.multi_llm_factory import MultiLLMFactory
        
        print(f"\nğŸ”§ åˆ›å»º OpenRouter LLM å®ä¾‹...")
        llm = MultiLLMFactory.create_llm(
            provider="openrouter",
            temperature=0.7,
            max_tokens=500
        )
        
        print(f"âœ… LLM å®ä¾‹åˆ›å»ºæˆåŠŸ!")
        
        print(f"\nğŸ“¡ å‘é€æµ‹è¯•è¯·æ±‚...")
        response = llm.invoke("è¯·ç”¨ä¸€å¥è¯ä»‹ç» OpenRouter æ˜¯ä»€ä¹ˆã€‚")
        
        print(f"\nâœ… OpenRouter å“åº”æˆåŠŸ!")
        print(f"\nğŸ’¬ å›å¤å†…å®¹:")
        print(f"  {response.content}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ OpenRouter è¿æ¥å¤±è´¥: {e}")
        print(f"\nå¯èƒ½çš„åŸå› :")
        print(f"  1. API Key æ— æ•ˆæˆ–ä½™é¢ä¸è¶³")
        print(f"  2. æ¨¡å‹åç§°æ ¼å¼é”™è¯¯ (éœ€è¦åŠ å‰ç¼€,å¦‚ openai/gpt-4o)")
        print(f"  3. ç½‘ç»œè¿æ¥é—®é¢˜")
        print(f"\nè§£å†³æ–¹æ³•:")
        print(f"  1. è®¿é—® https://openrouter.ai/credits æ£€æŸ¥ä½™é¢")
        print(f"  2. è®¿é—® https://openrouter.ai/models æŸ¥çœ‹å¯ç”¨æ¨¡å‹")
        print(f"  3. æ£€æŸ¥æ¨¡å‹åç§°æ ¼å¼: OPENROUTER_MODEL=openai/gpt-4o")
        return False
def compare_with_official_api():
    """å¯¹æ¯” OpenRouter ä¸å®˜æ–¹ API"""
    print("\n" + "="*60)
    print("OpenRouter vs å®˜æ–¹ API å¯¹æ¯”")
    print("="*60)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å®˜æ–¹ OpenAI API Key
    openai_key = os.getenv("OPENAI_API_KEY")
    if not openai_key or openai_key.startswith("your_"):
        print(f"\nâš ï¸ æœªé…ç½®å®˜æ–¹ OpenAI API Keyï¼Œè·³è¿‡å¯¹æ¯”æµ‹è¯•")
        return
    
    try:
        from intelligent_project_analyzer.services.multi_llm_factory import MultiLLMFactory
        import time
        
        test_prompt = "1+1ç­‰äºå‡ ï¼Ÿåªå›ç­”æ•°å­—ã€‚"
        
        # æµ‹è¯• OpenRouter
        print(f"\nğŸ”µ æµ‹è¯• OpenRouter...")
        start_time = time.time()
        try:
            llm_or = MultiLLMFactory.create_llm(provider="openrouter", max_tokens=50)
            response_or = llm_or.invoke(test_prompt)
            latency_or = time.time() - start_time
            print(f"  âœ… å“åº”: {response_or.content}")
            print(f"  â±ï¸  å»¶è¿Ÿ: {latency_or:.2f}s")
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            latency_or = None
        
        # æµ‹è¯•å®˜æ–¹ API
        print(f"\nğŸŸ¢ æµ‹è¯•å®˜æ–¹ OpenAI API...")
        start_time = time.time()
        try:
            llm_official = MultiLLMFactory.create_llm(provider="openai", max_tokens=50)
            response_official = llm_official.invoke(test_prompt)
            latency_official = time.time() - start_time
            print(f"  âœ… å“åº”: {response_official.content}")
            print(f"  â±ï¸  å»¶è¿Ÿ: {latency_official:.2f}s")
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            latency_official = None
        
        # å¯¹æ¯”ç»“æœ
        if latency_or and latency_official:
            print(f"\nğŸ“Š å¯¹æ¯”ç»“æœ:")
            print(f"  OpenRouter: {latency_or:.2f}s")
            print(f"  å®˜æ–¹ API: {latency_official:.2f}s")
            if latency_or < latency_official:
                print(f"  ğŸ† OpenRouter æ›´å¿« ({(latency_official/latency_or - 1)*100:.0f}%)")
            else:
                print(f"  âš ï¸ å®˜æ–¹ API æ›´å¿« ({(latency_or/latency_official - 1)*100:.0f}%)")
        
    except Exception as e:
        print(f"\nâŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")

def show_model_recommendations():
    """æ˜¾ç¤ºæ¨¡å‹æ¨è"""
    print("\n" + "="*60)
    print("OpenRouter æ¨¡å‹æ¨è")
    print("="*60)
    
    recommendations = [
        {
            "name": "openai/gpt-4o",
            "desc": "GPT-4o æœ€æ–°ç‰ˆ",
            "use_case": "é«˜è´¨é‡é¡¹ç›®åˆ†æ",
            "cost": "$2.5/$10 (è¾“å…¥/è¾“å‡º æ¯ç™¾ä¸‡tokens)"
        },
        {
            "name": "openai/gpt-4o-mini",
            "desc": "GPT-4o ç»æµç‰ˆ",
            "use_case": "æ—¥å¸¸å¯¹è¯å’Œç®€å•åˆ†æ",
            "cost": "$0.15/$0.6"
        },
        {
            "name": "openai/o1-preview",
            "desc": "OpenAI æ¨ç†æ¨¡å‹",
            "use_case": "å¤æ‚é€»è¾‘æ¨ç†",
            "cost": "$15/$60"
        },
        {
            "name": "anthropic/claude-3.5-sonnet",
            "desc": "Claude 3.5 Sonnet",
            "use_case": "é•¿æ–‡æœ¬åˆ†æ",
            "cost": "$3/$15"
        },
        {
            "name": "meta-llama/llama-3.3-70b-instruct",
            "desc": "Llama 3.3 70B",
            "use_case": "å¼€æºæ›¿ä»£ï¼ˆå…è´¹ï¼‰",
            "cost": "å…è´¹"
        }
    ]
    
    for i, rec in enumerate(recommendations, 1):
        print(f"\n{i}. {rec['name']}")
        print(f"   æè¿°: {rec['desc']}")
        print(f"   é€‚ç”¨: {rec['use_case']}")
        print(f"   æˆæœ¬: {rec['cost']}")
    
    print(f"\nğŸ’¡ æ›´å¤šæ¨¡å‹: https://openrouter.ai/models")

if __name__ == "__main__":
    print("\nğŸš€ OpenRouter é…ç½®æµ‹è¯•å·¥å…·")
    print("   å®˜ç½‘: https://openrouter.ai/")
    print("   æ–‡æ¡£: https://openrouter.ai/docs")
    
    # 1. é…ç½®æ£€æŸ¥
    config_ok = test_openrouter_config()
    
    if not config_ok:
        print("\nâš ï¸ è¯·å…ˆé…ç½® OpenRouter API Key")
        sys.exit(1)
    
    # 2. è¿æ¥æµ‹è¯•
    connection_ok = test_openrouter_connection()
    
    if connection_ok:
        # 3. å¯¹æ¯”æµ‹è¯•
        compare_with_official_api()
    
    # 4. æ¨¡å‹æ¨è
    show_model_recommendations()
    
    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆ!")
    print("="*60)
    
    if connection_ok:
        print(f"\nâœ… OpenRouter é…ç½®æˆåŠŸ!")
        print(f"\nğŸ“ ä½¿ç”¨æ–¹æ³•:")
        print(f"   1. ä¿®æ”¹ .env: LLM_PROVIDER=openrouter")
        print(f"   2. é‡å¯æœåŠ¡: python intelligent_project_analyzer/api/server.py")
        print(f"   3. è¿è¡Œå‰ç«¯: python intelligent_project_analyzer/frontend/run_frontend.py")
    else:
        print(f"\nâŒ OpenRouter é…ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
