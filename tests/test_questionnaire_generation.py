"""
é—®å·ç”Ÿæˆä¼˜åŒ–æµ‹è¯•

éªŒè¯ v7.5 LLMé©±åŠ¨çš„é—®å·ç”Ÿæˆå™¨èƒ½å¤Ÿï¼š
1. ç”Ÿæˆä¸ç”¨æˆ·è¾“å…¥ç´§å¯†ç›¸å…³çš„é—®é¢˜
2. æ­£ç¡®å›é€€åˆ°è§„åˆ™ç”Ÿæˆå™¨
3. é—®é¢˜ç±»å‹åˆ†å¸ƒåˆç†

è¿è¡Œæ–¹å¼ï¼š
    python tests/test_questionnaire_generation.py
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from loguru import logger


def test_llm_generator_with_real_input():
    """æµ‹è¯•LLMç”Ÿæˆå™¨å¤„ç†çœŸå®ç”¨æˆ·è¾“å…¥"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•1: LLMç”Ÿæˆå™¨å¤„ç†çœŸå®ç”¨æˆ·è¾“å…¥")
    logger.info("=" * 60)

    from intelligent_project_analyzer.interaction.questionnaire.llm_generator import LLMQuestionGenerator

    # æµ‹è¯•ç”¨ä¾‹1: ä½å®…è®¾è®¡
    user_input_1 = """
    æˆ‘éœ€è¦ä¸ºä¸€ä¸ª150ã¡çš„ä¸‰ä»£åŒå ‚å®¶åº­è®¾è®¡ä½å®…ç©ºé—´ã€‚
    å®¶é‡Œæœ‰è€äººã€ä¸­å¹´å¤«å¦»å’Œä¸€ä¸ª10å²çš„å­©å­ã€‚
    é¢„ç®—80ä¸‡ï¼Œå·¥æœŸ4ä¸ªæœˆã€‚
    å¸Œæœ›æ—¢æœ‰ç§å¯†æ€§åˆèƒ½ä¿ƒè¿›å®¶åº­äº’åŠ¨ï¼Œè€äººéœ€è¦æ— éšœç¢è®¾è®¡ã€‚
    """

    structured_data_1 = {
        "project_task": "ä¸ºä¸‰ä»£åŒå ‚å®¶åº­è®¾è®¡150ã¡ä½å®…ç©ºé—´",
        "project_type": "personal_residential",
        "design_challenge": "å¦‚ä½•å¹³è¡¡ä¸‰ä»£äººçš„'ç§å¯†éœ€æ±‚'ä¸'äº’åŠ¨éœ€æ±‚'ä¹‹é—´çš„çŸ›ç›¾",
        "core_tension": "ç§å¯†æ€§ vs å®¶åº­äº’åŠ¨",
        "character_narrative": "è€äººéœ€è¦å®‰é™ä¼‘æ¯ï¼Œå­©å­éœ€è¦ç©è€ç©ºé—´ï¼Œå¤«å¦»éœ€è¦ç‹¬å¤„æ—¶å…‰",
        "resource_constraints": "é¢„ç®—80ä¸‡ï¼Œå·¥æœŸ4ä¸ªæœˆ"
    }

    logger.info(f"ç”¨æˆ·è¾“å…¥: {user_input_1[:100]}...")
    questions_1, source_1 = LLMQuestionGenerator.generate(
        user_input=user_input_1,
        structured_data=structured_data_1
    )

    logger.info(f"ç”Ÿæˆæ¥æº: {source_1}")
    logger.info(f"é—®é¢˜æ•°é‡: {len(questions_1)}")

    # éªŒè¯é—®é¢˜å†…å®¹
    for i, q in enumerate(questions_1):
        logger.info(f"  Q{i+1} [{q.get('type')}]: {q.get('question', '')[:80]}...")

    # éªŒè¯é—®é¢˜æ˜¯å¦ä¸ç”¨æˆ·è¾“å…¥ç›¸å…³
    question_texts = " ".join([q.get("question", "") for q in questions_1])
    relevance_keywords = ["ä¸‰ä»£", "è€äºº", "å­©å­", "ç§å¯†", "äº’åŠ¨", "é¢„ç®—", "å®¶åº­"]
    matched_keywords = [kw for kw in relevance_keywords if kw in question_texts]

    logger.info(f"ç›¸å…³æ€§æ£€æŸ¥: åŒ¹é…å…³é”®è¯ {len(matched_keywords)}/{len(relevance_keywords)}: {matched_keywords}")

    assert len(questions_1) >= 5, f"é—®é¢˜æ•°é‡ä¸è¶³: {len(questions_1)}"
    logger.info("âœ… æµ‹è¯•1 é€šè¿‡")

    return questions_1, source_1


def test_llm_generator_with_tech_project():
    """æµ‹è¯•LLMç”Ÿæˆå™¨å¤„ç†ç§‘æŠ€å…¬å¸é¡¹ç›®"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•2: LLMç”Ÿæˆå™¨å¤„ç†ç§‘æŠ€å…¬å¸é¡¹ç›®")
    logger.info("=" * 60)

    from intelligent_project_analyzer.interaction.questionnaire.llm_generator import LLMQuestionGenerator

    user_input_2 = """
    æˆ‘ä»¬æ˜¯ä¸€å®¶AIåˆ›ä¸šå…¬å¸ï¼Œéœ€è¦è®¾è®¡ä¸€ä¸ª500ã¡çš„åŠå…¬ç©ºé—´ã€‚
    å›¢é˜Ÿæœ‰30äººï¼Œä¸»è¦æ˜¯ç ”å‘å·¥ç¨‹å¸ˆå’Œæ•°æ®ç§‘å­¦å®¶ã€‚
    å¸Œæœ›ç©ºé—´èƒ½å¤Ÿæ”¯æŒæ•æ·å¼€å‘ï¼Œæœ‰è¶³å¤Ÿçš„åä½œåŒºå’Œä¸“æ³¨åŒºã€‚
    é¢„ç®—200ä¸‡ï¼Œéœ€è¦åœ¨3ä¸ªæœˆå†…å®Œæˆã€‚
    """

    structured_data_2 = {
        "project_task": "ä¸ºAIåˆ›ä¸šå…¬å¸è®¾è®¡500ã¡åŠå…¬ç©ºé—´",
        "project_type": "commercial_enterprise",
        "design_challenge": "å¦‚ä½•å¹³è¡¡'å¼€æ”¾åä½œ'ä¸'æ·±åº¦ä¸“æ³¨'çš„éœ€æ±‚",
        "core_tension": "åä½œ vs ä¸“æ³¨",
        "character_narrative": "ç ”å‘å·¥ç¨‹å¸ˆéœ€è¦å®‰é™ç¼–ç ï¼Œå›¢é˜Ÿéœ€è¦é¢‘ç¹è®¨è®º",
        "resource_constraints": "é¢„ç®—200ä¸‡ï¼Œå·¥æœŸ3ä¸ªæœˆ"
    }

    logger.info(f"ç”¨æˆ·è¾“å…¥: {user_input_2[:100]}...")
    questions_2, source_2 = LLMQuestionGenerator.generate(
        user_input=user_input_2,
        structured_data=structured_data_2
    )

    logger.info(f"ç”Ÿæˆæ¥æº: {source_2}")
    logger.info(f"é—®é¢˜æ•°é‡: {len(questions_2)}")

    for i, q in enumerate(questions_2):
        logger.info(f"  Q{i+1} [{q.get('type')}]: {q.get('question', '')[:80]}...")

    # éªŒè¯é—®é¢˜æ˜¯å¦ä¸ç§‘æŠ€å…¬å¸ç›¸å…³
    question_texts = " ".join([q.get("question", "") for q in questions_2])
    tech_keywords = ["åä½œ", "ä¸“æ³¨", "ç ”å‘", "å›¢é˜Ÿ", "æ•æ·", "AI", "æ•°æ®"]
    matched_keywords = [kw for kw in tech_keywords if kw in question_texts]

    logger.info(f"ç›¸å…³æ€§æ£€æŸ¥: åŒ¹é…å…³é”®è¯ {len(matched_keywords)}/{len(tech_keywords)}: {matched_keywords}")

    assert len(questions_2) >= 5, f"é—®é¢˜æ•°é‡ä¸è¶³: {len(questions_2)}"
    logger.info("âœ… æµ‹è¯•2 é€šè¿‡")

    return questions_2, source_2


def test_fallback_generator():
    """æµ‹è¯•è§„åˆ™ç”Ÿæˆå™¨ï¼ˆfallbackï¼‰"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•3: è§„åˆ™ç”Ÿæˆå™¨ï¼ˆFallbackï¼‰")
    logger.info("=" * 60)

    from intelligent_project_analyzer.interaction.questionnaire.generators import FallbackQuestionGenerator
    from intelligent_project_analyzer.interaction.questionnaire.context import KeywordExtractor

    user_input = "æˆ‘éœ€è¦è®¾è®¡ä¸€ä¸ªå’–å•¡å…ï¼Œé¢ç§¯100ã¡ï¼Œé¢„ç®—50ä¸‡"

    structured_data = {
        "project_task": "è®¾è®¡100ã¡å’–å•¡å…",
        "project_type": "commercial_enterprise",
        "design_challenge": "å¦‚ä½•åœ¨æœ‰é™ç©ºé—´å†…å¹³è¡¡åº§ä½æ•°é‡å’Œé¡¾å®¢ä½“éªŒ",
        "core_tension": "åªæ•ˆ vs ä½“éªŒ"
    }

    # æå–å…³é”®ä¿¡æ¯
    extracted_info = KeywordExtractor.extract(user_input, structured_data)
    logger.info(f"æå–çš„é¢†åŸŸ: {extracted_info.get('domain', {}).get('label', 'unknown')}")
    logger.info(f"æ ¸å¿ƒæ¦‚å¿µ: {extracted_info.get('core_concepts', [])}")

    # ç”Ÿæˆé—®é¢˜
    questions = FallbackQuestionGenerator.generate(
        structured_data,
        user_input=user_input,
        extracted_info=extracted_info
    )

    logger.info(f"é—®é¢˜æ•°é‡: {len(questions)}")

    # éªŒè¯é¢˜å‹åˆ†å¸ƒ
    type_counts = {}
    for q in questions:
        q_type = q.get("type", "unknown")
        type_counts[q_type] = type_counts.get(q_type, 0) + 1

    logger.info(f"é¢˜å‹åˆ†å¸ƒ: {type_counts}")

    for i, q in enumerate(questions):
        logger.info(f"  Q{i+1} [{q.get('type')}]: {q.get('question', '')[:60]}...")

    # éªŒè¯æ²¡æœ‰æŠ½è±¡æ¦‚å¿µ
    abstract_terms = ["èº«ä»½è¡¨è¾¾", "èº«ä½“ä½“éªŒ", "æ ¸å¿ƒåŠŸèƒ½åŒº", "è¾…åŠ©æ”¯æŒåŒº", "çµæ´»å¤šç”¨åŒº"]
    question_texts = " ".join([q.get("question", "") + " ".join(q.get("options", [])) for q in questions])

    found_abstract = [term for term in abstract_terms if term in question_texts]
    if found_abstract:
        logger.warning(f"âš ï¸ å‘ç°æŠ½è±¡æ¦‚å¿µ: {found_abstract}")
    else:
        logger.info("âœ… æœªå‘ç°æŠ½è±¡æ¦‚å¿µ")

    assert len(questions) >= 5, f"é—®é¢˜æ•°é‡ä¸è¶³: {len(questions)}"
    assert "single_choice" in type_counts, "ç¼ºå°‘å•é€‰é¢˜"
    assert "multiple_choice" in type_counts, "ç¼ºå°‘å¤šé€‰é¢˜"

    logger.info("âœ… æµ‹è¯•3 é€šè¿‡")

    return questions


def test_question_type_order():
    """æµ‹è¯•é—®é¢˜ç±»å‹æ’åº"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•4: é—®é¢˜ç±»å‹æ’åº")
    logger.info("=" * 60)

    from intelligent_project_analyzer.interaction.questionnaire.llm_generator import LLMQuestionGenerator

    # ä½¿ç”¨ç®€å•è¾“å…¥å¿«é€Ÿæµ‹è¯•
    user_input = "è®¾è®¡ä¸€ä¸ªå°å‹ä¹¦æˆ¿"
    structured_data = {
        "project_task": "è®¾è®¡å°å‹ä¹¦æˆ¿",
        "project_type": "personal_residential"
    }

    questions, _ = LLMQuestionGenerator.generate(user_input, structured_data)

    # éªŒè¯æ’åºï¼šå•é€‰ -> å¤šé€‰ -> å¼€æ”¾
    type_order = [q.get("type") for q in questions]
    logger.info(f"é—®é¢˜ç±»å‹é¡ºåº: {type_order}")

    # æ£€æŸ¥æ˜¯å¦æŒ‰é¡ºåºæ’åˆ—
    expected_order = {"single_choice": 0, "multiple_choice": 1, "open_ended": 2}
    is_ordered = True
    last_order = -1

    for t in type_order:
        current_order = expected_order.get(t, 3)
        if current_order < last_order:
            is_ordered = False
            break
        last_order = current_order

    if is_ordered:
        logger.info("âœ… é—®é¢˜ç±»å‹é¡ºåºæ­£ç¡®")
    else:
        logger.warning("âš ï¸ é—®é¢˜ç±»å‹é¡ºåºä¸æ­£ç¡®ï¼Œä½†ç³»ç»Ÿä¼šè‡ªåŠ¨ä¿®å¤")

    logger.info("âœ… æµ‹è¯•4 é€šè¿‡")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹é—®å·ç”Ÿæˆä¼˜åŒ–æµ‹è¯•")
    logger.info("=" * 80)

    try:
        # æµ‹è¯•1: LLMç”Ÿæˆå™¨ - ä½å®…é¡¹ç›®
        test_llm_generator_with_real_input()
        print()

        # æµ‹è¯•2: LLMç”Ÿæˆå™¨ - ç§‘æŠ€å…¬å¸
        test_llm_generator_with_tech_project()
        print()

        # æµ‹è¯•3: è§„åˆ™ç”Ÿæˆå™¨
        test_fallback_generator()
        print()

        # æµ‹è¯•4: é—®é¢˜ç±»å‹æ’åº
        test_question_type_order()
        print()

        logger.info("=" * 80)
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        logger.info("=" * 80)

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return False

    return True


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(
        sys.stdout,
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | {message}",
        level="INFO"
    )

    success = run_all_tests()
    sys.exit(0 if success else 1)
