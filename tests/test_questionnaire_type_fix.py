"""
æµ‹è¯•é—®å·ç±»å‹ä¿®å¤åŠŸèƒ½

éªŒè¯åç«¯èƒ½å¤Ÿæ­£ç¡®ä¿®å¤å„ç§é”™è¯¯çš„é—®é¢˜ç±»å‹åˆ«åï¼ŒåŒ…æ‹¬ï¼š
- multi_choice â†’ multiple_choice
- checkbox â†’ multiple_choice
- radio â†’ single_choice
- text â†’ open_ended
ç­‰å…¶ä»–å¸¸è§é”™è¯¯æ ¼å¼

è¿è¡Œæ–¹å¼ï¼š
    pytest tests/test_questionnaire_type_fix.py -v
    æˆ–
    python tests/test_questionnaire_type_fix.py
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from loguru import logger

from intelligent_project_analyzer.interaction.questionnaire.llm_generator import LLMQuestionGenerator
from intelligent_project_analyzer.services.llm_gap_question_generator import LLMGapQuestionGenerator


def test_llm_generator_type_fix():
    """æµ‹è¯• LLMQuestionGenerator çš„ç±»å‹ä¿®å¤åŠŸèƒ½"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• LLMQuestionGenerator ç±»å‹ä¿®å¤")
    logger.info("=" * 60)

    # æ¨¡æ‹ŸLLMè¿”å›çš„é”™è¯¯ç±»å‹é—®é¢˜
    raw_questions = [
        {"id": "q1", "question": "è¿™æ˜¯å•é€‰é¢˜", "type": "single", "options": ["A", "B", "C"], "context": "æµ‹è¯•"},  # é”™è¯¯ç±»å‹
        {"id": "q2", "question": "è¿™æ˜¯å¤šé€‰é¢˜", "type": "multi_choice", "options": ["A", "B", "C"], "context": "æµ‹è¯•"},  # é”™è¯¯ç±»å‹
        {"id": "q3", "question": "è¿™æ˜¯å¦ä¸€ä¸ªå¤šé€‰é¢˜", "type": "checkbox", "options": ["A", "B"], "context": "æµ‹è¯•"},  # é”™è¯¯ç±»å‹
        {"id": "q4", "question": "è¿™æ˜¯å•é€‰é¢˜2", "type": "radio", "options": ["X", "Y"], "context": "æµ‹è¯•"},  # é”™è¯¯ç±»å‹
        {"id": "q5", "question": "è¿™æ˜¯å¼€æ”¾é¢˜", "type": "text", "placeholder": "è¯·è¾“å…¥", "context": "æµ‹è¯•"},  # é”™è¯¯ç±»å‹
        {"id": "q6", "question": "è¿™æ˜¯ä¸‹æ‹‰é€‰æ‹©", "type": "select", "options": ["é€‰é¡¹1", "é€‰é¡¹2"], "context": "æµ‹è¯•"},  # é”™è¯¯ç±»å‹
        {"id": "q7", "question": "è¿™æ˜¯å¼€æ”¾æ–‡æœ¬", "type": "textarea", "placeholder": "è¯·è¯¦ç»†æè¿°", "context": "æµ‹è¯•"},  # é”™è¯¯ç±»å‹
        {
            "id": "q8",
            "question": "è¿™æ˜¯å¤šé€‰å¸¦æ¨ªçº¿",
            "type": "multi-choice",  # é”™è¯¯ç±»å‹
            "options": ["A", "B", "C"],
            "context": "æµ‹è¯•",
        },
    ]

    # è°ƒç”¨éªŒè¯æ–¹æ³•
    fixed_questions = LLMQuestionGenerator._validate_and_fix_questions(raw_questions)

    # éªŒè¯ä¿®å¤ç»“æœ
    expected_types = {
        "q1": "single_choice",
        "q2": "multiple_choice",
        "q3": "multiple_choice",
        "q4": "single_choice",
        "q5": "open_ended",
        "q6": "single_choice",
        "q7": "open_ended",
        "q8": "multiple_choice",
    }

    logger.info(f"\nğŸ“Š ä¿®å¤ç»“æœç»Ÿè®¡:")
    all_passed = True
    for q in fixed_questions:
        qid = q["id"]
        expected = expected_types[qid]
        actual = q["type"]
        status = "âœ…" if actual == expected else "âŒ"
        logger.info(f"  {status} {qid}: {actual} (æœŸæœ›: {expected})")
        if actual != expected:
            all_passed = False

    if all_passed:
        logger.success("âœ… LLMQuestionGenerator ç±»å‹ä¿®å¤æµ‹è¯•é€šè¿‡")
    else:
        logger.error("âŒ LLMQuestionGenerator ç±»å‹ä¿®å¤æµ‹è¯•å¤±è´¥")

    return all_passed


def test_gap_generator_type_fix():
    """æµ‹è¯• LLMGapQuestionGenerator çš„ç±»å‹ä¿®å¤åŠŸèƒ½"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯• LLMGapQuestionGenerator ç±»å‹ä¿®å¤")
    logger.info("=" * 60)

    # æ¨¡æ‹Ÿç¬¬ä¸‰æ­¥LLMè¿”å›çš„é”™è¯¯ç±»å‹é—®é¢˜
    raw_questions = [
        {
            "id": "budget",
            "question": "é¢„ç®—èŒƒå›´æ˜¯ï¼Ÿ",
            "type": "multi_choice",  # é”™è¯¯ç±»å‹
            "options": ["10ä¸‡ä»¥ä¸‹", "10-30ä¸‡"],
            "is_required": True,
        },
        {
            "id": "timeline",
            "question": "äº¤ä»˜æ—¶é—´ï¼Ÿ",
            "type": "radio",  # é”™è¯¯ç±»å‹
            "options": ["1ä¸ªæœˆ", "3ä¸ªæœˆ"],
            "is_required": True,
        },
        {"id": "special", "question": "ç‰¹æ®Šéœ€æ±‚ï¼Ÿ", "type": "text", "placeholder": "è¯·æè¿°", "is_required": False},  # é”™è¯¯ç±»å‹
    ]

    # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹å¹¶è°ƒç”¨éªŒè¯æ–¹æ³•
    generator = LLMGapQuestionGenerator()
    fixed_questions = generator._validate_and_fix_questions(raw_questions)

    # éªŒè¯ä¿®å¤ç»“æœ
    expected_types = {"budget": "multiple_choice", "timeline": "single_choice", "special": "open_ended"}

    logger.info(f"\nğŸ“Š ä¿®å¤ç»“æœç»Ÿè®¡:")
    all_passed = True
    for q in fixed_questions:
        qid = q["id"]
        expected = expected_types[qid]
        actual = q["type"]
        status = "âœ…" if actual == expected else "âŒ"
        logger.info(f"  {status} {qid}: {actual} (æœŸæœ›: {expected})")
        if actual != expected:
            all_passed = False

    if all_passed:
        logger.success("âœ… LLMGapQuestionGenerator ç±»å‹ä¿®å¤æµ‹è¯•é€šè¿‡")
    else:
        logger.error("âŒ LLMGapQuestionGenerator ç±»å‹ä¿®å¤æµ‹è¯•å¤±è´¥")

    return all_passed


def test_type_inference():
    """æµ‹è¯•ä»é—®é¢˜æ–‡æœ¬æ¨æ–­ç±»å‹"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•ç±»å‹æ¨æ–­åŠŸèƒ½")
    logger.info("=" * 60)

    # æ²¡æœ‰æ˜ç¡®ç±»å‹ï¼Œä½†æœ‰æ ‡æ³¨æˆ–é€‰é¡¹
    raw_questions = [
        {"id": "q1", "question": "æ‚¨çš„é¢„ç®—èŒƒå›´æ˜¯ï¼Ÿ(å•é€‰)", "type": "unknown_type", "options": ["A", "B"]},  # æœªçŸ¥ç±»å‹ï¼Œä½†æ–‡æœ¬æœ‰å•é€‰æ ‡æ³¨
        {"id": "q2", "question": "éœ€è¦å“ªäº›åŠŸèƒ½ï¼Ÿ(å¤šé€‰)", "type": "xyz", "options": ["åŠŸèƒ½1", "åŠŸèƒ½2"]},  # æœªçŸ¥ç±»å‹ï¼Œä½†æ–‡æœ¬æœ‰å¤šé€‰æ ‡æ³¨
        {"id": "q3", "question": "è¯·æè¿°æ‚¨çš„éœ€æ±‚(å¼€æ”¾é¢˜)", "type": "abc"},  # æœªçŸ¥ç±»å‹ï¼Œä½†æ–‡æœ¬æœ‰å¼€æ”¾é¢˜æ ‡æ³¨
        {"id": "q4", "question": "é€‰æ‹©ä¸€ä¸ªé€‰é¡¹", "type": "invalid", "options": ["é€‰é¡¹1", "é€‰é¡¹2"]},  # æœªçŸ¥ç±»å‹ï¼Œä½†æœ‰é€‰é¡¹åˆ—è¡¨
    ]

    fixed_questions = LLMQuestionGenerator._validate_and_fix_questions(raw_questions)

    expected_types = {
        "q1": "single_choice",  # ä»"(å•é€‰)"æ¨æ–­
        "q2": "multiple_choice",  # ä»"(å¤šé€‰)"æ¨æ–­
        "q3": "open_ended",  # ä»"(å¼€æ”¾é¢˜)"æ¨æ–­
        "q4": "single_choice",  # ä»æœ‰optionsæ¨æ–­
    }

    logger.info(f"\nğŸ“Š æ¨æ–­ç»“æœç»Ÿè®¡:")
    all_passed = True
    for q in fixed_questions:
        qid = q["id"]
        expected = expected_types[qid]
        actual = q["type"]
        status = "âœ…" if actual == expected else "âŒ"
        logger.info(f"  {status} {qid}: {actual} (æœŸæœ›: {expected})")
        if actual != expected:
            all_passed = False

    if all_passed:
        logger.success("âœ… ç±»å‹æ¨æ–­æµ‹è¯•é€šè¿‡")
    else:
        logger.error("âŒ ç±»å‹æ¨æ–­æµ‹è¯•å¤±è´¥")

    return all_passed


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("\n" + "ğŸ§ª" * 30)
    logger.info("å¼€å§‹è¿è¡Œé—®å·ç±»å‹ä¿®å¤æµ‹è¯•å¥—ä»¶")
    logger.info("ğŸ§ª" * 30 + "\n")

    results = {
        "LLMQuestionGeneratorç±»å‹ä¿®å¤": test_llm_generator_type_fix(),
        "LLMGapQuestionGeneratorç±»å‹ä¿®å¤": test_gap_generator_type_fix(),
        "ç±»å‹æ¨æ–­åŠŸèƒ½": test_type_inference(),
    }

    # æ±‡æ€»ç»“æœ
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•ç»“æœæ±‡æ€»")
    logger.info("=" * 60)

    for test_name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        logger.info(f"{status} - {test_name}")

    all_passed = all(results.values())

    if all_passed:
        logger.success("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        logger.error("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

    return all_passed


if __name__ == "__main__":
    import pytest

    # æ£€æŸ¥æ˜¯å¦é€šè¿‡pytestè¿è¡Œ
    if "pytest" in sys.modules:
        # é€šè¿‡pytestè¿è¡Œï¼Œå®šä¹‰æµ‹è¯•å‡½æ•°
        def test_all():
            assert run_all_tests(), "éƒ¨åˆ†æµ‹è¯•å¤±è´¥"

    else:
        # ç›´æ¥è¿è¡Œ
        success = run_all_tests()
        sys.exit(0 if success else 1)
