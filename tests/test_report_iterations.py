"""
æµ‹è¯•æŠ¥å‘Šè¿­ä»£åŠŸèƒ½
éªŒè¯ä¸‰ä¸ªæ–°å¢åŠŸèƒ½ï¼š
1. å®¡æ ¸åé¦ˆç« èŠ‚
2. ç”¨æˆ·è®¿è°ˆè®°å½•
3. å¤šè½®å®¡æ ¸å¯è§†åŒ–
"""

import json
import sys
from datetime import datetime
from pydantic import BaseModel, Field, ConfigDict
from typing import List, Optional, Dict, Any


# ç›´æ¥å®šä¹‰æµ‹è¯•ç”¨çš„æ•°æ®æ¨¡å‹ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
class ReviewFeedbackItem(BaseModel):
    """å•ä¸ªå®¡æ ¸åé¦ˆé¡¹"""
    model_config = ConfigDict(extra='forbid')
    
    issue_id: str
    reviewer: str
    issue_type: str
    description: str
    response: str
    status: str
    priority: str


class ReviewFeedback(BaseModel):
    """å®¡æ ¸åé¦ˆç« èŠ‚"""
    model_config = ConfigDict(extra='forbid')
    
    red_team_challenges: List[ReviewFeedbackItem]
    blue_team_validations: List[ReviewFeedbackItem]
    judge_rulings: List[ReviewFeedbackItem]
    client_decisions: List[ReviewFeedbackItem]
    iteration_summary: str


class QuestionnaireResponse(BaseModel):
    """å•ä¸ªé—®å·é—®é¢˜çš„å›ç­”"""
    model_config = ConfigDict(extra='forbid')
    
    question_id: str
    question: str
    answer: str
    context: str


class QuestionnaireResponses(BaseModel):
    """ç”¨æˆ·è®¿è°ˆè®°å½•"""
    model_config = ConfigDict(extra='forbid')
    
    responses: List[QuestionnaireResponse]
    timestamp: str
    analysis_insights: str


class ReviewRoundData(BaseModel):
    """å•è½®å®¡æ ¸æ•°æ®"""
    model_config = ConfigDict(extra='forbid')
    
    round_number: int
    red_score: int
    blue_score: int
    judge_score: int
    issues_found: int
    issues_resolved: int
    timestamp: str


class ReviewVisualization(BaseModel):
    """å¤šè½®å®¡æ ¸å¯è§†åŒ–æ•°æ®"""
    model_config = ConfigDict(extra='forbid')
    
    rounds: List[ReviewRoundData]
    final_decision: str
    total_rounds: int
    improvement_rate: float


def test_review_feedback():
    """æµ‹è¯•å®¡æ ¸åé¦ˆæ•°æ®æ¨¡å‹"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 1: å®¡æ ¸åé¦ˆæ•°æ®æ¨¡å‹")
    print("=" * 80)
    
    feedback_items = [
        ReviewFeedbackItem(
            issue_id="R1",
            reviewer="çº¢é˜Ÿï¼ˆç¬¬1è½®ï¼‰",
            issue_type="é£é™©",
            description="æ¸…æ°´æ··å‡åœŸæ–½å·¥é£é™©é«˜",
            response="å¼ºåˆ¶è¦æ±‚1:1æ ·æ¿å¢™éªŒè¯",
            status="å·²ä¿®å¤",
            priority="high"
        ),
        ReviewFeedbackItem(
            issue_id="B1",
            reviewer="è“é˜Ÿï¼ˆç¬¬1è½®ï¼‰",
            issue_type="ä¼˜åŒ–",
            description="å¢åŠ æè´¨å¯¹æ¯”å±•ç¤º",
            response="å·²é‡‡çº³ï¼Œå¢åŠ æ ·æ¿é—´å¯¹æ¯”åŒº",
            status="å·²ä¿®å¤",
            priority="medium"
        )
    ]
    
    review_feedback = ReviewFeedback(
        red_team_challenges=[feedback_items[0]],
        blue_team_validations=[feedback_items[1]],
        judge_rulings=[],
        client_decisions=[],
        iteration_summary="ç»è¿‡1è½®å®¡æ ¸ï¼Œè¯†åˆ«2ä¸ªå…³é”®é—®é¢˜ï¼Œå…¨éƒ¨å®Œæˆä¿®å¤"
    )
    
    print("âœ… å®¡æ ¸åé¦ˆæ¨¡å‹éªŒè¯é€šè¿‡")
    print(f"   - çº¢é˜Ÿè´¨ç–‘: {len(review_feedback.red_team_challenges)}ä¸ª")
    print(f"   - è“é˜ŸéªŒè¯: {len(review_feedback.blue_team_validations)}ä¸ª")
    print(f"   - è¿­ä»£æ€»ç»“: {review_feedback.iteration_summary[:50]}...")
    
    return review_feedback


def test_questionnaire_responses():
    """æµ‹è¯•é—®å·å›ç­”æ•°æ®æ¨¡å‹"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 2: é—®å·å›ç­”æ•°æ®æ¨¡å‹")
    print("=" * 80)
    
    responses = [
        QuestionnaireResponse(
            question_id="Q1",
            question="æ‚¨å¯¹å®‰è—¤å¿ é›„çš„æ¸…æ°´æ··å‡åœŸé£æ ¼æœ‰ä»€ä¹ˆç‰¹æ®Šåå¥½ï¼Ÿ",
            answer="å¸Œæœ›ä¿ç•™æç®€ä¸»ä¹‰ç²¾ç¥ï¼Œä½†å¢åŠ ä¸€äº›æ¸©æš–å…ƒç´ ",
            context="é£æ ¼åå¥½"
        ),
        QuestionnaireResponse(
            question_id="Q2",
            question="æ‚¨å¯¹é¡¹ç›®é¢„ç®—æœ‰ä½•æœŸæœ›ï¼Ÿ",
            answer="ä¸­é«˜ç«¯å®šä½ï¼Œæ„¿æ„ä¸ºé«˜å“è´¨ææ–™æŠ•å…¥",
            context="é¢„ç®—è€ƒé‡"
        )
    ]
    
    questionnaire_responses = QuestionnaireResponses(
        responses=responses,
        timestamp=datetime.now().isoformat(),
        analysis_insights="ç”¨æˆ·è¿½æ±‚æç®€ç¾å­¦ä¸å®ç”¨æ€§çš„å¹³è¡¡"
    )
    
    print("âœ… é—®å·å›ç­”æ¨¡å‹éªŒè¯é€šè¿‡")
    print(f"   - å›ç­”æ•°é‡: {len(questionnaire_responses.responses)}ä¸ª")
    print(f"   - æäº¤æ—¶é—´: {questionnaire_responses.timestamp}")
    print(f"   - å…³é”®æ´å¯Ÿ: {questionnaire_responses.analysis_insights[:40]}...")
    
    return questionnaire_responses


def test_review_visualization():
    """æµ‹è¯•å®¡æ ¸å¯è§†åŒ–æ•°æ®æ¨¡å‹"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 3: å®¡æ ¸å¯è§†åŒ–æ•°æ®æ¨¡å‹")
    print("=" * 80)
    
    rounds = [
        ReviewRoundData(
            round_number=1,
            red_score=65,
            blue_score=75,
            judge_score=70,
            issues_found=5,
            issues_resolved=3,
            timestamp=datetime.now().isoformat()
        ),
        ReviewRoundData(
            round_number=2,
            red_score=80,
            blue_score=85,
            judge_score=82,
            issues_found=2,
            issues_resolved=2,
            timestamp=datetime.now().isoformat()
        )
    ]
    
    visualization = ReviewVisualization(
        rounds=rounds,
        final_decision="æœ‰æ¡ä»¶é€šè¿‡",
        total_rounds=2,
        improvement_rate=0.23
    )
    
    print("âœ… å®¡æ ¸å¯è§†åŒ–æ¨¡å‹éªŒè¯é€šè¿‡")
    print(f"   - æ€»è½®æ¬¡: {visualization.total_rounds}è½®")
    print(f"   - æœ€ç»ˆå†³ç­–: {visualization.final_decision}")
    print(f"   - æ”¹è¿›ç‡: {visualization.improvement_rate*100:.1f}%")
    print(f"   - å„è½®è¯„åˆ†:")
    for r in visualization.rounds:
        print(f"     ç¬¬{r.round_number}è½®: çº¢é˜Ÿ{r.red_score} | è“é˜Ÿ{r.blue_score} | è¯„å§”{r.judge_score}")
    
    return visualization


def test_final_report_with_new_fields():
    """æµ‹è¯•å®Œæ•´æŠ¥å‘Šæ¨¡å‹ï¼ˆåŒ…å«æ–°å­—æ®µï¼‰"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 4: æ–°å­—æ®µJSONåºåˆ—åŒ–")
    print("=" * 80)
    
    # åˆ›å»ºæ–°å­—æ®µæ•°æ®
    review_feedback = test_review_feedback()
    questionnaire_responses = test_questionnaire_responses()
    review_visualization = test_review_visualization()
    
    # æµ‹è¯•åºåˆ—åŒ–
    try:
        data = {
            "review_feedback": review_feedback.model_dump(),
            "questionnaire_responses": questionnaire_responses.model_dump(),
            "review_visualization": review_visualization.model_dump()
        }
        report_json = json.dumps(data, ensure_ascii=False, indent=2)
        print(f"\nâœ… æ–°å­—æ®µå¯æˆåŠŸåºåˆ—åŒ–ä¸ºJSONï¼ˆ{len(report_json)}å­—ç¬¦ï¼‰")
        print("\nç¤ºä¾‹æ•°æ®ï¼ˆå‰500å­—ç¬¦ï¼‰:")
        print(report_json[:500] + "...")
    except Exception as e:
        print(f"\nâŒ åºåˆ—åŒ–å¤±è´¥: {e}")
        raise
    
    return data


def test_state_fields():
    """æµ‹è¯• state å­—æ®µæ˜¯å¦æ­£ç¡®æ·»åŠ """
    print("\n" + "=" * 80)
    print("æµ‹è¯• 5: State å­—æ®µéªŒè¯")
    print("=" * 80)
    
    # ç®€å•æ£€æŸ¥å­—æ®µå®šä¹‰æ˜¯å¦å­˜åœ¨
    try:
        # è¯»å– state.py æ–‡ä»¶å†…å®¹
        with open("intelligent_project_analyzer/core/state.py", "r", encoding="utf-8") as f:
            content = f.read()
        
        required_fields = [
            "calibration_questionnaire",
            "questionnaire_responses",
            "review_history"
        ]
        
        for field in required_fields:
            if field in content:
                print(f"   âœ“ {field}: å·²å®šä¹‰")
            else:
                print(f"   âœ— {field}: æœªæ‰¾åˆ°")
                raise ValueError(f"Stateç¼ºå°‘å¿…éœ€å­—æ®µå®šä¹‰: {field}")
        
        print("âœ… Stateå­—æ®µéªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âŒ Stateå­—æ®µéªŒè¯å¤±è´¥: {e}")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("ğŸš€ å¼€å§‹æµ‹è¯•æŠ¥å‘Šè¿­ä»£åŠŸèƒ½")
    print("=" * 80)
    
    try:
        # æµ‹è¯•å„ä¸ªæ•°æ®æ¨¡å‹
        test_review_feedback()
        test_questionnaire_responses()
        test_review_visualization()
        
        # æµ‹è¯•å®Œæ•´æŠ¥å‘Š
        report = test_final_report_with_new_fields()
        
        # æµ‹è¯• state å­—æ®µ
        test_state_fields()
        
        print("\n" + "=" * 80)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 80)
        print("\næ–°å¢åŠŸèƒ½æ€»ç»“:")
        print("1. âœ… å®¡æ ¸åé¦ˆç« èŠ‚ - åŒ…å«çº¢è“å¯¹æŠ—ã€è¯„å§”è£å†³ã€ç”²æ–¹å†³ç­–")
        print("2. âœ… ç”¨æˆ·è®¿è°ˆè®°å½• - å®Œæ•´çš„é—®å·å›ç­”å’Œæ´å¯Ÿåˆ†æ")
        print("3. âœ… å¤šè½®å®¡æ ¸å¯è§†åŒ– - è¯„åˆ†è¶‹åŠ¿å’Œæ”¹è¿›ç‡æ•°æ®")
        print("\næ•°æ®æ¨¡å‹:")
        print("- ReviewFeedback (å®¡æ ¸åé¦ˆ)")
        print("- QuestionnaireResponses (é—®å·å›ç­”)")
        print("- ReviewVisualization (å®¡æ ¸å¯è§†åŒ–)")
        print("\nState å­—æ®µ:")
        print("- calibration_questionnaire")
        print("- questionnaire_responses")
        print("- review_history")
        
    except Exception as e:
        print("\n" + "=" * 80)
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("=" * 80)
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
