"""
v7.17 é›†æˆæµ‹è¯•ï¼šéœ€æ±‚åˆ†æå¸ˆ StateGraph Agent åœ¨ä¸»å·¥ä½œæµä¸­çš„æ‰§è¡Œ
"""

import os
import sys

# å¯ç”¨ v7.17 æ¨¡å¼
os.environ["USE_V717_REQUIREMENTS_ANALYST"] = "true"

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from intelligent_project_analyzer.workflow.main_workflow import MainWorkflow


class MockLLM:
    """æ¨¡æ‹Ÿ LLM ç”¨äºæµ‹è¯•"""
    call_count = 0
    
    def invoke(self, messages):
        MockLLM.call_count += 1
        
        class MockResponse:
            pass
        
        response = MockResponse()
        
        import json
        
        # æ ¹æ®è°ƒç”¨æ¬¡æ•°è¿”å›ä¸åŒçš„å“åº”
        if MockLLM.call_count == 1:
            # Phase1 å“åº”
            response.content = json.dumps({
                "info_status": "sufficient",
                "info_status_reason": "ä¿¡æ¯å®Œæ•´",
                "project_summary": "75å¹³ç±³å…¬å¯“è®¾è®¡é¡¹ç›®",
                "project_type_preliminary": "personal_residential",
                "primary_deliverables": [
                    {
                        "deliverable_id": "D1",
                        "type": "design_strategy",
                        "description": "è®¾è®¡ç­–ç•¥æ–‡æ¡£",
                        "priority": "MUST_HAVE",
                        "capability_check": {"within_capability": True}
                    },
                    {
                        "deliverable_id": "D2",
                        "type": "naming_list",
                        "description": "ç©ºé—´å‘½åæ–¹æ¡ˆ",
                        "priority": "NICE_TO_HAVE",
                        "capability_check": {"within_capability": True}
                    }
                ],
                "recommended_next_step": "phase2_analysis"
            }, ensure_ascii=False)
        else:
            # Phase2 å“åº”
            response.content = json.dumps({
                "analysis_layers": {
                    "L1_facts": [
                        "ç”¨æˆ·èº«ä»½: 32å²å‰é‡‘èå¾‹å¸ˆ",
                        "ç©ºé—´: 75å¹³ç±³å…¬å¯“",
                        "é¢„ç®—: 60ä¸‡",
                        "é£æ ¼åå¥½: ç°ä»£ç®€çº¦"
                    ],
                    "L2_user_model": {
                        "psychological": "è¿½æ±‚å“è´¨ç”Ÿæ´»ï¼Œæ³¨é‡ç»†èŠ‚",
                        "sociological": "èŒä¸šè½¬å‹ä¸­ï¼Œå¸Œæœ›è¡¨è¾¾æ–°èº«ä»½",
                        "aesthetic": "åå¥½ç®€çº¦ï¼Œä½†ä¸å¤±æ¸©åº¦"
                    },
                    "L3_core_tension": "ä¸“ä¸šå½¢è±¡ vs ç”Ÿæ´»æ¸©åº¦çš„å¹³è¡¡",
                    "L4_project_task": "ä¸ºè½¬å‹æœŸçš„å¹´è½»ä¸“ä¸šäººå£«æ‰“é€ ä¸€ä¸ªæ—¢æœ‰ä¸“ä¸šæ„Ÿåˆæœ‰ç”Ÿæ´»æ¸©åº¦çš„å±…ä½ç©ºé—´",
                    "L5_sharpness": {"score": 85, "note": "éœ€æ±‚æ¸…æ™°ï¼Œæ ¸å¿ƒçŸ›ç›¾æ˜ç¡®"}
                },
                "structured_output": {
                    "project_task": "ä¸º32å²å‰é‡‘èå¾‹å¸ˆè®¾è®¡75å¹³ç±³ç°ä»£ç®€çº¦å…¬å¯“ï¼Œä½“ç°ä¸“ä¸šå“è´¨ä¸ç”Ÿæ´»æ¸©åº¦çš„èåˆ",
                    "character_narrative": "ä¸€ä½ä»é‡‘èæ³•å¾‹ç•Œè½¬å‹çš„å¹´è½»å¥³æ€§ï¼Œè¿½æ±‚å“è´¨ä¸æ•ˆç‡ï¼Œå¸Œæœ›å±…ä½ç©ºé—´èƒ½ä½“ç°å…¶ä¸“ä¸šç´ å…»ä¸å¯¹ç”Ÿæ´»ç¾å­¦çš„è¿½æ±‚",
                    "physical_context": "75å¹³ç±³ä¸€å±…å®¤å…¬å¯“ï¼Œé«˜å±‚å—å‘",
                    "resource_constraints": "é¢„ç®—60ä¸‡ï¼Œ4ä¸ªæœˆå·¥æœŸ",
                    "regulatory_requirements": "ä½å®…è£…ä¿®æ ‡å‡†è§„èŒƒ",
                    "inspiration_references": "åŒ—æ¬§æç®€ + æ—¥å¼æ”¶çº³æ™ºæ…§",
                    "experience_behavior": "å·¥ä½œæ—¥é«˜æ•ˆï¼Œå‘¨æœ«æ”¾æ¾é˜…è¯»ä¸ç‘œä¼½",
                    "design_challenge": "åœ¨æœ‰é™ç©ºé—´å†…å®ç°å·¥ä½œã€ç”Ÿæ´»ã€ä¼‘é—²çš„åŠŸèƒ½åˆ†åŒº"
                },
                "expert_handoff": {
                    "critical_questions_for_experts": {
                        "V3_å™äº‹ä¸“å®¶": ["å¦‚ä½•é€šè¿‡ç©ºé—´å™äº‹è¡¨è¾¾èŒä¸šè½¬å‹çš„å¿ƒç†å˜åŒ–ï¼Ÿ"],
                        "V4_è®¾è®¡ç ”ç©¶å‘˜": ["æœ‰å“ªäº›æˆåŠŸçš„å°ç©ºé—´å¤šåŠŸèƒ½è®¾è®¡æ¡ˆä¾‹ï¼Ÿ"],
                        "V5_åœºæ™¯ä¸“å®¶": ["å¦‚ä½•è®¾è®¡ä»é«˜æ•ˆå·¥ä½œåˆ°æ”¾æ¾ä¼‘æ¯çš„åœºæ™¯è½¬æ¢ï¼Ÿ"]
                    },
                    "design_challenge_spectrum": {
                        "tension_axis": "ä¸“ä¸šå½¢è±¡ â†” ç”Ÿæ´»æ¸©åº¦",
                        "risk_tolerance": "ä¸­ç­‰"
                    },
                    "permission_to_diverge": {
                        "encouraged_areas": ["æ”¶çº³ç³»ç»Ÿåˆ›æ–°", "å…‰å½±æ°›å›´è®¾è®¡"],
                        "constrained_areas": ["é£æ ¼ç»Ÿä¸€æ€§", "é¢„ç®—æ§åˆ¶"]
                    }
                }
            }, ensure_ascii=False)
        
        return response


def test_workflow_integration():
    """æµ‹è¯•å·¥ä½œæµé›†æˆ"""
    print("=" * 60)
    print("v7.17 é›†æˆæµ‹è¯•ï¼šéœ€æ±‚åˆ†æå¸ˆ StateGraph Agent")
    print("=" * 60)
    
    # é‡ç½® Mock LLM è°ƒç”¨è®¡æ•°
    MockLLM.call_count = 0
    
    # åˆ›å»ºå·¥ä½œæµ
    mock_llm = MockLLM()
    workflow = MainWorkflow(llm_model=mock_llm)
    
    print(f"âœ… å·¥ä½œæµåˆ›å»ºæˆåŠŸ")
    print(f"   - v7.17 æ¨¡å¼: {os.getenv('USE_V717_REQUIREMENTS_ANALYST')}")
    
    # æ¨¡æ‹Ÿåˆå§‹çŠ¶æ€
    initial_state = {
        "session_id": "test-integration-001",
        "user_input": "æˆ‘æ˜¯ä¸€ä½32å²çš„å‰é‡‘èå¾‹å¸ˆï¼Œæœ‰ä¸€å¥—75å¹³ç±³çš„å…¬å¯“ï¼Œé¢„ç®—60ä¸‡ï¼Œå¸Œæœ›ç°ä»£ç®€çº¦é£æ ¼çš„è®¾è®¡",
        "calibration_processed": False,
        "calibration_skipped": False
    }
    
    # ç›´æ¥è°ƒç”¨éœ€æ±‚åˆ†æå¸ˆèŠ‚ç‚¹ï¼ˆè·³è¿‡å®‰å…¨éªŒè¯èŠ‚ç‚¹ï¼‰
    print("\nğŸ“‹ æ‰§è¡Œéœ€æ±‚åˆ†æå¸ˆèŠ‚ç‚¹...")
    result = workflow._requirements_analyst_node(initial_state)
    
    print(f"\nâœ… èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ")
    print(f"   - LLM è°ƒç”¨æ¬¡æ•°: {MockLLM.call_count}")
    print(f"   - è¿”å›å­—æ®µæ•°: {len(result)}")
    
    # æ£€æŸ¥å…³é”®å­—æ®µ
    if "structured_requirements" in result:
        sr = result["structured_requirements"]
        print(f"\nğŸ“Š ç»“æ„åŒ–éœ€æ±‚:")
        print(f"   - project_task: {sr.get('project_task', 'N/A')[:50]}...")
        print(f"   - analysis_mode: {sr.get('analysis_mode', 'N/A')}")
        print(f"   - project_type: {sr.get('project_type', 'N/A')}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ StateGraph å…ƒæ•°æ®
        if "precheck_elapsed_ms" in sr:
            print(f"\nâ±ï¸ StateGraph è€—æ—¶ç»Ÿè®¡:")
            print(f"   - precheck: {sr.get('precheck_elapsed_ms', 0):.1f}ms")
            print(f"   - phase1: {sr.get('phase1_elapsed_ms', 0):.1f}ms")
            print(f"   - phase2: {sr.get('phase2_elapsed_ms', 0):.1f}ms")
        
        # æ£€æŸ¥äº¤ä»˜ç‰©
        deliverables = sr.get("primary_deliverables", [])
        if deliverables:
            print(f"\nğŸ¯ äº¤ä»˜ç‰©è¯†åˆ« ({len(deliverables)}ä¸ª):")
            for d in deliverables:
                print(f"   - {d.get('deliverable_id')}: {d.get('type')} ({d.get('priority')})")
        
        # æ£€æŸ¥ä¸“å®¶æ¥å£
        expert_handoff = sr.get("expert_handoff", {})
        if expert_handoff:
            critical_q = expert_handoff.get("critical_questions_for_experts", {})
            if critical_q:
                print(f"\nğŸ¤ ä¸“å®¶æ¥å£ ({len(critical_q)}ä¸ªä¸“å®¶):")
                for expert, questions in list(critical_q.items())[:3]:
                    print(f"   - {expert}: {questions[0][:40] if questions else 'N/A'}...")
    
    # æ£€æŸ¥é¡¹ç›®ç±»å‹
    if "project_type" in result:
        print(f"\nğŸ  é¡¹ç›®ç±»å‹: {result['project_type']}")
    
    # æ£€æŸ¥äº¤ä»˜ç‰©è´£ä»»è€…æ˜ å°„
    if "deliverable_owner_map" in result:
        print(f"\nğŸ“‹ äº¤ä»˜ç‰©è´£ä»»è€…æ˜ å°„: {result['deliverable_owner_map']}")
    
    print("\n" + "=" * 60)
    print("âœ… é›†æˆæµ‹è¯•é€šè¿‡")
    print("=" * 60)
    
    return True


if __name__ == "__main__":
    test_workflow_integration()
